[
    {
        "id": "9811757",
        "title": "1D-LRF Aided Visual-Inertial Odometry for High-Altitude MAV Flight",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of visual-inertial odometry (VIO) with a downward facing monocular camera when a micro aerial vehicle (MAV) flying at high altitude (over 100 meters). It is important to note that large scene depth causes visual motion constraints significantly less informative than that in near-sighted scenarios as considered in most existing VIO methods. To cope with this challenge, we develop an efficient MSCKF-based VIO algorithm aided by a single 1D laser range finder (LRF), termed LRF-VIO, which runs in real time on an embedded system. The key idea of the proposed LRF-VIO is to fully exploit the limited metric distance information provided by the 1D LRF to disambiguate the scale during visual feature tracking, thus improving the VIO performance at high altitude. Specifically, during the MSCKF visual measurement update, we deliberately constrain the depth of those SLAM features co-planar with the single LRF measuring point. Additionally, delayed initialization of features utilizes the LRF measurements whenever possible, and online extrinsic calibration between the LRF and monocular camera is performed to further improve estimation accuracy and robustness. The proposed LRF-VIO is extensively validated in both indoor and outdoor real-world experiments, outperforming the state-of-the-art methods.",
        "primary_area": "",
        "author": "Jiaxin Hu;Jun Hu;Yunjun Shen;Xiaoming Lang;Bo Zang;Guoquan Huang;Yinian Mao;Jiaxin Hu;Jun Hu;Yunjun Shen;Xiaoming Lang;Bo Zang;Guoquan Huang;Yinian Mao",
        "authorids": "/37089379711;/37089446908;/37089447432;/37089450635;/37089448053;/37077670600;/37089321433;/37089379711;/37089446908;/37089447432;/37089450635;/37089448053;/37077670600;/37089321433",
        "aff": "Meituan UAV, Beijing, China; Meituan UAV, Beijing, China; Meituan UAV, Beijing, China; Meituan UAV, Beijing, China; Meituan UAV, Beijing, China; Meituan UAV, Beijing, China; Meituan UAV, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811757/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2831101213650370408&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Meituan",
        "aff_unique_dep": "UAV",
        "aff_unique_url": "https://www.meituan.com",
        "aff_unique_abbr": "Meituan",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812203",
        "title": "360VO: Visual Odometry Using A Single 360 Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel direct visual odometry algorithm to take the advantage of a 360-degree camera for robust localization and mapping. Our system extends direct sparse odometry by using a spherical camera model to process equirectangular images without rectification to attain omnidirectional perception. After adapting mapping and optimization algorithms to the new model, camera parameters, including intrinsic and extrinsic parameters, and 3D mapping can be jointly optimized within the local sliding window. In addition, we evaluate the proposed algorithm using both real world and large-scale simulated scenes for qualitative and quantitative validations. The extensive experiments indicate that our system achieves start of the art results.",
        "primary_area": "",
        "author": "Huajian Huang;Sai-Kit Yeung;Huajian Huang;Sai-Kit Yeung",
        "authorids": "/37088691434;/37529101500;/37088691434;/37529101500",
        "aff": "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812203/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10549300167235875521&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812010",
        "title": "3D Perception based Imitation Learning under Limited Demonstration for Laparoscope Control in Robotic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic laparoscope motion control is fundamentally important for surgeons to efficiently perform operations. However, its traditional control methods based on tool tracking without considering information hidden in surgical scenes are not intelligent enough, while the latest supervised imitation learning (IL)-based methods require expensive sensor data and suffer from distribution mismatch issues caused by limited demonstrations. In this paper, we propose a novel Imitation Learning framework for Laparoscope Control (ILLC) with reinforcement learning (RL), which can efficiently learn the control policy from limited surgical video clips. Specially, we first extract surgical laparoscope trajectories from unlabeled videos as the demonstrations and reconstruct the corresponding surgical scenes. To fully learn from limited motion trajectory demonstrations, we propose Shape Preserving Trajectory Augmentation (SPTA) to augment these data, and build a simulation environment that supports parallel RGB-D rendering to reinforce the RL policy for interacting with the environment efficiently. With adversarial training for IL, we obtain the laparoscope control policy based on the generated rollouts and surgical demonstrations. Extensive experiments are conducted in unseen reconstructed surgical scenes, and our method outperforms the previous IL methods, which proves the feasibility of our unified learning-based framework for laparoscope control.",
        "primary_area": "",
        "author": "Bin Li;Ruofeng Wei;Jiaqi Xu;Bo Lu;Chi Hang Yee;Chi Fai Ng;Pheng-Ann Heng;Qi Dou;Yun-Hui Liu;Bin Li;Ruofeng Wei;Jiaqi Xu;Bo Lu;Chi Hang Yee;Chi Fai Ng;Pheng-Ann Heng;Qi Dou;Yun-Hui Liu",
        "authorids": "/37089266122;/37088701950;/37088541643;/37085991083;/37089446726;/37089000397;/37283077400;/37085465414;/37279412600;/37089266122;/37088701950;/37088541643;/37085991083;/37089446726;/37089000397;/37283077400;/37085465414;/37279412600",
        "aff": "The Department of Mechanical and Automation Engineering, T stone Robotics Institute, The Chinese University of Hong Kong; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; The Department of Mechanical and Automation Engineering, T stone Robotics Institute, The Chinese University of Hong Kong; Department of Surgery, SH Ho Urology Centre, The Chinese University of Hong Kong; Department of Surgery, SH Ho Urology Centre, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; The Department of Mechanical and Automation Engineering, T stone Robotics Institute, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812010/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2188121090906204081&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong;City University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;Department of Biomedical Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.cityu.edu.hk",
        "aff_unique_abbr": "CUHK;CityU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812123",
        "title": "3D Printing of Concrete with a Continuum Robot Hose Using Variable Curvature Kinematics",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel application of continuum robots acting as concrete hoses to support 3D printing of cementitious materials. An industrial concrete hose was fitted with a cable harness and remotely actuated via tendons. The resulting continuum hose robot exhibited non constant curvature. In order to account for this, a new geometric approach to modeling variable curvature inverse kinematics using Euler curves is introduced herein. The new closed form model does not impose any additional computational cost compared to the constant curvature model and results in a marked improvement in the observed performance. Experiments involving 3D printing with cementitious mortar using a continuum hose robot were also conducted.",
        "primary_area": "",
        "author": "Manu Srivastava;Jake Ammons;Abdul B. Peerzada;Venkat N. Krovi;Prasad Rangaraju;Ian D. Walker;Manu Srivastava;Jake Ammons;Abdul B. Peerzada;Venkat N. Krovi;Prasad Rangaraju;Ian D. Walker",
        "authorids": "/37089448270;/37089449107;/37089447247;/37281399700;/37089447018;/37276152000;/37089448270;/37089449107;/37089447247;/37281399700;/37089447018;/37276152000",
        "aff": "Dept. Electrical and Computer Engineering, Clemson University, Clemson, USA; Dept. Electrical and Computer Engineering, Clemson University, Clemson, USA; Glenn Dept. Civil Engineering, Clemson University, Clemson, USA; Dept. Automotive Engineering, Clemson University, Clemson, USA; Glenn Dept. Civil Engineering, Clemson University, Clemson, USA; Dept. Electrical and Computer Engineering, Clemson University, Clemson, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812123/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1272137090246667947&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Clemson University",
        "aff_unique_dep": "Dept. Electrical and Computer Engineering",
        "aff_unique_url": "https://www.clemson.edu",
        "aff_unique_abbr": "Clemson",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Clemson",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811564",
        "title": "A Benchmark Comparison of Learned Control Policies for Agile Quadrotor Flight",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadrotors are highly nonlinear dynamical systems that require carefully tuned controllers to be pushed to their physical limits. Recently, learning-based control policies have been proposed for quadrotors, as they would potentially allow learning direct mappings from high-dimensional raw sensory observations to actions. Due to sample inefficiency, training such learned controllers on the real platform is impractical or even impossible. Training in simulation is attractive but requires to transfer policies between domains, which demands trained policies to be robust to such domain gap. In this work, we make two contributions: (i) we perform the first benchmark comparison of existing learned control policies for agile quadrotor flight and show that training a control policy that commands body-rates and thrust results in more robust sim-to-real transfer compared to a policy that directly specifies individual rotor thrusts, (ii) we demonstrate for the first time that such a control policy trained via deep reinforcement learning can control a quadrotor in real-world experiments at speeds over 45 km/h.",
        "primary_area": "",
        "author": "Elia Kaufmann;Leonard Bauersfeld;Davide Scaramuzza;Elia Kaufmann;Leonard Bauersfeld;Davide Scaramuzza",
        "authorids": "/37086293209;/37086827655;/37397688400;/37086293209;/37086827655;/37397688400",
        "aff": "Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811564/",
        "gs_citation": 90,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8709765187996660510&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Zurich",
        "aff_unique_dep": "Department of Neuroinformatics",
        "aff_unique_url": "https://www.unizh.ch",
        "aff_unique_abbr": "UZH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9812280",
        "title": "A Collision-Free MPC for Whole-Body Dynamic Locomotion and Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a real-time whole-body planner for collision-free legged mobile manipulation. We enforce both self-collision and environment-collision avoidance as soft constraints within a Model Predictive Control (MPC) scheme that solves a multi-contact optimal control problem. By penalizing the signed distances among a set of representative primitive collision bodies, the robot is able to safely execute a variety of dynamic maneuvers while preventing any self-collisions. Moreover, collision-free navigation and manipulation in both static and dynamic environments are made viable through efficient queries of distances and their gradients via a euclidean signed distance field. We demonstrate through a comparative study that our approach only slightly increases the computational complexity of the MPC planning. Finally, we validate the effectiveness of our framework through a set of hardware experiments involving dynamic mobile manipulation tasks with potential collisions, such as locomotion balancing with the swinging arm, weight throwing, and autonomous door opening.",
        "primary_area": "",
        "author": "Jia-Ruei Chiu;Jean-Pierre Sleiman;Mayank Mittal;Farbod Farshidian;Marco Hutter;Jia-Ruei Chiu;Jean-Pierre Sleiman;Mayank Mittal;Farbod Farshidian;Marco Hutter",
        "authorids": "/37088690419;/37087322472;/37089654860;/37085428006;/37545251000;/37088690419;/37087322472;/37089654860;/37085428006;/37545251000",
        "aff": "Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; NVIDIA; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812280/",
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14992162141518481133&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "ETH Zurich;NVIDIA",
        "aff_unique_dep": "Robotic Systems Lab;NVIDIA Corporation",
        "aff_unique_url": "https://www.ethz.ch;https://www.nvidia.com",
        "aff_unique_abbr": "ETHZ;NVIDIA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zurich;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "9811549",
        "title": "A Colored Petri Net Model for Control Problem of Border Crossing Under Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider the European Rail Traffic Management System (ERTMS) as a System-of-Systems (SoS) and propose modeling it using colored Petri nets. We formally control the European rail transport, while guaranteeing a set of cross-border security properties. This becomes an essential and challenging task since each of them have mainly developed safety and trackside rules regardless of its neighbors. The feature of this work lies in the approach that considers ERTMS Level 2 as an SoS and addresses the cross-border railway as a mode management problem. In addition, the aspects of mode activation/deactivation, starting state and handling of resource states common to multiple operating modes are taken into account in the proposed model.",
        "primary_area": "",
        "author": "Hela Kadri;Simon Collart-Dutilleul;Philippe Bon;Rochdi Merzouki;Hela Kadri;Simon Collart-Dutilleul;Philippe Bon;Rochdi Merzouki",
        "authorids": "/37085424888;/38270622000;/37300231500;/37299569900;/37085424888;/38270622000;/37300231500;/37299569900",
        "aff": "Laboratoire Cristal, Universit\u00e9 de Lille Campus Cit\u00e9 scientifique, Sciences et technologies Batiment Esprit, Villeneuve-d'Ascq, France; D\u00e9partement COSYS, Universit\u00e9 de Gustave Eiffel, France; D\u00e9partement COSYS, Universit\u00e9 de Gustave Eiffel, France; Laboratoire Cristal, Universit\u00e9 de Lille Campus Cit\u00e9 scientifique, Sciences et technologies Batiment Esprit, Villeneuve-d'Ascq, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811549/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13862147415167389213&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Universit\u00e9 de Lille;Universit\u00e9 de Gustave Eiffel",
        "aff_unique_dep": "Laboratoire Cristal;D\u00e9partement COSYS",
        "aff_unique_url": "https://www.univ-lille.fr;https://www.univ-gustave-eiffel.fr",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Campus Cit\u00e9 scientifique;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9811906",
        "title": "A Continuous Learning Approach for Probabilistic Human Motion Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Human Motion Prediction (HMP) plays a crucial role in safe Human-Robot-Interaction (HRI). Currently, the majority of HMP algorithms are trained by massive pre-collected data. As the training data only contains a few pre-defined motion patterns, these methods cannot handle the unfamiliar motion patterns. Moreover, the pre-collected data are usually non-interactive, which does not consider the real-time responses of collaborators. As a result, these methods usually perform unsatisfactorily in real HRI scenarios. To solve this problem, in this paper, we propose a novel Continual Learning (CL) approach for probabilistic HMP which makes the robot continually learns during its interaction with collaborators. The proposed approach consists of two steps. First, we leverage a Bayesian Neural Network to model diverse uncertainties of observed human motions for collecting online interactive data safely. Then we take Experience Replay and Knowledge Distillation to elevate the model with new experiences while maintaining the knowledge learned before. We first evaluate our approach on a large-scale benchmark dataset Human3.6m. The experimental results show that our approach achieves a lower prediction error compared with the baselines methods. Moreover, our approach could continually learn new motion patterns without forgetting the learned knowledge. We further conduct real-scene experiments using Kinect DK. The results show that our approach can learn the human kinematic model from scratch, which effectively secures the interaction.",
        "primary_area": "",
        "author": "Jie Xu;Shihong Wang;Xingyu Chen;Jiahao Zhang;Xuguang Lan;Nanning Zheng;Jie Xu;Shihong Wang;Xingyu Chen;Jiahao Zhang;Xuguang Lan;Nanning Zheng",
        "authorids": "/37087083468;/37089450186;/37085568094;/37089449469;/37270865300;/37271536700;/37087083468;/37089450186;/37085568094;/37089449469;/37270865300;/37271536700",
        "aff": "Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811906/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15501305057794071087&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Xi'an Jiao Tong University",
        "aff_unique_dep": "Institute of Artificial Intelligence and Robotics",
        "aff_unique_url": "http://www.xjtu.edu.cn",
        "aff_unique_abbr": "XJTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811987",
        "title": "A Continuum Robot Surface of Woven, McKibben Muscles Embedded in and Giving Shape to Rooms",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots are typically designed as occupants of rooms, adapting to, and navigating within them. \u201cRobot surfaces,\u201d an emerging robot typology, are not occupants of but integral with rooms, physically shaping rooms to support human activity. We report on an advancement of robot surfaces formed by weaving McKibben Pneumatic Air Muscles that, when actuated, morph a 2D planar surface to generate 3D geometries including a \u201cspherical cap.\u201d Following our foundational study at different scales with different materials, we developed a full-scale prototype that offers an intimate and private space for people meeting in open plan environments. We report on our research, focusing on a design case, and validate the full-scale prototype as compared to our Non-Uniform Rational B-Splines (NURBS) model for three useful configurations. Our quantitative and qualitative results suggest that our robot surface can support human activity as envisioned. This research contributes foundational understanding of an emerging category of robotics from which our team and peers can build.",
        "primary_area": "",
        "author": "Grace Tan;Harrison Hidalgo;Hsin-Liu Kao;Ian. D. Walker;Keith E. Green;Grace Tan;Harrison Hidalgo;Hsin-Liu Kao;Ian. D. Walker;Keith E. Green",
        "authorids": "/37089447991;/37089446892;/37089446689;/37276152000;/37086537054;/37089447991;/37089446892;/37089446689;/37276152000;/37086537054",
        "aff": "Department of Electrical & Computer Engineering, Cornell University, Ithaca, NY, USA; Sibley School of Mechanical & Aerospace Engineering, Cornell University, Ithaca, NY, USA; Department of Human Centered Design, Cornell University, Ithaca, NY, USA; Department of Electrical & Computer Engineering, Clemson University, Clemson, SC, USA; Department of Human Centered Design, Sibley School of Mechanical & Aerospace Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811987/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5346717933253824064&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Cornell University;Clemson University",
        "aff_unique_dep": "Department of Electrical & Computer Engineering;Department of Electrical & Computer Engineering",
        "aff_unique_url": "https://www.cornell.edu;https://www.clemson.edu",
        "aff_unique_abbr": "Cornell;Clemson",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Ithaca;Clemson",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812432",
        "title": "A Data-Driven Multiple Model Framework for Intention Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a data-driven multiple model framework for estimating the intention of a target from observations. Multiple model (MM) state estimation methods have been extensively used for intention estimation by mapping one intention to one dynamic model assuming one-to-one relations. However, intentions are subjective to humans and it is difficult to establish the one-to-one relations explicitly. The proposed framework infers the multiple-to-multiple relations between intentions and models directly from observations that are labeled with intentions. For intention estimation, both the relations and model probabilities of an Interacting Multiple Model (IMM) state estimation approach are integrated into a recursive Bayesian framework. Taking advantage of the inferred multiple-to-multiple relations, the framework incorpo-rates more accurate relations and avoids following the strict one-to-one relations. Numerical and real experiments were performed to investigate the framework through the intention estimation of a maneuvered quadrotor. Results show higher estimation accuracy and superior flexibility in designing mod-els over the conventional approach that assumes one-to-one relations.",
        "primary_area": "",
        "author": "Yongming Qin;Makoto Kumon;Tomonari Furukawa;Yongming Qin;Makoto Kumon;Tomonari Furukawa",
        "authorids": "/37086637925;/37296098600;/37280186200;/37086637925;/37296098600;/37280186200",
        "aff": "VICTOR Laboratory, University of Virginia, Charlottesville, VA, USA; Faculty of Advanced Science and Technology and International Research Organization of Advanced Science and Technology, Kumamoto University, Kumamoto, Japan; VICTOR Laboratory, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812432/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5151620564939161850&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Virginia;Kumamoto University",
        "aff_unique_dep": "VICTOR Laboratory;Faculty of Advanced Science and Technology",
        "aff_unique_url": "https://www.virginia.edu;https://www.kumamoto-u.ac.jp",
        "aff_unique_abbr": "UVA;KU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Charlottesville;Kumamoto",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9811567",
        "title": "A Deep Concept Graph Network for Interaction-Aware Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Temporal patterns (how vehicles behave in our observed past) underline our reasoning of how people drive on the road, and can explain why we make certain predictions about interactions among road agents. In this paper we propose the ConceptNet trajectory predictor - a novel prediction framework that is able to incorporate agent interactions as explicit edges in a temporal knowledge graph. We demonstrate the sample efficiency and the overall accuracy of the proposed approach, and show that using the graphical structure to explicitly model interactions enables better detection of agent interactions and improved trajectory predictions on a large real-world driving dataset.",
        "primary_area": "",
        "author": "Yutong Ban;Xiao Li;Guy Rosman;Igor Gilitschenski;Ozanan Meireles;Sertac Karaman;Daniela Rus;Yutong Ban;Xiao Li;Guy Rosman;Igor Gilitschenski;Ozanan Meireles;Sertac Karaman;Daniela Rus",
        "authorids": "/37086284172;/37088812042;/37393688300;/38469566100;/37086164472;/37304113000;/37279652300;/37086284172;/37088812042;/37393688300;/38469566100;/37086164472;/37304113000;/37279652300",
        "aff": "Massachusetts General Hospital; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology; Toyota Research Institute; Department of Computer Science, University of Toronto; Massachusetts General Hospital; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811567/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16816457763343236536&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;0;1;1",
        "aff_unique_norm": "Massachusetts General Hospital;Massachusetts Institute of Technology;Toyota Research Institute;University of Toronto",
        "aff_unique_dep": ";Computer Science and Artificial Intelligence Lab;;Department of Computer Science",
        "aff_unique_url": "https://www.massgeneral.org;https://www.csail.mit.edu;https://www.tri.global;https://www.utoronto.ca",
        "aff_unique_abbr": "MGH;MIT;TRI;U of T",
        "aff_campus_unique_index": "1;2;1;1",
        "aff_campus_unique": ";Cambridge;Toronto",
        "aff_country_unique_index": "0;0;0;1;0;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9811965",
        "title": "A Deep Reinforcement Learning Environment for Particle Robot Navigation and Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Particle robots are novel biologically-inspired robotic systems where locomotion can be achieved collectively and robustly, but not independently. While its control is currently limited to a hand-crafted policy for basic locomotion tasks, such a multi-robot system could be potentially controlled via Deep Reinforcement Learning (DRL) for different tasks more efficiently. However, the particle robot system presents a new set of challenges for DRL differing from existing swarm robotics systems: the low degrees of freedom of each robot and the increased necessity of coordination between robots. We present a 2D particle robot simulator using the OpenAI Gym interface and Pymunk as the physics engine, and introduce new tasks and challenges to research the underexplored applications of DRL in the particle robot system. Moreover, we use Stable-baselines3 to provide a set of benchmarks for the tasks. Current baseline DRL algorithms show signs of achieving the tasks but are yet unable to reach the performance of the hand-crafted policy. Further development of DRL algorithms is necessary in order to accomplish the proposed tasks.",
        "primary_area": "",
        "author": "Jeremy Shen;Erdong Xiao;Yuchen Liu;Chen Feng;Jeremy Shen;Erdong Xiao;Yuchen Liu;Chen Feng",
        "authorids": "/37089447736;/37088337256;/149273849162738;/37086391326;/37089447736;/37088337256;/149273849162738;/37086391326",
        "aff": "Stuyvesant High School, New York, NY, USA; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811965/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12541093955233075832&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Stuyvesant High School;New York University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stuy.edu;https://www.nyu.edu",
        "aff_unique_abbr": ";NYU",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Brooklyn",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812067",
        "title": "A Detumbling Strategy for an Orbital Manipulator in the Post-Grasp Phase",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a detumbling strategy that stabilizes the motion of a tumbling client satellite using an orbital servicing manipulator, which is the goal of the post-grasp phase. One of the critical aspects in this phase is ensuring that excessive contact forces are not generated at the grasp interface. In addition, space mission requirements might demand a nominal manipulator configuration that is suitable for further manipulation/servicing activities. The proposed strategy allows the detumbling of the client motion while ensuring that the contact forces developed at the grasp interface do not violate a safety threshold. Further, it allows the reconfiguration of the manipulator arm by exploiting the full actuation capability of the manipulator-equipped servicing spacecraft. The controller guarantees joint task convergence in the nullspace of the manipulator's end-effector, and is also valid for kinematically singular configurations of the manipulator. It is further augmented using a quadratic programming based approach to optimally constrain the contact forces. Finally, simulation results for a post-grasp detumbling scenario are shown to validate the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Ria Vijayan;Marco De Stefano;Christian Ott;Ria Vijayan;Marco De Stefano;Christian Ott",
        "authorids": "/37088471411;/37085376264;/37282440400;/37088471411;/37085376264;/37282440400",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812067/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1511311082815438764&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Wessling",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812058",
        "title": "A Divide-and-Merge Point Cloud Clustering Algorithm for LiDAR Panoptic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Clustering objects from the LiDAR point cloud is an important research problem with many applications such as autonomous driving. To meet the real-time requirement, existing research proposed to apply the connected-component-labeling (CCL) technique on LiDAR spherical range image with a heuristic condition to check if two neighbor points are connected. However, LiDAR range image is different from a binary image which has a deterministic condition to tell if two pixels belong to the same component. The heuristic condition used on the LiDAR range image only works empirically, which suggests the LiDAR clustering algorithm should be robust to potential failures of the empirical heuristic condition. To overcome this challenge, this paper proposes a divide-and-merge LiDAR clustering algorithm. This algorithm firstly conducts clustering in each evenly divided local region, then merges the local clustered small components by voting on edge point pairs. Assuming there are NN LiDAR points of objects in total with mm divided local regions, the time complexity of the proposed algorithm is O(N)+O(m^{2})O(N)+O(m^{2}). A smaller mm means the voting will involve more neighbor points, but the time complexity will become larger. So the mm controls the trade-off between the time complexity and the clustering accuracy. A proper mm helps the proposed algorithm work in real-time as well as maintain good performance. We evaluate the divide-and-merge clustering algorithm on the SemanticKITTI panoptic segmentation benchmark by cascading it with a state-of-the-art semantic segmentation model. The final performance evaluated through the leaderboard achieves the best among all published methods. The proposed algorithm is implemented with C++ and wrapped as a python function. It can be easily used with the modern deep learning framework in python. We released the code under the following link 11https://github.com/placeforyiming/Divide-and-Merge-LiDAR-Panoptic-Cluster. Show More",
        "primary_area": "",
        "author": "Yiming Zhao;Xiao Zhang;Xinming Huang;Yiming Zhao;Xiao Zhang;Xinming Huang",
        "authorids": "/37086463567;/37089158251;/37281303400;/37086463567;/37089158251;/37281303400",
        "aff": "Department of Electrical and Computer Engineering, Worcester Polytechnic Institute, Massachusetts, USA; Department of Electrical and Computer Engineering, Worcester Polytechnic Institute, Massachusetts, USA; Department of Electrical and Computer Engineering, Worcester Polytechnic Institute, Massachusetts, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812058/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10232122924490108593&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811769",
        "title": "A Double Branch Next-Best-View Network and Novel Robot System for Active Object Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "Next best view (NBV) is a technology that finds the best view sequence for sensor to perform scanning based on partial information, which is the core part for robot active reconstruction. Traditional works are mostly based on the evaluation of candidate views through time-consuming volu-metric transformation and ray casting, which heavily limits the applications of NBV. Recent deep learning based NBV methods aim to approximately learn the evaluation function by large-scale training, and improve both the effectiveness and efficiency of NBV. However, these methods force the network to regress the exact groundtruth value of each candidate view, which is much harder than simply ranking all the candidate views. Besides, most previous NBV works assume perfect sensing and perform in simulation environments, lacking real application abilities. In this paper, we propose a novel double branch NBV network, DB-NBV, to utilize the ranking process together with the evaluation process. We further design a real NBV robot and a pipeline to conduct real active reconstruction. Experiments on both simulation and real robot show that our method achieves the best performance and can be applied to real application with high accuracy and speed.",
        "primary_area": "",
        "author": "Yiheng Han;Irvin Haozhe Zhan;Wang Zhao;Yong-Jin Liu;Yiheng Han;Irvin Haozhe Zhan;Wang Zhao;Yong-Jin Liu",
        "authorids": "/37086529078;/37089417071;/37087232745;/37279426700;/37086529078;/37089417071;/37087232745;/37279426700",
        "aff": "Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China; Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China; Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China; Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811769/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13334518546744833050&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812075",
        "title": "A Dual-Stream Architecture for Real-Time Morphological Analysis of Aneurysm in Robot-Assisted Minimally Invasive Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time and precise morphological analysis of intraoperative AAA is a significant pre-imperative for robot-assisted minimally invasive surgery (RMIS). However, this task is frequently accompanied by the difficulties of ambiguous boundaries and obscured surfaces of aneurysms. To remedy these problems, we propose a Light-Weight Dual-Stream Boundary-Aware Network (DSB-Net) and a novel diagnosis algorithm for real-time morphological analysis of AAA. In the network, the features at the boundaries are preserved by incorporating a boundary localization stream, while the interior segmentation accuracy is guaranteed with a mask prediction stream. Moreover, the diagnosis algorithm is developed to measure the exact size of AAA. Quantitative and qualitative assessments on two different types of datasets illustrate that (1) The presented DSB-Net remarkably outperforms the other previously proposed medical networks with the inference rate of 10.8 FPS, which meets the real-time clinical necessities. (2) The developed algorithm provides accurate size measurements for AAA, which indicates the proposed approach can be integrated into the robotic navigation framework for RMIS.",
        "primary_area": "",
        "author": "Yan-Jie Zhou;Shi-Qi Liu;Xiao-Liang Xie;Xiao-Hu Zhou;Zeng-Guang Hou;Rui-Qi Li;Zhen-Liang Ni;Chen-Chen Fan;Yan-Jie Zhou;Shi-Qi Liu;Xiao-Liang Xie;Xiao-Hu Zhou;Zeng-Guang Hou;Rui-Qi Li;Zhen-Liang Ni;Chen-Chen Fan",
        "authorids": "/37087016101;/37086480801;/37533295000;/37085823497;/37279945000;/37087030761;/37087030579;/37089268878;/37087016101;/37086480801;/37533295000;/37085823497;/37279945000;/37087030761;/37087030579;/37089268878",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Joint Laboratory of Intelligence Science and Technology, Institute of Systems Engineering, Macau University of Science and Technology, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812075/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15292710050150082939&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;1;2;0;0;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences;Macau University of Science and Technology",
        "aff_unique_dep": "School of Artificial Intelligence;Institute of Automation;Institute of Systems Engineering",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.ia.cas.cn;https://www.must.edu.mo",
        "aff_unique_abbr": "UCAS;CAS;MUST",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812278",
        "title": "A Force-Sensitive Grasping Controller Using Tactile Gripper Fingers and an Industrial Position-Controlled Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping fragile objects in the presence of un-certainty is a crucial task for robots, that becomes inherently challenging if the manipulator in use is an industrial robot platform that does not provide compliant control inputs. This requires not only to estimate the alignment error during object contact but also to alter the robot configuration to decrease this error while taking interaction constraints into account. Thus, this work proposes a novel grasping controller tailored to industrial robots by exploiting tactile sensor feedback on the robot gripper fingers in order to estimate and compensate for the alignment error when touching the object. Specifically, we propose two grasping strategies, that allow to either directly compensate for interaction wrenches or to solve a model predictive control-problem to minimize the estimated alignment error. Eventually, we outline how these modalities can be realized as a hybrid Cartesian force-velocity-controller on an industrial manipulator. We evaluate the proposed grasping strategies on a WSG 50 parallel two-finger gripper, that is equipped with a digital sensor array (DSA) per finger, for which we also provide an extended ROS-driver that allows to obtain DSA-data at a communication rate above 5 Hz. Given the collected empirical evidence, the presented grasping controller increases the skill-set of industrial robots in the presence of uncertainty and thus allows to apply stiff robots to handle fragile objects autonomously.",
        "primary_area": "",
        "author": "Volker Gabler;Gerold Huber;Dirk Wollherr;Volker Gabler;Gerold Huber;Dirk Wollherr",
        "authorids": "/37085642348;/37085637435;/37295545400;/37085642348;/37085637435;/37295545400",
        "aff": "Chair of Automatic Control Engineering, Technische Universit\u00e4t M\u00fcnchen, Munchen, Germany; Chair of Automatic Control Engineering, Technische Universit\u00e4t M\u00fcnchen, Munchen, Germany; Chair of Automatic Control Engineering, Technische Universit\u00e4t M\u00fcnchen, Munchen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812278/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17791752181564818250&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": "Chair of Automatic Control Engineering",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "M\u00fcnchen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811744",
        "title": "A Framework for Real-World Multi-Robot Systems Running Decentralized GNN-Based Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "Graph Neural Networks (GNNs) are a paradigm-shifting neural architecture to facilitate the learning of complex multi-agent behaviors. Recent work has demonstrated remarkable performance in tasks such as flocking, multi-agent path planning and cooperative coverage. However, the policies derived through GNN-based learning schemes have not yet been deployed to the real-world on physical multi-robot systems. In this work, we present the design of a system that allows for fully decentralized execution of GNN-based policies. We create a framework based on ROS2 and elaborate its details in this paper. We demonstrate our framework on a case-study that requires tight coordination between robots, and present first-of-a-kind results that show successful real-world deployment of GNN-based policies on a decentralized multi-robot system relying on Adhoc communication. A video demonstration of this case-study can be found online11youtube.com/watch?v=COh-WLn4i04.",
        "primary_area": "",
        "author": "Jan Blumenkamp;Steven Morad;Jennifer Gielis;Qingbiao Li;Amanda Prorok;Jan Blumenkamp;Steven Morad;Jennifer Gielis;Qingbiao Li;Amanda Prorok",
        "authorids": "/37089450704;/37086388707;/37088697757;/37088524830;/37542741000;/37089450704;/37086388707;/37088697757;/37088524830;/37542741000",
        "aff": "Department of Computer Science and Technol-ogy, University of Cambridge; Department of Computer Science and Technol-ogy, University of Cambridge; Department of Computer Science and Technol-ogy, University of Cambridge; Department of Computer Science and Technol-ogy, University of Cambridge; Department of Computer Science and Technol-ogy, University of Cambridge",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811744/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5292449655696893099&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812110",
        "title": "A Hierarchical Control Framework for Drift Maneuvering of Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Maneuvering an autonomous vehicle under drift condition is critical to the safety of autonomous vehicles when there is a sudden loss of traction due to external conditions such as rain or snow, which is a challenging control problem due to the presence of significant sideslip and nearly full saturation of the tires. In this paper, we focus on the control of drift maneuvers of autonomous vehicle to track circular paths with either fixed or moving centers, subject to change in the tire-ground interaction. In order to achieve the above tasks, we propose a hierarchical control architecture which decouples the curvature and center control of the trajectory. In particular, an outer control loop is proposed to stabilize the center by tuning the target curvature, and an inner control loop tracks the curvature using a feedforward/feedback controller enhanced by an \\mathcal{L}_{1}\\mathcal{L}_{1} adaptive component. The hierarchical architecture is flexible because the inner loop is task-agnostic and adaptive to changes in tire-ground interaction, which allows the outer loop to be designed independent of low-level dynamics, opening up the possibility of incorporating sophisticated planning algorithms. We implement our control strategy on a simulation platform as well as on a 1/10 scale RC car, and both the simulation and experiment results illustrate the effectiveness of our strategy in achieving the above described set of drift maneuvering tasks.",
        "primary_area": "",
        "author": "Bo Yang;Yiwen Lu;Xu Yang;Yilin Mo;Bo Yang;Yiwen Lu;Xu Yang;Yilin Mo",
        "authorids": "/37089329910;/37089332825;/37088987495;/37605284400;/37089329910;/37089332825;/37088987495;/37605284400",
        "aff": "Department of Automation, BNRist, Tsinghua University, Beijing, China; Department of Automation, BNRist, Tsinghua University, Beijing, China; Department of Automation, BNRist, Tsinghua University, Beijing, China; Department of Automation, BNRist, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812110/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16828556208277269153&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811936",
        "title": "A Hierarchical Deliberative-Reactive System Architecture for Task and Motion Planning in Partially Known Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We describe a task and motion planning architecture for highly dynamic systems that combines a domain-independent sampling-based deliberative planning algorithm with a global reactive planner. We leverage the recent development of a reactive, vector field planner that provides guarantees of reachability to large regions of the environment even in the face of unknown or unforeseen obstacles. The reachability guarantees can be formalized using contracts that allow a deliberative planner to reason purely in terms of those contracts and synthesize a plan by choosing a sequence of reactive behaviors and their target configurations, without evaluating specific motion plans between targets. This reduces both the search depth at which plans will be found, and the number of samples required to ensure a plan exists, while crucially preserving correctness guarantees. The result is reduced computational cost of synthesizing plans, and increased robustness of generated plans to actuator noise, model misspecification, or unknown obstacles. Simulation studies show that our hierarchical planning and execution architecture can solve complex navigation and rearrangement tasks, even when faced with narrow passageways or incomplete world information.",
        "primary_area": "",
        "author": "Vasileios Vasilopoulos;Sebastian Castro;William Vega-Brown;Daniel E. Koditschck;Nicholas Roy;Vasileios Vasilopoulos;Sebastian Castro;William Vega-Brown;Daniel E. Koditschck;Nicholas Roy",
        "authorids": "/37085350448;/38352614400;/37077048700;/37089447980;/37274058700;/37085350448;/38352614400;/37077048700;/37089447980;/37274058700",
        "aff": "Computer Science and Artificial Intelligence Laboratory (CSAIL), MIT, Cambridge, MA; Computer Science and Artificial Intelligence Laboratory (CSAIL), MIT, Cambridge, MA; Tagup, Inc.; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA; Computer Science and Artificial Intelligence Laboratory (CSAIL), MIT, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811936/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7794277870767938039&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Tagup, Inc.;University of Pennsylvania",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;;GRASP Laboratory",
        "aff_unique_url": "https://www.mit.edu;https://www.tagupinc.com;https://www.upenn.edu",
        "aff_unique_abbr": "MIT;;UPenn",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Cambridge;;Philadelphia",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811735",
        "title": "A Hybrid Approach for Learning to Shift and Grasp with Elaborate Motion Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Many possible fields of application of robots in real world settings hinge on the ability of robots to grasp objects. As a result, robot grasping has been an active field of research for many years. With our publication we contribute to the endeavor of enabling robots to grasp, with a particular focus on bin picking applications. Bin picking is especially challenging due to the often cluttered and unstructured arrangement of objects and the often limited graspability of objects by simple top down grasps. To tackle these challenges, we propose a fully self-supervised reinforcement learning approach based on a hybrid discrete-continuous adaptation of soft actor-critic (SAC). We employ parametrized motion primitives for pushing and grasping movements in order to enable a flexibly adaptable behavior to the difficult setups we consider. Furthermore, we use data augmentation to increase sample efficiency. We demonstrate our proposed method on challenging picking scenarios in which planar grasp learning or action discretization methods would face a lot of difficulties.",
        "primary_area": "",
        "author": "Zohar Feldman;Hanna Ziesche;Ngo Anh Vien;Dotan Di Castro;Zohar Feldman;Hanna Ziesche;Ngo Anh Vien;Dotan Di Castro",
        "authorids": "/37089446842;/37089196852;/37838848600;/37088874538;/37089446842;/37089196852;/37838848600;/37088874538",
        "aff": "Bosch Center for Artificial Intelligence (BCAI); Bosch Center for Artificial Intelligence (BCAI); Bosch Center for Artificial Intelligence (BCAI); Bosch Center for Artificial Intelligence (BCAI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811735/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6594845495171656490&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence",
        "aff_unique_dep": "Artificial Intelligence",
        "aff_unique_url": "https://www.bosch-ai.com",
        "aff_unique_abbr": "BCAI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812426",
        "title": "A Hybrid, Soft Robotic Exoskeleton Glove with Inflatable, Telescopic Structures and a Shared Control Operation Scheme",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping and manipulation are two of the most important hand functions that allow people to efficiently execute activities of daily living. Over the last years, many robotic devices have been proposed to assist people who suffer from neurological conditions by enhancing their grasping capabilities. In this work, we focus on the development of a robotic exoskeleton glove that can increase the grasp stability and the force exertion capabilities of the user by employing soft, telescopic, inflatable structures on the palmar side of the hand. Also, the proposed design employs a camera and an object identification system to facilitate the development of a shared control scheme that simplifies the operation of the device. The experiments demonstrate that the soft robotic exoskeleton glove can successfully execute semi-autonomous grasps and that the soft telescopic structures can increase the total exerted grasping forces by more than 40% when inflated.",
        "primary_area": "",
        "author": "Lucas Gerez;Gal Gorjup;Yuran Zhou;Minas Liarokapis;Lucas Gerez;Gal Gorjup;Yuran Zhou;Minas Liarokapis",
        "authorids": "/37086448935;/37087237844;/37089450694;/38558084100;/37086448935;/37087237844;/37089450694;/38558084100",
        "aff": "School of Engineering and Applied Sciences, Harvard University, USA; Department of Mechanical Engineering and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812426/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4449538868274199483&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Harvard University;University of Auckland",
        "aff_unique_dep": "School of Engineering and Applied Sciences;Department of Mechanical Engineering and Mechatronics Engineering",
        "aff_unique_url": "https://www.harvard.edu;https://www.auckland.ac.nz",
        "aff_unique_abbr": "Harvard;UoA",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "United States;New Zealand"
    },
    {
        "id": "9811976",
        "title": "A Lightweight, High-Extension, Planar 3-Degree-of-Freedom Manipulator Using Pinched Bistable Tapes",
        "track": "main",
        "status": "Poster",
        "abstract": "To facilitate sensing and physical interaction in remote and/or constrained environments, high-extension, lightweight robot manipulators are easier to transport and reach substantially further than traditional serial chain manipulators. We propose a novel planar 3-degree-of-freedom manipulator that achieves low weight and high extension through the use of a pair of spooling bistable tapes, commonly used in self-retracting tape measures, which are pinched together to form a reconfigurable revolute joint. The pinching action flattens the tapes to produce a localized bending region, resulting in a revolute joint that can change its orientation by cable tension and its location on the tapes though friction-driven movement of the pinching mechanism. We present the design, implementation, kinematic modeling, stiffness behavior of the revolute joint, and quasi-static performance of this manipulator. In particular, we demonstrate the ability of the manipulator to reach specified targets in free space, reach a 2D target with various orientations, and maintain an end-effector angle or stationary bending point while changing the other. The long-term goal of this work is to integrate the manipulator with an aerial robot to enable more capable aerial manipulation.",
        "primary_area": "",
        "author": "O. Godson Osele;Allison M. Okamura;Brian H. Do;O. Godson Osele;Allison M. Okamura;Brian H. Do",
        "authorids": "/37089450434;/37276156400;/37086414589;/37089450434;/37276156400;/37086414589",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811976/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13364803608127591522&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812003",
        "title": "A Linear Comb Filter for Event Flicker Removal",
        "track": "main",
        "status": "Poster",
        "abstract": "Event cameras are bio-inspired sensors that capture per-pixel asynchronous intensity change rather than the synchronous absolute intensity frames captured by a classical camera sensor. Such cameras are ideal for robotics applications since they have high temporal resolution, high dynamic range and low latency. However, due to their high temporal resolution, event cameras are particularly sensitive to flicker such as from fluorescent or LED lights. During every cycle from bright to dark, pixels that image a flickering light source generate many events that provide little or no useful information for a robot, swamping the useful data in the scene. In this paper, we propose a novel linear filter to preprocess event data to remove unwanted flicker events from an event stream. The proposed algorithm achieves over 4.6 times relative improvement in the signal-to-noise ratio when compared to the raw event stream due to the effective removal of flicker from fluorescent lighting. Thus, it is ideally suited to robotics applications that operate in indoor settings or scenes illuminated by flickering light sources. Code, Datasets and Video: https://github.com/ziweiWWANG/EFR",
        "primary_area": "",
        "author": "Ziwei Wang;Dingran Yuan;Yonhon Ng;Robert Mahony;Ziwei Wang;Dingran Yuan;Yonhon Ng;Robert Mahony",
        "authorids": "/37089197011;/37089447451;/37086203065;/37283743600;/37089197011;/37089447451;/37086203065;/37283743600",
        "aff": "Systems Theory and Robotics Group, College of Engineering and Computer Science, The Australian National University; Systems Theory and Robotics Group, College of Engineering and Computer Science, The Australian National University; Systems Theory and Robotics Group, College of Engineering and Computer Science, The Australian National University; Systems Theory and Robotics Group, College of Engineering and Computer Science, The Australian National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812003/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16944220043966888870&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Australian National University",
        "aff_unique_dep": "College of Engineering and Computer Science",
        "aff_unique_url": "https://www.anu.edu.au",
        "aff_unique_abbr": "ANU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9812433",
        "title": "A Linearization of Centroidal Dynamics for the Model-Predictive Control of Quadruped Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Centroidal dynamics, which describes the overall linear and angular motion of a robot, is often used in locomotion generation and control of legged robots. However, the equation of centroidal dynamics contains nonlinear terms mainly caused by the robot's angular motion and needs to be linearized for deriving a linear model-predictive motion controller. This paper proposes a new linearization of the robot's centroidal dynamics. By expressing the angular motion with exponential coordinates, more linear terms are identified and retained than in the existing methods to reduce the loss from the model linearization. As a consequence, a model-predictive control (MPC) algorithm is derived and shows a good performance in tracking angular motions on a quadruped robot.",
        "primary_area": "",
        "author": "Wanchao Chi;Xinyang Jiang;Yu Zheng;Wanchao Chi;Xinyang Jiang;Yu Zheng",
        "authorids": "/37089549060;/37089450681;/37086993722;/37089549060;/37089450681;/37086993722",
        "aff": "Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812433/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6305664470389844214&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tencent",
        "aff_unique_dep": "Robotics X",
        "aff_unique_url": "https://robotics.tencent.com",
        "aff_unique_abbr": "Tencent Robotics X",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811761",
        "title": "A Low-Cost, Easy-to-Manufacture, Flexible, Multi-Taxel Tactile Sensor and its Application to In-Hand Object Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotics is an emerging field that yields promising results for tasks that require safe and robust interactions with the environment or with humans, such as grasping, manipulation, and human-robot interaction. Soft robots rely on intrinsically compliant components and are difficult to equip with traditional, rigid sensors which would interfere with their compliance. We propose a highly flexible tactile sensor that is low-cost and easy to manufacture while measuring contact pressures independently from 14 taxels. The sensor is built from piezoresistive fabric for highly sensitive, continuous responses and from a custom-designed flexible printed circuit board which provides a high taxel density. From these taxels, location and intensity of contact with the sensor can be inferred. In this paper, we explain the design and manufacturing of the proposed sensor, characterize its input-output relation, evaluate its effects on compliance when equipped to the silicone-based pneumatic actuators of the soft robotic RBO Hand 2, and demonstrate that the sensor provides rich and useful feedback for learning-based in-hand object recognition.",
        "primary_area": "",
        "author": "Tessa J. Pannen;Steffen Puhlmann;Oliver Brock;Tessa J. Pannen;Steffen Puhlmann;Oliver Brock",
        "authorids": "/37089449595;/37085375934;/37279727100;/37089449595;/37085375934;/37279727100",
        "aff": "Robotics and Biology Laboratory, Technische Universit\u00e4t, Berlin, Germany; Robotics and Biology Laboratory, Technische Universit\u00e4t, Berlin, Germany; Robotics and Biology Laboratory, Technische Universit\u00e4t, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811761/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12431052760660467880&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Berlin",
        "aff_unique_dep": "Robotics and Biology Laboratory",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812300",
        "title": "A Low-Profile Hip Exoskeleton for Pathological Gait Assistance: Design and Pilot Testing",
        "track": "main",
        "status": "Poster",
        "abstract": "Hip exoskeletons may hold potential to augment walking performance and mobility in individuals with disabilities. The purpose of this study was to design and validate a novel autonomous hip exoskeleton with a user-adaptive control strategy capable of reducing the energy cost of level and incline walking in individuals with and without walking impairment. First, in a small cohort of three unimpaired individuals, we validated the ability of our control strategy to provide hip flexion-extension torque that was proportional to the biological hip moment and reduce the energy cost of level and incline walking (24 \u00b1 5% and 13 \u00b1 5% reductions, respectively). Next, in a clinical feasibility experiment with an individual with significant walking impairment from cerebral palsy, we demonstrated that our untethered device and adaptive control scheme improved hip extension by 14\u00b0 across the gait cycle, reduced average rectus femoris and semitendinosus muscle activity by 23% and 46%, respectively, and resulted in a 15% improvement in metabolic cost relative to walking without wearing the device.",
        "primary_area": "",
        "author": "Safoura Sadegh Pour Aji Bishe;Leah Liebelt;Ying Fang;Zachary F. Lerner;Safoura Sadegh Pour Aji Bishe;Leah Liebelt;Ying Fang;Zachary F. Lerner",
        "authorids": "/37089446701;/37089447716;/37087889041;/37085768418;/37089446701;/37089447716;/37087889041;/37085768418",
        "aff": "Mechanical Engineering Department, Northern Arizona University, Flagstaff, AZ, USA; Mechanical Engineering Department, Northern Arizona University, Flagstaff, AZ, USA; Mechanical Engineering Department, Northern Arizona University, Flagstaff, AZ, USA; Department of Orthopedics, The University of Arizona College of Medicine-Phoenix, Phoenix, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812300/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9923087738415175335&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Northern Arizona University;University of Arizona College of Medicine-Phoenix",
        "aff_unique_dep": "Mechanical Engineering Department;Department of Orthopedics",
        "aff_unique_url": "https://www.nau.edu;https://phoenixmed.arizona.edu",
        "aff_unique_abbr": "NAU;UACOM-P",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Flagstaff;Phoenix",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811787",
        "title": "A Magnetorheological Fluid-based Damper Towards Increased Biomimetism in Soft Robotic Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "Damping properties in biological muscle are crit-ical for absorbing shock, maintaining posture, and positioning limbs and appendages. When creating biomimetic robots, the ability to replicate the dynamics of biological muscle is neces-sary to reproduce behaviors seen in an animal model. However, the damping properties of existing soft artificial muscles are difficult to predict and tune to match specific muscles as may be needed in biomimetic robots. Here, we present the design, manufacturing, and characterization of a novel soft damper to enable a greater degree of biomimetism in these soft actuators. The damper is composed of magnetorheological fluid contained within an elastomeric shell, which is cast using low-cost 3D printed parts and commercially available urethane rubber. We demonstrate that the force-velocity response over a velocity range of 0.1 to 10 mm/s is proportional to applied magnetic flux densities between 0.12 and 0.31 T. In the presence of a 0.31 T magnetic field from a small permanent magnet, the damper is capable of a maximum damping force increase of 13.2 N to 15.5 N relative to the 0 T control, at a compression depth of 7.9 mm, which is larger than that of several previously reported centimeter-scale dampers. As a proof-of-concept for integration with a Pneumatic Artificial Muscle (PAM), we use two parallel dampers to reduce the oscillations of a rapidly pressurized McKibben actuator. The ability to modulate the force-velocity performance of our elastomeric damper paves the way for custom damping profiles that can be used to improve biomimetism in soft robotic actuators.",
        "primary_area": "",
        "author": "Ravesh Sukhnandan;Kevin Dai;Victoria Webster\u2013Wood;Ravesh Sukhnandan;Kevin Dai;Victoria Webster\u2013Wood",
        "authorids": "/37089447826;/37089447235;/37088689130;/37089447826;/37089447235;/37088689130",
        "aff": "Department of Biomedical Engineering, Carnegie Mellon University, Pittsburgh, PA, United States; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, United States; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811787/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3482367081862319692&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811958",
        "title": "A Mathematical Design for a Novel Walking Support Device that Leverages Passive Dynamics and Coupling Effects",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper mathematically conceives a novel walking support device that leverages passive dynamics and coupling effects. In this model, a passive human walker is flexibly connected to an active humanoid, where the coupling effect induces a stable walking gait of the human. To understand the key mechanism of such indirect gait regulation, different actuation modes are designed for the humanoid and compared via phase-plane analysis of the steady-state gaits. Moreover, stability analysis is conducted via Poincar\u00e9 map. The results show that it is difficult to enhance the human walker's stability when coupled to a humanoid robot using additional sensory information, compared to using a humanoid robot actuated with a predetermined force that employs no state feedback. The present mathematical model and our theoretical findings contribute to analysis and control design for locomotion systems with robot-human or inter-robots cooperation.",
        "primary_area": "",
        "author": "Longchuan Li;Shugen Ma;Isao Tokuda;Makoto Nokata;Yang Tian;Liang Du;Zhiqing Li;Longchuan Li;Shugen Ma;Isao Tokuda;Makoto Nokata;Yang Tian;Liang Du;Zhiqing Li",
        "authorids": "/37086240920;/37280187400;/38241778000;/37325259400;/37085347588;/37087006997;/37597736000;/37086240920;/37280187400;/38241778000;/37325259400;/37085347588;/37087006997;/37597736000",
        "aff": "Graduate School of Science and Engineering, Ritsumeikan University, Shiga, Japan; Graduate School of Science and Engineering, Ritsumeikan University, Shiga, Japan; Graduate School of Science and Engineering, Ritsumeikan University, Shiga, Japan; Graduate School of Science and Engineering, Ritsumeikan University, Shiga, Japan; Graduate School of Science and Engineering, Ritsumeikan University, Shiga, Japan; Shanghai Robotics Institute, School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China; College of Information Science and Technology, Beijing University Of Chemical Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811958/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:JX7Tc1WXqC0J:scholar.google.com/&scioq=A+Mathematical+Design+for+a+Novel+Walking+Support+Device+that+Leverages+Passive+Dynamics+and+Coupling+Effects&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;2",
        "aff_unique_norm": "Ritsumeikan University;Shanghai University;Beijing University of Chemical Technology",
        "aff_unique_dep": "Graduate School of Science and Engineering;School of Mechatronic Engineering and Automation;College of Information Science and Technology",
        "aff_unique_url": "https://www.ritsumei.ac.jp;https://www.shu.edu.cn;http://www.buct.edu.cn",
        "aff_unique_abbr": "Ritsumeikan;SHU;BUCT",
        "aff_campus_unique_index": "0;0;0;0;0;1;2",
        "aff_campus_unique": "Shiga;Shanghai;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;1;1",
        "aff_country_unique": "Japan;China"
    },
    {
        "id": "9812268",
        "title": "A Memory-based SO(3) Parameterization: Theory and Application to 6D Impedance Control with Radially Unbounded Potential Function",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a parameterization method to represent SO (3) over multiple turns. This method is called a memory-based parameterization, because the idea is to integrate the past trajectory of exponential coordinates. The parameterization is consistent in the sense that the true rotation matrix can be reconstructed by using the exponential map. As an application of the proposed method, a 6D impedance controller is designed with a radially unbounded potential function. Consequently, in contrast to the conventional methods, an arbitrarily large angular deflection can be accommodated, resulting in a more realistic impedance behavior. The proposed schemes are validated through simulations and experiments.",
        "primary_area": "",
        "author": "Jinyeong Jeong;Hrishik Mishra;Christian Ott;Min Jun Kim;Jinyeong Jeong;Hrishik Mishra;Christian Ott;Min Jun Kim",
        "authorids": "/37088568071;/37086428941;/37282440400;/38239144100;/37088568071;/37086428941;/37282440400;/38239144100",
        "aff": "Intelligent Robotic Systems Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Intelligent Robotic Systems Laboratory, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812268/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14542707157767667529&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;German Aerospace Center",
        "aff_unique_dep": "Intelligent Robotic Systems Laboratory;Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.dlr.de",
        "aff_unique_abbr": "KAIST;DLR",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Daejeon;Wessling",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "South Korea;Germany"
    },
    {
        "id": "9812030",
        "title": "A Method for Designing Autonomous Robots that Know Their Limits",
        "track": "main",
        "status": "Poster",
        "abstract": "While the design of autonomous robots often emphasizes developing proficient robots, another important attribute of autonomous robot systems is their ability to evaluate their own proficiency and limitations. A robot should be able to assess how well it can perform a task before, during, and after it attempts the task. Thus, we consider the following question: How can we design autonomous robots that know their own limits? Toward this end, this paper presents an approach, called assumption-alignment tracking (AAT), for designing autonomous robots that can effectively evaluate their own limits. In AAT, the robot combines (a) measures of how well its decision-making algorithms align with its environment and hardware systems with (b) its past experiences to assess its ability to succeed at a given task. The effectiveness of AAT in assessing a robot's limits are illustrated in a robot navigation task.",
        "primary_area": "",
        "author": "Alvika Gautam;Tim Whiting;Xuan Cao;Michael A. Goodrich;Jacob W. Crandall;Alvika Gautam;Tim Whiting;Xuan Cao;Michael A. Goodrich;Jacob W. Crandall",
        "authorids": "/37085410010;/37086336050;/37089603400;/37278340100;/37339706800;/37085410010;/37086336050;/37089603400;/37278340100;/37339706800",
        "aff": "Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA; Computer Science Department, Brigham Young University, Provo, UT, USA; Computer Science Department, Brigham Young University, Provo, UT, USA; Computer Science Department, Brigham Young University, Provo, UT, USA; Computer Science Department, Brigham Young University, Provo, UT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812030/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9845888975103658437&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Texas A&M University;Brigham Young University",
        "aff_unique_dep": "Department of Mechanical Engineering;Computer Science Department",
        "aff_unique_url": "https://www.tamu.edu;https://www.byu.edu",
        "aff_unique_abbr": "TAMU;BYU",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "College Station;Provo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811717",
        "title": "A Model Predictive-based Motion Planning Method for Safe and Agile Traversal of Unknown and Occluding Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Agile navigation through uncertain and obstacle-rich environments remains a challenging task for autonomous mobile robots (AMR). For most AMR, obstacles are identified using onboard sensors, e.g., lidar or cameras. The effectiveness of these sensors may be severely limited, however, by occlusions introduced from the presence of other obstacles. The occluded area may contain obstacles, static or dynamic, not included into the motion planning of the robot and could cause potential collisions if they suddenly appear in the field of view of the robot. This paper proposes a general Model Predictive Control (MPC)-based framework for handling occlusions in structured or unstructured environments, that contain known or unknown static or dynamic obstacles. Safety is promoted by commanding velocities that consider surrounding obstacle uncertainty, while perception is promoted through a specially designed objective that can reduce the occluded area created by obstacles. The effectiveness of this framework is validated through simulations that show swift and safe motion in a variety of different environments. Similarly, experimental validation is achieved with a Boston Dynamics' Spot quadruped robot operating in an occluding environment.",
        "primary_area": "",
        "author": "Jacob Higgins;Nicola Bezzo;Jacob Higgins;Nicola Bezzo",
        "authorids": "/37088837091;/37546843800;/37088837091;/37546843800",
        "aff": "Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811717/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7049863731765747244&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811542",
        "title": "A Multi-VTOL Modular Aspect Ratio Reconfigurable Aerial Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a novel Aspect Ratio-Modular Vertical Take-Off and Landing (ARM-VTOL) aerial robot, which is a meta-aircraft composed of two or more TiltRotor hybrid aircraft systems capable of magnetically being coupled during hovering flight, and of executing VTOL / Fixed-Wing hybrid missions once combined. The proposed meta-aircraft system carries the advantage of improved aerodynamic efficiency due its increased cumulative planform aspect ratio, which can be leveraged to achieve prolonged flight times in collaborative multi-vehicle flight. We propose an extendable methodology for its control which relies on the multi-body equivalent dynamics, and we present the coupling mechanism design that facilitates its experimental demonstration. We accompany these contributions with a field test-driven evaluation study conducted with a bi-vehicle ARM-VTOL prototype. The presented sequence includes vehicle-to-vehicle magnetic coupling during hovering flight, and is followed by a combined-vehicle mission comprising vertical climb, VTOL-forward transition, fixed-wing flight and maneuvering, and reverse-transition to VTOL and landing.",
        "primary_area": "",
        "author": "Stephen J. Carlson;Prateek Arora;Christos Papachristos;Stephen J. Carlson;Prateek Arora;Christos Papachristos",
        "authorids": "/37088919008;/37085797792;/37681703400;/37088919008;/37085797792;/37681703400",
        "aff": "University of Nevada, Reno, NV, USA; University of Nevada, Reno, NV, USA; University of Nevada, Reno, NV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811542/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13825804466873669445&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Nevada, Reno",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.unr.edu",
        "aff_unique_abbr": "UNR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Reno",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811550",
        "title": "A New Bio-Inspired Hybrid Cable-Driven Robot (HCDR) to Design More Realistic Snakebots",
        "track": "main",
        "status": "Poster",
        "abstract": "Bioinspired robots are useful tools to study complex biomechanical processes of animal locomotion. Key movements and kinematic parameters are under the control of experimenters, which is impossible to perform when experimenting with living animals. The primary challenge to test biological hypotheses is designing realistic robots taking inspiration from swimming snakes. Yet, underlying biomechanics of undulatory swimming i.e., anguilliform swimming, remains poorly understood. Many of underwater snakebots are made of rigid segments that form a broken-line system, unlike the skeleto-muscular systems of living snakes include more than 200 vertebrae, conferring an extreme fluidity. This paper introduces a novel design based on hybrid continuum cable driven robot (HCDR) developed through interaction with biologists and roboticists. This Biology-Push design significantly increases the fluidity and freedom of the robot's motion. Thus, improved mimic snake's locomotion is given using cable-driven to represent linkages between muscles and vertebrae providing good fluidity. In addition, the association of rigid and flexible parts allows a homogeneous distribution of actuators and masses to design autonomous swimming snake robot. Combining literature data and kinematic of swimming snakes\u2019 analyses, we implemented a kinematic model to control prototype\u2019 motion in both a plane and a volume. Finally, a comparative study between the device kinematics and the snake's movements is carried out.",
        "primary_area": "",
        "author": "E. Gautreau;J. Sandoval;X. Bonnet;M. Arsicault;S. Zeghloul;M.A. Laribi;E. Gautreau;J. Sandoval;X. Bonnet;M. Arsicault;S. Zeghloul;M.A. Laribi",
        "authorids": "/37089446710;/37085807701;/37089448107;/37681153800;/37390838900;/38248174700;/37089446710;/37085807701;/37089448107;/37681153800;/37390838900;/38248174700",
        "aff": "Dept GMSC of the Pprime Institute, CNRS - University of Poitiers -ENSMA, Poitiers, France; Dept GMSC of the Pprime Institute, CNRS - University of Poitiers -ENSMA, Poitiers, France; ECOPHY of the Center for Biological Studies of Chiz\u00e9, UMR 7372 CNRS, University of La Rochelle, Poitiers, France; Dept GMSC of the Pprime Institute, CNRS - University of Poitiers -ENSMA, Poitiers, France; Dept GMSC of the Pprime Institute, CNRS - University of Poitiers -ENSMA, Poitiers, France; Dept GMSC of the Pprime Institute, CNRS - University of Poitiers -ENSMA, Poitiers, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811550/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3906288442576185536&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Pprime Institute;University of La Rochelle",
        "aff_unique_dep": "Dept GMSC;Center for Biological Studies of Chiz\u00e9",
        "aff_unique_url": ";https://www.univ-larochelle.fr",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Poitiers",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9811593",
        "title": "A Novel Assistive Controller Based on Differential Geometry for Users of the Differential-Drive Wheeled Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Certain wheeled mobile robots e.g., electric wheelchairs, can operate through indirect joystick controls from users. Correct steering angle becomes essential when the user should determine the vehicle direction and velocity, in particular for differential wheeled vehicles since the vehicle velocity and direction are controlled with only two actuating wheels. This problem gets more challenging when complex curves should be realized by the user. A novel assistive controller with safety constraints is needed to address these problems. Also, the classic control methods mostly require the desired states beforehand which completely contradicts human's spontaneous decisions on the desired location to go. In this work, we develop a novel assistive control strategy based on differential geometry relying on only joystick inputs and vehicle states where the controller does not require any desired states. We begin with explaining the vehicle kinematics and our designed Darboux frame kinematics on a contact point of a virtual wheel and plane. Next, the geometric controller using the Darboux frame kinematics is designed for having smooth trajectories under certain safety constraints. We experiment our approach with different participants and evaluate its performance in various routes.",
        "primary_area": "",
        "author": "Seyed Amir Tafrishi;Ankit A. Ravankar;Jose Victorio Salazar Luces;Yasuhisa Hirata;Seyed Amir Tafrishi;Ankit A. Ravankar;Jose Victorio Salazar Luces;Yasuhisa Hirata",
        "authorids": "/37086457214;/38236067100;/37088234483;/37274134900;/37086457214;/38236067100;/37088234483;/37274134900",
        "aff": "Department of Robotics, Tohoku University, 6- 6-01 Aramaki-Aoba, Sendai, Japan; Department of Robotics, Tohoku University, 6- 6-01 Aramaki-Aoba, Sendai, Japan; Department of Robotics, Tohoku University, 6- 6-01 Aramaki-Aoba, Sendai, Japan; Department of Robotics, Tohoku University, 6- 6-01 Aramaki-Aoba, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811593/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3073716312867053131&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811868",
        "title": "A Novel Convolutional Neural Network for Emotion Recognition Using Neurophysiological Signals",
        "track": "main",
        "status": "Poster",
        "abstract": "Non-invasive brain-computer interfaces (BCIs) provide us with the unique ability to classify the psychological state of a person using only neurophysiological signals, such as those captured with an electroencephalogram (EEG). With this ability, new avenues for innovation in the field of healthcare arise, especially as it is used for robotics. EEGNet is a novel deep learning technique for the classification of EEG data with a limited training set that generalizes well to a variety of BCI paradigms, and the performance thereof can further be improved. We propose the use of Thomson Multitaper Power Spectral Density estimation in the EEG-BCI classification pipeline as well as a novel convolutional neural network (CNN), which extends EEGNet with sparse feature maps produced by efficient regularized separable convolutions. Further, we test the efficacy of interspersed Gaussian noise as a data augmentation technique. To show the improvements found with this new pipeline, we test on a widely used public EEG dataset related to emotion classification, then perform an ablation study to determine the most contributing factors. The accuracy on this public dataset was 77.16%. These results show that our pipeline improved the classification accuracy by 10.86% when compared with the state-of-the-art.",
        "primary_area": "",
        "author": "Marc Tunnell;Huijin Chung;Yuchou Chang;Marc Tunnell;Huijin Chung;Yuchou Chang",
        "authorids": "/37089450827;/37089447191;/37086493896;/37089450827;/37089447191;/37086493896",
        "aff": "School of Computing and Engineering, Grand Valley State University, Allendale, MI, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Computer and Information Science Department, University of Massachusetts Dartmouth, North Dartmouth, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811868/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8416954308833191271&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Grand Valley State University;Georgia Institute of Technology;University of Massachusetts Dartmouth",
        "aff_unique_dep": "School of Computing and Engineering;School of Electrical and Computer Engineering;Computer and Information Science Department",
        "aff_unique_url": "https://www.gvsu.edu;https://www.gatech.edu;https://www.umassd.edu",
        "aff_unique_abbr": "GVSU;Georgia Tech;UMass Dartmouth",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Allendale;Atlanta;North Dartmouth",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812047",
        "title": "A Novel Full State Feedback Decoupling Controller For Elastic Robot Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper a novel full state feedback approach for control of compliant actuated robot with nonlinear spring characteristics is presented. A multi-DOF elastic robot arm is a multi-input multi-output (MIMO) under-actuated system. By the new novel controller, which is based on motor coordinate transformation and motor inertia shaping, the MIMO system can be converted into a set of decoupled single-input single-output (SISO) systems. Using full state feedback controller, we can configurate the poles of each SISO system. The controller is validated by an 3-DOF elastic robot with nonlinear spring characteristics in simulation of MATLAB/Simulink.",
        "primary_area": "",
        "author": "Hongxi Zhu;Ulrike Thomas;Hongxi Zhu;Ulrike Thomas",
        "authorids": "/37087049784;/37281523200;/37087049784;/37281523200",
        "aff": "Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, Chemnitz, Germany; Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, Chemnitz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812047/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5719260567646154024&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chemnitz University of Technology",
        "aff_unique_dep": "Lab of Robotics and Human-Machine-Interaction",
        "aff_unique_url": "https://www.tu-chemnitz.de",
        "aff_unique_abbr": "TUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chemnitz",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811571",
        "title": "A Novel Limbs-Free Variable Structure Wheelchair based on Face-Computer Interface (FCI) with Shared Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to meet the mobility and physical activity needs of people with impaired limbs function, a novel limbs-free variable structure wheelchair system controled by face-computer interface (FCI) was developed in this study. FCI used facial electromyography (fEMG) as a human intention recognition method from 6 facial movements, and the accuracy of intent recognition reached 97.6% under a series of offline optimization including channel optimization based on the Hilbert transform to obtain the envelope of fEMG, features optimization, and channel-independent model optimization. A collection of finite state machines (FSM) was used to control the movement and structural changes of the wheelchair. A shared control strategy called \u201c Keep Action after Take Over (KAaTO) \u201c that can reduce user fatigue while increasing safety was used in long-distance movement control of wheelchair. To test the performance of the system, in the braking distance test experiment, the result of 0.429m under KAaTO was better than the EMG-based discrete command control and speech command control method. Finally, an outdoor long-distance control pilot experiment proved the superior performance of the developed system.",
        "primary_area": "",
        "author": "Bo Zhu;DaoHui Zhang;YaQi Chu;XinGang Zhao;Bo Zhu;DaoHui Zhang;YaQi Chu;XinGang Zhao",
        "authorids": "/37088476328;/38466316600;/37085415817;/37293146000;/37088476328;/38466316600;/37085415817;/37293146000",
        "aff": "Bo Zhu is with University of Chinese Academy of Sciences, Beijing, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811571/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9224859771735096055&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": ";Institutes for Robotics and Intelligent Manufacturing",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.cas.cn",
        "aff_unique_abbr": "UCAS;CAS",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Beijing;Shenyang",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812351",
        "title": "A Novel Model of Interaction Dynamics between Legged Robots and Deformable Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigating natural environments with deformable terrain is a difficult challenge in robotics. Understanding the interaction dynamics between robots and such terrain is an important first step in enabling them to explore these environments. Terramechanics models are largely developed and tested on wheeled and tracked platforms, but with the advent of readily available lightweight legged robots, developing an understanding of how robot feet interact with the terrain becomes increasingly important. Works on estimating terramechanical properties of deformable sands and soils use an underlying assumption that translation of the robot foot along the surface of the terrain is due to internal shear deformation of the soil. We show that for lightweight legged robots, this is not the case. Shear forces acting on the foot of a robot during a stride are not accurately predicted by the widely-used Janosi-Hanamoto formula. We propose a new model in which two forces acting on the foot dominate the foot-terrain interaction - gross sliding friction and bulldozing resistance - and propose a model of how these forces act on the foot. We test this model on multiple soil types with different foot materials. Experimental data, collected on a testbench equipped with actuators and sensors identical to those deployed on a robot in the field, is used to validate our proposed model.",
        "primary_area": "",
        "author": "Anthony Vanderkop;Navinda Kottege;Thierry Peynot;Peter Corke;Anthony Vanderkop;Navinda Kottege;Thierry Peynot;Peter Corke",
        "authorids": "/37088832073;/37696586900;/38321139400;/37279654600;/37088832073;/37696586900;/38321139400;/37279654600",
        "aff": "Robotics and Autonomous Systems Group, CSIRO, Pullenvale, QLD, Australia; Robotics and Autonomous Systems Group, CSIRO, Pullenvale, QLD, Australia; QUT Centre for Robotics, Queensland University of Technology, Brisbane, Queensland, Australia; QUT Centre for Robotics, Queensland University of Technology, Brisbane, Queensland, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812351/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6800456243057835489&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "CSIRO;Queensland University of Technology",
        "aff_unique_dep": "Robotics and Autonomous Systems Group;Centre for Robotics",
        "aff_unique_url": "https://www.csiro.au;https://www.qut.edu.au",
        "aff_unique_abbr": "CSIRO;QUT",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Pullenvale;Brisbane",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9812180",
        "title": "A Novel Multimodal Human-Exoskeleton Interface Based on EEG and sEMG Activity for Rehabilitation Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the advances in the field of human-robot interface (HRI) based on biological neural signal, the use of the sole electroencephalography (EEG) signal to help robotic exoskeleton predict the limb movement is currently no mature in rehabilitation training, due to its unreliability. Multimodal HRI represents a very recent solution to enhance the performance of single modal HRI. These HRI normally include the EEG signal with surface electromyography (sEMG) signal. However, their use for the lower limb movement prediction in hemiplegia is still limited, and the deep fusion feature of sEMG and EEG signal is ignored. This paper proposes a Dense co-attention mechanism-based Multimodal Enhance fusion Network (DMEFNet) for the lower limb movement prediction in hemiplegia. The DMEFNet can realize the mapping and deep fusion between the sEMG and EEG signal features and get a high accuracy movement prediction of the lower limbs. A sEMG and EEG data acquisition experiment and an incomplete asynchronous data collection paradigm are designed to verify the effectiveness of DMEFNet. The experimental results show that DMEFNet has a good movement prediction performance in both within-subject and cross-subject situations, reaching an accuracy of 82.96% and 88.44% respectively.",
        "primary_area": "",
        "author": "Kecheng Shi;Rui Huang;Fengjun Mu;Zhinan Peng;Ke Huang;Yizhe Qin;Xiao Yang;Hong Cheng;Kecheng Shi;Rui Huang;Fengjun Mu;Zhinan Peng;Ke Huang;Yizhe Qin;Xiao Yang;Hong Cheng",
        "authorids": "/37085491942;/37085625169;/37089186306;/37086471879;/37089448608;/37089447786;/37089448980;/37280209600;/37085491942;/37085625169;/37089186306;/37086471879;/37089448608;/37089447786;/37089448980;/37280209600",
        "aff": "School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Glasgow College, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Orthopedics, Sichuan Provincial People's Hospital, University of Electronic Science and Technology of China, Chengdu, China; School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812180/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8151282078946481618&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China",
        "aff_unique_dep": "School of Automation Engineering",
        "aff_unique_url": "https://www.uestc.edu.cn",
        "aff_unique_abbr": "UESTC",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Chengdu",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811671",
        "title": "A Novel Passive Mechanism for Flying Robots to Perch onto Surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Perching onto objects can allow flying robots to stay at a desired height at low or no cost of energy. This paper presents a novel passive mechanism for aerial perching onto smooth surfaces. This mechanism is made from a bistable mechanism and a soft suction cup. Different from existing designs, it can be easily attached onto and detached from a surface, but it can also hold a large weight when attached to a surface. Further, the mechanism can still work when the suction cup is not precisely aligned with the surface, alleviating the requirement for precise motion control of flying robots. The attachment and detachment are facilitated by the bistable mechanism, while the strong holding is enabled by a locking mechanism that can disable the bistable mechanism. We conduct experiments to characterize the required forces for successful attachments and detachments. We also equip the perching mechanism onto a quadcopter to demonstrate it can be successfully used for perching onto smooth surfaces (e.g., glass).",
        "primary_area": "",
        "author": "HaoTse Hsiao;Feiyu Wu;Jiefeng Sun;Jianguo Zhao;HaoTse Hsiao;Feiyu Wu;Jiefeng Sun;Jianguo Zhao",
        "authorids": "/37089447252;/37089448267;/37086575299;/37537638600;/37089447252;/37089448267;/37086575299;/37537638600",
        "aff": "Department of Mechanical Engineering, Colorado State University, Fort Collins, CO, USA; Department of Mechanical Engineering, Colorado State University, Fort Collins, CO, USA; Department of Mechanical Engineering, Colorado State University, Fort Collins, CO, USA; Department of Mechanical Engineering, Colorado State University, Fort Collins, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811671/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5645356242661058849&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Colorado State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.colostate.edu",
        "aff_unique_abbr": "CSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Fort Collins",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812124",
        "title": "A Novel Triad Twisted String Actuator for Controlling a Two Degrees of Freedom Joint: Design and Experimental Validation",
        "track": "main",
        "status": "Poster",
        "abstract": "Actuated universal joints, or equivalent joint systems, are found in a number of robotic applications, in particular mobile snake robots, continuum robots and robotic tails. These joints have two degrees of freedom on two axes, each perpendicular to a third axis and to themselves. Such joints use a variety of actuation methods, including direct drive motors, linear screw drives, cable based systems, and hydraulics/pneumatics. In this paper the authors design and validate a mechanism that uses the Twisted String Actuator (TSA) in an antagonistic triad to actuate the universal joint, using orientation sensors and load cells to create a robust cascading closed loop control system. This results in a light, compact, high-performance actuation system that avoids the extra mass and hardware complexity that alternative actuation methods present, with the additional challenge of nonlinearity.",
        "primary_area": "",
        "author": "Damian Crosby;Joaquin Carrasco;William Heath;Andrew Weightman;Damian Crosby;Joaquin Carrasco;William Heath;Andrew Weightman",
        "authorids": "/37089447154;/37596217000;/37299824700;/37891948500;/37089447154;/37596217000;/37299824700;/37891948500",
        "aff": "Department of Mechanical, Aerospace and Civil Engineering, University of Manchester, United Kingdom; Department of Electrical and Electronic Engineering, University of Manchester, United Kingdom; Department of Electrical and Electronic Engineering, University of Manchester, United Kingdom; Department of Mechanical, Aerospace and Civil Engineering, University of Manchester, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812124/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2806382696772340360&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Manchester",
        "aff_unique_dep": "Department of Mechanical, Aerospace and Civil Engineering",
        "aff_unique_url": "https://www.manchester.ac.uk",
        "aff_unique_abbr": "UoM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Manchester;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811545",
        "title": "A Passively Adaptable Toroidal Continuously Variable Transmission Combined with Twisted String Actuator",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots performing close physical interaction with humans would require a continuously variable transmission to operate in the region around the peak efficiency or peak power of the driving system. Conventional continuously variable transmission (CVT) has shown advantages in energy-efficient driving systems. However, these CVT designs are heavy and large for robotic applications. This paper presents a passively adaptable toroidal-CVT (pat-CVT) that is coupled with a twisted string actuator (TSA). The proposed combination of pat-CVT with TSA expands the operation range of TSA and mimics the torque-speed characteristics of artificial muscles. The contributions of the proposed system are as follows: 1) It has a high transmission ratio (4.6:1) compared to the level of existing CVT, and compact design; 2) We propose a structure that increases the power transmission efficiency by reducing slip rate during rotation through the application of soft material on the input/output disk and roller surfaces of the CVT; 3) Relations between the external load and the transmission ratio can be determined by selecting the spring in the system to optimize the motor operating conditions over the entire range of loads. We show theoretical modeling of pat-CVT with TSA and characterization of the transmission ratio, energy efficiency, and force-velocity curve.",
        "primary_area": "",
        "author": "Wonseok Shin;Sungbin Park;Gunhee Park;Jung Kim;Wonseok Shin;Sungbin Park;Gunhee Park;Jung Kim",
        "authorids": "/37086493895;/854106688641405;/37086918573;/37407273800;/37086493895;/854106688641405;/37086918573;/37407273800",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811545/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4998109727482792463&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811694",
        "title": "A Proprioceptive Haptic Device Design for Teaching Bimanual Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulation involves a broad spectrum of skills, e.g., polishing, peeling, flipping, screwing, etc., requiring complex and delicate control over both force and position. This paper aims at designing an optimal haptic interface for providing a robot with direct demonstrations of human's innate intelligence in performing a wide range of force-based bimanual manipulation tasks. Based on the proprioceptive actuation mechanism, kinodynamic design parameters of the (dual) 7-DOF haptic arm are optimized so as to maximize the force transparency perceived by the operator over the full real-scale workspace of human arm while also ensuring other important constraints including robot-to-operator collision and singularity avoidance, payload, controlled stiffness, etc. 2.65 kg of average reflective mass and 1500 N/m of controlled stiffness is achieved over the entire workspace. We show the efficacy of our haptic interface by demonstrating various force-based manipulation tasks with a light-weight anthropomorphic bimanual manipulator, LIMS2-AMBIDEX [1].",
        "primary_area": "",
        "author": "Choongin Lee;Taeyoon Lee;Jae-Kyung Min;Albert Wang;SungPyo Lee;Jaesung Oh;Chang-Woo Park;Keunjun Choi;Choongin Lee;Taeyoon Lee;Jae-Kyung Min;Albert Wang;SungPyo Lee;Jaesung Oh;Chang-Woo Park;Keunjun Choi",
        "authorids": "/37089449126;/37086353797;/37085429831;/38540871200;/37089448331;/37085762789;/37089449470;/37088930457;/37089449126;/37086353797;/37085429831;/38540871200;/37089448331;/37085762789;/37089449470;/37088930457",
        "aff": "NAVER LABS, Seongnam, South Korea; NAVER LABS, Seongnam, South Korea; NAVER LABS, Seongnam, South Korea; NAVER LABS, Seongnam, South Korea; NAVER LABS, Seongnam, South Korea; NAVER LABS, Seongnam, South Korea; NAVER LABS, Seongnam, South Korea; NAVER LABS, Seongnam, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811694/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4058416465323667498&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "NAVER LABS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.naverlabs.com",
        "aff_unique_abbr": "NAVER LABS",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Seongnam",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811960",
        "title": "A Quantitative Analysis of Activities of Daily Living: Insights into Improving Functional Independence with Assistive Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Wheelchair-mounted robotic manipulators have the potential to help the elderly and individuals living with disabilities carry out their activities of daily living (ADLs) independently. Robotics researchers focus on assistive tasks from the perspective of various control schemes and motion types, whereas, health research focuses on clinical assessment and rehabilitation, arguably leaving important differences between the two domains. In particular, there have been many studies on which activities are relevant to functional independence, but little is known quantitatively about the frequencies of ADLs that are typically carried out in everyday life. Understanding what activities are frequently carried out during the day can help guide the development and prioritization of robotic technology for in-home assistive robotic deployment. Robotics and health care communities have differing terms and taxonomies for representing tasks and motions; we aim to ameliorate taxonomic differences by consolidating quantitative task data with prior results from subjective task priority surveys. This study targets lifelogging databases, where we compute (i) daily activity task frequency from long-term low sampling frequency video and Internet of Things sensor data, and (ii) short term arm and hand movement data from video data of domestic tasks. In this work, we aim to provide deeper insights and meaningful guidelines to focus research and future developments in the field of assistive robotic manipulation that support the needs and performance requirements of the target population.",
        "primary_area": "",
        "author": "Laura Petrich;Jun Jin;Masood Dehghan;Martin Jagersand;Laura Petrich;Jun Jin;Masood Dehghan;Martin Jagersand",
        "authorids": "/37086934069;/37086574802;/37951137300;/37269568300;/37086934069;/37086574802;/37951137300;/37269568300",
        "aff": "Department of Computing Science, University of Alberta, Canada; Department of Computing Science, University of Alberta, Canada; Department of Computing Science, University of Alberta, Canada; Department of Computing Science, University of Alberta, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811960/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9443574433163885836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Department of Computing Science",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812135",
        "title": "A Recurrent Differentiable Engine for Modeling Tensegrity Robots Trainable with Low-Frequency Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Tensegrity robots, composed of rigid rods and flexible cables, are difficult to accurately model and control given the presence of complex dynamics and high number of DoFs. Differentiable physics engines have been recently proposed as a data-driven approach for model identification of such complex robotic systems. These engines are often executed at a high-frequency to achieve accurate simulation. Ground truth trajectories for training differentiable engines, however, are not typically available at such high frequencies due to limitations of real-world sensors. The present work focuses on this frequency mismatch, which impacts the modeling accuracy. We proposed a recurrent structure for a differentiable physics engine of tensegrity robots, which can be trained effectively even with low-frequency trajectories. To train this new recurrent engine in a robust way, this work introduces relative to prior work: (i) a new implicit integration scheme, (ii) a progressive training pipeline, and (iii) a differentiable collision checker. A model of NASA's icosahedron SUPERballBot on MuJoCo is used as the ground truth system to collect training data. Simulated experiments show that once the recurrent differentiable engine has been trained given the low-frequency trajectories from MuJoCo, it is able to match the behavior of MuJoCo's system. The criterion for success is whether a locomotion strategy learned using the differentiable engine can be transferred back to the ground-truth system and result in a similar motion. Notably, the amount of ground truth data needed to train the differentiable engine, such that the policy is transferable to the ground truth system, is 1% of the data needed to train the policy directly on the ground-truth system.",
        "primary_area": "",
        "author": "Kun Wang;Mridul Aanjaneya;Kostas Bekris;Kun Wang;Mridul Aanjaneya;Kostas Bekris",
        "authorids": "/37089194334;/37546899300;/37282424700;/37089194334;/37546899300;/37282424700",
        "aff": "Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812135/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18040989381002862395&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811690",
        "title": "A Robotic Lower Limb With Eight DoFs and Whole-Foot Tactile Perception for Anthropomorphic Behavior Performance",
        "track": "main",
        "status": "Poster",
        "abstract": "Humanoid lower limbs with tactile cognition are crucial for future bipedal robots developing advanced bionic intelligence, such as owning autonomous reflexes and performing human-like actions. Most existing robotic lower limbs focus on providing physical support and mobility, with little work on more bionic DoFs or tactile sensing abilities that are more than significant for a fully humanoid system. This paper develops a robotic lower limb with whole-foot tactile sensing capability. An eight-DoF mechanism with humanoid joints is designed comprehensively, and a tactile sensor with electric double-layer capacitors principle wraps the special-shaped foot surface. An STM32-based circuit integrating perception and control with a real-time inverse kinematics algorithm is experimentally demonstrated. This work provides novel insight and methodology for humanoid robots and tactile-based bionic intelligence.",
        "primary_area": "",
        "author": "Funing Hou;Jixiao Liu;Kuo Liu;Dicai Chen;Shijie Guo;Funing Hou;Jixiao Liu;Kuo Liu;Dicai Chen;Shijie Guo",
        "authorids": "/37088373895;/37087007842;/37089447496;/37089195312;/37086276620;/37088373895;/37087007842;/37089447496;/37089195312;/37086276620",
        "aff": "Academy for Engineering and Technology, Fudan University, Shanghai, China; School of Mechanical Engineering, Hebei University of Technology, Tianjin, China; School of Mechanical Engineering, Hebei University of Technology, Tianjin, China; School of Mechanical Engineering, Hebei University of Technology, Tianjin, China; Academy for Engineering and Technology, Fudan University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811690/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17829128192694067864&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Fudan University;Hebei University of Technology",
        "aff_unique_dep": "Academy for Engineering and Technology;School of Mechanical Engineering",
        "aff_unique_url": "https://www.fudan.edu.cn;",
        "aff_unique_abbr": "Fudan;",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Shanghai;Tianjin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812224",
        "title": "A Simple Formulation for Fast Prioritized Optimal Control of Robots using Weighted Exact Penalty Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Prioritization of tasks is a common approach to resolve conflicts in instantaneous control of redundant robots. However, the idea of prioritization has not yet been satisfactorily extended to model predictive control (MPC) to allow for real-time robot control. The standard sequential approach for prioritization is unsuitable because of the computational burden involved in solving a nonlinear problem (NLP) at every priority level. We introduce an alternate promising approach of using weighted exact penalties for the MPC stage costs, where a correctly tuned set of weights can introduce strict prioritization. We prove the existence of a set of equivalent weights that provides the same solution as the sequential approach for a local convex approximation of the original NLP and use this insight to design an algorithm to adaptively tune the weights. The weighted method is validated on a dual arm robot task in simulations and also implemented on a physical robot. We report computational times that are fast enough for prioritized MPC of robot manipulators for the first time, to the best of our knowledge.",
        "primary_area": "",
        "author": "Ajay Suresha Sathya;Wilm Decre;Goele Pipeleers;Jan Swevers;Ajay Suresha Sathya;Wilm Decre;Goele Pipeleers;Jan Swevers",
        "authorids": "/37086528446;/37571970600;/37322615600;/37322616700;/37086528446;/37571970600;/37322615600;/37322616700",
        "aff": "DMMS-M Lab, Flanders Make, Leuven, Belgium; DMMS-M Lab, Flanders Make, Leuven, Belgium; DMMS-M Lab, Flanders Make, Leuven, Belgium; DMMS-M Lab, Flanders Make, Leuven, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812224/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2651394156342444002&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Flanders Make",
        "aff_unique_dep": "DMMS-M Lab",
        "aff_unique_url": "https://www.flandersmake.be",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Leuven",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9812018",
        "title": "A Single Correspondence Is Enough: Robust Global Registration to Avoid Degeneracy in Urban Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Global registration using 3D point clouds is a crucial technology for mobile platforms to achieve localization or manage loop-closing situations. In recent years, numerous researchers have proposed global registration methods to address a large number of outlier correspondences. Unfortunately, the degeneracy problem, which represents the phenomenon in which the number of estimated inliers becomes lower than three, is still potentially inevitable. To tackle the problem, a degeneracy-robust decoupling-based global registration method is proposed, called Quatro. In particular, our method employs quasi-SO(3) estimation by leveraging the Atlanta world assumption in urban environments to avoid degeneracy in rotation estimation. Thus, the minimum degree of freedom (DoF) of our method is reduced from three to one. As verified in indoor and outdoor 3D LiDAR datasets, our proposed method yields robust global registration performance compared with other global registration methods, even for distant point cloud pairs. Furthermore, the experimental results confirm the applicability of our method as a coarse alignment. Our code is available: https://github.com/url-kaist/quatro",
        "primary_area": "",
        "author": "Hyungtae Lim;Suyong Yeon;Soohyun Ryu;Yonghan Lee;Youngji Kim;Jaeseong Yun;Euigon Jung;Donghwan Lee;Hyun Myung;Hyungtae Lim;Suyong Yeon;Soohyun Ryu;Yonghan Lee;Youngji Kim;Jaeseong Yun;Euigon Jung;Donghwan Lee;Hyun Myung",
        "authorids": "/37086920570;/37085644725;/37711035700;/37089001508;/37086148447;/37089448143;/37089427860;/37088886388;/37424926900;/37086920570;/37085644725;/37711035700;/37089001508;/37086148447;/37089448143;/37089427860;/37088886388;/37424926900",
        "aff": "NAVER LABS, Seongnam-si, Gyeonggido, South Korea; NAVER LABS, Seongnam-si, Gyeonggi-do, South Korea; NAVER LABS, Seongnam-si, Gyeonggi-do, South Korea; NAVER LABS, Seongnam-si, Gyeonggi-do, South Korea; NAVER LABS, Seongnam-si, Gyeonggi-do, South Korea; NAVER LABS, Seongnam-si, Gyeonggi-do, South Korea; NAVER LABS, Seongnam-si, Gyeonggi-do, South Korea; NAVER LABS, Seongnam-si, Gyeonggi-do, South Korea; School of Electrical Engineering, KI-AI at KAIST (Korea Advanced Institute of Science and Technology), Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812018/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=577293411538076247&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;1",
        "aff_unique_norm": "NAVER LABS;KAIST (Korea Advanced Institute of Science and Technology)",
        "aff_unique_dep": ";School of Electrical Engineering",
        "aff_unique_url": "https://www.naverlabs.com;https://www.kaist.ac.kr",
        "aff_unique_abbr": "NAVER LABS;KAIST",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;1",
        "aff_campus_unique": "Seongnam-si;Daejeon",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812074",
        "title": "A Switchable Rigid-Continuum Robot Arm: Design and Testing",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel robot arm that is capable of switching between a rigid robot arm and a continuum robot arm. Therefore, the novel robot arm can perform adaptive physical interaction and manipulation against complex working environments and tasks. The switch-ability of the robot arm is achieved with two types of joints: knee-like flexible joints and continuum flexible joints, with which the continuum segment of the robot arm is capable of locking and losing, hence the degree of freedom of the robot arm is capable to be switched. In this work, kinematics is established for specifying the relationship between joints space and global coordinates in both rigid and continuum configurations. Then, the posture and workspace in rigid and continuum configurations are analyzed and illustrated with numerical simulations, and compared based on the established kinematic model. Finally, a series of preliminary experimental testing toward the joint motion and stiffness has been carried out to validate the design, the kinematic model, and the motion performance of the proposed robot arm. Both the numerical and experimental results show that the knee-like joints can guarantee favorable motion accuracy, and the motion of continuum segment from the testing is well aligned with the motion calculated from the theoretical model. Moreover, the stiffness of rigid configuration is larger than the continuum configuration based on the stiffness experiment results. Therefore, the proposed novel robot arm is capable to handle adaptive interaction and manipulation in a diverse environment through the switching between the rigid and continuum configurations.",
        "primary_area": "",
        "author": "Hao Wang;Zhengxue Zhou;Xingyu Yang;Xuping Zhang;Hao Wang;Zhengxue Zhou;Xingyu Yang;Xuping Zhang",
        "authorids": "/37089001401;/37088572103;/37089448853;/37085664403;/37089001401;/37088572103;/37089448853;/37085664403",
        "aff": "Department of Mechanical and Production Engineering, Aarhus University; Department of Mechanical and Production Engineering, Aarhus University; Department of Mechanical and Production Engineering, Aarhus University; Department of Mechanical and Production Engineering, Aarhus University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812074/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3969741691402709054&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Aarhus University",
        "aff_unique_dep": "Department of Mechanical and Production Engineering",
        "aff_unique_url": "https://www.au.dk",
        "aff_unique_abbr": "AU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9811711",
        "title": "A Universal Footstep Planning Methodology for Continuous Walking in Challenging Terrain Applicable to Different Types of Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, the capabilities of legged locomotion controllers have been significantly advanced enabling them to traverse basic types of uneven terrain without visual perception. However, safely and autonomously traversing longer distances over difficult uneven terrain requires appropriate motion planning using online collected environmental knowledge. In this paper, we present such a novel methodology for generic closed-loop preceding horizon footstep planning that enables legged robots equipped with capable locomotion controllers to autonomously traverse previously unknown terrain while continuously walking long distances. Hereby, our approach addresses the challenge of online terrain perception and soft real-time footstep planning. The proposed new formulation of the search-based planning problem makes no specific assumptions about the robot kinematics (e.g. number of legs) or the used locomotion control schemes. Therefore, it can be applied to a broad range of different types of legged robots. Unlike current methods, the proposed new framework can optionally consider the floating base as part of the state-space. It is possible to configure the complexity of the planner online, from efficiently solving tasks in flat terrain to using non-contiguous contacts in highly challenging terrain. Finally, the presented methodology is successfully applied and evaluated in virtual and real experiments on state of the art bipedal, quadrupedal, and a novel eight-legged robot.",
        "primary_area": "",
        "author": "Alexander Stumpf;Oskar von Stryk;Alexander Stumpf;Oskar von Stryk",
        "authorids": "/38241191900;/37293900600;/38241191900;/37293900600",
        "aff": "Department of Computer Science, Technical University of Darmstadt; Department of Computer Science, Technical University of Darmstadt",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811711/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5332050823392288062&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Darmstadt",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812396",
        "title": "A User-customized Automatic Music Composition System",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces an intelligent system which composes music following the users' instructions. Current auto-matic music generation models are lack of stability. Meanwhile, they cannot satisfy the preference of different people. To overcome these challenges, we train a Transformer-based neural network to generate short music segments using a dataset. A user can compose music pieces by interacting with a well-trained generator. Our system collects the user's feedback during the interactions, and fine-tunes the neural network to optimize the generator. After a large number of interactions, our system can learn the musical taste of the user and customize a personal automatic music composer for him or her. Our work enhances the application value of generative models significantly, which enables people to compose music with the assistance of artificial intelligence.",
        "primary_area": "",
        "author": "Fan Mo;Xiaoqiang Ji;Huihuan Qian;Yangsheng Xu;Fan Mo;Xiaoqiang Ji;Huihuan Qian;Yangsheng Xu",
        "authorids": "/37545048300;/37088954362;/37549401900;/37277722000;/37545048300;/37088954362;/37549401900;/37277722000",
        "aff": "School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812396/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10008826292331348970&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "School of Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812131",
        "title": "A Wearable Fingertip Cutaneous Haptic Device with Continuous Omnidirectional Motion Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "In both teleoperation in real space and exploration in virtual space, \u2018passive\u2019 and \u2018active\u2019 haptic feedback can help to improve the performance of the task, especially in object handover and exploring. However, the current wearable haptic devices are hard to display continuous omnidirectional motion feedback simultaneously, which makes it not yet achieved. In this study, we thus propose a cutaneous haptic device, which enables continuous omnidirectional motion feedback for exhibiting \u2018active\u2019 and \u2018passive\u2019 haptic feedback. By applying small smart actuators (i.e., piezo actuators), the device can obtain contact force and be wearable. By arranging the closed loop with a plain-woven structure, our device makes continuous omnidirectional motion feedback possible. Our 35 g device can generate 0.94 N contact force and 0.5 N shear force. The passive and active haptic evaluations also proved its haptic capability. In conclusion, our proposed device with \u2018active\u2019 and \u2018passive\u2019 haptic feedback can provide continuous omnidirectional motion making it possible to be used for precise teleoperation.",
        "primary_area": "",
        "author": "Peizhi Zhang;Mitsuhiro Kamezaki;Yutaro Hattori;Shigeki Sugano;Peizhi Zhang;Mitsuhiro Kamezaki;Yutaro Hattori;Shigeki Sugano",
        "authorids": "/37086449639;/37546400600;/37089450653;/37274050800;/37086449639;/37546400600;/37089450653;/37274050800",
        "aff": "Graduate Program for Embodiment Informatics for Leading Graduate Schools, Waseda University, Research Innovation Center Waseda Univ., Tokyo, Japan; Research Institute for Science and Engineering (RISE), Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, Waseda University, Research Innovation Center Waseda Univ., Tokyo, Japan; Department of Modern Mechanical Engineering, Waseda University, Research Innovation Center Waseda Univ., Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812131/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12606040858420122712&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Graduate Program for Embodiment Informatics for Leading Graduate Schools",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812229",
        "title": "A beetle-claw inspired miniature mesh climbing robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Beetles can walk smoothly on the meshed surface without slipping or getting stuck in the meshed surface due to its stiffness-variable tarsi and expandable hooks on the tip of tarsi. In this study, we find that beetles bend and open their claws proactively to walk freely. Inspired by the mechanism, we designed a centimeter-scale climbing robot, equipping an artificial claw to open and bend in the same cyclic manner as the natural beetles. The robot can climb freely on the mesh surface of 30\u00b0 without being stuck at a speed of 26.18 mm/s (0.3 body length per second), and the speed was 37.5 mm/s on the 55-degree rough slop. This is the first demonstration of a centimeter-scale robot that can climb on the mesh surface.",
        "primary_area": "",
        "author": "Hong Wang;Yao Li;Bing Li;Hong Wang;Yao Li;Bing Li",
        "authorids": "/37087114365;/37088420142;/37405869400;/37087114365;/37088420142;/37405869400",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812229/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14074006054692513746&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "School of Mechanical Engineering and Automation",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811606",
        "title": "A hybrid model-based evolutionary optimization with passive boundaries for physical human-robot interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "The field of physical human-robot interaction has dramatically evolved in the last decades. As a result, the robotic system's requirements have become more challenging, including personalized behavior for different tasks and users. Various machine learning techniques have been proposed to give the robot such adaptability features. This paper proposes a model-based evolutionary optimization algorithm to tune the apparent impedance of a wrist rehabilitation device. We used passivity to define boundaries for the possible controller outcomes, limiting the shared autonomy of the robot and ensuring the coupled system stability. The experiment consists of a hardware-in-the-loop optimization and a one-degree-of-freedom robot used for wrist rehabilitation. Experimental results showed that the proposed technique could generate customized passive impedance controllers for three subjects. Furthermore, when compared with a constant impedance controller, the method suggested decreased in 20% the root mean square of interaction torques while maintaining stability during optimization.",
        "primary_area": "",
        "author": "Gustavo J. G. Lahr;Henrique B. Garcia;Arash Ajoudani;Thiago Boaventura;Glauco A. P. Caurin;Gustavo J. G. Lahr;Henrique B. Garcia;Arash Ajoudani;Thiago Boaventura;Glauco A. P. Caurin",
        "authorids": "/37086036401;/37086034955;/37945239900;/37542633900;/37326152700;/37086036401;/37086034955;/37945239900;/37542633900;/37326152700",
        "aff": "Human-Robot Interfaces and Physical Interaction Lab (HRI2), Istituto Italiano di Tecnologia, Genoa, Italy; S\u00e3o Carlos School of Engineering, University of S\u00e3o Paulo, S\u00e3o Carlos, Brazil; Human-Robot Interfaces and Physical Interaction Lab (HRI2), Istituto Italiano di Tecnologia, Genoa, Italy; S\u00e3o Carlos School of Engineering, University of S\u00e3o Paulo, S\u00e3o Carlos, Brazil; S\u00e3o Carlos School of Engineering, University of S\u00e3o Paulo, S\u00e3o Carlos, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811606/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=427479481355423042&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;University of S\u00e3o Paulo",
        "aff_unique_dep": "Human-Robot Interfaces and Physical Interaction Lab (HRI2);S\u00e3o Carlos School of Engineering",
        "aff_unique_url": "https://www.iit.it;https://www5.usp.br",
        "aff_unique_abbr": "IIT;USP",
        "aff_campus_unique_index": "0;1;0;1;1",
        "aff_campus_unique": "Genoa;S\u00e3o Carlos",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "Italy;Brazil"
    },
    {
        "id": "9811686",
        "title": "A model free robot control method for dragging an object on a planar surface by applying top contact forces",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, a robot control method is proposed for dragging an object by applying top contact forces under unknown friction and object dynamics. This is a non-prehensile manipulation of an object that can enhance the grasping capabilities of a robotic manipulator in a plethora of grasping scenarios. In the proposed method, an initializing controller generates reference contact force trajectories until a desired contact motion status is achieved that enables dragging the object without slippage of the robot tip. Based on these forces, a sufficient Virtual Friction Cone (VFC) is calculated which allows proper position control of the object with no further slippage of the robotic tip. The proposed method is validated via simulations, where contact forces are simulated with the elasto-plastic friction model, and experiments with a KUKA robot dragging a variety of objects with different dynamics and surface friction.",
        "primary_area": "",
        "author": "Savvas Sampaziotis;Zoe Doulgeri;Savvas Sampaziotis;Zoe Doulgeri",
        "authorids": "/37089450821;/37274011500;/37089450821;/37274011500",
        "aff": "Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811686/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1313052912138454041&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9812164",
        "title": "A novel hydrogel-based connection mechanism for soft modular robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Connection mechanisms are crucial in reconfigurable robots. In this work, we present a novel approach, based on the self-healing property of a hydrogel synthesized by our group, which allows us to easily attach and detach robotic modules using water as the only trigger element. Our connection mechanism does not need external energy to work and it is reversible and soft, being useful for soft modular robots. Tensile, fatigue and adhesion tests are presented to demonstrate the mechanical performance of our mechanism. Two modular soft robots, manipulator and snake, are featured to show the functionality of our approach.",
        "primary_area": "",
        "author": "Antonio L\u00f3pez-D\u00edaz;Jes\u00fas De La Morena;Francisco Ramos;Ester V\u00e1zquez;Andr\u00e9s S. V\u00e1zquez;Antonio L\u00f3pez-D\u00edaz;Jes\u00fas De La Morena;Francisco Ramos;Ester V\u00e1zquez;Andr\u00e9s S. V\u00e1zquez",
        "authorids": "/37086936153;/37089450085;/37412355500;/37086937053;/37418987100;/37086936153;/37089450085;/37412355500;/37086937053;/37418987100",
        "aff": "ETS Ingenier\u00eda Industrial. Universidad de Castilla-La Mancha, Ciudad Real, Spain; ETS Ingenier\u00eda Industrial. Universidad de Castilla-La Mancha, Ciudad Real, Spain; ETS Ingenier\u00eda Industrial. Universidad de Castilla-La Mancha, Ciudad Real, Spain; Instituto Regional de Investigaci\u00f3n Cient\u00edfica Aplicada (IRICA). Universidad de Castilla-La Mancha, Ciudad Real, Spain; ETS Ingenier\u00eda Industrial. Universidad de Castilla-La Mancha, Ciudad Real, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812164/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16222906042645745987&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Universidad de Castilla-La Mancha",
        "aff_unique_dep": "ETS Ingenier\u00eda Industrial",
        "aff_unique_url": "https://www.uclm.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Ciudad Real",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9811909",
        "title": "A physics-informed, vision-based method to reconstruct all deformation modes in slender bodies",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper is concerned with the problem of estimating (interpolating and smoothing) the shape (pose and the six modes of deformation) of a slender flexible body from multiple camera measurements. This problem is important in both biology, where slender, soft, and elastic structures are ubiquitously encountered across species, and in engineering, particularly in the area of soft robotics. The proposed mathematical formulation for shape estimation is physics-informed, based on the use of the special Cosserat rod theory whose equations encode slender body mechanics in the presence of bending, shearing, twisting and stretching. The approach is used to derive numerical algorithms which are experimentally demonstrated for fiber reinforced and cable-driven soft robot arms. These experimental demonstrations show that the methodology is accurate (<5 mm error, three times less than the arm diameter) and robust to noise and uncertainties.",
        "primary_area": "",
        "author": "Seung Hyun Kim;Heng-Sheng Chang;Chia-Hsien Shih;Naveen Kumar Uppalapati;Udit Halder;Girish Krishnan;Prashant G. Mehta;Mattia Gazzola;Seung Hyun Kim;Heng-Sheng Chang;Chia-Hsien Shih;Naveen Kumar Uppalapati;Udit Halder;Girish Krishnan;Prashant G. Mehta;Mattia Gazzola",
        "authorids": "/37089448335;/37088749259;/37088754837;/37086935112;/37706076400;/38540614800;/37301338300;/37086479547;/37089448335;/37088749259;/37088754837;/37086935112;/37706076400;/38540614800;/37301338300;/37086479547",
        "aff": "Mechanical Science and Engineering; Mechanical Science and Engineering; Mechanical Science and Engineering; Coordinated Science Laboratory, University of Illinois at Urbana-Champaign; Coordinated Science Laboratory, University of Illinois at Urbana-Champaign; Mechanical Science and Engineering; Mechanical Science and Engineering; Mechanical Science and Engineering",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811909/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1742675377937769239&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Mechanical Science and Engineering",
        "aff_unique_url": "https://mse.illinois.edu/",
        "aff_unique_abbr": "UIUC MSE",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811714",
        "title": "A2DIO: Attention-Driven Deep Inertial Odometry for Pedestrian Localization based on 6D IMU",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose A2DIO, a novel hybrid neural network model with a set of carefully designed attention mechanisms for pose invariant inertial odometry. The key idea is to extract both local and global features from the window of IMU measurements for velocity prediction. A2DIO leverages the convolutional neural network (CNN) to capture the sectional features and long-short term memory (LSTM) recurrent neural network to extract long-range dependencies. In both CNN and LSTM modules, attention mechanisms are designed and embedded for better model representation. Specifically, in the CNN attention block, the convolved features are refined along both channel and spatial dimensions, respectively. For the LSTM module, softmax scoring is applied to update the weights of the hidden states along the temporal axis. We evaluate A2DIO on the benchmark with the largest and most natural IMU data, RoNIN. Extensive ablation experiments demonstrate the effectiveness of our A2DIO model. Compared with the state of the art, the 50th percentile accuracy of A2DIO is 18.21 % higher and the 90th percentile accuracy is 21.15 % higher for all the phone holders not appeared in the training set.",
        "primary_area": "",
        "author": "Yingying Wang;Hu Cheng;Max Q.-H. Meng;Yingying Wang;Hu Cheng;Max Q.-H. Meng",
        "authorids": "/37088689053;/37086801643;/37274117000;/37088689053;/37086801643;/37274117000",
        "aff": "Robotics, Perception and Artificial Intelligence Lab in the Electronic Engineering Department, The Chinese University of Hong Kong, N.T., Hong Kong SAR, China; Robotics, Perception and Artificial Intelligence Lab in the Electronic Engineering Department, The Chinese University of Hong Kong, N.T., Hong Kong SAR, China; Shenzhen Research Institute of The Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811714/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10830057986726725517&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Electronic Engineering Department",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "N.T.;Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812121",
        "title": "AMI: Adaptive Motion Imitation Algorithm Based on Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we develop a novel adaptive motion imitation algorithm (AMI) for robotic systems. Although AMI can be used in a variety of human-robot interaction scenarios, we are particularly interested in robotic rehabilitation where the robot plays the role of demonstrating and practicing challenging motion physiotherapy. During therapy, the robot first demonstrates a reference trajectory to the patient that needs to be repeated during practice and then adapts its motion to a cyclic speed and amplitude based on the patient's abilities. Using this algorithm, the robotic system learns an upper-body motion of the human user and performs a unique, similar, and easier motion based on the learned trajectory from the user. Adaptation in the AMI is based on deep reinforcement learning with deep deterministic policy gradient implemented in the Robot Operating System (ROS) environment. Experimental data collected from 11 users during upper body human-robot imitation sessions with social robot Zeno was used to show that the algorithm can learn reference elbow joint trajectories of the user in an off-line manner after just a few cycles. Finally, we also implemented the algorithm online using the Baxter robot to demonstrate its learning and playback performance.",
        "primary_area": "",
        "author": "Nazita Taghavi;Moath H. A. Alqatamin;Dan O. Popa;Nazita Taghavi;Moath H. A. Alqatamin;Dan O. Popa",
        "authorids": "/37088998669;/37086424471;/37283733600;/37088998669;/37086424471;/37283733600",
        "aff": "Louisville Automation & Robotics Research Institute, University of Louisville, KY; Louisville Automation & Robotics Research Institute, University of Louisville, KY; Louisville Automation & Robotics Research Institute, University of Louisville, KY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812121/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1006329617627703377&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Louisville",
        "aff_unique_dep": "Louisville Automation & Robotics Research Institute",
        "aff_unique_url": "https://www.louisville.edu",
        "aff_unique_abbr": "UofL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Louisville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812359",
        "title": "AMRA*: Anytime Multi-Resolution Multi-Heuristic A*",
        "track": "main",
        "status": "Poster",
        "abstract": "Heuristic search-based motion planning algorithms typically discretise the search space in order to solve the shortest path problem. Their performance is closely related to this discretisation. A fine discretisation allows for better approximations of the continuous search space, but makes the search for a solution more computationally costly. A coarser resolution might allow the algorithms to find solutions quickly at the expense of quality. For large state spaces, it can be beneficial to search for solutions across multiple resolutions even though defining the discretisations is challenging. The recently proposed algorithm Multi-Resolution A* (MRA*) searches over multiple resolutions. It traverses large areas of obstacle-free space and escapes local minima at a coarse resolution. It can also navigate so-called narrow passageways at a finer resolution. In this work, we develop AMRA*, an anytime version of MRA*, AMRA* tries to find a solution quickly using the coarse resolution as much as possible. It then refines the solution by relying on the fine resolution to discover better paths that may not have been available at the coarse resolution. In addition to being anytime, AMRA* can also leverage information sharing between multiple heuristics. We prove that AMRA* is complete and optimal (in-the-limit of time) with respect to the finest resolution. We show its performance on 2D grid navigation and 4D kinodynamic planning problems.",
        "primary_area": "",
        "author": "Dhruv Mauria Saxena;Tushar Kusnur;Maxim Likhachev;Dhruv Mauria Saxena;Tushar Kusnur;Maxim Likhachev",
        "authorids": "/37086188218;/37086579092;/37309318800;/37086188218;/37086579092;/37309318800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812359/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16442483009927136001&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811537",
        "title": "APF-RL: Safe Mapless Navigation in Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper is focused on safe mapless navigation of mobile robots in unknown and possibly complex environments containing both internal and dynamic obstacles. We present a novel modular approach that combines the strengths of artificial potential functions (APF) with deep reinforcement learning. Differing from related work, the robot learns how to adjust the two input parameters of the APF controller as necessary through soft actor-critic algorithm. Environmental complexity measures are introduced in order to ensure that the robot's training covers a range of learning scenarios that vary in regard to maneuvering difficulty. Our experimental results show that differing from the classical navigation methods and end-to-end models, the robot can navigate successfully on its own even in complex scenarios with moving entities without requiring any maps.",
        "primary_area": "",
        "author": "Kemal Bekta\u015f;H. I\u015f\u0131l Bozma;Kemal Bekta\u015f;H. I\u015f\u0131l Bozma",
        "authorids": "/37089450018;/38222255200;/37089450018;/38222255200",
        "aff": "Systems and Control Engineering, Bo\u011fazici University; Intelligent Systems Laboratory, Electrical & Electronics Engineering, Bo\u011fazi\u00e7i University, Istanbul, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811537/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17261651880020508604&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Bo\u011fazici University;Bo\u011fazi\u00e7i University",
        "aff_unique_dep": "Systems and Control Engineering;Electrical & Electronics Engineering",
        "aff_unique_url": "https://www.boun.edu.tr;https://www.boun.edu.tr",
        "aff_unique_abbr": "BU;Bo\u011fazi\u00e7i",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Istanbul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "T\u00fcrkiye"
    },
    {
        "id": "9811996",
        "title": "ARChemist: Autonomous Robotic Chemistry System Architecture",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated laboratory experiments have the potential to propel new discoveries, while increasing reproducibility and improving scientists' safety when handling dangerous materials. However, many automated laboratory workflows have not fully leveraged the remarkable advancements in robotics and digital lab equipment. As a result, most robotic systems used in the labs are programmed specifically for a single experiment, often relying on proprietary architectures or using unconventional hardware. In this work, we tackle this problem by proposing a novel robotic system architecture specifically designed with and for chemists, which allows the scientist to easily reconfigure their setup for new experiments. Specifically, the system's strength is its ability to combine together heterogeneous robotic platforms with standard laboratory equipment to create different experimental setups. Finally, we show how the architecture can be used for specific laboratory experiments through case studies such as solubility screening and crystallisation.",
        "primary_area": "",
        "author": "Hatem Fakhruldeen;Gabriella Pizzuto;Jakub Glowacki;Andrew Ian Cooper;Hatem Fakhruldeen;Gabriella Pizzuto;Jakub Glowacki;Andrew Ian Cooper",
        "authorids": "/37089449228;/37087016402;/37089177869;/37089449046;/37089449228;/37087016402;/37089177869;/37089449046",
        "aff": "Leverhulme Research Centre for Functional Materials Design, University of Liverpool, United Kingdom; Leverhulme Research Centre for Functional Materials Design, University of Liverpool, United Kingdom; Leverhulme Research Centre for Functional Materials Design, University of Liverpool, United Kingdom; Leverhulme Research Centre for Functional Materials Design, University of Liverpool, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811996/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6147448013887908499&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Liverpool",
        "aff_unique_dep": "Leverhulme Research Centre for Functional Materials Design",
        "aff_unique_url": "https://www.liverpool.ac.uk",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812442",
        "title": "ASHA: Assistive Teleoperation via Human-in-the-Loop Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Building assistive interfaces for controlling robots through arbitrary, high-dimensional, noisy inputs (e.g., webcam images of eye gaze) can be challenging, especially when it involves inferring the user's desired action in the absence of a natural \u2018default\u2019 interface. Reinforcement learning from online user feedback on the system's performance presents a natural solution to this problem, and enables the interface to adapt to individual users. However, this approach tends to require a large amount of human-in-the-loop training data, especially when feedback is sparse. We propose a hierarchical solution that learns efficiently from sparse user feedback: we use offline pre-training to acquire a latent embedding space of useful, high-level robot behaviors, which, in turn, enables the system to focus on using online user feedback to learn a mapping from user inputs to desired high-level behaviors. The key insight is that access to a pre-trained policy enables the system to learn more from sparse rewards than a na\u00efve RL algorithm: using the pre-trained policy, the system can make use of successful task executions to relabel, in hindsight, what the user actually meant to do during unsuccessful executions. We evaluate our method primarily through a user study with 12 participants who perform tasks in three simulated robotic manipulation domains using a webcam and their eye gaze: flipping light switches, opening a shelf door to reach objects inside, and rotating a valve. The results show that our method successfully learns to map 128-dimensional gaze features to 7-dimensional joint torques from sparse rewards in under 10 minutes of online training, and seamlessly helps users who employ different gaze strategies, while adapting to distributional shift in webcam inputs, tasks, and environments",
        "primary_area": "",
        "author": "Sean Chen;Jensen Gao;Siddharth Reddy;Glen Berseth;Anca D. Dragan;Sergey Levine;Sean Chen;Jensen Gao;Siddharth Reddy;Glen Berseth;Anca D. Dragan;Sergey Levine",
        "authorids": "/37089447557;/37089448284;/37088506876;/37085864638;/37960625200;/37085481973;/37089447557;/37089448284;/37088506876;/37085864638;/37960625200;/37085481973",
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; MILA; University of California, Berkeley; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812442/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11701836132419662306&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Mila",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://mila.quebec",
        "aff_unique_abbr": "UC Berkeley;MILA",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9812106",
        "title": "Abnormal Occupancy Grid Map Recognition using Attention Network",
        "track": "main",
        "status": "Poster",
        "abstract": "The occupancy grid map is a critical component of autonomous positioning and navigation in the mobile robotic system, as many other systems' performance depends heavily on it. To guarantee the quality of the occupancy grid maps, researchers previously had to perform tedious manual recognition for a long time. This work focuses on automatic abnormal occupancy grid map recognition using the residual neural network with novel attention mechanism modules. We propose an effective channel and spatial Residual Squeeze-and-Excitation (csRSE) attention module, which contains a residual block for producing hierarchical features, followed by both channel SE (cSE) block and spatial SE (sSE) block for the sufficient information extraction along the channel and spatial pathways. To further summarize the occupancy grid map characteristics and experiments with our csRSE attention modules, we constructed a dataset called occupancy grid map dataset (OGMD) for our experiments. On this OGMD test dataset, we tested a few variants of our proposed structure and compared them with other attention mechanisms. Our experimental results show that the proposed attention network can infer the abnormal map with state-of-the-art (SOTA) accuracy of 96.23% for abnormal occupancy grid map recognition.",
        "primary_area": "",
        "author": "Fuqin Deng;Hua Feng;Mingjian Liang;Qi Feng;Ningbo Yi;Yong Yang;Yuan Gao;Junfeng Chen;Tin Lun Lam;Fuqin Deng;Hua Feng;Mingjian Liang;Qi Feng;Ningbo Yi;Yong Yang;Yuan Gao;Junfeng Chen;Tin Lun Lam",
        "authorids": "/37087470921;/37088468115;/37089194206;/37089501040;/37086244798;/37088468673;/37089157084;/37089393433;/37571111600;/37087470921;/37088468115;/37089194206;/37089501040;/37086244798;/37088468673;/37089157084;/37089393433;/37571111600",
        "aff": "The 3irobotix Co., Ltd, Shenzhen, China; School of Intelligent Manufacturing, the Wuyi University, Jiangmen, China; School of Intelligent Manufacturing, the Wuyi University, Jiangmen, China; School of Intelligent Manufacturing, the Wuyi University, Jiangmen, China; School of Intelligent Manufacturing, the Wuyi University, Jiangmen, China; The 3irobotix Co., Ltd, Shenzhen, China; The Shenzhen Institute of Artificial Intelligence and Robotics for Society, the Chinese University of Hong Kong, Shenzhen, China; The Shenzhen Institute of Artificial Intelligence and Robotics for Society, the Chinese University of Hong Kong, Shenzhen, China; The Shenzhen Institute of Artificial Intelligence and Robotics for Society, the Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812106/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6556744387322827468&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;1;0;2;2;2",
        "aff_unique_norm": "3irobotix Co., Ltd;Wuyi University;Chinese University of Hong Kong",
        "aff_unique_dep": ";School of Intelligent Manufacturing;Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_url": ";;https://www.cuhk.edu.cn",
        "aff_unique_abbr": ";;CUHK",
        "aff_campus_unique_index": "1;1;1;1;2;2;2",
        "aff_campus_unique": ";Jiangmen;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811818",
        "title": "Abstract Flow for Temporal Semantic Segmentation on the Permutohedral Lattice",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic segmentation is a core ability required by autonomous agents, as being able to distinguish which parts of the scene belong to which object class is crucial for navigation and interaction with the environment. Approaches which use only one time-step of data cannot distinguish between moving objects nor can they benefit from temporal integration. In this work, we extend a backbone LatticeNet to process temporal point cloud data. Additionally, we take inspiration from optical flow methods and propose a new module called Abstract Flow which allows the network to match parts of the scene with similar abstract features and gather the information temporally. We obtain state-of-the-art results on the SemanticKITTI dataset that contains LiDAR scans from real urban environments. We share the PyTorch implementation of TemporalLatticeNet at https://github.com/AIS-Bonn/temporal_latticenet.",
        "primary_area": "",
        "author": "Peer Schutt;Radu Alexandru Rosu;Sven Behnke;Peer Schutt;Radu Alexandru Rosu;Sven Behnke",
        "authorids": "/37087053762;/37086213624;/37295987100;/37087053762;/37086213624;/37295987100",
        "aff": "Autonomous Intelligent Systems Group, Computer Science VI, University of Bonn, Germany; Autonomous Intelligent Systems Group, Computer Science VI, University of Bonn, Germany; Autonomous Intelligent Systems Group, Computer Science VI, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811818/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17101025389375155906&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Computer Science VI",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812113",
        "title": "Accessibility-Based Clustering for Efficient Learning of Locomotion Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "For model-free deep reinforcement learning of quadruped locomotion, the initialization of robot configurations is crucial for data efficiency and robustness. This work focuses on algorithmic improvements of data efficiency and robustness simultaneously through automatic discovery of initial states, which is achieved by our proposed K-Access algorithm based on accessibility metrics. Specifically, we formulated accessibility metrics to measure the difficulty of transitions between two arbitrary states, and proposed a novel K-Access algorithm for state-space clustering that automatically discovers the centroids of the static-pose clusters based on the accessibility metrics. By using the discovered centroidal static poses as the initial states, we can improve data efficiency by reducing redundant explorations, and enhance the robustness by more effective explorations from the centroids to sampled poses. Focusing on fall recovery as a very hard set of locomotion skills, we validated our method extensively using an 8-DoF quadrupedal robot Bittle. Compared to the baselines, the learning curve of our method converges much faster, requiring only 60% of training episodes. With our method, the robot can successfully recover to standing poses within 3 seconds in 99.4% of the test cases. Moreover, the method can generalize to other difficult skills successfully, such as backflipping.",
        "primary_area": "",
        "author": "Chong Zhang;Wanming Yu;Zhibin Li;Chong Zhang;Wanming Yu;Zhibin Li",
        "authorids": "/37089450912;/37089448166;/37857029500;/37089450912;/37089448166;/37857029500",
        "aff": "Department of Precision Instrument, Tsinghua University, Beijing, China; School of Informatics, University of Edinburgh, Edinburgh, United Kingdom; School of Informatics, University of Edinburgh, Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812113/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11560464424632520706&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Tsinghua University;University of Edinburgh",
        "aff_unique_dep": "Department of Precision Instrument;School of Informatics",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.ed.ac.uk",
        "aff_unique_abbr": "THU;Edinburgh",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Beijing;Edinburgh",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9811577",
        "title": "Accurate Calibration of Multi-Perspective Cameras from a Generalization of the Hand-Eye Constraint",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-perspective cameras are quickly gaining importance in many applications such as smart vehicles and virtual or augmented reality. However, a large system size or absence of overlap in neighbouring fields-of-view often complicate their calibration. We present a novel solution which relies on the availability of an external motion capture system. Our core contribution consists of an extension to the hand-eye calibration problem which jointly solves multi-eye-to-base problems in closed form. We furthermore demonstrate its equivalence to the multi-eye-in-hand problem. The practical validity of our approach is supported by our experiments, indicating that the method is highly efficient and accurate, and outperforms existing closed-form alternatives.",
        "primary_area": "",
        "author": "Yifu Wang;Wenqing Jiang;Kun Huang;S\u00f6ren Schwertfeger;Laurent Kneip;Yifu Wang;Wenqing Jiang;Kun Huang;S\u00f6ren Schwertfeger;Laurent Kneip",
        "authorids": "/37086160259;/37089448499;/37712672400;/37391715800;/37569040300;/37086160259;/37089448499;/37712672400;/37391715800;/37569040300",
        "aff": "ShanghaiTech University; ShanghaiTech University; ShanghaiTech University; ShanghaiTech University; Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811577/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17935286421149556593&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "ShanghaiTech University;Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.shanghaitech.edu.cn;",
        "aff_unique_abbr": "ShanghaiTech;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812071",
        "title": "Acoustic and magnetic hybrid actuated immune cell robot for target and kill cancer cells",
        "track": "main",
        "status": "Poster",
        "abstract": "Macrophage immunotherapy is a promising clinical approach to treat cancer. However, low targeting efficiency severely limits the immunotherapeutic effect of macrophages. Here, we report a unique macrophage robot that can target and kill cancer cells using a combination of external acoustic and magnetic fields. First, the inactive macrophages (M\u00f8) are magnetized by endocytosis of the \\gamma\\gamma-Fe2O3 nanoparticles (FeNPs). Then, the magnetized M\u2298can be moved towards the capillary wall under the influence of an acoustic radiation force generated from a lead zirconate titanate piezoelectric (PZT) transducer. Finally, the magnetized cells rotate forward under the action of alternating magnetic fields (AMF). During the process of magnetizing macrophages, FeNPs activate the anti-tumor immune activity of macrophages (M1) to induce cancer cell death. Overall, the present study highlights a novel cell robot that can target and kill cancer cells. Considering that the nanoparticles, macrophages, magnetic fields, and ultrasound technology have all been FDA approved for clinical settings, our targeted delivery system has tremendous clinical translational potential.",
        "primary_area": "",
        "author": "Xue Bai;Wei Zhang;Yuguo Dai;Yueying Wang;Hongyan Sun;Lin Feng;Xue Bai;Wei Zhang;Yuguo Dai;Yueying Wang;Hongyan Sun;Lin Feng",
        "authorids": "/37088554994;/37086933988;/37086561173;/37089451011;/37089154851;/37403324400;/37088554994;/37086933988;/37086561173;/37089451011;/37089154851;/37403324400",
        "aff": "Engineering & Automation, Beihang University, Beijing, China; Engineering & Automation, Beihang University, Beijing, China; Engineering & Automation, Beihang University, Beijing, China; Engineering & Automation, Beihang University, Beijing, China; Engineering & Automation, Beihang University, Beijing, China; Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812071/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1599046885087251417&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "Engineering & Automation",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812294",
        "title": "Active Autorotation of Micro Aerial Vehicle with Foldable Winged Shell for Impact Mitigation during Free Fall",
        "track": "main",
        "status": "Poster",
        "abstract": "Drop mitigation is an important function of micro aerial vehicles (MAVs) that are used for internal inspections of enclosed and cluttered structures (height: 5\u201310 m). The mechanism also allows continuous operation of drones, prevents the downtime required for maintenance and repair and also provides a safer environment for workers who are working below the drones. Some solutions include parachutes, auto-rotors, and active auto-rotors. However, these are inapplicable to MAV s with a protector shell because of their size and payload. We herein propose a new rapid response drop mitigation method for MA V s involving active autorotation with bendable wings and shells. Active autorotation enables faster deceleration during dropping motion as compared to parachutes or passive autorotation. Bendable wings can ensure optimal flight performance and enable sufficient deceleration during falling motion. This newly proposed fixture was shown to reduce the impact impulse by 32.2 % and horizontal oscillation by 34.4 %. From our flight tests conducted at heights of 5 m and 10m in both outdoor and indoor environments, the measured impact impulse for both profiles were attained at 0.93 N s. The minimum impact impulse that can cause harm to the human eye, which is the most vulnerable part, is 2 N s. Thus, this mechanism was successfully proven to provide a greater safety buffer based on the drop test conducted. We envision this mechanism to provide greater safety to drone operating environments in relevant fields involving indoor and urban drone flights. Furthermore, it can reduce damage to drones and structures and avoid injuries arising from drone crashes.",
        "primary_area": "",
        "author": "Quek Ching Alvin;Kazunori Ohno;Yoshito Okada;Daiki Fujikura;Satoshi Abe;Masaki Takahashi;Zitong Han;Satoshi Tadokoro;Quek Ching Alvin;Kazunori Ohno;Yoshito Okada;Daiki Fujikura;Satoshi Abe;Masaki Takahashi;Zitong Han;Satoshi Tadokoro",
        "authorids": "/37089450792;/37285220400;/37402546000;/37088687774;/37089447394;/37089448213;/37089449736;/37296054300;/37089450792;/37285220400;/37402546000;/37088687774;/37089447394;/37089448213;/37089449736;/37296054300",
        "aff": "Tohoku University, Japan; Tohoku University, Japan; Tohoku University, Japan; Tohoku University, Japan; Tohoku University, Japan; Tohoku University, Japan; Tohoku University, Japan; Tohoku University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812294/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=182513797489796451&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812017",
        "title": "Active Extrinsic Contact Sensing: Application to General Peg-in-Hole Insertion",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a method that actively estimates contact location between a grasped rigid object and its environment and uses this as input to a peg-in-hole insertion policy. An estimation model and an active tactile feedback controller work collaboratively to estimate the external contacts accurately. The controller helps the estimation model get a better estimate by regulating a consistent contact mode. The better estimation makes it easier for the controller to regulate the contact. We then train an object-agnostic insertion policy that learns to use the series of contact estimates to guide the insertion of an unseen peg into a hole. In contrast with previous works that learn a policy directly from tactile signals, since this policy is in contact configuration space, it can be learned directly in simulation. Lastly, we demonstrate and evaluate the active extrinsic contact line estimation and the trained insertion policy together in a real experiment. We show that the proposed method inserts various-shaped test objects with higher success rates and fewer insertion attempts than previous work with end-to-end approaches. See supplementary video and results at https://sites.google.com/view/active-extrinsic-contact.",
        "primary_area": "",
        "author": "Sangwoon Kim;Alberto Rodriguez;Sangwoon Kim;Alberto Rodriguez",
        "authorids": "/37088997798;/38194796600;/37088997798;/38194796600",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology; Department of Mechanical Engineering, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812017/",
        "gs_citation": 83,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2471906557916422440&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812453",
        "title": "Active Learning for Testing and Evaluation in Field Robotics: A Case Study in Autonomous, Off-Road Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Testing and evaluation of field robotic systems requires both experimentation in representative conditions and human supervision to effectively assess components, manage risk, and interpret results. Due to the complexity of robotic sys-tems, we argue this experimentation should be done adaptively by using insights gained from previous trials. Furthermore, we envision an advisory system that could assist experimenters with selecting trial configurations by learning and accounting for human preferences and risk tolerances; however, formal methods for human decision making in the context of field robotic experimentation remains an open question. In this work, we present and analyze a case study for how decisions were made during the testing and evaluation of an off-road, autonomous navigation system. From the perspective of active learning, we find that Bayesian Optimization is a promising mathematical framework for modeling human decision making in adaptive experimental design of field robotics and that a combination of the EI, KG, and PES acquisition functions would likely be useful for realizing an advisory system.",
        "primary_area": "",
        "author": "Jason M. Gregory;Daniel Sahu;Eli Lancaster;Felix Sanchez;Trevor Rocks;Brian Kaukeinen;Jonathan Fink;Satyandra K. Gupta;Jason M. Gregory;Daniel Sahu;Eli Lancaster;Felix Sanchez;Trevor Rocks;Brian Kaukeinen;Jonathan Fink;Satyandra K. Gupta",
        "authorids": "/37086090183;/37089449734;/37089450262;/37089450762;/37089450361;/37089448568;/37528865400;/37878971100;/37086090183;/37089449734;/37089450262;/37089450762;/37089450361;/37089448568;/37528865400;/37878971100",
        "aff": "DEVCOM Army Research Laboratory, Adelphi, MD, USA; DEVCOM Army Research Laboratory, Adelphi, MD, USA; Booz Allen Hamilton, Washington, D.C, USA; Booz Allen Hamilton, Washington, D.C, USA; DEVCOM Army Research Laboratory, Adelphi, MD, USA; DEVCOM Army Research Laboratory, Adelphi, MD, USA; DEVCOM Army Research Laboratory, Adelphi, MD, USA; Viterbi School of Engineering, University of Southern California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812453/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5746912438029857870&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;1;0;0;0;2",
        "aff_unique_norm": "DEVCOM Army Research Laboratory;Booz Allen Hamilton;University of Southern California",
        "aff_unique_dep": ";;Viterbi School of Engineering",
        "aff_unique_url": ";https://www.boozallen.com;https://www.usc.edu",
        "aff_unique_abbr": ";;USC",
        "aff_campus_unique_index": "0;0;1;1;0;0;0;2",
        "aff_campus_unique": "Adelphi;Washington, D.C;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812056",
        "title": "Ad2Attack: Adaptive Adversarial Attack on Real-Time UAV Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual tracking is adopted to extensive unmanned aerial vehicle (UAV)-related applications, which leads to a highly demanding requirement on the robustness of UAV trackers. However, adding imperceptible perturbations can easily fool the tracker and cause tracking failures. This risk is often overlooked and rarely researched at present. Therefore, to help increase awareness of the potential risk and the robustness of UAV tracking, this work proposes a novel adaptive adversarial attack approach, i.e., Ad2 Attack, against UAV object tracking. Specifically, adversarial examples are generated online during the resampling of the search patch image, which leads trackers to lose the target in the following frames. Ad2 Attack is composed of a direct downsampling module and a super-resolution upsampling module with adaptive stages. A novel optimization function is proposed for balancing the imperceptibility and efficiency of the attack. Comprehensive experiments on several well-known benchmarks and real-world conditions show the effectiveness of our attack method, which dramatically reduces the performance of the most advanced Siamese trackers.",
        "primary_area": "",
        "author": "Changhong Fu;Sihang Li;Xinnan Yuan;Junjie Ye;Ziang Cao;Fangqiang Ding;Changhong Fu;Sihang Li;Xinnan Yuan;Junjie Ye;Ziang Cao;Fangqiang Ding",
        "authorids": "/37086797986;/37089451036;/37089450034;/37088917418;/37088997696;/37088456219;/37086797986;/37089451036;/37089450034;/37088917418;/37088997696;/37088456219",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Automotive Studies, Tongji University, Shanghai, China; School of Informatics at the University of Edinburgh, United Kingdom, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812056/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10305946911938432397&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Tongji University;University of Edinburgh",
        "aff_unique_dep": "School of Mechanical Engineering;School of Informatics",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.ed.ac.uk",
        "aff_unique_abbr": "Tongji;Edinburgh",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Shanghai;Edinburgh",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9811614",
        "title": "Ada-Detector: Adaptive Frontier Detector for Rapid Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an efficient frontier detector method based on adaptive Rapidly-exploring Random Tree (RRT) for autonomous robot exploration. Robots can achieve real-time incremental frontier detection when they are exploring unknown environments. First, our detector adaptively adjusts the sampling space of RRT by sensing the surrounding environment structure. The adaptive sampling space can greatly improve the successful sampling rate of RRT (the ratio of the number of samples successfully added to the RRT tree to the number of sampling attempts) according to the environment structure and control the expansion bias of the RRT. Second, by generating non-uniform distributed samples, our method also solves the over-sampling problem of RRT in the sliding windows, where uniform random sampling causes over-sampling in the overlap area between two adjacent sliding windows. In this way, our detector is more inclined to sample in the latest explored area, which improves the efficiency of frontier detection and achieves incremental detection. We validated our method in three simulated benchmark scenarios. The experimental comparison shows that we reduce the frontier detection runtime by about 40% compared with the SOTA method, DSV Planner.",
        "primary_area": "",
        "author": "Zezhou Sun;Banghe Wu;Chengzhong Xu;Hui Kong;Zezhou Sun;Banghe Wu;Chengzhong Xu;Hui Kong",
        "authorids": "/37086934230;/37088686871;/37278305300;/37061510500;/37086934230;/37088686871;/37278305300;/37061510500",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, Jiangsu, China; Department of Computer Science, The State Key Laboratory of Internet of Things for Smart City (SKL-IOTSC), University of Macau, Macau, China; Department of Electromechanical Engineering (EME), The State Key Laboratory of Internet of Things for Smart City (SKL-IOTSC), University of Macau, Macau, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811614/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12035408732674046457&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Nanjing University of Science and Technology;University of Macau",
        "aff_unique_dep": "School of Computer Science and Engineering;Department of Computer Science",
        "aff_unique_url": "http://www.nust.edu.cn;https://www.um.edu.mo",
        "aff_unique_abbr": "NUST;UMacau",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Nanjing;Macau",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812176",
        "title": "Adaptable Action-Aware Vital Models for Personalized Intelligent Patient Monitoring",
        "track": "main",
        "status": "Poster",
        "abstract": "Vital signs such as heart rate, oxygen saturation, and blood pressure are crucial information for healthcare workers to identify clinical deterioration of ward patients. Currently, medical devices monitor these vital signs and trigger alarms when the vital signs are not in the normal ranges based on predefined thresholds, which suggests the presence of clinical deterioration. However, such threshold-based approach is not robust for patient monitoring. This is because vital signs differ among patients due to human physiology and change across time based on the action performed by a patient. In this work, we want to tackle these problems by building adaptable action-aware vital models. These models can understand the changes in vital signs caused by patient's actions and can be adapted to the normal vital sign ranges of individual patients. Our experimental results show that general vital sign patterns for different actions exist and can be personalized to new patients. Additionally, we investigate the possibility of estimating the initial vital model for an unobserved action using models of observed actions for model personalization. The resulting adaptable action-aware vital models have the potential to improve patient monitoring by reducing false clinical alarms.",
        "primary_area": "",
        "author": "Kai Wu;Ee Heng Chen;Xing Hao;Felix Wirth;Keti Vitanova;R\u00fcdiger Lange;Darius Burschka;Kai Wu;Ee Heng Chen;Xing Hao;Felix Wirth;Keti Vitanova;R\u00fcdiger Lange;Darius Burschka",
        "authorids": "/37089447973;/37086453676;/37089447061;/37089448937;/37089446801;/37409644000;/37267429200;/37089447973;/37086453676;/37089447061;/37089448937;/37089446801;/37409644000;/37267429200",
        "aff": "Department of Informatics, Machine Vision and Perception Group, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Garching bei M\u00fcnchen, Germany; Department of Informatics, Machine Vision and Perception Group, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Garching bei M\u00fcnchen, Germany; Department of Informatics, Machine Vision and Perception Group, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Garching bei M\u00fcnchen, Germany; German Heart Center Munich, M\u00fcnchen, Germany; German Heart Center Munich, M\u00fcnchen, Germany; German Heart Center Munich, M\u00fcnchen, Germany; Department of Informatics, Machine Vision and Perception Group, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Garching bei M\u00fcnchen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812176/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14266182716734146320&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;1;0",
        "aff_unique_norm": "Technical University of Munich;German Heart Center Munich",
        "aff_unique_dep": "Department of Informatics;",
        "aff_unique_url": "https://www.tum.de;https://www.dhm.uni-muenchen.de",
        "aff_unique_abbr": "TUM;",
        "aff_campus_unique_index": "0;0;0;1;1;1;0",
        "aff_campus_unique": "Garching bei M\u00fcnchen;Munich",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811715",
        "title": "Adaptive Dynamic Sliding Mode Control of Soft Continuum Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots are made of compliant materials and perform tasks that are challenging for rigid robots. However, their continuum nature makes it difficult to develop model-based control strategies. This work presents a robust model-based control scheme for soft continuum robots. Our dynamic model is based on the Euler-Lagrange approach, but it uses a more accurate description of the robot's inertia and does not include oversimplified assumptions. Based on this model, we introduce an adaptive sliding mode control scheme, which is robust against model parameter uncertainties and unknown input disturbances. We perform a series of experiments with a physical soft continuum arm to evaluate the effectiveness of our controller at tracking task-space trajectory under different payloads. The tracking performance of the controller is around 38 % more accurate than that of a state-of-the-art controller, i.e., the inverse dynamics method. Moreover, the proposed model-based control design is flexible and can be generalized to any continuum robotic arm with an arbitrary number of segments. With this control strategy, soft robotic object manipulation can become more accurate while remaining robust to disturbances.",
        "primary_area": "",
        "author": "Amirhossein Kazemipour;Oliver Fischer;Yasunori Toshimitsu;Ki Wan Wong;Robert K. Katzschmann;Amirhossein Kazemipour;Oliver Fischer;Yasunori Toshimitsu;Ki Wan Wong;Robert K. Katzschmann",
        "authorids": "/37085991853;/37089449614;/37086842924;/37088686152;/37085423557;/37085991853;/37089449614;/37086842924;/37088686152;/37085423557",
        "aff": "The Sapienza University of Rome, Italy; ETH Zurich, Switzerland; The University of Tokyo, Japan; ETH Zurich, Switzerland; ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811715/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4437686719582979829&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;1",
        "aff_unique_norm": "Sapienza University of Rome;ETH Zurich;University of Tokyo",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uniroma1.it;https://www.ethz.ch;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "Sapienza;ETHZ;UTokyo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2;1;1",
        "aff_country_unique": "Italy;Switzerland;Japan"
    },
    {
        "id": "9811853",
        "title": "Adaptive Impedance Controller for Human-Robot Arbitration based on Cooperative Differential Game Theory",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem addressed in this work is the arbitration of the role between a robot and a human during physical Human-Robot Interaction, sharing a common task. The system is modeled as a Cartesian impedance, with two separate external forces provided by the human and the robot. The problem is then reformulated as a Cooperative Differential Game, which possibly has multiple solutions on the Pareto frontier. Finally, the bargaining problem is addressed by proposing a solution depending on the interaction force, interpreted as the human will to lead or follow. This defines the arbitration law and assigns the role of leader or follower to the robot. Experiments show the feasibility and capabilities of the proposed control in managing the human-robot arbitration during a shared- trajectory following task.",
        "primary_area": "",
        "author": "Paolo Franceschi;Nicola Pedrocchi;Manuel Beschi;Paolo Franceschi;Nicola Pedrocchi;Manuel Beschi",
        "authorids": "/37086600596;/37402911000;/38232892600;/37086600596;/37402911000;/38232892600",
        "aff": "Dipartimento di Ingegneria Meccanica ed Industriale, Universit\u00e0 di Brescia, Brescia, Italy; Institute of Intelligent Industrial Technologies and Systems for Advanced Manufacturing of the National Research Council of Italy (CNR-STIIMA), Milano, Italy; Dipartimento di Ingegneria Meccanica ed Industriale, Universit\u00e0 di Brescia, Brescia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811853/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=47062370236983565&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universit\u00e0 di Brescia;National Research Council of Italy",
        "aff_unique_dep": "Dipartimento di Ingegneria Meccanica ed Industriale;Institute of Intelligent Industrial Technologies and Systems for Advanced Manufacturing",
        "aff_unique_url": "https://www.unibs.it;https://www.cnr.it/en",
        "aff_unique_abbr": ";CNR-STIIMA",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Brescia;Milano",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9812025",
        "title": "Adaptive Informative Path Planning Using Deep Reinforcement Learning for UAV-based Active Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial robots are increasingly being utilized for environmental monitoring and exploration. However, a key challenge is efficiently planning paths to maximize the information value of acquired data as an initially unknown environment is explored. To address this, we propose a new approach for informative path planning based on deep reinforcement learning (RL). Combining recent advances in RL and robotic applications, our method combines tree search with an offline-learned neural network predicting informative sensing actions. We introduce several components making our approach applicable for robotic tasks with high-dimensional state and large action spaces. By deploying the trained network during a mission, our method enables sample-efficient online replanning on platforms with limited computational resources. Simulations show that our approach performs on par with existing methods while reducing runtime by 8-10\u00d7. We validate its performance using real-world surface temperature data.",
        "primary_area": "",
        "author": "Julius R\u00fcckin;Liren Jin;Marija Popovi\u0107;Julius R\u00fcckin;Liren Jin;Marija Popovi\u0107",
        "authorids": "/37089433811;/37089432247;/37086001290;/37089433811;/37089432247;/37086001290",
        "aff": "Cluster of Excellence PhenoRob, Institute of Geodesy and Geoinformation, University of Bonn; Cluster of Excellence PhenoRob, Institute of Geodesy and Geoinformation, University of Bonn; Cluster of Excellence PhenoRob, Institute of Geodesy and Geoinformation, University of Bonn",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812025/",
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9752635322306508754&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Institute of Geodesy and Geoinformation",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "Uni Bonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811932",
        "title": "Adaptive Semi-Supervised Intent Inferral to Control a Powered Hand Orthosis for Stroke",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to provide therapy in a functional context, controls for wearable robotic orthoses need to be robust and intuitive. We have previously introduced an intuitive, user-driven, EMG-based method to operate a robotic hand orthosis, but the process of training a control that is robust to concept drift (changes in the input signal) places a substantial burden on the user. In this paper, we explore semi-supervised learning as a paradigm for controlling a powered hand orthosis for stroke subjects. To the best of our knowledge, this is the first use of semi-supervised learning for an orthotic application. Specifically, we propose a disagreement-based semi-supervision algorithm for handling intrasession concept drift based on multimodal ipsilateral sensing. We evaluate the performance of our algorithm on data collected from five stroke subjects. Our results show that the proposed algorithm helps the device adapt to intrasession drift using unlabeled data and reduces the training burden placed on the user. We also validate the feasibility of our proposed algorithm with a functional task; in these experiments, two subjects successfully completed multiple instances of a pick-and-handover task.",
        "primary_area": "",
        "author": "Jingxi Xu;Cassie Meeker;Ava Chen;Lauren Winterbottom;Michaela Fraser;Sangwoo Park;Lynne M. Weber;Mitchell Miya;Dawn Nilsen;Joel Stein;Matei Ciocarlie;Jingxi Xu;Cassie Meeker;Ava Chen;Lauren Winterbottom;Michaela Fraser;Sangwoo Park;Lynne M. Weber;Mitchell Miya;Dawn Nilsen;Joel Stein;Matei Ciocarlie",
        "authorids": "/37088507340;/37086098554;/37089446059;/37089446353;/37088521829;/37085809969;/37086455885;/37089447821;/37088811396;/37408310900;/37297485500;/37088507340;/37086098554;/37089446059;/37089446353;/37088521829;/37085809969;/37086455885;/37089447821;/37088811396;/37408310900;/37297485500",
        "aff": "Department of Computer Science, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Columbia University, New York, NY, USA; Department of Rehabilitation and Regenerative Medicine, Columbia University, New York, NY, USA; Department of Rehabilitation and Regenerative Medicine, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Columbia University, New York, NY, USA; Department of Rehabilitation and Regenerative Medicine, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Columbia University, New York, NY, USA; Co-Principal Investigators; Co-Principal Investigators; Co-Principal Investigators",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811932/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1140165465649011737&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Columbia University;",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.columbia.edu;",
        "aff_unique_abbr": "Columbia;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "New York;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "9811748",
        "title": "Adaptive Tracking Control for Industrial Robot Manipulators with Unknown Inner loop Architecture",
        "track": "main",
        "status": "Poster",
        "abstract": "The task space control of robot manipulators requires solving the thorny problem of stabilizing the compound system {outer controller - inner controller - robot manipulator}. To stabilize this compound system, both controllers must be designed by the user to achieve convergence of the tracking error. This problem is tricky to solve in the case of the control of an industrial robot manipulator because its internal controller is not accessible to users. In this work, we propose an adaptive neural network outer controller. The neural networks approximate the dynamics of the inner controller, the kinematic and dynamic parameters of the robot. Besides, the adaptive part finds parameters that achieve the stability of the global system. Since an adaptive approach is sensitive to errors in initial values, we have integrated into the controller a term that constrains the closed-loop system to maintain the prescribed performances. The effectiveness of the approach is demonstrated through Lyapunov's theory, simulation comparisons, and experimental studies.",
        "primary_area": "",
        "author": "Joseph Jean-Baptiste Mvogo Ahanda;Achille Melingui;Othman Lakhal;Bernard Essimbi Zobo;Hela Kadri;Rochdi Merzouki;Joseph Jean-Baptiste Mvogo Ahanda;Achille Melingui;Othman Lakhal;Bernard Essimbi Zobo;Hela Kadri;Rochdi Merzouki",
        "authorids": "/37089421365;/38469049400;/37085396104;/38234034900;/37085424888;/37299569900;/37089421365;/38469049400;/37085396104;/38234034900;/37085424888;/37299569900",
        "aff": "Electrical and Power Engineering Department of Higher Technical Teachers Training College, the University of Bamenda, NW Region, Cameroon; Electrical and Telecommunications Engineering Department of Ecole Nationale Sup\u00e9rieure Polytechnique, the University of Yaound\u00e9, Yaound\u00e9, Cameroon; CRIStAL Laboratory, CNRS-UMR, University of Lille, Nord, France; Department of Physics, Laboratory of Electronics, Faculty of Science, University of Yaound\u00e9, Yaound\u00e9, Cameroon; CRIStAL Laboratory, CNRS-UMR, University of Lille, Nord, France; CRIStAL Laboratory, CNRS-UMR, University of Lille, Nord, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811748/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:anOusNuWFr8J:scholar.google.com/&scioq=Adaptive+Tracking+Control+for+Industrial+Robot+Manipulators+with+Unknown+Inner+loop+Architecture&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;2;2",
        "aff_unique_norm": "University of Bamenda;Ecole Nationale Sup\u00e9rieure Polytechnique;University of Lille;University of Yaound\u00e9",
        "aff_unique_dep": "Electrical and Power Engineering Department;Electrical and Telecommunications Engineering Department;CRIStAL Laboratory;Department of Physics",
        "aff_unique_url": ";;https://www.univ-lille.fr;",
        "aff_unique_abbr": ";;;",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Bamenda;Yaound\u00e9;",
        "aff_country_unique_index": "0;0;1;0;1;1",
        "aff_country_unique": "Cameroon;France"
    },
    {
        "id": "9812218",
        "title": "Adaptive Vision-Based Control of Redundant Robots with Null-Space Interaction for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot collaboration aims to extend human ability through cooperation with robots. This technology is currently helping people with physical disabilities, has transformed the manufacturing process of companies, improved surgical performance, and will likely revolutionize the daily lives of everyone in the future. Being able to enhance the performance of both sides, such that human-robot collaboration outperforms a single robot/human, remains an open issue. For safer and more effective collaboration, a new control scheme has been proposed for redundant robots in this paper, consisting of an adaptive vision-based control term in task space and an interactive control term in null space. Such a formulation allows the robot to autonomously carry out tasks in an unknown environment without prior calibration while also interacting with humans to deal with unforeseen changes (e.g., potential collision, temporary needs) under the redundant configuration. The decoupling between task space and null space helps to explore the collaboration safely and effectively without affecting the main task of the robot end-effector. The stability of the closed-loop system has been rigorously proved with Lyapunov methods, and both the convergence of the position error in task space and that of the damping model in null space are guaranteed. The experimental results of a robot manipulator guided with the technology of augmented reality (AR) are presented to illustrate the performance of the control scheme.",
        "primary_area": "",
        "author": "Xiangjie Yan;Chen Chen;Xiang Li;Xiangjie Yan;Chen Chen;Xiang Li",
        "authorids": "/37089450143;/37089448000;/37280877200;/37089450143;/37089448000;/37280877200",
        "aff": "Department of Automation, Tsinghua University; Department of Automation, Tsinghua University; Department of Automation, Tsinghua University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812218/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11699313960295542770&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811553",
        "title": "Admittance Control Based Human-in-the-Loop Optimization for Hip Exoskeleton Reduces Human Exertion during Walking",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-in-the-loop (HIL) optimization usually optimizes assistive torque of exoskeletons to minimize the human's energetic expenditure in walking, quantified by metabolic cost. This formulation can, however, result in altered gait pattern of the human joint from the natural pattern, which is undesired. In this paper, we proposed a novel concept of HIL optimization of a hip exoskeleton. The optimization goal was to maintain the hip kinematics while providing optimal mechanical energy from the exoskeleton by modulating the admittance control. Policy iteration was used to optimize the switching time within the gait phase, at which a single parameter of the admittance controller was altered to provide assistance. The stiffness and equilibrium angle were considered as the two parameters for altering at the switching time, resulting in three possible modes of operation for the algorithm: (i) switching the equilibrium point, (ii) switching stiffness while equilibrium point is set at maximum extension and, (iii) maximum flexion. The optimization algorithm was found to converge for all three modes, with the equilibrium mode resulting in multiple solutions. Further analysis of power injected by the exoskeleton in the three modes showed that the first and third mode reduced human energetic exertion while the second mode increased human exertion. Implications of the results as well as the observed muscle activation patterns in response to assistance are discussed.",
        "primary_area": "",
        "author": "Varun Nalam;Xikai Tu;Minhan Li;Jennie Si;He Helen Huang;Varun Nalam;Xikai Tu;Minhan Li;Jennie Si;He Helen Huang",
        "authorids": "/37086046980;/37085375520;/37086936924;/37308391800;/37401091200;/37086046980;/37085375520;/37086936924;/37308391800;/37401091200",
        "aff": "University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Mechanical Engineering, Hubei University of Technology, Wuhan, Hubei, China; University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA; University of North Carolina at Chapel Hill, Chapel Hill, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811553/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4954035326455090748&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "University of North Carolina at Chapel Hill;Hubei University of Technology;Arizona State University",
        "aff_unique_dep": ";Department of Mechanical Engineering;Department of Electrical, Computer, and Energy Engineering",
        "aff_unique_url": "https://www.unc.edu;;https://www.asu.edu",
        "aff_unique_abbr": "UNC Chapel Hill;;ASU",
        "aff_campus_unique_index": "0;1;0;2;0",
        "aff_campus_unique": "Chapel Hill;Wuhan;Tempe",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9811594",
        "title": "Admittance Model Optimization for Gait Balance Assistance of a Robotic Walker: Passive Model-based Mechanical Assessment",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an optimization of an admittance control model for gait balance assistance offered by a walker-type assistive robot. We previously introduced the notion of quasi-passive physical Human-Robot Interaction (pHRI) where a non-wearable assistive device adaptively achieves supportability for providing physical assistance and operability to follow the user's intuitive operation. Aiming to mitigate the falling risk of elderly people with reduced mobility with our pHRI approach, we propose a hierarchical algorithm to optimize an admittance control model for a walker robot. By employing dynamic trajectories such as Zero Moment Point (ZMP) and Divergent Component of Motion (DCM) with optimization, our controller provides appropriate physical interaction to improve the gait stability while considering intrinsic body dynamics. In the current implementation, based on a model predictive control (MPC) framework, we formulate the optimization problems in the form of quadratic programming (QP), making the optimization suitable for real-time interaction. Through mechanical assessments with passive walking models of compass gait, we demonstrate the feasibility of our proposed optimization framework in stabilizing the limit cycle gait with minimized assistance.",
        "primary_area": "",
        "author": "Shunki Itadera;Gordon Cheng;Shunki Itadera;Gordon Cheng",
        "authorids": "/37085707829;/37276253300;/37085707829;/37276253300",
        "aff": "Institute for Cognitive Systems, Technical University of Munich, Germany; Institute for Cognitive Systems, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811594/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4870330560602224411&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Institute for Cognitive Systems",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811570",
        "title": "Adversarial Imitation Learning from Video Using a State Observer",
        "track": "main",
        "status": "Poster",
        "abstract": "The imitation learning research community has recently made significant progress towards the goal of enabling artificial agents to imitate behaviors from video demonstrations alone. However, current state-of-the-art approaches developed for this problem exhibit high sample complexity due, in part, to the high-dimensional nature of video observations. Towards addressing this issue, we introduce here a new algorithm called Visual Generative Adversarial Imitation from Observation using a State Observer (VGAIfO-SO). At its core, VGAIfO-SO seeks to address sample inefficiency using a novel, self-supervised state observer, which provides estimates of lower-dimensional proprioceptive state representations from high-dimensional images. We show experimentally in several continuous control environments that VGAIfO-SO is more sample efficient than other IfO algorithms at learning from video-only demonstrations and can sometimes even achieve performance close to the Generative Adversarial Imitation from Observation (GAIfO) algorithm that has privileged access to the demonstrator's proprioceptive state information.",
        "primary_area": "",
        "author": "Haresh Karnan;Faraz Torabi;Garrett Warnell;Peter Stone;Haresh Karnan;Faraz Torabi;Garrett Warnell;Peter Stone",
        "authorids": "/37086310655;/37088467305;/37079072000;/37269574900;/37086310655;/37088467305;/37079072000;/37269574900",
        "aff": "Department of Mechanical Engineering, University of Texas, Austin, USA; Department of Computer Science, University of Texas, Austin, USA; Department of Computer Science, University of Texas, Austin, USA; Department of Computer Science, University of Texas, Austin and Sony AI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811570/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6936004425529556857&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Texas at Austin;University of Texas, Austin",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.utexas.edu;https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin;UT Austin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811948",
        "title": "Aerial Manipulation Using Contact with the Environment by Thrust Vectorable Multilinked Aerial Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, an increasing number of research works have been focusing on the manipulation by aerial robots. Previous works using aerial robots with robotic arms have two problems: underactuation and external disturbances. We propose the fully-actuated control method and motion strategy using contact with the environment to solve these problems, along with the mechanical approach required. First, each propeller's 1 degree-of-freedom (DoF) thrust vectoring units are applied to enable fully-actuated flight control. In order to obtain the desired thrust and vectoring angle inputs for aerial manipulation satisfying hardware limits, we developed a fully-actuated control method using non-linear optimization. Second, we propose a manipulation motion strategy that treats the multilink robot body as a fixed manipulator by making contact with the environment. The contact mechanism attached to the link end is developed to maintain contact and resist external disturbances. In a real machine experiment, the robot successfully opened the door while in contact with the wall, demonstrating the feasibility of the proposed methods.",
        "primary_area": "",
        "author": "Nobuki Sugito;Moju Zhao;Tomoki Anzai;Takuzumi Nishio;Kei Okada;Masayuki Inaba;Nobuki Sugito;Moju Zhao;Tomoki Anzai;Takuzumi Nishio;Kei Okada;Masayuki Inaba",
        "authorids": "/37089447030;/37085684946;/37086287194;/37088506280;/37280639000;/37286658200;/37089447030;/37085684946;/37086287194;/37088506280;/37280639000;/37286658200",
        "aff": "JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811948/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12978829726228321561&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812319",
        "title": "Aerial-Ground Robots Collaborative 3D Mapping in GNSS-Denied Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative heterogeneous robots are expected to perform comprehensive perception, mapping and coordination in search and rescue scenarios. The challenge of collaboration between heterogeneous robots lies in their huge differences in perception, mobility and processing capabilities. In this paper, a novel collaborative UAV-UGV mapping framework is proposed in GNSS-denied and unknown environments. The key novelty of this work is the proposing of a unified framework to formulate the UAV-UGV collaborative mapping problem with a continuous-discrete model, as well as its realization in real robotic systems. In order to project continuous space into discrete space, a novel information gain trigger scheme is pro-posed. The continuous space allows each robot to perform high frequency local map estimation, while discrete space describes the problem of multi-resolution hybrid map fusion. Considering the nature of data heterogeneity, a flexible probabilistic fusion algorithm is proposed that addresses the multi-resolution hybrid map fusion problem, where the local maps generated by UAV and UGV are fused based on Bayesian rule. The proposed UAV-UGV hybrid system is validated in various challenging scenarios, demonstrating its accuracy and utility in practical tasks.",
        "primary_area": "",
        "author": "Yufeng Yue;Chunyang Zhao;Yuanzhe Wang;Yi Yang;Danwei Wang;Yufeng Yue;Chunyang Zhao;Yuanzhe Wang;Yi Yang;Danwei Wang",
        "authorids": "/37086172414;/37088406475;/37086089727;/37899921700;/37279547600;/37086172414;/37088406475;/37086089727;/37899921700;/37279547600",
        "aff": "School of Automation, Beijing Institute of Technology, Beijing, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Automation, Beijing Institute of Technology, Beijing, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812319/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=341378045221279695&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Beijing Institute of Technology;Nanyang Technological University",
        "aff_unique_dep": "School of Automation;School of Electrical and Electronic Engineering",
        "aff_unique_url": "http://www.bit.edu.cn;https://www.ntu.edu.sg",
        "aff_unique_abbr": "BIT;NTU",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Beijing;Singapore",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "9811889",
        "title": "Affordance Learning from Play for Sample-Efficient Policy Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots operating in human-centered environments should have the ability to understand how objects function: what can be done with each object, where this interaction may occur, and how the object is used to achieve a goal. To this end, we propose a novel approach that extracts a self-supervised visual affordance model from human teleoperated play data and leverages it to enable efficient policy learning and motion planning. We combine model-based planning with model-free deep reinforcement learning (RL) to learn policies that favor the same object regions favored by people, while requiring minimal robot interactions with the environment. We evaluate our algorithm, Visual Affordance-guided Policy Optimization (VAPO), with both diverse simulation manipulation tasks and real world robot tidy-up experiments to demonstrate the effectiveness of our affordance-guided policies. We find that our policies train 4 \u00d7 faster than the baselines and generalize better to novel objects because our visual affordance model can anticipate their affordance regions.",
        "primary_area": "",
        "author": "Jessica Borja-Diaz;Oier Mees;Gabriel Kalweit;Lukas Hermann;Joschka Boedecker;Wolfram Burgard;Jessica Borja-Diaz;Oier Mees;Gabriel Kalweit;Lukas Hermann;Joschka Boedecker;Wolfram Burgard",
        "authorids": "/37089450198;/37086205346;/37087323482;/37088504270;/37888921900;/37270485300;/37089450198;/37086205346;/37087323482;/37088504270;/37888921900;/37270485300",
        "aff": "University of Freiburg, Germany; University of Freiburg, Germany; University of Freiburg, Germany; University of Freiburg, Germany; University of Freiburg, Germany; University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811889/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17467643213796504757&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Freiburg",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-freiburg.de",
        "aff_unique_abbr": "UoF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811667",
        "title": "AirDOS: Dynamic SLAM benefits from Articulated Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic Object-aware SLAM (DOS) exploits object-level information to enable robust motion estimation in dynamic environments. Existing methods mainly focus on identifying and excluding dynamic objects from the optimization. In this paper, we show that feature-based visual SLAM systems can also benefit from the presence of dynamic articulated objects by taking advantage of two observations: (1) The 3D structure of each rigid part of articulated object remains consistent over time; (2) The points on the same rigid part follow the same motion. In particular, we present AirDOS, a dynamic object-aware system that introduces rigidity and motion constraints to model articulated objects. By jointly optimizing the camera pose, object motion, and the object 3D structure, we can rectify the camera pose estimation, preventing tracking loss, and generate 4D spatio-temporal maps for both dynamic objects and static scenes. Experiments show that our algorithm improves the robustness of visual SLAM algorithms in challenging crowded urban environments. To the best of our knowledge, AirDOS is the first dynamic object-aware SLAM system demonstrating that camera pose estimation can be improved by incorporating dynamic articulated objects.",
        "primary_area": "",
        "author": "Yuheng Qiu;Chen Wang;Wenshan Wang;Mina Henein;Sebastian Scherer;Yuheng Qiu;Chen Wang;Wenshan Wang;Mina Henein;Sebastian Scherer",
        "authorids": "/37088687947;/37089398088;/37087322184;/37086330243;/37584159000;/37088687947;/37089398088;/37087322184;/37086330243;/37584159000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; System, Theory and Robotics Lab, Australian National University; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811667/",
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7625613382406191219&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Australian National University",
        "aff_unique_dep": "Robotics Institute;System, Theory and Robotics Lab",
        "aff_unique_url": "https://www.cmu.edu;https://www.anu.edu.au",
        "aff_unique_abbr": "CMU;ANU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "9811658",
        "title": "AirLoop: Lifelong Loop Closure Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Loop closure detection is an important building block that ensures the accuracy and robustness of simultaneous localization and mapping (SLAM) systems. Due to their generalization ability, CNN-based approaches have received increasing attention. Although they normally benefit from training on datasets that are diverse and reflective of the environments, new environments often emerge after the model is deployed. It is therefore desirable to incorporate the data newly collected during operation for incremental learning. Nevertheless, simply finetuning the model on new data is infeasible since it may cause the model's performance on previously learned data to degrade over time, which is also known as the problem of catastrophic forgetting. In this paper, we present AirLoop, a method that leverages techniques from lifelong learning to minimize forgetting when training loop closure detection models incrementally. We experimentally demonstrate the effectiveness of AirLoop on TartanAir, Nordland, and RobotCar datasets. To the best of our knowledge, AirLoop is one of the first works to achieve lifelong learning of deep loop closure detectors.",
        "primary_area": "",
        "author": "Dasong Gao;Chen Wang;Sebastian Scherer;Dasong Gao;Chen Wang;Sebastian Scherer",
        "authorids": "/37089450726;/37089398088;/37584159000;/37089450726;/37089398088;/37584159000",
        "aff": "Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811658/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=551921295673706469&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811797",
        "title": "All-in-One: A DRL-based Control Switch Combining State-of-the-art Navigation Planners",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation of mobile robots is an es-sential aspect in use cases such as delivery, assistance or logistics. Although traditional planning methods are well integrated into existing navigation systems, they struggle in highly dynamic en-vironments. On the other hand, Deep-Reinforcement-Learning-based methods show superior performance in dynamic obstacle avoidance but are not suitable for long-range navigation and struggle with local minima. In this paper, we propose a Deep-Reinforcement-Learning-based control switch, which has the ability to select between different planning paradigms based solely on sensor data observations. Therefore, we develop an interface to efficiently operate multiple model-based, as well as learning-based local planners and integrate a variety of state-of-the-art planners to be selected by the control switch. Subsequently, we evaluate our approach against each planner individually and found improvements in navigation performance especially for highly dynamic scenarios. Our planner was able to prefer learning-based approaches in situations with a high number of obstacles while relying on the traditional model-based planners in long corridors or empty spaces.",
        "primary_area": "",
        "author": "Linh KU+000E4stner;Johannes Cox;Teham Buiyan;Jens Lambrecht;Linh KU+000E4stner;Johannes Cox;Teham Buiyan;Jens Lambrecht",
        "authorids": "/37087466037;/37089450213;/37089197716;/37342634600;/37087466037;/37089450213;/37089197716;/37342634600",
        "aff": "Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811797/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12906376044739977637&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Berlin Institute of Technology",
        "aff_unique_dep": "Faculty of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812381",
        "title": "Amplitude Control for Parallel Lattices of Docked Modboats",
        "track": "main",
        "status": "Poster",
        "abstract": "The Modboat is a low-cost, underactuated, modular robot capable of surface swimming. It is able to swim individually, dock to other Modboats, and undock from them using only a single motor and two passive flippers. Undocking without additional actuation is achieved by causing intentional self-collision between the tails of neighboring modules; this becomes a challenge when group swimming as one connected component is desirable. In this work, we develop a control strategy to allow parallel lattices of Modboats to swim as a single unit, which conventionally requires holonomic modules. We show that the control strategy is guaranteed to avoid unintentional undocking and minimizes internal forces within the lattice. Experimental verification shows that the controller performs well and is consistent for lattices of various sizes. Controllability is maintained while swimming, but pure yaw control causes lateral movement that cannot be counteracted by the presented framework.",
        "primary_area": "",
        "author": "Gedaliah Knizhnik;Mark Yim;Gedaliah Knizhnik;Mark Yim",
        "authorids": "/37086285239;/37274063600;/37086285239;/37274063600",
        "aff": "GRASP Laboratory, University of Pensylvannia, Philadelphia, PA; GRASP Laboratory, University of Pensylvannia, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812381/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15132994726640745261&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812441",
        "title": "An Adaptable Approach to Learn Realistic Legged Locomotion without Examples",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning controllers that reproduce legged locomotion in nature has been a longtime goal in robotics and computer graphics. While yielding promising results, recent approaches are not yet flexible enough to be applicable to legged systems of different morphologies. This is partly because they often rely on precise motion capture references or elaborate learning environments that ensure the naturality of the emergent locomotion gaits but prevent generalization. This work proposes a generic approach for ensuring realism in locomotion by guiding the learning process with the spring-loaded inverted pendulum model as a reference. Leveraging on the exploration capacities of Reinforcement Learning (RL), we learn a control policy that fills in the information gap between the template model and full-body dynamics required to maintain stable and periodic locomotion. The proposed approach can be applied to robots of different sizes and morphologies and adapted to any RL technique and control architecture. We present experimental results showing that even in a model-free setup and with a simple reactive control architecture, the learned policies can generate realistic and energy-efficient locomotion gaits for a bipedal and a quadrupedal robot. And most importantly, this is achieved without using motion capture, strong constraints in the dynamics or kinematics of the robot, nor prescribing limb coordination. We provide supplemental videos for qualitative analysis of the naturality of the learned gaits4.",
        "primary_area": "",
        "author": "Daniel Ordonez-Apraez;Antonio Agudo;Francesc Moreno-Noguer;Mario Martin;Daniel Ordonez-Apraez;Antonio Agudo;Francesc Moreno-Noguer;Mario Martin",
        "authorids": "/37089450775;/38231983300;/38274555200;/37089449733;/37089450775;/38231983300;/38274555200;/37089449733",
        "aff": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; Barcelona Supercomputing Center (BSC)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812441/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2862605823779396832&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial;Barcelona Supercomputing Center",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.iri.upc.edu/;https://www.bsc.es",
        "aff_unique_abbr": "IRI;BSC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Barcelona;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9812065",
        "title": "An Adaptive PID Autotuner for Multicopters with Experimental Results",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper develops an adaptive PID autotuner for multicopters, and presents simulation and experimental results. The autotuner consists of adaptive digital control laws based on retrospective cost adaptive control implemented in the PX4 flight stack. A learning trajectory is used to optimize the autopilot during a single flight. The autotuned autopilot is then compared with the default PX4 autopilot by flying a test trajectory constructed using the second-order Hilbert curve. In order to investigate the sensitivity of the autotuner to the quadcopter dynamics, the mass of the quadcopter is varied, and the performance of the autotuned and default autopilot is compared. It is observed that the autotuned autopilot outperforms the default autopilot.",
        "primary_area": "",
        "author": "John Spencer;Joonghyun Lee;Juan Augusto Paredes;Ankit Goel;Dennis Bernstein;John Spencer;Joonghyun Lee;Juan Augusto Paredes;Ankit Goel;Dennis Bernstein",
        "authorids": "/37089449815;/37089447453;/37086009317;/37085430576;/37271808000;/37089449815;/37089447453;/37086009317;/37085430576;/37271808000",
        "aff": "Department of Aerospace Engineering, University of Michigan, Ann Arbor, MI; Department of Aerospace Engineering, University of Michigan, Ann Arbor, MI; Department of Aerospace Engineering, University of Michigan, Ann Arbor, MI; Department of Mechanical Engineering, University of Maryland, Baltimore County, Md; Department of Aerospace Engineering, University of Michigan, Ann Arbor, MI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812065/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9750576271416640139&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Michigan;University of Maryland, Baltimore County",
        "aff_unique_dep": "Department of Aerospace Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.umich.edu;https://www.umbc.edu",
        "aff_unique_abbr": "UM;UMBC",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Ann Arbor;Baltimore County",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812153",
        "title": "An Agile Bicycle-like Robot for Complex Steel Structure Inspection",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a simple but compact design of a bicycle-like robot for inspecting complex-shaped ferromagnetic structures. The design concept for versatile locomotion relies on two independently steered magnetic wheels formed in a bicycle-like configuration, allowing the robot to possess multi-directional mobility. The key feature of a reciprocating mechanism enables the robot to change its shape when passing obstacles. A dynamic joint of the robot configuration makes it naturally adapt to uneven and complex surfaces of steel structures. We demonstrate the usability and practical deployment of the robot for steel thickness measurement using an ultrasonic sensor.",
        "primary_area": "",
        "author": "Son Thanh Nguyen;Hai Nguyen;Son Tien Bui;Van Anh Ho;Trung Dung Ngo;Hung Manh La;Son Thanh Nguyen;Hai Nguyen;Son Tien Bui;Van Anh Ho;Trung Dung Ngo;Hung Manh La",
        "authorids": "/37087321874;/37086805743;/37089447757;/37529964700;/37602317100;/37542872700;/37087321874;/37086805743;/37089447757;/37529964700;/37602317100;/37542872700",
        "aff": "Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA; Northeastern University, USA; Japan Advanced Institute of Science and Tech., Japan; Japan Advanced Institute of Science and Tech., Japan; University of Prince Edward Island, Canada; Department of Computer Science and Engineering, Advanced Robotics and Automation (ARA) Lab, University of Nevada, Reno, NV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812153/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14388775439585936620&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;3;0",
        "aff_unique_norm": "University of Nevada, Reno;Northeastern University;Japan Advanced Institute of Science and Technology;University of Prince Edward Island",
        "aff_unique_dep": "Department of Computer Science and Engineering;;;",
        "aff_unique_url": "https://www.unr.edu;https://www.northeastern.edu;https://www.jaist.ac.jp;https://www.upei.ca",
        "aff_unique_abbr": "UNR;NEU;JAIST;UPEI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Reno;",
        "aff_country_unique_index": "0;0;1;1;2;0",
        "aff_country_unique": "United States;Japan;Canada"
    },
    {
        "id": "9811867",
        "title": "An Assembly Sequence Planning Framework for Complex Data using General Voronoi Diagram",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the first realization of an assembly sequence planning framework for large-scale and complex 3D real-world CAD scenarios. Other than in academic benchmark data sets, in our scenario each assembled part is allowed to contain flexible fastening elements and the number of assembled parts is quite high. With our framework we are able to derive a meaningful assembly priority graph for the parts. Our framework divides the disassembly motion of each part into a NEAR- and a subsequent FAR planning phase and uses existing specialized motion planners for each phase. To reduce the number of unsuccessful motion planning requests we use a general Voronoi diagram graph and a novel collision perceiving method which significantly speed up our framework. At the end, we create an assembly priority graph to indicate which parts must be disassembled before others. In our experiments, we show that our framework is the first one which is able to generate a priority graph for a representative data set from the automotive industry. Moreover, the reported disassembly motions for the individual parts are shorter and can be computed faster than with other state-of-the-art frameworks.",
        "primary_area": "",
        "author": "Sebastian Dorn;Nicola Wolpert;Elmar Sch\u00f6mer;Sebastian Dorn;Nicola Wolpert;Elmar Sch\u00f6mer",
        "authorids": "/37088503781;/37085352554;/37331462600;/37088503781;/37085352554;/37331462600",
        "aff": "Production Planning, Mercedes-Benz, AG, Germany; Department: Geomatics, Computer Science and Mathematics, University of Applied Science, Stuttgart, Germany; Department: Physics, Mathematics and Computer Science, Johannes Gutenberg - University, Mainz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811867/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8515410472203099795&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Mercedes-Benz AG;University of Applied Sciences Stuttgart;Johannes Gutenberg University Mainz",
        "aff_unique_dep": "Production Planning;Department of Geomatics, Computer Science and Mathematics;Department of Physics, Mathematics and Computer Science",
        "aff_unique_url": "https://www.mercedes-benz.com;https://www.hft-stuttgart.de;https://www.jgu.de",
        "aff_unique_abbr": "MB AG;HFT Stuttgart;JGU",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Stuttgart;Mainz",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811834",
        "title": "An Experimental Study of Wind Resistance and Power Consumption in MAVs with a Low-Speed Multi-Fan Wind System",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper discusses a low-cost, open-source and open-hardware design and performance evaluation of a low-speed, multi-fan wind system dedicated to micro air vehicle (MAV) testing. In addition, a set of experiments with a flapping wing MAV and rotorcraft is presented, demonstrating the capabilities of the system and the properties of these different types of drones in response to various types of wind. We performed two sets of experiments where a MAV is flying into the wake of the fan system, gathering data about states, battery voltage and current. Firstly, we focus on steady wind conditions with wind speeds ranging from 0.5 m S-1 to 3.4 m S-1. During the second set of experiments, we introduce wind gusts, by periodically modulating the wind speed from 1.3 m S\u22121 to 3.4 m S\u22121 with wind gust oscillations of 0.5 Hz, 0.25 Hz and 0.125 Hz. The \u201cFlapper\u201d flapping wing MAV requires much larger pitch angles to counter wind than the \u201cCrazyFlie\u201d quadrotor. This is due to the Flapper's larger wing surface. In forward flight, its wings do provide extra lift, considerably reducing the power consumption. In contrast, the CrazyFlie's power consumption stays more constant for different wind speeds. The experiments with the varying wind show a quicker gust response by the CrazyFlie compared with the Flapper drone, but both their responses could be further improved. We expect that the proposed wind gust system will provide a useful tool to the community to achieve such improvements.",
        "primary_area": "",
        "author": "Diana A. Olejnik;Sunyi Wang;Julien Dupeyroux;Stein Stroobants;Matej Karasek;Christophe De Wagter;Guido de Croon;Diana A. Olejnik;Sunyi Wang;Julien Dupeyroux;Stein Stroobants;Matej Karasek;Christophe De Wagter;Guido de Croon",
        "authorids": "/37086029766;/37089449988;/37086222518;/37089449015;/37086182071;/37862967200;/37698062600;/37086029766;/37089449988;/37086222518;/37089449015;/37086182071;/37862967200;/37698062600",
        "aff": "Department of Control and Operations, MAVLab, Delft University of Technology, the Netherlands; Department of Control and Operations, MAVLab, Delft University of Technology, the Netherlands; Department of Control and Operations, MAVLab, Delft University of Technology, the Netherlands; Department of Control and Operations, MAVLab, Delft University of Technology, the Netherlands; Department of Control and Operations, MAVLab, Delft University of Technology, the Netherlands; Department of Control and Operations, MAVLab, Delft University of Technology, the Netherlands; Department of Control and Operations, MAVLab, Delft University of Technology, the Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811834/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12132489446728781951&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Department of Control and Operations",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9811375",
        "title": "An Indeterministic Vision-Based State Observer for Growing Magnetic Microrobot Motion Status Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "To date, untethered micro/nanorobots have attracted considerable attention in various aspects due to their unique potential for in-vivo applications such as the targeted therapy. One of the most promising types of micro/nanorobots is the class of ferromagnetic microrobots which can be efficiently actuated via gradient/rotational magnetic field generated by less costly electromagnetic coil systems. For performing successful operations, locomotion control of the magnetic microrobots is non-trivial. Modern controllers commonly require motion status-based feedback. To fully utilize those advanced approaches, motion state of one microrobot should be supplied, however it is still challenging in cases. It is noted that, during locomotion, one ferromagnetic microrobot can combine with others to form an unstructured larger one, namely growing magnetic microrobot (GMM), whose dynamic behavior keeps changing, and thus the model-based observers are never applicable. Besides, tracking and estimating states of those unstructured time-varying GMMs in complex surroundings are always challenging, especially for an uneven sampling scenario. In order to accurately estimate the GMM motion status in a complex environment via micro-vision, this study develops an indeterministic observer leveraging on the approach of discriminative correlation filter with channel/spatial reliability (CSR-DCF) and the variable-step finite-time sliding mode (FSM-V) state estimation theory. Experimental study verifies that the proposed observation scheme can effectively estimate motion states of one GMM moving in obstacle surroundings throughout.",
        "primary_area": "",
        "author": "Zhiyong Sun;Yu Cheng;Chao Zhou;Erkang Cheng;Gengliang Chen;Lixin Dong;Bo Song;Zhiyong Sun;Yu Cheng;Chao Zhou;Erkang Cheng;Gengliang Chen;Lixin Dong;Bo Song",
        "authorids": "/37085395655;/37085377130;/37876898300;/37088874018;/37088578554;/37275019100;/37400698100;/37085395655;/37085377130;/37876898300;/37088874018;/37088578554;/37275019100;/37400698100",
        "aff": "Institute of Intelligent Machines, Hefei Institute of Physical Science CAS, Hefei, China; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Institute of Plasma Physics, Hefei Institute of Physical Science, CAS, Hefei, China; Institute of Intelligent Machines, Hefei Institute of Physical Science CAS, Hefei, China; Shenzhen Technology University, Shenzhen Academy of Robotics, Shenzhen, Guangdong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Institute of Intelligent Machines, Hefei Institute of Physical Science CAS, Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811375/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16586534307131828540&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;3;4;0",
        "aff_unique_norm": "Hefei Institute of Physical Science, Chinese Academy of Sciences;Michigan State University;Hefei Institute of Physical Science;Shenzhen Technology University;City University of Hong Kong",
        "aff_unique_dep": "Institute of Intelligent Machines;Department of Electrical and Computer Engineering;Institute of Plasma Physics;;Department of Biomedical Engineering",
        "aff_unique_url": "http://www.hfips.ac.cn;https://www.msu.edu;http://www.hipac.cn;;https://www.cityu.edu.hk",
        "aff_unique_abbr": "HFIPS;MSU;HIPAC;;CityU",
        "aff_campus_unique_index": "0;1;0;0;2;3;0",
        "aff_campus_unique": "Hefei;East Lansing;Shenzhen;Hong Kong",
        "aff_country_unique_index": "0;1;0;0;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9812335",
        "title": "An Integrated Design Pipeline for Tactile Sensing Robotic Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional robotic manipulator design methods require extensive, time-consuming, and manual trial and error to produce a viable design. During this process, engineers often spend their time redesigning or reshaping components as they discover better topologies for the robotic manipula-tor. Tactile sensors, while useful, often complicate the design due to their bulky form factor. We propose an integrated design pipeline to streamline the design and manufacturing of robotic manipulators with knitted, glove-like tactile sensors. The proposed pipeline allows a designer to assemble a collection of modular, open-source components by applying predefined graph grammar rules. The end result is an intuitive design paradigm that allows the creation of new virtual designs of manipulators in a matter of minutes. Our framework allows the designer to fine-tune the manipulator's shape through cage-based geometry deformation. Finally, the designer can select surfaces for adding tactile sensing. Once the manipulator design is finished, the program will automatically generate 3D printing and knitting files for manufacturing. We demonstrate the utility of this pipeline by creating four custom manipulators tested on real-world tasks: screwing in a wing nut, pouring water from a bottle, picking up an egg, and cutting paper with scissors.",
        "primary_area": "",
        "author": "Lara Zlokapa;Yiyue Luo;Jie Xu;Michael Foshey;Kui Wu;Pulkit Agrawal;Wojciech Matusik;Lara Zlokapa;Yiyue Luo;Jie Xu;Michael Foshey;Kui Wu;Pulkit Agrawal;Wojciech Matusik",
        "authorids": "/37089447908;/37089013363;/37088996337;/37089013761;/37089447962;/37085611190;/37295070400;/37089447908;/37089013363;/37088996337;/37089013761;/37089447962;/37085611190;/37295070400",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Lightspeed & Quantum Studios, Tencent America, Los Angeles, CA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812335/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1460668519305047238&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Tencent",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Tencent America",
        "aff_unique_url": "https://www.mit.edu;https://www.tencent.com",
        "aff_unique_abbr": "MIT;Tencent",
        "aff_campus_unique_index": "0;0;0;0;1;0;0",
        "aff_campus_unique": "Cambridge;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812160",
        "title": "An MPC Framework For Planning Safe & Trustworthy Robot Motions",
        "track": "main",
        "status": "Poster",
        "abstract": "Strategies for safe human-robot interaction (HRI), such as the well-established Safe Motion Unit, provide a velocity scaling for biomechanically safe robot motion. In addition, psychologically-based safety approaches are required for trustworthy HRI. Such schemes can be very conservative and robot motion complying with such safety approaches should be time efficient within the robot motion planning. In this study, we improve the efficiency of a previously introduced approach for psychologically-based safety in HRI via a Model Predictive Control robot motion planner that simultaneously adjusts Cartesian path and speed to minimise the distance to the target pose as fast as possible. A subordinate real-time motion generator ensures human physical safety by integrating the Safe Motion Unit. Our motion planner is validated by two experiments. The simultaneous adjustment of path and velocity accomplishes highly time efficient robot motion, while considering the human physical and psychological safety. Compared to direct path velocity scaling approaches our planner enables 28 % faster motion execution.",
        "primary_area": "",
        "author": "Moritz Eckhoff;Robin Jeanne Kirschner;Elena Kern;Saeed Abdolshah;Sami Haddadin;Moritz Eckhoff;Robin Jeanne Kirschner;Elena Kern;Saeed Abdolshah;Sami Haddadin",
        "authorids": "/37089446685;/37088861072;/37089447933;/37086148547;/37542865300;/37089446685;/37088861072;/37089447933;/37086148547;/37542865300",
        "aff": "Chair for Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Chair for Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Chair for Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Chair for Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Chair for Robotics and Systems Intelligence, Munich Institute of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812160/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7971858089813251399&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Chair for Robotics and Systems Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812197",
        "title": "An Over-Actuated Bionic Knee Prosthesis: Modeling, Design and Preliminary Experimental Characterization",
        "track": "main",
        "status": "Poster",
        "abstract": "A pressing challenge in the design of actuated knee prostheses is the ability to address the high variation of speed and torque requirements for the different types and phases of locomotion. This manuscript presents a novel over-actuated knee prosthesis which makes use of a dual motor actuation architecture to address this issue. It utilizes a high speed/low torque motor to enable natural and highly dynamical motion, as required for swing phases of walking, which is permanently engaged. In addition to this motor, a clutchable uni-directional low dynamics high torque motor is present to assist during the execution of tasks which demand active torque. Preliminary experimental validations have been performed on a healthy subject provided with an able-bodied adapter to demonstrate natural walk patterns and power-assisted sit-to-stand activities.",
        "primary_area": "",
        "author": "Lorenzo Guercini;Federico Tessari;Josephus Driessen;Stefano Buccelli;Anna Pace;Samuele De Giuseppe;Simone Traverso;Lorenzo De Michieli;Matteo Laffranchi;Lorenzo Guercini;Federico Tessari;Josephus Driessen;Stefano Buccelli;Anna Pace;Samuele De Giuseppe;Simone Traverso;Lorenzo De Michieli;Matteo Laffranchi",
        "authorids": "/37089447456;/37088534054;/37086579834;/37086497964;/37088658994;/37088503805;/37089448510;/37087850759;/37528362900;/37089447456;/37088534054;/37086579834;/37086497964;/37088658994;/37088503805;/37089448510;/37087850759;/37528362900",
        "aff": "Rehab Technologies Laboratory, Istituto Italiano di Tecnologia, Genova, Italy; Rehab Technologies Laboratory, Istituto Italiano di Tecnologia, Genova, Italy; Rehab Technologies Laboratory, Istituto Italiano di Tecnologia, Genova, Italy; Rehab Technologies Laboratory, Istituto Italiano di Tecnologia, Genova, Italy; Rehab Technologies Laboratory, Istituto Italiano di Tecnologia, Genova, Italy; Rehab Technologies Laboratory, Istituto Italiano di Tecnologia, Genova, Italy; Rehab Technologies Laboratory, Istituto Italiano di Tecnologia, Genova, Italy; Rehab Technologies Laboratory, Istituto Italiano di Tecnologia, Genova, Italy; Rehab Technologies Laboratory, Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812197/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11392879268477844600&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Rehab Technologies Laboratory",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9811833",
        "title": "An in-depth experimental study of sensor usage and visual reasoning of robots navigating in real environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual navigation by mobile robots is classically tackled through SLAM plus optimal planning, and more recently through end-to-end training of policies implemented as deep networks. While the former are often limited to waypoint planning, but have proven their efficiency even on real physical environments, the latter solutions are most frequently employed in simulation, but have been shown to be able learn more complex visual reasoning, involving complex semantic regularities. Navigation by real robots in physical environments is still an open problem. End-to-end training approaches have been thoroughly tested in simulation only, with experiments involving real robots being restricted to rare performance evaluations in simplified laboratory conditions. In this work we present an in-depth study of the performance and reasoning capacities of real physical agents, trained in simulation and deployed to two different physical environments. Beyond benchmarking, we provide insights into the generalization capabilities of different agents training in different conditions. We visualize sensor usage and the importance of the different types of signals. We show, that for the PointGoal task, an agent pre-trained on wide variety of tasks and fine-tuned on a simulated version of the target environment can reach competitive performance without modelling any sim2real transfer, i.e. by deploying the trained agent directly from simulation to a real physical robot.",
        "primary_area": "",
        "author": "Assem Sadek;Guillaume Bono;Boris Chidlovskii;Christian Wolf;Assem Sadek;Guillaume Bono;Boris Chidlovskii;Christian Wolf",
        "authorids": "/37088686419;/37089161767;/37373194900;/37285119900;/37088686419;/37089161767;/37373194900;/37285119900",
        "aff": "Naver Labs Europe, Meylan, France; LIRIS, UMR CNRS 5205, Universite de Lyon, INSA Lyon, Villeurbanne, France; Naver Labs Europe, Meylan, France; LIRIS, UMR CNRS 5205, Universite de Lyon, INSA Lyon, Villeurbanne, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811833/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6735196880961037150&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "NAVER LABS Europe;Universite de Lyon",
        "aff_unique_dep": ";LIRIS",
        "aff_unique_url": "https://labs.naver.com;https://www.universite-lyon.fr",
        "aff_unique_abbr": "NLE;UDL",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Meylan;Lyon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812292",
        "title": "An observer cascade for velocity and multiple line estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Previous incremental estimation methods consider estimating a single line, requiring as many observers as the number of lines to be mapped. This leads to the need for having at least 4N state variables, with N being the number of lines. This paper presents the first approach for multi-line incremental estimation. Since lines are common in structured environments, we aim to exploit that structure to reduce the state space. The modeling of structured environments proposed in this paper reduces the state space to 3N + 3 and is also less susceptible to singular configurations. An assumption the previous methods make is that the camera velocity is available at all times. However, the velocity is usually retrieved from odometry, which is noisy. With this in mind, we propose coupling the camera with an Inertial Measurement Unit (IMU) and an observer cascade. A first observer retrieves the scale of the linear velocity and a second observer for the lines mapping. The stability of the entire system is analyzed. The cascade is shown to be asymptotically stable and shown to converge in experiments with simulated data.",
        "primary_area": "",
        "author": "Andr\u00e9 Mateus;Pedro U. Lima;Pedro Miraldo;Andr\u00e9 Mateus;Pedro U. Lima;Pedro Miraldo",
        "authorids": "/37086110885;/37267147500;/38241727500;/37086110885;/37267147500;/38241727500",
        "aff": "Institute for Systems and Robotics (ISR/IST), LARSyS, Instituto Superior T\u00e9cnico, Univ. Lisboa, Portugal; Institute for Systems and Robotics (ISR/IST), LARSyS, Instituto Superior T\u00e9cnico, Univ. Lisboa, Portugal; Institute for Systems and Robotics (ISR/IST), LARSyS, Instituto Superior T\u00e9cnico, Univ. Lisboa, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812292/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:s43CiJqMV2YJ:scholar.google.com/&scioq=An+observer+cascade+for+velocity+and+multiple+line+estimation&hl=en&as_sdt=0,14",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Instituto Superior T\u00e9cnico",
        "aff_unique_dep": "Institute for Systems and Robotics (ISR/IST)",
        "aff_unique_url": "https://www.ist.utl.pt",
        "aff_unique_abbr": "IST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "9812118",
        "title": "Analyzing Multiagent Interactions in Traffic Scenes via Topological Braids",
        "track": "main",
        "status": "Poster",
        "abstract": "We focus on the problem of analyzing multiagent interactions in traffic domains. Understanding the space of behavior of real-world traffic may offer significant advantages for algorithmic design, data-driven methodologies, and bench-marking. However, the high dimensionality of the space and the stochasticity of human behavior may hinder the identification of important interaction patterns. Our key insight is that traffic environments feature significant geometric and temporal structure, leading to highly organized collective behaviors, often drawn from a small set of dominant modes. In this work, we propose a representation based on the formalism of topological braids that can summarize arbitrarily complex multiagent behavior into a compact object of dual geometric and symbolic nature, capturing critical events of interaction. This representation allows us to formally enumerate the space of outcomes in a traffic scene and characterize their complexity. We illustrate the value of the proposed representation in summarizing critical aspects of real-world traffic behavior through a case study on recent driving datasets. We show that despite the density of real-world traffic, observed behavior tends to follow highly organized patterns of low interaction. Our framework may be a valuable tool for evaluating the richness of driving datasets, but also for synthetically designing balanced training datasets or benchmarks.",
        "primary_area": "",
        "author": "Christoforos Mavrogiannis;Jonathan DeCastro;Siddhartha S. Srinivasa;Christoforos Mavrogiannis;Jonathan DeCastro;Siddhartha S. Srinivasa",
        "authorids": "/37077312800;/37400557200;/37339877600;/37077312800;/37400557200;/37339877600",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, WA, USA; Toyota Research Institute, Cambridge, MA, USA; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812118/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11397923008635900997&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Washington;Toyota Research Institute",
        "aff_unique_dep": "Paul G. Allen School of Computer Science & Engineering;",
        "aff_unique_url": "https://www.washington.edu;https://www.tri.global",
        "aff_unique_abbr": "UW;TRI",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Seattle;Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812445",
        "title": "Anti-collision Static Rotation Local Planner for Four Independent Steering Drive Self-reconfigurable Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Pavement cleaning is a labor-intensive, repetitive task and can be automated. Several autonomous pavement cleaning robots have been developed, pushing research towards their design and autonomous capabilities. Advances in design have been reported in earlier works on a self-reconfigurable robot with four independent steering drive (4ISD) capabilities, Panthera, for pavement cleaning and maintenance. Moreover, autonomous navigation requires sharp turns, heading angle adjustments, sideways movement, and locomotion without col-lision through constrained pavement conditions. The present work proposes an algorithm to ingeniously select the instan-taneous center of rotation (ICR) within the self-reconfigurable robot footprint and perform static rotation to adjust its heading angle during the waypoint navigation while avoiding collision with the constrained environment. Finally, the proposed algorithm is implemented, and experiments are conducted in real-world pavement scenarios. The experimental outcome success-fully demonstrates the self-reconfigurable robot's capability to navigate constrained pavement scenarios using the proposed algorithm during autonomous cleaning and maintenance tasks.",
        "primary_area": "",
        "author": "Lim Yi;Anh Vu Le;A.A. Hayat;K. Elangovan;K. Leong;A. Povendhan;M.R. Elara;Lim Yi;Anh Vu Le;A.A. Hayat;K. Elangovan;K. Leong;A. Povendhan;M.R. Elara",
        "authorids": "/37088429249;/37086917297;/37085563101;/37088428727;/37089450481;/37089000428;/37546093700;/37088429249;/37086917297;/37085563101;/37088428727;/37089450481;/37089000428;/37546093700",
        "aff": "Lim Yi; Anh Vu Le; A.A. Hayat; K. Elangovan; K. Leong; A. Povendhan; M.R. Elara",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812445/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8267110232602983713&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "1",
        "aff_unique_norm": ";A.A. Hayat",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9811709",
        "title": "Approximating the Polynomial System for Effective Relative Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Finding relative pose for cameras is of vital importance in computer vision and robotics. We investigate the problem of relative motion estimation between successive frames from a minimal number of correspondences. Existing approximated methods use a first-order approximation to relative pose in order to simplify the problem and produce an estimate quickly. Our solution uses Cayley parameterization to represent rotation and simplifies the high-degree polynomials only at the very end of the formulation, resulting in more accurate models. Furthermore, our method can be more effective if the camera rotates mainly around one coordinate axis. By treating the main rotation component as the hidden variable in the solution, we can retain more high-degree terms for the main rotation part, considerably widening the effective approximation range. Our experiments show that our method is more accurate than existing approximated solver, and that it is still effective for relatively large motions. Besides, our method produces far fewer solutions than essential matrix parameterized solvers.",
        "primary_area": "",
        "author": "Deshun Hu;Deshun Hu",
        "authorids": "/37086129601;/37086129601",
        "aff": "Department of Communication Engineering, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811709/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7408600715584004136&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "Department of Communication Engineering",
        "aff_unique_url": "http://www.hit.edu.cn",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811864",
        "title": "Assisting Operators of Articulated Machinery with Optimal Planning and Goal Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Operating an articulated machine is a complex and hierarchical task, involving several levels of decision making. Motivated by the timber-harvesting applications of these machines, we are interested in developing a collaborative framework for operating an articulated machine/robot in order to increase its level of autonomy. In this paper, we consider two problems in the context of collaborative operation of a feller-buncher: first, the problem of planning a sequence of cut/grasp/bunch tasks for the trees in the vicinity of the machine. Here we propose a human-inspired planning algorithm based on our observations of the operators in the field. Then, a Markov Decision Process (MDP) framework is provided, which enables us to obtain an optimal sequence of tasks. We provide numerical illustrations of how our MDP framework works. Second is the problem of inferring the operator's goal from the motions of the machine. The goal inference algorithm presented here enables the robot equipped with the planning intelligence to perceive the human's intent in real-time. We evaluate the performance of our goal inference algorithm through a user-study with a feller-buncher simulator. The results show the benefits of our algorithm over a robot that assumes the human is moving to the closest target.",
        "primary_area": "",
        "author": "Ehsan Yousefi;Dylan P. Losey;Inna Sharf;Ehsan Yousefi;Dylan P. Losey;Inna Sharf",
        "authorids": "/37089108206;/37085812055;/37283633500;/37089108206;/37085812055;/37283633500",
        "aff": "Dept. of Mechanical Engineering, McGill University, Montreal, QC, Canada; Dept. of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Dept. of Mechanical Engineering, McGill University, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811864/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10518156197885825179&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "McGill University;Virginia Tech",
        "aff_unique_dep": "Department of Mechanical Engineering;Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.mcgill.ca;https://www.vt.edu",
        "aff_unique_abbr": "McGill;VT",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Montreal;Blacksburg",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9811919",
        "title": "AstroLoc: An Efficient and Robust Localizer for a Free-flying Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "We present AstroLoc, an efficient and robust monocular visual-inertial graph-based localization system used by the Astrobee free-flying robots onboard the International Space Station (ISS). We provide a novel localization system that limits the traditionally higher computation times for graph-based localization systems and enables the resource constrained Astrobee robots to benefit from their increased accuracy. We also introduce methods for handling cheirality issues for visual odometry and localization factors that further increase localization robustness. We evaluate the performance of AstroLoc on a dataset of ISS activities and show that it greatly improves pose, velocity, and IMU bias estimation accuracy while efficiently running in a limited computation environment. AstroLoc has improved the localization accuracy for the Astrobee robots on the ISS and has led to more successful and longer duration activities. While the AstroLoc system is tuned for the Astrobee robots, it can be configured for any resource constrained platform. The source code for AstroLoc is released to the public.",
        "primary_area": "",
        "author": "Ryan Soussan;Varsha Kumar;Brian Coltin;Trey Smith;Ryan Soussan;Varsha Kumar;Brian Coltin;Trey Smith",
        "authorids": "/37088229840;/37089447153;/37592328000;/37085701375;/37088229840;/37089447153;/37592328000;/37085701375",
        "aff": "Aerodyne Industries; Carnegie Mellon University, Pittsburgh, PA, USA; KBR, Inc.; NASA Ames Research Center, Moffett Field, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811919/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9315435093743380150&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Aerodyne Industries;Carnegie Mellon University;KBR, Inc.;NASA Ames Research Center",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.aerodyne.com;https://www.cmu.edu;https://www.kbr.com;https://ames.nasa.gov",
        "aff_unique_abbr": ";CMU;KBR;NASA Ames",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Pittsburgh;Moffett Field",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811613",
        "title": "Asynchronous Collaborative Localization by Integrating Spatiotemporal Graph Learning with Model-Based Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative localization is an essential capability for a team of robots such as connected vehicles to collaboratively estimate object locations from multiple perspectives with reliant cooperation. To enable collaborative localization, four key challenges must be addressed, including modeling complex relationships between observed objects, fusing observations from an arbitrary number of collaborating robots, quantifying localization uncertainty, and addressing latency of robot communications. In this paper, we introduce a novel approach that integrates uncertainty-aware spatiotemporal graph learning and model-based state estimation for a team of robots to collaboratively localize objects. Specifically, we introduce a new uncertainty-aware graph learning model that learns spatiotemporal graphs to represent historical motions of the objects observed by each robot over time and provides uncertainties in object localization. Moreover, we propose a novel method for integrated learning and model-based state estimation, which fuses asynchronous observations obtained from an arbitrary number of robots for collaborative localization. We evaluate our approach in two collaborative object localization scenarios in simulations and on real robots. Experimental results show that our approach outperforms previous methods and achieves state-of-the-art performance on asynchronous collaborative localization.",
        "primary_area": "",
        "author": "Peng Gao;Brian Reily;Rui Guo;Hongsheng Lu;Qingzhao Zhu;Hao Zhang;Peng Gao;Brian Reily;Rui Guo;Hongsheng Lu;Qingzhao Zhu;Hao Zhang",
        "authorids": "/37089501844;/37088504746;/37086487136;/37085839592;/37088503796;/37085545929;/37089501844;/37088504746;/37086487136;/37085839592;/37088503796;/37085545929",
        "aff": "Human-Centered Robotics Laboratory, Colorado School of Mines, Golden, CO, USA; DEVCOM Army Research Laboratory; Toyota Motor North America, Mountain View, CA, USA; Toyota Motor North America, Mountain View, CA, USA; Human-Centered Robotics Laboratory, Colorado School of Mines, Golden, CO, USA; Human-Centered Robotics Laboratory, Colorado School of Mines, Golden, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811613/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10875883815300878242&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;0;0",
        "aff_unique_norm": "Colorado School of Mines;United States Army Research Laboratory;Toyota Motor North America",
        "aff_unique_dep": "Human-Centered Robotics Laboratory;Army Research Laboratory;",
        "aff_unique_url": "https://www.mines.edu;https://www.arl.army.mil;https://www.toyota.com",
        "aff_unique_abbr": "CSM;ARL;TMNA",
        "aff_campus_unique_index": "0;2;2;0;0",
        "aff_campus_unique": "Golden;;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811943",
        "title": "Asynchronous Optimisation for Event-based Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Event cameras open up new possibilities for robotic perception due to their low latency and high dynamic range. On the other hand, developing effective event-based vision algorithms that fully exploit the beneficial properties of event cameras remains work in progress. In this paper, we focus on event-based visual odometry (VO). While existing event-driven VO pipelines have adopted continuous-time representations to asynchronously process event data, they either assume a known map, restrict the camera to planar trajectories, or integrate other sensors into the system. Towards map-free event-only monocular VO in SE(3), we propose an asynchronous structure-from-motion optimisation back-end. Our formulation is underpinned by a principled joint optimisation problem involving non-parametric Gaussian Process motion modelling and incremental maximum a posteriori inference. A high-performance incremental computation engine is employed to reason about the camera trajectory with every incoming event. We demonstrate the robustness of our asynchronous back-end in comparison to frame-based methods which depend on accurate temporal accumulation of measurements.",
        "primary_area": "",
        "author": "Daqi Liu;Alvaro Parra;Yasir Latif;Bo Chen;Tat-Jun Chin;Ian Reid;Daqi Liu;Alvaro Parra;Yasir Latif;Bo Chen;Tat-Jun Chin;Ian Reid",
        "authorids": "/37088454667;/37088232465;/38541523400;/37088230116;/37411757200;/37282640200;/37088454667;/37088232465;/38541523400;/37088230116;/37411757200;/37282640200",
        "aff": "SmartSat CRC Professorial Chair of Sentient Satellites; SmartSat CRC Professorial Chair of Sentient Satellites; SmartSat CRC Professorial Chair of Sentient Satellites; SmartSat CRC Professorial Chair of Sentient Satellites; School of Computer Science, The University of Adelaide; SmartSat CRC Professorial Chair of Sentient Satellites",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811943/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14443656002837005682&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "SmartSat CRC;University of Adelaide",
        "aff_unique_dep": "Professorial Chair of Sentient Satellites;School of Computer Science",
        "aff_unique_url": "https://smartsatcrc.com;https://www.adelaide.edu.au",
        "aff_unique_abbr": "SmartSat CRC;Adelaide",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9811771",
        "title": "Asynchronous Reinforcement Learning for Real-Time Control of Physical Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "An oft-ignored challenge of real-world reinforcement learning is that the real world does not pause when agents make learning updates. As standard simulated environments do not address this real-time aspect of learning, most available implementations of RL algorithms process environment interactions and learning updates sequentially. As a consequence, when such implementations are deployed in the real world, they may make decisions based on significantly delayed observations and not act responsively. Asynchronous learning has been proposed to solve this issue, but no systematic comparison between sequential and asynchronous reinforcement learning was conducted using real-world environments. In this work, we set up two vision-based tasks with a robotic arm, implement an asynchronous learning system that extends a previous architecture, and compare sequential and asynchronous reinforcement learning across different action cycle times, sensory data dimensions, and mini-batch sizes. Our experiments show that when the time cost of learning updates increases, the action cycle time in sequential implementation could grow excessively long, while the asynchronous implementation can always maintain an appropriate action cycle time. Consequently, when learning updates are expensive, the performance of sequential learning diminishes and is outperformed by asynchronous learning by a substantial margin. Our system learns in real-time to reach and track visual targets from pixels within two hours of experience and does so directly using real robots, learning completely from scratch. Our code is available at: https://github.com/YufengYuan/ur5_async_r1.",
        "primary_area": "",
        "author": "Yufeng Yuan;A. Rupam Mahmood;Yufeng Yuan;A. Rupam Mahmood",
        "authorids": "/37088394240;/37408373700;/37088394240;/37408373700",
        "aff": "Department of Computing Science, University of Alberta, Edmonton, Canada; CIFAR AI Chair, Alberta Machine Intelligence Institute (Amii)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811771/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=509624956066207005&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Alberta;Alberta Machine Intelligence Institute",
        "aff_unique_dep": "Department of Computing Science;AI Chair",
        "aff_unique_url": "https://www.ualberta.ca;https://www.amii.ca",
        "aff_unique_abbr": "UAlberta;Amii",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Edmonton;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812281",
        "title": "Attentive One-Shot Meta-Imitation Learning From Visual Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to apply a previously-learned skill (e.g., pushing) to a new task (context or object) is an important requirement for new-age robots. An attempt is made to solve this problem in this paper by proposing a deep meta-imitation learning framework comprising of an attentive-embedding net-work and a control network, capable of learning a new task in an end-to-end manner while requiring only one or a few visual demonstrations. The feature embeddings learnt by incorporating spatial attention is shown to provide higher embedding and control accuracy compared to other state-of-the-art methods such as TecNet [7] and MIL [4]. The interaction between the embedding and the control networks is improved by using multiplicative skip-connections and is shown to overcome the overfitting of the trained model. The superiority of the proposed model is established through rigorous experimentation using a publicly available dataset and a new dataset created using PyBullet [36]. Several ablation studies have been carried out to justify the design choices.",
        "primary_area": "",
        "author": "Vishal Bhutani;Anima Majumder;Madhu Vankadari;Samrat Dutta;Aaditya Asati;Swagat Kumar;Vishal Bhutani;Anima Majumder;Madhu Vankadari;Samrat Dutta;Aaditya Asati;Swagat Kumar",
        "authorids": "/37088688259;/38068641200;/37086448149;/37085369267;/37089449926;/37535549500;/37088688259;/38068641200;/37086448149;/37085369267;/37089449926;/37535549500",
        "aff": "TCS Research, TATA Consultancy Services, India; TCS Research, TATA Consultancy Services, India; University of Oxford; TCS Research, TATA Consultancy Services, India; TCS Research, TATA Consultancy Services, India; Edge Hill University, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812281/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6474408318062435732&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;2",
        "aff_unique_norm": "Tata Consultancy Services;University of Oxford;Edge Hill University",
        "aff_unique_dep": "TCS Research;;",
        "aff_unique_url": "https://www.tcs.com;https://www.ox.ac.uk;https://www.edgehill.ac.uk",
        "aff_unique_abbr": "TCS;Oxford;EHU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;1",
        "aff_country_unique": "India;United Kingdom"
    },
    {
        "id": "9811895",
        "title": "Audio-Visual Grounding Referring Expression for Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Referring expressions are commonly used when referring to a specific target in people's daily dialogue. In this paper, we develop a novel task of audio-visual grounding referring expression for robotic manipulation. The robot leverages both the audio and visual information to understand the referring expression in the given manipulation instruction and the corresponding manipulations are implemented. To solve the proposed task, an audio-visual framework is proposed for visual localization and sound recognition. We have also established a dataset which contains visual data, auditory data and manipulation instructions for evaluation. Finally, extensive experiments are conducted both offline and online to verify the effectiveness of the proposed audio-visual framework. And it is demonstrated that the robot performs better with the audio-visual data than with only the visual data.",
        "primary_area": "",
        "author": "Yefei Wang;Kaili Wang;Yi Wang;Di Guo;Huaping Liu;Fuchun Sun;Yefei Wang;Kaili Wang;Yi Wang;Di Guo;Huaping Liu;Fuchun Sun",
        "authorids": "/37089450435;/37089448706;/37089450563;/37085360957;/37310126400;/37279269000;/37089450435;/37089448706;/37089450563;/37085360957;/37310126400;/37279269000",
        "aff": "School of Electronic and Information Engineering, Nanjing University of Information Science and Technology; School of Physics and Electronic Information, Yantai University; Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology, Institute for Artificial Intelligence, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology, Institute for Artificial Intelligence, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology, Institute for Artificial Intelligence, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology, Institute for Artificial Intelligence, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811895/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14118963190362832783&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;2;2",
        "aff_unique_norm": "Nanjing University of Information Science and Technology;Yantai University;Tsinghua University",
        "aff_unique_dep": "School of Electronic and Information Engineering;School of Physics and Electronic Information;Department of Computer Science and Technology",
        "aff_unique_url": "http://www.nuist.edu.cn;https://www.ytu.edu.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": ";;THU",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811617",
        "title": "Augmented Pointing Gesture Estimation for Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "With recent advancements in CV (computer vision) and AI (Artificial Intelligence) technologies, pointing gesture is becoming an emerging trend for human-robot interaction. Its intuitive and deictic nature makes it an ideal way for giving commands, especially referring spatial information to the robots. In this paper, we propose an augmented pointing gesture estimation method to enable richer and programmable instructions to be given to the robots. We propose five pointing gestures and demonstrate the idea using a collaborative robot with a multi-finger robotic gripper. Experiments are designed and conducted to test the pointing accuracy in space and in gesture estimation. The results show that our proposed method can achieve a mean drift of 8.3 cm and an estimation accuracy of 94.08%.",
        "primary_area": "",
        "author": "Zhixian Hu;Yingtian Xu;Waner Lin;Ziya Wang;Zhenglong Sun;Zhixian Hu;Yingtian Xu;Waner Lin;Ziya Wang;Zhenglong Sun",
        "authorids": "/37087244887;/37089448605;/37089447309;/37089447836;/37086799406;/37087244887;/37089448605;/37089447309;/37089447836;/37086799406",
        "aff": "School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811617/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17563292908752144205&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Chinese University of Hong Kong;Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "School of Science and Engineering;",
        "aff_unique_url": "https://www.cuhk.edu.cn;",
        "aff_unique_abbr": "CUHK;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811885",
        "title": "Augmenting Imitation Experience via Equivariant Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "The robustness of visual navigation policies trained through imitation often hinges on the augmentation of the training image-action pairs. Traditionally, this has been done by collecting data from multiple cameras, by using standard data augmentations from computer vision, such as adding random noise to each image, or by synthesizing training images. In this paper we show that there is another practical alternative for data augmentation for visual navigation based on extrapolating viewpoint embeddings and actions nearby the ones observed in the training data. Our method makes use of the geometry of the visual navigation problem in 2D and 3D and relies on policies that are functions of equivariant embeddings, as opposed to images. Given an image-action pair from a training navigation dataset, our neural network model predicts the latent representations of images at nearby viewpoints, using the equivariance property, and augments the dataset. We then train a policy on the augmented dataset. Our simulation results indicate that policies trained in this way exhibit reduced cross-track error, and require fewer interventions compared to policies trained using standard augmentation methods. We also show similar results in autonomous visual navigation by a real ground robot along a path of over 500m.",
        "primary_area": "",
        "author": "Dhruv Sharma;Alihusein Kuwajerwala;Florian Shkurti;Dhruv Sharma;Alihusein Kuwajerwala;Florian Shkurti",
        "authorids": "/37089450296;/37089448260;/37706697200;/37089450296;/37089448260;/37706697200",
        "aff": "Robot Vision and Learning Laboratory, University of Toronto Robotics Institute; Robot Vision and Learning Laboratory, University of Toronto Robotics Institute; Robot Vision and Learning Laboratory, University of Toronto Robotics Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811885/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5588649640989166992&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812140",
        "title": "Augmenting Reinforcement Learning with Behavior Primitives for Diverse Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Realistic manipulation tasks require a robot to interact with an environment with a prolonged sequence of motor actions. While deep reinforcement learning methods have recently emerged as a promising paradigm for automating manipulation behaviors, they usually fall short in long-horizon tasks due to the exploration burden. This work introduces Manipulation Primitive-augmented reinforcement Learning (MAPLE), a learning framework that augments standard reinforcement learning algorithms with a pre-defined library of behavior primitives. These behavior primitives are robust functional modules specialized in achieving manipulation goals, such as grasping and pushing. To use these heterogeneous primitives, we develop a hierarchical policy that involves the primitives and instantiates their executions with input parameters. We demonstrate that MAPLE out-performs baseline approaches by a significant margin on a suite of simulated manipulation tasks. We also quantify the compositional structure of the learned behaviors and highlight our method's ability to transfer policies to new task variants and to physical hardware. Videos and code are available at https://ut-austin-rpl.github.io/maple",
        "primary_area": "",
        "author": "Soroush Nasiriany;Huihan Liu;Yuke Zhu;Soroush Nasiriany;Huihan Liu;Yuke Zhu",
        "authorids": "/37089001338;/37089448557;/37086080772;/37089001338;/37089448557;/37086080772",
        "aff": "The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812140/",
        "gs_citation": 140,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17927855586515776470&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811869",
        "title": "AutoPlace: Robust Place Recognition with Single-chip Automotive Radar",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel place recognition approach to autonomous vehicles by using low-cost, single-chip automotive radar. Aimed at improving recognition robustness and fully exploiting the rich information provided by this emerging automotive radar, our approach follows a principled pipeline that comprises (1) dynamic points removal from instant Doppler measurement, (2) spatial-temporal feature embedding on radar point clouds, and (3) retrieved candidates refinement from Radar Cross Section measurement. Extensive experimental results on the public nuScenes dataset demonstrate that existing visual/LiDAR/spinning radar place recognition approaches are less suitable for single-chip automotive radar. In contrast, our purpose-built approach for automotive radar consistently outperforms a variety of baseline methods via a comprehensive set of metrics, providing insights into the efficacy when used in a realistic system.",
        "primary_area": "",
        "author": "Kaiwen Cai;Bing Wang;Chris Xiaoxuan Lu;Kaiwen Cai;Bing Wang;Chris Xiaoxuan Lu",
        "authorids": "/37089489008;/37088504237;/37086107301;/37089489008;/37088504237;/37086107301",
        "aff": "University of Liverpool; University of Oxford; University of Edinburgh",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811869/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14050083658879859330&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Liverpool;University of Oxford;University of Edinburgh",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.liverpool.ac.uk;https://www.ox.ac.uk;https://www.ed.ac.uk",
        "aff_unique_abbr": "Liv Uni;Oxford;Edinburgh",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811679",
        "title": "Automated Linear and Non-Linear Path Planning for Neurosurgical Interventions",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in medical technology have produced a number of flexible instruments that are capable of traversing non-linear paths. This is of special interest in the field of neurosurgery. However, the non-rigid instruments have the disadvantage that path planning becomes increasingly difficult. In addition to anatomical risk factors, the mechanical properties and constraints of the specific instrument must also be considered. To support surgeons to deal with the increase in planning complexity, we present a novel method for both linear and arbitrary follow-the-leader flexible path planning. Our method is utilizing patient-specific image data, which is then used to generate a multi-objective problem consisting of conventional risk metrics for path planning in high-risk regions like the accumulated path cost or the distance to risk structures. Simultaneously, the path-problem is also constraint to mechanical properties of the instrument such as curvature or maximum operational length. Optimal paths can then be generated by solving a multi-objective problem by approximating the Pareto front. We show that our method can automatically generate linear and non-linear paths for neurosurgical interventions in the human brain in less than 2 minutes. Furthermore, we show that the proposed automated method generates paths with 87% reduced risk compared to standard of care plannings.",
        "primary_area": "",
        "author": "Steffen Peikert;Christian Kunz;Nikola Fischer;Michal Hlav\u00e1\u010d;Andrej Pala;Max Schneider;Franziska Mathis-Ullrich;Steffen Peikert;Christian Kunz;Nikola Fischer;Michal Hlav\u00e1\u010d;Andrej Pala;Max Schneider;Franziska Mathis-Ullrich",
        "authorids": "/37089449112;/37088949738;/37089448241;/37088950211;/37088948928;/37089119348;/37088949823;/37089449112;/37088949738;/37089448241;/37088950211;/37088948928;/37089119348;/37088949823",
        "aff": "Health Robotics and Automation Laboratory, Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Health Robotics and Automation Laboratory, Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Health Robotics and Automation Laboratory, Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Department of Neurosurgery, University Hospital Ulm/G\u00fcnzburg, Gunzburg, Germany; Department of Neurosurgery, University Hospital Ulm/G\u00fcnzburg, Gunzburg, Germany; Department of Neurosurgery, University Hospital Ulm/G\u00fcnzburg, Gunzburg, Germany; Health Robotics and Automation Laboratory, Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811679/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6379082919476688645&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;1;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology;University Hospital Ulm/G\u00fcnzburg",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics;Department of Neurosurgery",
        "aff_unique_url": "https://www.kit.edu;",
        "aff_unique_abbr": "KIT;",
        "aff_campus_unique_index": "0;0;0;1;1;1;0",
        "aff_campus_unique": "Karlsruhe;Gunzburg",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812045",
        "title": "Automated Task Updates of Temporal Logic Specifications for Heterogeneous Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Given a heterogeneous group of robots executing a complex task represented in Linear Temporal Logic, and a new set of tasks for the group, we define the task update problem and propose a framework for automatically updating individual robot tasks given their respective existing tasks and capabilities. Our heuristic, token-based, conflict resolution task allocation algorithm generates a near-optimal assignment for the new task. We demonstrate the scalability of our approach through simulations of multi-robot tasks.",
        "primary_area": "",
        "author": "Amy Fang;Hadas Kress-Gazit;Amy Fang;Hadas Kress-Gazit",
        "authorids": "/37089449350;/38307602100;/37089449350;/38307602100",
        "aff": "Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812045/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10767908439952400602&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "Sibley School of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811579",
        "title": "Automated Testing With Temporal Logic Specifications for Robotic Controllers Using Adaptive Experiment Design",
        "track": "main",
        "status": "Poster",
        "abstract": "Many robot control scenarios involve assessing system robustness against a task specification. If either the controller or environment are composed of \u201cblack-box\u201d components with unknown dynamics, we cannot rely on formal verification to assess our system. Assessing robustness via exhaustive testing is also often infeasible if the number of possible environments is large compared to experiment cost. Given limited budget, we provide a method to choose experiment inputs which accurately reflect how robustly a system satisfies a given specification across the domain. By combining signal temporal logic metrics with adaptive experiment design, our method chooses each experiment by incrementally constructing a surrogate model of the specification robustness. This model then chooses experiments in areas of either high prediction error or high uncertainty. Our evaluation shows how this adaptive experiment design results in sample-efficient descriptions of system robustness. Further, we show how to use the constructed surrogate model to assess the behaviour of a data-driven control system under domain shift.",
        "primary_area": "",
        "author": "Craig Innes;Subramanian Ramamoorthy;Craig Innes;Subramanian Ramamoorthy",
        "authorids": "/37088996171;/37529920500;/37088996171;/37529920500",
        "aff": "Institute of Perception, Action and Behaviour (IPAB), University of Edinburgh, United Kingdom; Institute of Perception, Action and Behaviour (IPAB), University of Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811579/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6544929430824855399&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "Institute of Perception, Action and Behaviour (IPAB)",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811837",
        "title": "Automatic Acquisition of a Repertoire of Diverse Grasping Trajectories through Behavior Shaping and Novelty Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping a particular object may require a dedicated grasping movement that may also be specific to the robot end-effector. No generic and autonomous method does exist to generate these movements without making hypotheses on the robot or on the object. Learning methods could help to autonomously discover relevant grasping movements, but they face an important issue: grasping movements are so rare that a learning method based on exploration has little chance to ever observe an interesting movement, thus creating a bootstrap issue. We introduce an approach to generate diverse grasping movements in order to solve this problem. The movements are generated in simulation, for particular object positions. We test it on several simulated robots: Baxter, Pepper and a Kuka Iiwa arm. Although we show that generated movements actually work on a real Baxter robot, the aim is to use this method to create a large dataset to bootstrap deep learning methods.",
        "primary_area": "",
        "author": "Aur\u00e9lien Morel;Yakumo Kunimoto;Alex Coninx;St\u00e9phane Doncieux;Aur\u00e9lien Morel;Yakumo Kunimoto;Alex Coninx;St\u00e9phane Doncieux",
        "authorids": "/37089448488;/37089449552;/37085899862;/37568716500;/37089448488;/37089449552;/37085899862;/37568716500",
        "aff": "Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Suisse; Sorbonne Universit\u00e9, CNRS, Institut des Syst\u00e9mes Intelligents et de Robotique, ISIR, Paris, France; Sorbonne Universit\u00e9, CNRS, Institut des Syst\u00e9mes Intelligents et de Robotique, ISIR, Paris, France; Sorbonne Universit\u00e9, CNRS, Institut des Syst\u00e9mes Intelligents et de Robotique, ISIR, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811837/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5632910187689891092&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "EPFL;Sorbonne Universit\u00e9",
        "aff_unique_dep": ";Institut des Syst\u00e9mes Intelligents et de Robotique",
        "aff_unique_url": "https://www.epfl.ch;https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "EPFL;Sorbonne U",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Lausanne;Paris",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Switzerland;France"
    },
    {
        "id": "9811982",
        "title": "Automatic Biopsy Tool Presence and Episode Recognition in Robotic Bronchoscopy Using a Multi-Task Vision Transformer Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic recognition of surgical workflow is a growing area of interest with significant potential to become part of context-aware decision-support systems in future enhanced ORs and clinical suites. Applications range from post-operative analysis to intra-operative monitoring to providing automated assistance to the clinical staff. This work proposes, for the first time, automatic tool presence and episodes recognition in bronchoscopy images, using a newly annotated video dataset obtained from robotic bronchoscopy procedures. A novel multi-task architecture that utilizes Vision Transformers for the episode recognition task is used to achieve improved accuracy while reducing the computational burden during the training stage. The method is thoroughly validated on clinical procedure video data obtained across 135 procedures, displaying improved performance and training times compared to various state-of-the-art methods.",
        "primary_area": "",
        "author": "Mingyi Zheng;Menglong Ye;Hedyeh Rafii\u2013Tari;Mingyi Zheng;Menglong Ye;Hedyeh Rafii\u2013Tari",
        "authorids": "/37089447180;/37089447249;/37085485799;/37089447180;/37089447249;/37085485799",
        "aff": "Auris Health Inc, Redwood City, CA; Auris Health Inc, Redwood City, CA; Auris Health Inc, Redwood City, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811982/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2797348042113049024&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Auris Health Inc",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Redwood City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811539",
        "title": "Automatic Classification and Disassembly of Fasteners in Industrial 3D CAD-Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "The automatic generation of (dis)assembly sequences for complex technical products is a challenging field. Complex products like vehicles consist of numerous different components. Determining the sequence using a brute-force-approach by testing all components for disassembly one after another in a loop until all components are disassembled is laborious and costly. In industrial scenarios, a large proportion of the components are fasteners. In this paper, we propose a new framework which improves the disassembly sequencing generation by prioritizing fasteners during planning. Our proposed framework comprises a preprocessing in which fasteners are identified with a convolutional neural network within a dataset and a procedure that preferentially and automatically checks fasteners for disassembly. The algorithm takes initial and unavoidable collisions of the fasteners into account. We show the effectiveness of our approach on real-world data from the automotive industry. A new synthetic dataset of fasteners for training neural networks is available.",
        "primary_area": "",
        "author": "Michele F. Adesso;Robert Hegewald;Nicola Wolpert;Elmar Sch\u00f6mer;Bianca Maier;Benjamin A. Epple;Michele F. Adesso;Robert Hegewald;Nicola Wolpert;Elmar Sch\u00f6mer;Bianca Maier;Benjamin A. Epple",
        "authorids": "/37089257780;/37088998118;/37085352554;/37331462600;/37089450488;/37089449687;/37089257780;/37088998118;/37085352554;/37331462600;/37089450488;/37089449687",
        "aff": "Department: Geomatics, Computer Science and Mathematics, Stuttgart University of Applied Science, Germany; Digital Factory Body in White & Validation, Mercedes-Benz AG, Germany; Department: Geomatics, Computer Science and Mathematics, Stuttgart University of Applied Science, Germany; Department: Physics, Mathematics and Computer Science, Johannes Gutenberg - University Mainz, Germany; Department: Geomatics, Computer Science and Mathematics, Stuttgart University of Applied Science, Germany; Department: Geomatics, Computer Science and Mathematics, Stuttgart University of Applied Science, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811539/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8897662903465917299&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;0",
        "aff_unique_norm": "Stuttgart University of Applied Science;Mercedes-Benz AG;Johannes Gutenberg University Mainz",
        "aff_unique_dep": "Department of Geomatics, Computer Science and Mathematics;Digital Factory Body in White & Validation;Department of Physics, Mathematics and Computer Science",
        "aff_unique_url": "https://www.hft-stuttgart.de;https://www.mercedes-benz.com;https://www.jgu.de",
        "aff_unique_abbr": ";MBAG;JGU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mainz",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812028",
        "title": "Autonomous Actuation of Flapping Wing Robots Inspired by Asynchronous Insect Muscle",
        "track": "main",
        "status": "Poster",
        "abstract": "In most instances, flapping wing robots have emulated the \u201csynchronous\u201d actuation of insects in which the wingbeat timing is generated from a time-dependent, rhythmic signal. The internal dynamics of asynchronous insect flight muscle enable high-frequency, adaptive wingbeats with minimal direct neural control. In this paper, we investigate how the delayed stretch-activation (dSA) response of asynchronous insect flight muscle can be transformed into a feedback control law for flapping wing robots that results in stable limit cycle wingbeats. We first demonstrate - in theory and simulation - the mechanism by which asynchronous wingbeats self-excite. Then, we implement the feedback law on a dynamically-scaled robophysical model as well as on an insect-scale robotic flapping wing. Experiments on large- and small-scale robots demonstrate good agreement with the theory results and highlight how dSA parameters govern wingbeat amplitude and frequency. Lastly, we demonstrate that asynchronous actuation has several advantages over synchronous actuation schemes, including the ability to rapidly adapt or halt wingbeats in response to external loads or collisions through low-level feedback control.",
        "primary_area": "",
        "author": "James Lynch;Jeff Gau;Simon Sponberg;Nick Gravish;James Lynch;Jeff Gau;Simon Sponberg;Nick Gravish",
        "authorids": "/37089450022;/37089448814;/38132557500;/37085401269;/37089450022;/37089448814;/38132557500;/37085401269",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California, San Diego; Bioengineering Graduate Program, Georgia Institute of Technology, Atlanta, GA; School of Physics and Biological Scienes, Georgia Institute of Technology, Atlanta, GA; Department of Mechanical and Aerospace Engineering, University of California, San Diego",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812028/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13148702710289564954&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of California, San Diego;Georgia Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;Bioengineering Graduate Program",
        "aff_unique_url": "https://www.ucsd.edu;https://www.gatech.edu",
        "aff_unique_abbr": "UCSD;Georgia Tech",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "San Diego;Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812330",
        "title": "Autonomous Exploration Development Environment and the Planning Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous Exploration Development Environment is an open-source repository released to facilitate development of high-level planning algorithms and integration of com-plete autonomous navigation systems. The repository contains representative simulation environment models, fundamental navigation modules, e.g., local planner, terrain traversability analysis, waypoint following, and visualization tools. Together with two of our high-level planner releases - TARE planner for exploration and FAR planner for route planning, we detail usage of the three open-source repositories and share experiences in integration of autonomous navigation systems. We use DARPA Subterranean Challenge as a use case where the repositories together form the main navigation system of the CMU-OSU Team. In the end, we discuss a few potential use cases in extended applications.",
        "primary_area": "",
        "author": "Chao Cao;Hongbiao Zhu;Fan Yang;Yukun Xia;Howie Choset;Jean Oh;Ji Zhang;Chao Cao;Hongbiao Zhu;Fan Yang;Yukun Xia;Howie Choset;Jean Oh;Ji Zhang",
        "authorids": "/37086934694;/37086564449;/37089448792;/37089198269;/37281322200;/37933996900;/38541910000;/37086934694;/37086564449;/37089448792;/37089198269;/37281322200;/37933996900;/38541910000",
        "aff": "Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812330/",
        "gs_citation": 97,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17236749450546309610&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811969",
        "title": "Autonomous Racing with Multiple Vehicles using a Parallelized Optimization with Safety Guarantee using Control Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel planning and control strategy for competing with multiple vehicles in a car racing scenario. The proposed racing strategy switches between two modes. When there are no surrounding vehicles, a learning-based model predictive control (MPC) trajectory planner is used to guarantee that the ego vehicle achieves better lap timing performance. When the ego vehicle is competing with other surrounding vehicles to overtake, an optimization-based planner generates multiple dynamically-feasible trajectories through parallel computation. Each trajectory is optimized under a MPC formulation with different homotopic Bezier-curve reference paths lying laterally between surrounding vehicles. The time-optimal trajectory among these different homotopic trajectories is selected and a low-level MPC controller with control barrier function constraints for obstacle avoidance is used to guarantee the system's safety-critical performance. The proposed algorithm has the capability to generate collision-free trajectories and track them while enhancing the lap timing performance with steady low computational complexity, outper-forming existing approaches in both timing and performance for an autonomous racing environment. To demonstrate the performance of our racing strategy, we simulate with multiple randomly generated moving vehicles on the track and test the ego vehicle's overtaking maneuvers.",
        "primary_area": "",
        "author": "Suiyi He;Jun Zeng;Koushil Sreenath;Suiyi He;Jun Zeng;Koushil Sreenath",
        "authorids": "/37088921234;/37086963288;/37563179200;/37088921234;/37086963288;/37563179200",
        "aff": "University of Minnesota-Twin Cities, MN; University of California, Berkeley; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811969/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2466123172853415674&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Minnesota;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.minnesota.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "UMN;UC Berkeley",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Twin Cities;Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812401",
        "title": "Autonomous Teamed Exploration of Subterranean Environments using Legged and Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel strategy for autonomous teamed exploration of subterranean environments using legged and aerial robots. Tailored to the fact that subterranean settings, such as cave networks and underground mines, often involve complex, large-scale and multi-branched topologies, while wireless communication within them can be particularly challenging, this work is structured around the synergy of an onboard exploration path planner that allows for resilient long-term autonomy, and a multi-robot coordination framework. The onboard path planner is unified across legged and flying robots and enables navigation in environments with steep slopes, and diverse geometries. When a communication link is available, each robot of the team shares submaps to a centralized location where a multi-robot coordination framework identifies global frontiers of the exploration space to inform each system about where it should re-position to best continue its mission. The strategy is verified through a field deployment inside an underground mine in Switzerland using a legged and a flying robot collectively exploring for 45 min, as well as a longer simulation study with three systems.",
        "primary_area": "",
        "author": "Mihir Kulkarni;Mihir Dharmadhikari;Marco Tranzatto;Samuel Zimmermann;Victor Reijgwart;Paolo De Petris;Huan Nguyen;Nikhil Khedekar;Christos Papachristos;Lionel Ott;Roland Siegwart;Marco Hutter;Kostas Alexis;Mihir Kulkarni;Mihir Dharmadhikari;Marco Tranzatto;Samuel Zimmermann;Victor Reijgwart;Paolo De Petris;Huan Nguyen;Nikhil Khedekar;Christos Papachristos;Lionel Ott;Roland Siegwart;Marco Hutter;Kostas Alexis",
        "authorids": "/37088998874;/37088504973;/37085705789;/37086117772;/37086454863;/37088600627;/37088471319;/37086935230;/37681703400;/38251784400;/37281398300;/37545251000;/37546514600;/37088998874;/37088504973;/37085705789;/37086117772;/37086454863;/37088600627;/37088471319;/37086935230;/37681703400;/38251784400;/37281398300;/37545251000;/37546514600",
        "aff": "NTNU, Trondheim, Norway; NTNU, Trondheim, Norway; ETH Zurich, Zurich, Switzerland; ETH Zurich, Zurich, Switzerland; ETH Zurich, Zurich, Switzerland; NTNU, Trondheim, Norway; NTNU, Trondheim, Norway; NTNU, Trondheim, Norway; University of Nevada, Reno, Reno, NV, USA; ETH Zurich, Zurich, Switzerland; ETH Zurich, Zurich, Switzerland; ETH Zurich, Zurich, Switzerland; NTNU, Trondheim, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812401/",
        "gs_citation": 112,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5770981820880631187&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;0;1;1;1;0;0;0;2;1;1;1;0",
        "aff_unique_norm": "Norwegian University of Science and Technology;ETH Zurich;University of Nevada, Reno",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ntnu.no;https://www.ethz.ch;https://www.unr.edu",
        "aff_unique_abbr": "NTNU;ETHZ;UNR",
        "aff_campus_unique_index": "0;0;1;1;1;0;0;0;2;1;1;1;0",
        "aff_campus_unique": "Trondheim;Zurich;Reno",
        "aff_country_unique_index": "0;0;1;1;1;0;0;0;2;1;1;1;0",
        "aff_country_unique": "Norway;Switzerland;United States"
    },
    {
        "id": "9812410",
        "title": "Autonomous Ultrasound Scanning using Bayesian Optimization and Hybrid Force Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Ultrasound scanning is an imaging technique that aids medical professionals in diagnostics and interventional procedures. However, a trained human-in-the-loop (HITL) with a radiologist is required to perform the scanning procedure. We seek to create a novel ultrasound system that can provide imaging in the absence of a trained radiologist, say for patients in the field who suffered injuries after a natural disaster. One challenge of automating ultrasound scanning involves finding the optimal area to scan and then performing the actual scan. This task requires simultaneously maintaining contact with the surface while moving along it to capture high quality images. In this work, we present an automated Robotic Ultrasound System (RUS) to tackle these challenges. Our approach introduces a Bayesian Optimization framework to guide the probe to multiple points on the unknown surface. Our proposed framework collects the ultrasound images as well as the pose information at every probed point to estimate regions with high vessel density (information map) and the surface contour. Based on the information map and the surface contour, an area of interest is selected for scanning. Furthermore, to scan the proposed region, a novel 6-axis hybrid force-position controller is presented to ensure acoustic coupling. Lastly, we provide experimental results on two different phantom models to corroborate our approach.",
        "primary_area": "",
        "author": "Raghavv Goel;Fnu Abhimanyu;Kirtan Patel;John Galeotti;Howie Choset;Raghavv Goel;Fnu Abhimanyu;Kirtan Patel;John Galeotti;Howie Choset",
        "authorids": "/37088635312;/37089447292;/37089227440;/38558753600;/37281322200;/37088635312;/37089447292;/37089227440;/38558753600;/37281322200",
        "aff": "Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, USA; Department of Mechanical Engineering, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812410/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5047298251908577530&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812309",
        "title": "Autonomous Vehicle Parking in Dynamic Environments: An Integrated System with Prediction and Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an integrated motion planning system for autonomous vehicle (AV) parking in the presence of other moving vehicles. The proposed system includes 1) a hybrid environment predictor that predicts the motions of the surrounding vehicles and 2) a strategic motion planner that reacts to the predictions. The hybrid environment predictor performs short-term predictions via an extended Kalman filter and an adaptive observer. It also combines short-term predictions with a driver behavior cost-map to make long-term predictions. The strategic motion planner comprises 1) a model predictive control-based safety controller for trajectory tracking; 2) a search-based retreating planner for finding an evasion path in an emergency; 3) an optimization-based repairing planner for planning a new path when the original path is invalidated. Simulation validation demonstrates the effectiveness of the proposed method in terms of initial planning, motion prediction, safe tracking, retreating in an emergency, and trajectory repairing.",
        "primary_area": "",
        "author": "Jessica Leu;Yebin Wang;Masayoshi Tomizuka;Stefano Di Cairano;Jessica Leu;Yebin Wang;Masayoshi Tomizuka;Stefano Di Cairano",
        "authorids": "/37086917046;/37407582500;/37281933000;/37545385600;/37086917046;/37407582500;/37281933000;/37545385600",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812309/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6919598789646805367&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of California, Berkeley;Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.merl.com",
        "aff_unique_abbr": "UC Berkeley;MERL",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Berkeley;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811661",
        "title": "Autonomy and Perception for Space Mining",
        "track": "main",
        "status": "Poster",
        "abstract": "Future Moon bases will likely be constructed using resources mined from the surface of the Moon. The difficulty of maintaining a human workforce on the Moon and communications lag with Earth means that mining will need to be conducted using collaborative robots with a high degree of autonomy. In this paper, we describe our solution for Phase 2 of the NASA Space Robotics Challenge, which provided a simulated lunar environment in which teams were tasked to develop software systems to achieve autonomous collaborative robots for mining on the Moon. Our 3rd place and innovation award winning solution shows how machine learning-enabled vision could alleviate major challenges posed by the lunar environment towards autonomous space mining, chiefly the lack of satellite positioning systems, hazardous terrain, and delicate robot interactions. A robust multi-robot coordinator was also developed to achieve long-term operation and effective collaboration between robots11A recording of our robots in action is available at [1]..",
        "primary_area": "",
        "author": "Ragav Sachdeva;Ravi Hammond;James Bockman;Alec Arthur;Brandon Smart;Dustin Craggs;Anh-Dzung Doan;Thomas Rowntree;Elijah Schutz;Adrian Orenstein;Andy Yu;Tat-Jun Chin;Ian Reid;Ragav Sachdeva;Ravi Hammond;James Bockman;Alec Arthur;Brandon Smart;Dustin Craggs;Anh-Dzung Doan;Thomas Rowntree;Elijah Schutz;Adrian Orenstein;Andy Yu;Tat-Jun Chin;Ian Reid",
        "authorids": "/37088887837;/37089448136;/37089447999;/37089450641;/37089448647;/37086612548;/37086526070;/37086455086;/37089449718;/37089449014;/37089449763;/37411757200;/37282640200;/37088887837;/37089448136;/37089447999;/37089450641;/37089448647;/37086612548;/37086526070;/37086455086;/37089449718;/37089449014;/37089449763;/37411757200;/37282640200",
        "aff": "Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide; Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide; Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide; Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide; Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide; Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide; Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide; Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide; Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide; Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide; Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide; SmartSat CRC Professorial Chair, Sentient Satellites; Australian Institute for Machine Learning and Andy Thomas Centre for Snace Resources, The University of Adelaide",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811661/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15687394134988686030&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Adelaide;Sentient Satellites",
        "aff_unique_dep": "Australian Institute for Machine Learning, Andy Thomas Centre for Space Resources;SmartSat CRC Professorial Chair",
        "aff_unique_url": "https://www.adelaide.edu.au;https://sentientsatellites.com",
        "aff_unique_abbr": "Adelaide;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9811999",
        "title": "BAANet: Learning Bi-directional Adaptive Attention Gates for Multispectral Pedestrian Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Thermal infrared (TIR) image has proven effectiveness in providing temperature cues to the RGB features for multispectral pedestrian detection. Most existing methods directly inject the TIR modality into the RGB-based framework or simply ensemble the results of two modalities. This, however, could lead to inferior detection performance, as the RGB and TIR features generally have modality-specific noise, which might worsen the features along with the propagation of the network. Therefore, this work proposes an effective and efficient cross-modality fusion module called Bi-directional Adaptive Attention Gate (BAA-Gate). Based on the attention mechanism, the BAA-Gate is devised to distill the informative features and recalibrate the representations asymptotically. Concretely, a bi-direction multi-stage fusion strategy is adopted to progressively optimize features of two modalities and retain their specificity during the propagation. Moreover, an adaptive interaction of BAA-Gate is introduced by the illumination-based weighting strategy to adaptively adjust the recalibrating and aggregating strength in the BAA-Gate and enhance the robustness towards illumination changes. Considerable experiments on the challenging KAIST dataset demonstrate the superior performance of our method with satisfactory speed.",
        "primary_area": "",
        "author": "Xiaoxiao Yang;Yeqiang Qian;Huijie Zhu;Chunxiang Wang;Ming Yang;Xiaoxiao Yang;Yeqiang Qian;Huijie Zhu;Chunxiang Wang;Ming Yang",
        "authorids": "/37089448858;/37086040809;/37089447696;/37578423000;/37576820400;/37089448858;/37086040809;/37089447696;/37578423000;/37576820400",
        "aff": "Science and Technology on Near-Surface Detection Laboratory, Wuxi, China; University of Michigan-Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, China; Science and Technology on Near-Surface Detection Laboratory, Wuxi, China; Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, China; Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811999/",
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13917922458021205786&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;2",
        "aff_unique_norm": "Science and Technology on Near-Surface Detection Laboratory;Shanghai Jiao Tong University;Key Laboratory of System Control and Information Processing",
        "aff_unique_dep": ";University of Michigan-Shanghai Jiao Tong University Joint Institute;Ministry of Education of China",
        "aff_unique_url": ";https://www.sjtu.edu.cn;",
        "aff_unique_abbr": ";SJTU;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Wuxi;Shanghai;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812243",
        "title": "Back to the Future: Efficient, Time-Consistent Solutions in Reach-Avoid Games",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the class of reach-avoid dynamic games in which multiple agents interact noncooperatively, and each wishes to satisfy a distinct target criterion while avoiding a failure criterion. Reach-avoid games are commonly used to express safety-critical optimal control problems found in mobile robot motion planning. Here, we focus on finding time-consistent solutions, in which future motion plans remain optimal even when a robot diverges from the plan early on due to, e.g., intrinsic dynamic uncertainty or extrinsic environment disturbances. Our main contribution is a computationally-efficient algorithm for multi-agent reach-avoid games which renders time-consistent solutions for all players. We demonstrate our approach in two- and three-player simulated driving scenarios, in which our method provides safe control strategies for all agents.",
        "primary_area": "",
        "author": "Dennis R. Anthony;Duy P. Nguyen;David Fridovich-Keil;Jaime F. Fisac;Dennis R. Anthony;Duy P. Nguyen;David Fridovich-Keil;Jaime F. Fisac",
        "authorids": "/37089448678;/37089448940;/37086041251;/37085467058;/37089448678;/37089448940;/37086041251;/37085467058",
        "aff": "Dept. of Mechanical and Aerospace Engineering, Princeton University; Dept. of Electrical and Computer Engineering, Princeton University; Dept. of Aerospace Engineering and Engineering Mechanics, UT Austin; Dept. of Electrical and Computer Engineering, Princeton University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812243/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17043891539571835976&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Princeton University;University of Texas at Austin",
        "aff_unique_dep": "Dept. of Mechanical and Aerospace Engineering;Dept. of Aerospace Engineering and Engineering Mechanics",
        "aff_unique_url": "https://www.princeton.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Princeton;UT Austin",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812332",
        "title": "Balancing Efficiency and Comfort in Robot-Assisted Bite Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-assisted feeding in household environments is challenging because it requires robots to generate trajectories that effectively bring food items of varying shapes and sizes into the mouth while making sure the user is comfortable. Our key insight is that in order to solve this challenge, robots must balance the efficiency of feeding a food item with the comfort of each individual bite. We formalize comfort and efficiency as heuristics to incorporate in motion planning. We present an approach based on heuristics-guided bi-directional Rapidly-exploring Random Trees (h-BiRRT) that selects bite transfer trajectories of arbitrary food item geometries and shapes using our developed bite efficiency and comfort heuristics and a learned constraint model. Real-robot evaluations show that op-timizing both comfort and efficiency significantly outperforms a fixed-pose based method, and users preferred our method significantly more than that of a method that maximizes only user comfort. Videos and Appendices are found on our website: https://tinyurl.com/bticra22.",
        "primary_area": "",
        "author": "Suneel Belkhale;Ethan K. Gordon;Yuxiao Chen;Siddhartha Srinivasa;Tapomayukh Bhattacharjee;Dorsa Sadigh;Suneel Belkhale;Ethan K. Gordon;Yuxiao Chen;Siddhartha Srinivasa;Tapomayukh Bhattacharjee;Dorsa Sadigh",
        "authorids": "/37086933683;/37088688098;/37089449451;/37339877600;/37531634500;/38234464200;/37086933683;/37088688098;/37089449451;/37339877600;/37531634500;/38234464200",
        "aff": "Stanford University; University of Washington; Stanford University; University of Washington; Cornell University; Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812332/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11806112045536408971&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;2;0",
        "aff_unique_norm": "Stanford University;University of Washington;Cornell University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.stanford.edu;https://www.washington.edu;https://www.cornell.edu",
        "aff_unique_abbr": "Stanford;UW;Cornell",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812012",
        "title": "Bang-bang Control with Constant Thrust of a Spherical Blimp Propelled by Ultrasound Beam",
        "track": "main",
        "status": "Poster",
        "abstract": "Ultrasound beam propulsion, a propulsion system that uses airborne ultrasound phased arrays (AUPAs) to propel a blimp in an indoor environment to propel a blimp, has advantages for operations near humans such as no audible noises and no risk of propeller strike. To achieve the high mobility with limited actuation force of AUPAs, the dynamics should be fully exploited. In this paper, we propose a two-degree-of-freedom controller specifically tailored for ultrasound beam propulsion. We investigate the trajectory of bang-bang control with constant thrust (BBCT control), where a blimp accelerates and then decelerates with constant thrust reaching the terminal point at rest, as one of the most basic trajectories. First, we analytically derive the trajectory of a blimp under aerodynamic drag. Then, we provide a trajectory generator that derives the maximum constant thrust for an arrangement of AUPAs and the constraints on the control input. Finally, we integrate the trajectory generator and a PID-based feedback controller in a physical setup. We evaluated the proposed controller in physical and numerical experiments. The results showed that the proposed method allows a blimp to reach the terminal point almost in expected time. We also showed that the flight time is shorter than a PID-based one-degree-of-freedom controller, which was typically used in previous studies, by 19.0 \u2212 43.2 %.",
        "primary_area": "",
        "author": "Takuro Furumoto;Masahiro Fujiwara;Yasutoshi Makino;Hiroyuki Shinoda;Takuro Furumoto;Masahiro Fujiwara;Yasutoshi Makino;Hiroyuki Shinoda",
        "authorids": "/37086529882;/37711470200;/37280554800;/37280567100;/37086529882;/37711470200;/37280554800;/37280567100",
        "aff": "Graduate School of Frontier Sciences, The University of Tokyo, Chiba, Japan; Graduate School of Frontier Sciences, The University of Tokyo, Chiba, Japan; Graduate School of Frontier Sciences, The University of Tokyo, Chiba, Japan; Graduate School of Frontier Sciences, The University of Tokyo, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812012/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1008343468995709676&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Graduate School of Frontier Sciences",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chiba",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812256",
        "title": "Barrier Forming: Separating Polygonal Sets with Minimum Number of Lines",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we carry out structural and al-gorithmic studies of a problem of barrier forming: selecting the minimum number of straight line segments (barriers) that separate several sets of mutually disjoint objects in the plane. The problem models the optimal placement of line sensors (e.g., infrared laser beams) for isolating many types of regions in a pair- wise manner for practical purposes (e.g., guarding against intrusions). The problem is NP-hard even if we want to find the minimum number of lines to separate two sets of points in the plane. Under the umbrella problem of barrier forming with minimum number of line segments, three settings are examined: barrier forming for point sets, point sets with polygonal obstacles, polygonal sets with polygonal obstacles. We describe methods for computing the optimal solution for the first two settings with the assistance of mathematical programming, and provide a 2-OPT solution for the third. We demonstrate the effectiveness of our methods through extensive simulations.",
        "primary_area": "",
        "author": "Si Wei Feng;Jingjin Yu;Si Wei Feng;Jingjin Yu",
        "authorids": "/37087233222;/37536570700;/37087233222;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812256/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8571422426312464708&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811604",
        "title": "Barrier Function-based Safe Reinforcement Learning for Formation Control of Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Distributed model predictive control (DMPC) concerns how to online control multiple robotic systems with constraints effectively. However, the nonlinearity, nonconvexity, and strong interconnections of dynamic system models and constraints can make the real-time and real-world DMPC implementations nontrivial. Reinforcement learning (RL) algorithms are promising for control policy design. However, how to ensure safety in terms of state constraints in RL remains a significant issue. This paper proposes a barrier function-based safe reinforcement learning algorithm for DMPC of nonlinear multi-robot systems under state constraints. The proposed approach is composed of several local learning-based MPC regulators. Each regulator, associated with a local system, learns and deploys the local control policy using a safe reinforcement learning algorithm in a distributed manner, i.e., with state information only among the neighbor agents. As a prominent feature of the proposed algorithm, we present a novel barrier-based policy structure to ensure safety, which has a clear mechanistic interpretation. Both simulated and real-world experiments on the formation control of mobile robots with collision avoidance show the effectiveness of the proposed safe reinforcement learning algorithm for DMPC.",
        "primary_area": "",
        "author": "Xinglong Zhang;Yaoqian Peng;Wei Pan;Xin Xu;Haibin Xie;Xinglong Zhang;Yaoqian Peng;Wei Pan;Xin Xu;Haibin Xie",
        "authorids": "/37088567941;/37088690396;/37088467306;/37334606400;/37289208200;/37088567941;/37088690396;/37088467306;/37334606400;/37289208200",
        "aff": "College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; Department of Cognitive Robotics, Delft University of Technology, the Netherlands; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811604/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5370935786372021772&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "National University of Defense Technology;Delft University of Technology",
        "aff_unique_dep": "College of Intelligence Science and Technology;Department of Cognitive Robotics",
        "aff_unique_url": ";https://www.tudelft.nl",
        "aff_unique_abbr": ";TU Delft",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Changsha;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "China;Netherlands"
    },
    {
        "id": "9812406",
        "title": "Bayesian Optimisation for Robust Model Predictive Control under Model Parameter Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an adaptive optimisation approach for tuning stochastic model predictive control (MPC) hyper-parameters while jointly estimating probability distributions of the transition model parameters based on performance rewards. In particular, we develop a Bayesian optimisation (BO) algorithm with a heteroscedastic noise model to deal with varying noise across the MPC hyper-parameter and dynamics model parameter spaces. Typical homoscedastic noise models are unrealistic for tuning MPC since stochastic controllers are inherently noisy, and the level of noise is affected by their hyper-parameter settings. We evaluate the proposed optimisation algorithm in simulated control and robotics tasks where we jointly infer control and dynamics parameters. Experimental results demonstrate that our approach leads to higher cumulative rewards and more stable controllers.",
        "primary_area": "",
        "author": "Rel Guzman;Rafael Oliveira;Fabio Ramos;Rel Guzman;Rafael Oliveira;Fabio Ramos",
        "authorids": "/37088536810;/37086456041;/37285364500;/37088536810;/37086456041;/37285364500",
        "aff": "School of Computer Science, the University of Sydney, Australia; Australian Research Council's centre in Data Analytics for Resources and Environments (DARE) and the University of Sydney's Brain and Mind Centre; NVIDIA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812406/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8668778636804755936&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Sydney;NVIDIA",
        "aff_unique_dep": "School of Computer Science;NVIDIA",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.nvidia.com",
        "aff_unique_abbr": "USYD;NV",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "9812154",
        "title": "Bayesian Optimization Meets Hybrid Zero Dynamics: Safe Parameter Learning for Bipedal Locomotion Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a multi-domain control parameter learning framework that combines Bayesian Optimization (BO) and Hybrid Zero Dynamics (HZD) for locomotion control of bipedal robots. We leverage BO to learn the control parameters used in the HZD-based controller. The learning process is firstly deployed in simulation to optimize different control parameters for a large repertoire of gaits. Next, to tackle the discrepancy between the simulation and the real world, the learning process is applied on the physical robot to learn for corrections to the control parameters learned in simulation while also respecting a safety constraint for gait stability. This method empowers an efficient sim-to-real transition with a small number of samples in the real world, and does not require a valid controller to initialize the training in simulation. Our proposed learning framework is experimentally deployed and validated on a bipedal robot Cassie to perform versatile locomotion skills with improved performance on smoothness of walking gaits and reduction of steady-state tracking errors.",
        "primary_area": "",
        "author": "Lizhi Yang;Zhongyu Li;Jun Zeng;Koushil Sreenath;Lizhi Yang;Zhongyu Li;Jun Zeng;Koushil Sreenath",
        "authorids": "/37088987506;/37088691308;/37086963288;/37563179200;/37088987506;/37088691308;/37086963288;/37563179200",
        "aff": "Department of Mechanical Engineering, Hybrid Robotics Group, University of California, Berkeley, USA; Department of Mechanical Engineering, Hybrid Robotics Group, University of California, Berkeley, USA; Department of Mechanical Engineering, Hybrid Robotics Group, University of California, Berkeley, USA; Department of Mechanical Engineering, Hybrid Robotics Group, University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812154/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8142993279269771707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811560",
        "title": "Belief Space Planning: a Covariance Steering Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "A new belief space planning algorithm, called covariance steering Belief RoadMap (CS-BRM), is introduced, which is a multi-query algorithm for motion planning of dynamical systems under simultaneous motion and observation uncertainties. CS-BRM extends the probabilistic roadmap (PRM) approach to belief spaces and is based on the recently developed theory of covariance steering (CS) that enables guaranteed satisfaction of terminal belief constraints in finitetime. The CS-BRM algorithm allows the sampling of non-stationary belief nodes, and thus is able to explore the velocity space and find efficient motion plans. We evaluate CS-BRM in different planning problems and demonstrate the benefits of the proposed approach.",
        "primary_area": "",
        "author": "Dongliang Zheng;Jack Ridderhof;Panagiotis Tsiotras;Ali-akbar Agha-mohammadi;Dongliang Zheng;Jack Ridderhof;Panagiotis Tsiotras;Ali-akbar Agha-mohammadi",
        "authorids": "/37086196977;/37088334125;/37330609800;/38274170800;/37086196977;/37088334125;/37330609800;/38274170800",
        "aff": "School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; NASA-JPL, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811560/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7049836776843162416&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Georgia Institute of Technology;California Institute of Technology",
        "aff_unique_dep": "School of Aerospace Engineering;",
        "aff_unique_url": "https://www.gatech.edu;https://www.caltech.edu",
        "aff_unique_abbr": "Georgia Tech;Caltech",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Atlanta;Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811665",
        "title": "Bidirectional Communication Control for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "A fruitful collaboration is based on the mutual knowledge of each other skills and on the possibility of communicating their own limits and proposing alternatives to adapt the execution of a task to the capabilities of the collaborators. This paper aims at reproducing such a scenario in a human-robot collaboration setting by proposing a novel communication control architecture. Exploiting control barrier functions, the robot is made aware of its (dynamic) skills and limits and, thanks to a local predictor, it is able to assess if it is possible to execute a requested task and, if not, to propose alternative by relaxing some constraints. The controller is interfaced with a communication infrastructure that enables human and robot to set up a bidirectional communication about the task to execute and the human to take an informed decision on the behavior of the robot. A comparative experimental validation is proposed.",
        "primary_area": "",
        "author": "Davide Ferrari;Federico Benzi;Cristian Secchi;Davide Ferrari;Federico Benzi;Cristian Secchi",
        "authorids": "/37089447302;/37088995970;/37300905500;/37089447302;/37088995970;/37300905500",
        "aff": "Department of Sciences and Methods of Engineering, University of Modena and Reggio Emilia, Italy; Department of Sciences and Methods of Engineering, University of Modena and Reggio Emilia, Italy; Department of Sciences and Methods of Engineering, University of Modena and Reggio Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811665/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7383132206983100643&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia",
        "aff_unique_dep": "Department of Sciences and Methods of Engineering",
        "aff_unique_url": "https://www.unimore.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9811988",
        "title": "Bidirectional Soft Robotic Catheter for Arrhythmia Treatment",
        "track": "main",
        "status": "Poster",
        "abstract": "Heart rhythm disorders are becoming increasingly prevalent with population aging. Atrial fibrillation ablation (AFA) is a procedure used to treat an irregular heart rhythm (arrhythmia) that starts in the heart's upper chambers. The AFA works by scarring or destroying heart tissue to disrupt aberrant conduction pathways causing the arrhythmia. In hospital cardiac units, a flexible catheter with integrated metal electrode is currently used for the AFA procedure. Despite advances, existing cardiac catheter tips are driven by cable mechanisms which are associated with high nonlinear hysteresis and force loss. In addition, they are also limited to rigid components which require multiple actuators to control the bending tip to reach the complex anatomical corners of the heart. This paper introduces a new soft hydraulic catheter that can achieve bidirectional bending motion via a single soft artificial muscle. The new catheter is also equipped with a portable handle as an ergonomic control interface. To validate the design concept, various prototypes are fabricated and tested including bending angles and generated force capability. Mathematical models for the bending arm are also developed and experimentally validated. The new soft catheter will enable rapid and precise manipulation to reach any target within the cardiac chambers, offering more rapid and focused ablation therapy to improve patient outcomes.",
        "primary_area": "",
        "author": "Chi Cong Nguyen;Timotius Teh;Mai Thanh Thai;Phuoc Thien Phan;Trung Thien Hoang;Harrison Low;James Davies;Emanuele Nicotra;Nigel H. Lovell;Thanh Nho Do;Chi Cong Nguyen;Timotius Teh;Mai Thanh Thai;Phuoc Thien Phan;Trung Thien Hoang;Harrison Low;James Davies;Emanuele Nicotra;Nigel H. Lovell;Thanh Nho Do",
        "authorids": "/37089447104;/37089446694;/37088497860;/37086208825;/37088498761;/37088845641;/37089446972;/37089449558;/37300634000;/37085436676;/37089447104;/37089446694;/37088497860;/37086208825;/37088498761;/37088845641;/37089446972;/37089449558;/37300634000;/37085436676",
        "aff": "Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Sapienza - Universit\u00e0 Di Roma, Italy; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811988/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1278584664821891484&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0;0",
        "aff_unique_norm": "UNSW Sydney;Sapienza University of Rome",
        "aff_unique_dep": "Graduate School of Biomedical Engineering;",
        "aff_unique_url": "https://www.unsw.edu.au;https://www.uniroma1.it",
        "aff_unique_abbr": "UNSW;Sapienza",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Kensington;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;1;0;0",
        "aff_country_unique": "Australia;Italy"
    },
    {
        "id": "9812247",
        "title": "Bipedal Walking on Constrained Footholds: Momentum Regulation via Vertical COM Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an online walking synthesis methodology to enable dynamic and stable walking on constrained footholds for underactuated bipedal robots. Our approach modulates the change of angular momentum about the foot-ground contact pivot at discrete impact using pre-impact vertical center of mass (COM) velocity. To this end, we utilize the underactuated Linear Inverted Pendulum (LIP) model for approximating the underactuated walking dynamics to provide the desired post-impact angular momentum for each step. Desired outputs are constructed via online optimization combined with closed-form polynomials and tracked via a quadratic program (QP) based controller. This method is demonstrated on two robots, AMBER and 3D Cassie, for which stable walking behaviors with constrained footholds are realized on flat ground, stairs, and randomly located stepping stones.",
        "primary_area": "",
        "author": "Min Dai;Xiaobin Xiong;Aaron Ames;Min Dai;Xiaobin Xiong;Aaron Ames",
        "authorids": "/37089450183;/37086275102;/37300877900;/37089450183;/37086275102;/37300877900",
        "aff": "California Institute of Technology; California Institute of Technology; California Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812247/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4018222313220522327&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812414",
        "title": "Blending Primitive Policies in Shared Control for Assisted Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Movement primitives have the property to accom-modate changes in the robot state while maintaining attraction to the original policy. As such, we investigate the use of primitives as a blending mechanism by considering that state deviations from the original policy are caused by user inputs. As the primitive recovers from the user input, it implicitly blends human and robot policies without requiring their weightings-referred to as arbitration. In this paper, we adopt Dynamical Movement Primitives (DMPs), which allow us to avoid the need for multiple demonstrations, and are fast enough to enable numerous instantiations, one for each hypothesis of the human intent. User studies are presented on assisted teleoperation tasks of reaching multiple goals and dynamic obstacle avoidance. Comparable performance to conventional teleoperation was achieved while significantly decreasing human intervention, often by more than 60%.",
        "primary_area": "",
        "author": "Guilherme Maeda;Guilherme Maeda",
        "authorids": "/37085364007;/37085364007",
        "aff": "Preferred Networks Inc., Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812414/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3944766156703253707&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Preferred Networks Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.preferred-networks.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812161",
        "title": "Brick Yourself within 3 Minutes",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an intelligent machine which can automatically convert the captured portrait into a physical gadget made up of LEGO bricks. On the contrary to synthesising a 2D image or a virtual 3D object, generating physical 3D assembly object needs to take physical properties and assembly process into consideration, leading to more challenges. To generate brick models for arbitrary portraits, we formulate the transformation between the attribute space (extracted from 2D images) and the brick model space as a constraint integer programming problem which can be solved with a heuristic search method. Furthermore, as the bricks are physically scattered, we propose an algorithm to generate corresponding assembly instructions for customized figure-featured-bricks to facilitate users' assembly. Meanwhile, we deploy the proposed algorithms on an automatic machine which integrates a camera, a printer, a laptop, and a brick operation unit. Finally, the generated brick models and assembly instructions are evaluated by a large number of users. It is worth noting that the whole system works as an intelligent vending machine, producing a 150-brick-model within 3 minutes.",
        "primary_area": "",
        "author": "Guyue Zhou;Liyi Luo;Hao Xu;Xinliang Zhang;Haole Guo;Hao Zhao;Guyue Zhou;Liyi Luo;Hao Xu;Xinliang Zhang;Haole Guo;Hao Zhao",
        "authorids": "/37085489402;/37089449103;/37089450837;/37089450352;/37089449179;/37086217629;/37085489402;/37089449103;/37089450837;/37089450352;/37089449179;/37086217629",
        "aff": "Institute for AI Industry Research (AIR), Tsinghua University, China; McGill University, Canada; Qianzhi Technology, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Institute for AI Industry Research (AIR), Tsinghua University, China; Intel Labs and Peking University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812161/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12532460035586739205&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;3",
        "aff_unique_norm": "Tsinghua University;McGill University;Qianzhi Technology;Peking University",
        "aff_unique_dep": "Institute for AI Industry Research (AIR);;;Intel Labs",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.mcgill.ca;;http://www.pku.edu.cn",
        "aff_unique_abbr": "Tsinghua;McGill;;PKU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "9811360",
        "title": "CATs: Task Planning for Shared Control of Assistive Robots with Variable Autonomy",
        "track": "main",
        "status": "Poster",
        "abstract": "From robotic space assistance to healthcare robotics, there is increasing interest in robots that offer adaptable levels of autonomy. In this paper, we propose an action representation and planning framework that is able to generate plans that can be executed with both shared control and supervised autonomy, even switching between them during task execution. The action representation - Constraint Action Templates (CATs) - combine the advantages of Action Templates [1] and Shared Control Templates [2]. We demonstrate that CATs enable our planning framework to generate goal-directed plans for variations of a typical task of daily living, and that users can execute them on the wheelchair-robot EDAN in shared control or in autonomous mode.",
        "primary_area": "",
        "author": "Samuel Bustamante;Gabriel Quere;Daniel Leidner;J\u00f6rn Vogel;Freek Stulp;Samuel Bustamante;Gabriel Quere;Daniel Leidner;J\u00f6rn Vogel;Freek Stulp",
        "authorids": "/37088505028;/37086933696;/37586132500;/37602887100;/37681682200;/37088505028;/37086933696;/37586132500;/37602887100;/37681682200",
        "aff": "German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u00dfling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u00dfling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u00dfling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u00dfling, Germany; German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), We\u00dfling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811360/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12481949791673433088&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Robotics and Mechatronics Center",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812250",
        "title": "CCO-VOXEL: Chance Constrained Optimization over Uncertain Voxel-Grid Representation for Safe Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present CCO-VOXEL: the very first chance-constrained optimization (CCO) algorithm that can compute trajectory plans with probabilistic safety guarantees in real-time directly on the voxel-grid representation of the world. CCO-VOXEL maps the distribution over the distance to the closest obstacle to a distribution over collision-constraint violation and computes an optimal trajectory that minimizes the violation probability. Importantly, unlike existing works, we never assume the nature of the sensor uncertainty or the probability distribution of the resulting collision-constraint violations. We leverage the notion of Hilbert Space embedding of distributions and Maximum Mean Discrepancy (MMD) to compute a tractable surrogate for the original chance-constrained optimization problem and employ a combination of A* based graph-search and Cross-Entropy Method for obtaining its minimum. We show tangible performance gain in terms of collision avoidance and trajectory smoothness as a consequence of our probabilistic formulation vis a vis state-of-the-art planning methods that do not account for such non-parametric noise. Finally, we also show how a combination of low-dimensional feature embedding and pre-caching of Kernel Matrices of MMD allow us to achieve real-time performance in simulations as well as in implementations on on-board commodity hardware that controls the quadrotor flight.",
        "primary_area": "",
        "author": "Sudarshan S Harithas;Rishabh Dev Yadav;Deepak Singh;Arun Kumar Singh;K Madhava Krishna;Sudarshan S Harithas;Rishabh Dev Yadav;Deepak Singh;Arun Kumar Singh;K Madhava Krishna",
        "authorids": "/37088551179;/37089227841;/37089448377;/38237873200;/38201465600;/37088551179;/37089227841;/37089448377;/38237873200;/38201465600",
        "aff": "RRC, IIIT, Hyderabad, India; RRC, IIIT, Hyderabad, India; RRC, IIIT, Hyderabad, India; University of Tartu, Estonia; RRC, IIIT, Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812250/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15467911666681230614&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "International Institute of Information Technology, Hyderabad;University of Tartu",
        "aff_unique_dep": "Not Available;",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.ut.ee",
        "aff_unique_abbr": "IIIT Hyderabad;UT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hyderabad;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "India;Estonia"
    },
    {
        "id": "9811603",
        "title": "CCRobot-V: A Silkworm-Like Cooperative Cable-Climbing Robotic System for Cable Inspection and Maintenance",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents CCRobot-V, the fifth version of CCRobot, a cooperative serial multi-robot system for bridge cable inspection and maintenance that uses silkworm-like locomotion to climb the entire length of super-long stay cable at high speeds while carrying heavy inspection/maintenance equipment. CCRobot-V consists of one climbing precursor robot, one inspection/maintenance robot, several cable-carrying robots, and a power-tethered cable guiding system. The pre-cursor robot is the \u201chead,\u201d which leads the affiliated sub-robots along the bridge cable. Every sub-robot possesses a pair of self-locking palms. When a sub-robot grips on the bridge cable with its palms, it becomes a fixed anchor point that allows the adjacent sub-robots in front and back to use winches and steel wires to pull themselves upward. With this cooperative multi-robot system, cable inspection/maintenance tasks can be divided into several functional units, with each inspection/maintenance equipment installed separately on a customized sub-robot. Thus, CCRobot-V provides a complete mobile inspection/maintenance work line for a bridge cable. The experimental and field tests demonstrate CCRobot-V's high climbing speed, high payload capacity, and full-length cable moving capability. It has the potential application value for the actual bridge cable inspection/maintenance.",
        "primary_area": "",
        "author": "Zhenliang Zheng;Ning Ding;Huaping Chen;Xiaoli Hu;Zhihao Zhu;Xueqi Fu;Wenchao Zhang;Lin Zhang;Sarsenbek Hazken;Ziya Wang;Min Zhao;Zhenliang Zheng;Ning Ding;Huaping Chen;Xiaoli Hu;Zhihao Zhu;Xueqi Fu;Wenchao Zhang;Lin Zhang;Sarsenbek Hazken;Ziya Wang;Min Zhao",
        "authorids": "/37086610641;/37086099653;/37089197841;/37089448223;/37089449974;/37085497654;/37089195762;/37089450021;/37089196631;/37089447836;/37089193934;/37086610641;/37086099653;/37089197841;/37089448223;/37089449974;/37085497654;/37089195762;/37089450021;/37089196631;/37089447836;/37089193934",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811603/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9629651457411117912&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_url": "https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812272",
        "title": "CLA-NeRF: Category-Level Articulated Neural Radiance Field",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose CLA-NeRF - a Category-Level Articulated Neural Radiance Field that can perform view synthesis, part segmentation, and articulated pose estimation. CLA-NeRF is trained at the object category level using no CAD models and no depth, but a set of RGB images with ground truth camera poses and part segments. During inference, it only takes a few RGB views (i.e., few-shot) of an unseen 3D object instance within the known category to infer the object part segmentation and the neural radiance field. Given an articulated pose as input, CLA-NeRF can perform articulation-aware volume rendering to generate the corresponding RGB image at any camera pose. Moreover, the articulated pose of an object can be estimated via inverse rendering. In our experiments, we evaluate the framework across five categories on both synthetic and real-world data. In all cases, our method shows realistic deformation results and accurate articulated pose estimation. We believe that both few-shot articulated object rendering and articulated pose estimation open doors for robots to perceive and interact with unseen articulated objects.",
        "primary_area": "",
        "author": "Wei-Cheng Tseng;Hung-Ju Liao;Lin Yen-Chen;Min Sun;Wei-Cheng Tseng;Hung-Ju Liao;Lin Yen-Chen;Min Sun",
        "authorids": "/37089450338;/37089448480;/37088505485;/37085873757;/37089450338;/37089448480;/37088505485;/37085873757",
        "aff": "National Tsing Hua University; National Tsing Hua University; Massachusetts Institute of Technology; Appier Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812272/",
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9388177443862893972&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "National Tsing Hua University;Massachusetts Institute of Technology;Appier Inc.",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nthu.edu.tw;https://web.mit.edu;https://www.appier.com",
        "aff_unique_abbr": "NTHU;MIT;Appier",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9812373",
        "title": "COP: Control & Observability-aware Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this research, we aim to answer the question: How to combine Closed-Loop State and Input Sensitivity-based with Observability-aware trajectory planning? These possibly op-posite optimization objectives can be used to improve trajectory control tracking and, at the same time, estimation performance. Our proposed novel Control & Observability-aware Planning (COP) framework is the first that uses these possibly opposing objectives in a Single-Objective Optimization Problem (SOOP) based on the Augmented Weighted Tchebycheff method to perform the balancing of them and generation of B\u00e9zier curve-based trajectories. Statistically relevant simulations for a 3D quadrotor unmanned aerial vehicle (UAV) case study produce results that support our claims and show the negative correlation between both objectives. We were able to reduce the positional mean integral error norm as well as the estimation uncertainty with the same trajectory to comparable levels of the trajectories optimized with individual objectives.",
        "primary_area": "",
        "author": "Christoph B\u00f6hm;Pascal Brault;Quentin Delamare;Paolo Robuffo Giordano;Stephan Weiss;Christoph B\u00f6hm;Pascal Brault;Quentin Delamare;Paolo Robuffo Giordano;Stephan Weiss",
        "authorids": "/37088521138;/37089308665;/37086301982;/37544316400;/37535323400;/37088521138;/37089308665;/37086301982;/37544316400;/37535323400",
        "aff": "Control of Networked Systems Group at the University of Klagenfurt, Austria; ENS, Inria, IRISA, Campus de Beaulieu, Univ Rennes, Rennes Cedex, France; ENS, Inria, IRISA, Campus de Beaulieu, Univ Rennes, Rennes Cedex, France; CNRS, Inria, IRISA, Campus de Beaulieu, Univ Rennes, Rennes Cedex, France; Control of Networked Systems Group at the University of Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812373/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2351233209111359571&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "University of Klagenfurt;Ecole Normale Superieure;CNRS",
        "aff_unique_dep": "Control of Networked Systems Group;;",
        "aff_unique_url": "https://www.uni-klagenfurt.at;https://www.ens.fr;https://www.cnrs.fr",
        "aff_unique_abbr": ";ENS;CNRS",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Campus de Beaulieu",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "Austria;France"
    },
    {
        "id": "9811767",
        "title": "CPGNet: Cascade Point-Grid Fusion Network for Real-Time LiDAR Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR semantic segmentation essential for advanced autonomous driving is required to be accurate, fast, and easy-deployed on mobile platforms. Previous point-based or sparse voxel-based methods are far away from real-time applications since time-consuming neighbor searching or sparse 3D convolution are employed. Recent 2D projection-based methods, including range view and multi-view fusion, can run in real time, but suffer from lower accuracy due to information loss during the 2 DD projection. Besides, to improve the performance, previous methods usually adopt test time augmentation (TTA), which further slows down the inference process. To achieve a better speed-accuracy trade-off, we propose Cascade Point-Grid Fusion Network (CPGNet), which ensures both effectiveness and efficiency mainly by the following two techniques: 1) the novel Point-Grid (PG) fusion block extracts semantic features mainly on the 2D projected grid for efficiency, while summarizes both 2D and 3D features on 3D point for minimal information loss; 2) the proposed transformation consistency loss narrows the gap between the single-time model inference and TTA. The experiments on the SemanticKITTI and nuScenes benchmarks demonstrate that the CPGNet without ensemble models or TTA is comparable with the state-of-the-art RPVNet, while it runs 4.7 times faster.",
        "primary_area": "",
        "author": "Xiaoyan Li;Gang Zhang;Hongyu Pan;Zhenhua Wang;Xiaoyan Li;Gang Zhang;Hongyu Pan;Zhenhua Wang",
        "authorids": "/37087014443;/37089449949;/37089613518;/37075914500;/37087014443;/37089449949;/37089613518;/37075914500",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; Damo Academy, Alibaba Group; Damo Academy, Alibaba Group; Damo Academy, Alibaba Group",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811767/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4240173338877615284&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Alibaba Group",
        "aff_unique_dep": ";Damo Academy",
        "aff_unique_url": "http://www.ucas.ac.cn;https://www.alibaba-group.com",
        "aff_unique_abbr": "UCAS;Alibaba",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811732",
        "title": "CRANE: a 10 Degree-of-Freedom, Tele-surgical System for Dexterous Manipulation within Imaging Bores",
        "track": "main",
        "status": "Poster",
        "abstract": "Physicians perform minimally invasive percuta-neous procedures under Computed Tomography (CT) image guidance both for the diagnosis and treatment of numerous diseases. For these procedures performed within Computed Tomography Scanners, robots can enable physicians to more accurately target sub-dermal lesions while increasing safety. However, existing robots for this application have limited dexterity, workspace, or accuracy. This paper describes the design, manufacture, and performance of a highly dexterous, low-profile, 8+2 Degree-of-Freedom (DoF) robotic arm for CT guided percutaneous needle biopsy. In this article, we propose CRANE: CT Robot and Needle Emplacer. The design focuses on system dexterity with high accuracy: extending physicians' ability to manipulate and insert needles within the scanner bore while providing the high accuracy possible with a robot. We also propose and validate a system architecture and control scheme for low profile and highly accurate image-guided robotics, that meets the clinical requirements for target accuracy during an in-situ evaluation. The accuracy is additionally evaluated through a trajectory tracking evaluation resulting in < \\boldsymbol{0.2}\\mathbf{mm}< \\boldsymbol{0.2}\\mathbf{mm} and <\\boldsymbol{ 0.71}^{\\circ}<\\boldsymbol{ 0.71}^{\\circ} tracking error. Finally, we present a novel needle driving and grasping mechanism with controlling electronics that provides simple manufacturing, sterilization, and adaptability to accom-modate different sizes and types of needles.",
        "primary_area": "",
        "author": "Dimitri Schreiber;Zhaowei Yu;Hanpeng Jiang;Taylor Henderson;Guosong Li;Julie Yu;Renjie Zhu;Alexander M. Norbash;Michael C. Yip;Dimitri Schreiber;Zhaowei Yu;Hanpeng Jiang;Taylor Henderson;Guosong Li;Julie Yu;Renjie Zhu;Alexander M. Norbash;Michael C. Yip",
        "authorids": "/37087322737;/37089449879;/37089449023;/37086339549;/37089449814;/37089450902;/37089450596;/37990574500;/37085382768;/37087322737;/37089449879;/37089449023;/37086339549;/37089449814;/37089450902;/37089450596;/37990574500;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Mechanical Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Radiology, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811732/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4754483934011054623&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811637",
        "title": "CRAT-Pred: Vehicle Trajectory Prediction with Crystal Graph Convolutional Neural Networks and Multi-Head Self-Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting the motion of surrounding vehicles is essential for autonomous vehicles, as it governs their own motion plan. Current state-of-the-art vehicle prediction models heavily rely on map information. In reality, however, this information is not always available. We therefore propose CRAT-Pred, a multi-modal and non-rasterization-based trajectory prediction model, specifically designed to effectively model social interactions between vehicles, without relying on map information. CRAT-Pred applies a graph convolution method originating from the field of material science to vehicle prediction, allowing to efficiently leverage edge features, and combines it with multi-head self-attention. Compared to other map-free approaches, the model achieves state-of-the-art performance with a significantly lower number of model parameters. In addition to that, we quantitatively show that the self-attention mechanism is able to learn social interactions between vehicles, with the weights representing a measurable interaction score. The source code is publicly available33Source code: https://github.com/schmidt-ju/crat-pred.",
        "primary_area": "",
        "author": "Julian Schmidt;Julian Jordan;Franz Gritschneder;Klaus Dietmayer;Julian Schmidt;Julian Jordan;Franz Gritschneder;Klaus Dietmayer",
        "authorids": "/37089003903;/37089448067;/37085728665;/37283417900;/37089003903;/37089448067;/37085728665;/37283417900",
        "aff": "Ulm University, Institute of Measurement, Control and Microtechnology, Ulm, Germany; R&D, Mercedes-Benz AG, Stuttgart, Germany; R&D, Mercedes-Benz AG, Stuttgart, Germany; Ulm University, Institute of Measurement, Control and Microtechnology, Ulm, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811637/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12266542957976156758&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Ulm University;Mercedes-Benz AG",
        "aff_unique_dep": "Institute of Measurement, Control and Microtechnology;R&D",
        "aff_unique_url": "https://www.uni-ulm.de;https://www.mercedes-benz.com",
        "aff_unique_abbr": ";MB AG",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Ulm;Stuttgart",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811849",
        "title": "CT-ICP: Real-time Elastic LiDAR Odometry with Loop Closure",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-beam LiDAR sensors are increasingly used in robotics, particularly with autonomous cars for localization and perception tasks, both relying on the ability to build a precise map of the environment. For this, we propose a new real-time LiDAR-only odometry method called CT-ICP (for Continuous-Time ICP), completed into a full SLAM with a novel loop detection procedure. The core of this method, is the introduction of the combined continuity in the scan matching, and discontinuity between scans. It allows both the elastic distortion of the scan during the registration for increased precision, and the increased robustness to high frequency motions from the discontinuity. We build a complete SLAM on top of this odometry, using a fast pure LiDAR loop detection based on elevation image 2D matching, providing a pose graph with loop constraints. To show the robustness of the method, we tested it on seven datasets: KITTI, KITTI-raw, KITTI-360, KITTICARLA, ParisLuco, Newer College, and NCLT in driving and high-frequency motion scenarios. Both the CT-ICP odometry and the loop detection are made available online. CT-ICP is currently first, among those giving access to a public code, on the KITTI odometry leaderboard, with an average Relative Translation Error (RTE) of 0.59% and an average time per scan of 60ms on a CPU with a single thread.",
        "primary_area": "",
        "author": "Pierre Dellenbach;Jean-Emmanuel Deschaud;Bastien Jacquet;Fran\u00e7ois Goulette;Pierre Dellenbach;Jean-Emmanuel Deschaud;Bastien Jacquet;Fran\u00e7ois Goulette",
        "authorids": "/37089197985;/38519215400;/37076103600;/37402879500;/37089197985;/38519215400;/37076103600;/37402879500",
        "aff": "Kitware, Computer Vision Team, Villeurbanne, France; Centre for Robotics, MINES ParisTech, PSL University, Paris, France; Kitware, Computer Vision Team, Villeurbanne, France; Centre for Robotics, MINES ParisTech, PSL University, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811849/",
        "gs_citation": 268,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10102112696189425089&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 24,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Kitware;MINES ParisTech",
        "aff_unique_dep": "Computer Vision Team;Centre for Robotics",
        "aff_unique_url": "https://www.kitware.com;https://www.minesparistech.fr",
        "aff_unique_abbr": ";MINES ParisTech",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Paris",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9811568",
        "title": "CaTGrasp: Learning Category-Level Task-Relevant Grasping in Clutter from Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Task-relevant grasping is critical for industrial assembly, where downstream manipulation tasks constrain the set of valid grasps. Learning how to perform this task, however, is challenging, since task-relevant grasp labels are hard to define and annotate. There is also yet no consensus on proper representations for modeling or off-the-shelf tools for performing task-relevant grasps. This work proposes a framework to learn task-relevant grasping for industrial objects without the need of time-consuming real-world data collection or manual annotation. To achieve this, the entire framework is trained solely in simulation, including supervised training with synthetic label generation and self-supervised, hand-object interaction. In the context of this framework, this paper proposes a novel, object-centric canonical representation at the category level, which allows establishing dense correspondence across object instances and transferring task-relevant grasps to novel instances. Extensive experiments on task-relevant grasping of densely-cluttered industrial objects are conducted in both simulation and real-world setups, demonstrating the effectiveness of the proposed framework. Code and data are available at https://sites.google.com/view/catgrasp.",
        "primary_area": "",
        "author": "Bowen Wen;Wenzhao Lian;Kostas Bekris;Stefan Schaal;Bowen Wen;Wenzhao Lian;Kostas Bekris;Stefan Schaal",
        "authorids": "/37088488448;/37088998889;/37282424700;/37282144700;/37088488448;/37088998889;/37282424700;/37282144700",
        "aff": "Rutgers University, NJ, USA; Intrinsic Innovation LLC, CA, USA; Rutgers University, NJ, USA; Intrinsic Innovation LLC, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811568/",
        "gs_citation": 99,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4090878567098922283&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Rutgers University;Intrinsic Innovation LLC",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.rutgers.edu;",
        "aff_unique_abbr": "Rutgers;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New Brunswick;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812007",
        "title": "Camera-Tracklet-Aware Contrastive Learning for Unsupervised Vehicle Re-Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, vehicle re-identification methods based on deep learning constitute remarkable achievement. However, this achievement requires large-scale and well-annotated datasets. In constructing the dataset, assigning globally available identities (Ids) to vehicles captured from a great number of cameras is labour-intensive, because it needs to consider their subtle appearance differences or viewpoint variations. In this paper, we propose camera-tracklet-aware contrastive learning (CTACL) using the multi-camera tracklet information without vehicle identity labels. The proposed CTACL divides an unlabelled domain, i.e., entire vehicle images, into multiple camera-level subdomains and conducts contrastive learning within and beyond the subdomains. The positive and negative samples for contrastive learning are defined using tracklet Ids of each camera. Additionally, the domain adaptation across camera networks is introduced to improve the generalisation performance of learnt representations and alleviate the performance degradation resulted from the domain gap between the subdomains. We demonstrate the effectiveness of our approach on video-based and image-based vehicle Re-ID datasets. Experimental results show that the proposed method outperforms the recent state-of-the-art unsupervised vehicle Re-ID methods. The source code for this paper is publicly available on https://github.com/andreYoo/CTAM-CTACL-VVReID.git.",
        "primary_area": "",
        "author": "Jongmin Yu;Junsik Kim;Minkyung Kim;Hyeontaek Oh;Jongmin Yu;Junsik Kim;Minkyung Kim;Hyeontaek Oh",
        "authorids": "/37089731854;/37068806700;/37086387012;/38063839000;/37089731854;/37068806700;/37086387012;/38063839000",
        "aff": "Institute for IT Convergence, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; KAIST, School of Electrical Engineering, Daejeon, Republic of Korea; KAIST, School of Electrical Engineering, Daejeon, Republic of Korea; Institute for IT Convergence, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812007/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17147364848164446556&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;KAIST",
        "aff_unique_dep": "Institute for IT Convergence;School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST;KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812187",
        "title": "Can your drone touch? Exploring the boundaries of consumer-grade multirotors for physical interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial robots have been widely used as sensor carrying platforms in a wide range of application, mainly because using this type of systems for physical interaction seems to be an unsuitable operation. This is not only due to the risk of collision and damage of the platform, but also because it is unclear whether a consumer-grade UAV can withstand physical contact with the environment. In this paper, we address the issue of performing physical interaction with the environment by a multirotor UAV implementing a basic cascaded position-attitude controller, typical of most of consumer-grade multirotor systems. Precisely, we identify mathematically the boundaries where the system can safely be used to perform physical interaction with the environment. The theoretical approach is finally validated through experiments showing that physical contact can only be achieved within a predefined region of control inputs.",
        "primary_area": "",
        "author": "Paul Lassen;Matteo Fumagalli;Paul Lassen;Matteo Fumagalli",
        "authorids": "/37089449766;/37533446100;/37089449766;/37533446100",
        "aff": "Department of Electrical Engineering, Automation and Control, Technical University of Denmark, Kgs. Lyngby, Denmark; Department of Electrical Engineering, Automation and Control, Technical University of Denmark, Kgs. Lyngby, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812187/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2954000627564070275&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Denmark",
        "aff_unique_dep": "Department of Electrical Engineering, Automation and Control",
        "aff_unique_url": "https://www.tu.dk",
        "aff_unique_abbr": "DTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kgs. Lyngby",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9811734",
        "title": "Capacitive Proximity Sensor for Non-Contact Endoscope Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "The promising automation of flexible surgical instruments and robots is impeded by the lack of sensory means, which allow for sensing of an instrument's position to the surrounding tissue. This work presents a novel sensory method utilizing capacitive proximity sensing to derive a relative localization of a flexible instrument inside a hollow organ. The method is evaluated by exemplary integration of a sensor in a commercial gastroendoscope and accuracy analysis using a high precision robot. The results show an accuracy of distance sensing from a medical phantom's center of 2%. The method is also evaluated for the irregularly shaped surrounding of ex-vivo tissue in a dynamic scenario. This promising approach holds potential for transfer to clinical scenarios and for further development towards pose estimation of flexible surgical robots and shape sensing of a minimally invasive environment.",
        "primary_area": "",
        "author": "Christian Marzi;Hosam Alagi;Olivia Rau;Jochen Hampe;Jan Gerrit Korvink;Bj\u00f6rn Hein;Franziska Mathis-Ullrich;Christian Marzi;Hosam Alagi;Olivia Rau;Jochen Hampe;Jan Gerrit Korvink;Bj\u00f6rn Hein;Franziska Mathis-Ullrich",
        "authorids": "/37089447256;/38666348400;/37089448947;/37089446850;/37271471200;/37604448500;/37088949823;/37089447256;/38666348400;/37089448947;/37089446850;/37271471200;/37604448500;/37088949823",
        "aff": "Health Robotics and Automation Laboratory, Institute for Anthropo-matics and Robotics, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Intelligent Process Automation and Robotics Laboratory, Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute of Microstructure Technology, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Department of Medicine I, University Hospital Dresden, Technical University (TU) Dresden, Dresden, Germany; Institute of Microstructure Technology, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Karlsruhe University of Applied Sciences, Karlsruhe, Germany; Health Robotics and Automation Laboratory, Institute for Anthropo-matics and Robotics, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811734/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11491448247922394252&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;2;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Technical University Dresden;Karlsruhe University of Applied Sciences",
        "aff_unique_dep": "Institute for Anthropo-matics and Robotics;Department of Medicine I;",
        "aff_unique_url": "https://www.kit.edu;https://tu-dresden.de;https://www.hs-karlsruhe.de",
        "aff_unique_abbr": "KIT;TU Dresden;HsKA",
        "aff_campus_unique_index": "0;0;0;1;0;0;0",
        "aff_campus_unique": "Karlsruhe;Dresden",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811696",
        "title": "Capacitive Tactile Sensor Using Mutual Capacitance Sensing Method for Increased Resolution",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots move toward more complex environments, imbuing them with a sense of touch similar to humans becomes increasingly important. To fulfill that goal, there has been significant research conducted in the past few decades to develop a tactile sensor that matches human level touch capabilities. Recently, the progress in capacitive touch screens has made capacitive sensing a very appealing option for such a sensor, and therefore many research groups have proposed novel designs of tactile sensors based on capacitive technologies. This technology has the advantage of generating a predictable sensor response with a high degree of sensitivity, but has the drawback of a limited spatial resolution. This paper shows how using mutual capacitance in combination with a microstructured dielectric can lead to a very sensitive sensor that also possesses a high spatial resolution. The response of the sensor in relation to its various components is explored in order to fully comprehend the physical principles of the sensing mechanism and generate a predictable output.",
        "primary_area": "",
        "author": "Jean-Christophe Sicotte-Brisson;Alexandre Bernier;Jennifer Kwiatkowski;Vincent Duchaine;Jean-Christophe Sicotte-Brisson;Alexandre Bernier;Jennifer Kwiatkowski;Vincent Duchaine",
        "authorids": "/37089449390;/37089447059;/37086302783;/37293913400;/37089449390;/37089447059;/37086302783;/37293913400",
        "aff": "Jean-Christophe Sicotte-Brisson; Alexandre Bernier; Jennifer Kwiatkowski; Vincent Duchaine",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811696/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7580148289663843073&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9812188",
        "title": "Causal-based Time Series Domain Generalization for Vehicle Intention Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurately predicting the possible behaviors of traffic participants is an essential capability for autonomous vehicles. Since autonomous vehicles need to navigate in dynamically changing environments, they are expected to make accurate predictions regardless of where they are and what driving circumstances they encountered. Therefore, generalization capability to unseen domains is crucial for prediction models when autonomous vehicles are deployed in the real world. In this paper, we aim to address the domain generalization problem for vehicle intention prediction tasks and a causal-based time series domain generalization (CTSDG) model is proposed. We construct a structural causal model for vehicle intention prediction tasks to learn an invariant representation of input driving data for domain generalization. We further integrate a recurrent latent variable model into our structural causal model to better capture temporal latent dependencies from time-series input data. The effectiveness of our approach is evaluated via real-world driving data. We demonstrate that our proposed method has consistent improvement on prediction accuracy compared to other state-of-the-art domain generalization and behavior prediction methods.",
        "primary_area": "",
        "author": "Yeping Hu;Xiaogang Jia;Masayoshi Tomizuka;Wei Zhan;Yeping Hu;Xiaogang Jia;Masayoshi Tomizuka;Wei Zhan",
        "authorids": "/37086307227;/37089446714;/37281933000;/37067099600;/37086307227;/37089446714;/37281933000;/37067099600",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Computer Science, University of Bristol, UK; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812188/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18083435019417159586&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;University of Bristol",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.berkeley.edu;https://www.bristol.ac.uk",
        "aff_unique_abbr": "UC Berkeley;Bristol",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9811799",
        "title": "CenterSnap: Single-Shot Multi-Object 3D Shape Reconstruction and Categorical 6D Pose and Size Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the complex task of simultaneous multi-object 3D reconstruction, 6D pose and size estimation from a single-view RGB-D observation. In contrast to instance- level pose estimation, we focus on a more challenging problem where CAD models are not available at inference time. Existing approaches mainly follow a complex multi-stage pipeline which first localizes and detects each object instance in the image and then regresses to either their 3D meshes or 6D poses. These approaches suffer from high-computational cost and low performance in complex multi-object scenarios, where occlusions can be present. Hence, we present a simple one- stage approach to predict both the 3D shape and estimate the 6D pose and size jointly in a bounding-box free manner. In particular, our method treats object instances as spatial centers where each center denotes the complete shape of an object along with its 6D pose and size. Through this per- pixel representation, our approach can reconstruct in real- time (40 FPS) multiple novel object instances and predict their 6D pose and sizes in a single-forward pass. Through extensive experiments, we demonstrate that our approach significantly outperforms all shape completion and categorical 6D pose and size estimation baselines on multi-object ShapeNet and NOCS datasets respectively with a 12.6% absolute improvement in mAP for 6D pose for novel real-world object instances.",
        "primary_area": "",
        "author": "Muhammad Zubair Irshad;Thomas Kollar;Michael Laskey;Kevin Stone;Zsolt Kira;Muhammad Zubair Irshad;Thomas Kollar;Michael Laskey;Kevin Stone;Zsolt Kira",
        "authorids": "/37089000067;/37402789000;/37085370242;/37089258903;/37681676600;/37089000067;/37402789000;/37085370242;/37089258903;/37681676600",
        "aff": "Georgia Institute of Technology; Toyota Research Institute; Toyota Research Institute; Toyota Research Institute; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811799/",
        "gs_citation": 83,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16228756887879837072&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Toyota Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gatech.edu;https://www.tri.global",
        "aff_unique_abbr": "Georgia Tech;TRI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812147",
        "title": "Centroidal Aerodynamic Modeling and Control of Flying Multibody Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a modeling and control frame-work for multibody flying robots subject to non-negligible aero-dynamic forces acting on the centroidal dynamics. First, aero-dynamic forces are calculated during robot flight in different operating conditions by means of Computational Fluid Dynamics (CFD) analysis. Then, analytical models of the aerodynamics coefficients are generated from the dataset collected with CFD analysis. The obtained simplified aerodynamic model is also used to improve the flying robot control design. We present two control strategies: compensating for the aerodynamic effects via feedback linearization and enforcing the controller robustness with gain-scheduling. Simulation results on the jet-powered humanoid robot iRonCub validate the proposed approach.",
        "primary_area": "",
        "author": "Tong Hui;Antonello Paolino;Gabriele Nava;Giuseppe L'Erario;Fabio Di Natale;Fabio Bergonti;Francesco Braghin;Daniele Pucci;Tong Hui;Antonello Paolino;Gabriele Nava;Giuseppe L'Erario;Fabio Di Natale;Fabio Bergonti;Francesco Braghin;Daniele Pucci",
        "authorids": "/37089939818;/37089447182;/37086044221;/37087995791;/37089447891;/37086933580;/37564362300;/37706167200;/37089939818;/37089447182;/37086044221;/37087995791;/37089447891;/37086933580;/37564362300;/37706167200",
        "aff": "Department of Mechanical Engineering, Politecnico di Milano, Milan, Italy; Department of Industrial Engineering, Universit\u00e0 degli Studi di Napoli Federico II, Naples, Italy; Artificial and Mechanical Intelligence, Istituto Italiano di Tecnologia, Genova, Italy; School of Computer Science, Univ. of Manchester, Manchester, U.K.; Artificial and Mechanical Intelligence, Istituto Italiano di Tecnologia, Genova, Italy; School of Computer Science, Univ. of Manchester, Manchester, U.K.; Department of Mechanical Engineering, Politecnico di Milano, Milan, Italy; School of Computer Science, Univ. of Manchester, Manchester, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812147/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12122396015654894634&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;3;2;3;0;3",
        "aff_unique_norm": "Politecnico di Milano;Universit\u00e0 degli Studi di Napoli Federico II;Istituto Italiano di Tecnologia;University of Manchester",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Industrial Engineering;Artificial and Mechanical Intelligence;School of Computer Science",
        "aff_unique_url": "https://www.polimi.it;https://www.unina.it;https://www.iit.it;https://www.manchester.ac.uk",
        "aff_unique_abbr": "Politecnico di Milano;;IIT;UoM",
        "aff_campus_unique_index": "0;1;2;3;2;3;0;3",
        "aff_campus_unique": "Milan;Naples;Genova;Manchester",
        "aff_country_unique_index": "0;0;0;1;0;1;0;1",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "9812130",
        "title": "Characterizing Error in Noncommutative Geometric Gait Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "A key problem in robotic locomotion is in finding optimal shape changes to effectively displace systems through the world. Variational techniques for gait optimization require estimates of body displacement per gait cycle; however, these estimates introduce error due to unincluded high order terms. In this paper, we formulate existing estimates for displacement, and describe the contribution of low order terms to these estimates. We additionally describe the magnitude of higher (third) order effects, and identify that choice of body coordinate, gait diameter, and starting phase influence these effects. We demonstrate that variation of such parameters on two example systems (the differential drive car and Purcell swimmer) effectively manages third order contributions.",
        "primary_area": "",
        "author": "Capprin Bass;Suresh Ramasamy;Ross L. Hatton;Capprin Bass;Suresh Ramasamy;Ross L. Hatton",
        "authorids": "/37089449422;/37086154106;/37542919100;/37089449422;/37086154106;/37542919100",
        "aff": "Collaborative Institute for Robotics and Intelligent Systems (CoRIS), Oregon State University, Corvallis, Oregon; Collaborative Institute for Robotics and Intelligent Systems (CoRIS), Oregon State University, Corvallis, Oregon; Collaborative Institute for Robotics and Intelligent Systems (CoRIS), Oregon State University, Corvallis, Oregon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812130/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14338430615635699148&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Institute for Robotics and Intelligent Systems (CoRIS)",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811751",
        "title": "Charting the trade-off between design complexity and plan execution under probabilistic actions",
        "track": "main",
        "status": "Poster",
        "abstract": "Practical robot designs must strike a compromise between fabrication/manufacture cost and anticipated execution performance. Compared to parsimonious designs, more capable (and hence more expensive) robots generally achieve their ends with greater efficiency. This paper examines how the roboticist might explore the space of designs to gain an understanding of such trade-offs. We focus, specifically, on design choices that alter the set of actions available to the robot, and model those actions as involving uncertainty. We consider planning problems under the Markov Decision Process (MDP) model, which leads us to examine how to relate the cost of some design to the expected cost of an execution for the optimal policies feasible with that design. The complexity of this problem \u2500expressed via hardness in the fixed parameter tractability sense\u2500depends on the number of actions to choose from. When that number is not negligible, we give a novel representation and an algorithm utilizing that structure that allows useful savings over na\u00efve enumeration.",
        "primary_area": "",
        "author": "Fatemeh Zahra Saberifar;Dylan A. Shell;Jason M. O'Kane;Fatemeh Zahra Saberifar;Dylan A. Shell;Jason M. O'Kane",
        "authorids": "/37086310003;/37269198900;/37279835400;/37086310003;/37269198900;/37279835400",
        "aff": "Department of Computer Sciences, Tarbiat Modares University, Tehran, Iran; Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811751/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2873768368813957467&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Tarbiat Modares University;Texas A&M University;University of South Carolina",
        "aff_unique_dep": "Department of Computer Sciences;Department of Computer Science and Engineering;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.modares.ac.ir;https://www.tamu.edu;https://www.sc.edu",
        "aff_unique_abbr": "TMU;TAMU;USC",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Tehran;College Station;Columbia",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Iran;United States"
    },
    {
        "id": "9811827",
        "title": "CineMPC: Controlling Camera Intrinsics and Extrinsics for Autonomous Cinematography",
        "track": "main",
        "status": "Poster",
        "abstract": "We present CineMPC, an algorithm to autonomously control a UAV-borne video camera in a nonlinear Model Predicted Control (MPC) loop. CineMPC controls both the position and orientation of the camera-the camera extrinsics-as well as the lens focal length, focal distance, and aperture-the camera intrinsics. While some existing solutions autonomously control the position and orientation of the camera, no existing solutions also control the intrinsic parameters, which are essential tools for rich cinematographic expression. The intrinsic parameters control the parts of the scene that are focused or blurred, the viewers' perception of depth in the scene and the position of the targets in the image. CineMPC closes the loop from camera images to UAV trajectory and lens parameters in order to follow the desired relative trajectory and image composition as the targets move through the scene. Experiments using a photo-realistic environment demon-strate the capabilities of the proposed control framework to successfully achieve a full array of cinematographic effects not possible without full camera control.",
        "primary_area": "",
        "author": "Pablo Pueyo;Eduardo Montijano;Ana C. Murillo;Mac Schwager;Pablo Pueyo;Eduardo Montijano;Ana C. Murillo;Mac Schwager",
        "authorids": "/37088690443;/37681715400;/37393616700;/37424620600;/37088690443;/37681715400;/37393616700;/37424620600",
        "aff": "Instituto de Investigacion en Ingenieria de Aragon, Universidad de Zaragoza, Spain; Instituto de Investigacion en Ingenieria de Aragon, Universidad de Zaragoza, Spain; Instituto de Investigacion en Ingenieria de Aragon, Universidad de Zaragoza, Spain; Dept. of Aeronautics and Astronautics, Stanford University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811827/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3266670972391964713&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Universidad de Zaragoza;Stanford University",
        "aff_unique_dep": "Instituto de Investigacion en Ingenieria de Aragon;Dept. of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.unizar.es;https://www.stanford.edu",
        "aff_unique_abbr": ";Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Spain;United States"
    },
    {
        "id": "9812144",
        "title": "Cityscapes TL++: Semantic Traffic Light Annotations for the Cityscapes Dataset",
        "track": "main",
        "status": "Poster",
        "abstract": "There is a gap in holistic urban scene understanding between multi-modal datasets for segmentation and object detection on the one hand and traffic light datasets on the other hand. The role of traffic lights in the former is not labelled, making it difficult to use them for higher-level tasks and leave critical information of an intersection scene blank. Including traffic lights from traffic light specific datasets into the comprehensive semantic data introduces a penalty from the domain shift. We close this gap by providing semantically annotated traffic lights for the Cityscapes dataset. We demonstrate the domain shift penalty by using a traffic light dataset from a similar domain and show superior performance on data labelled in the original domain. We demonstrate an application by training a real-time capable network for semantic segmentation and object detection which can now additionally make sense of traffic lights, delivering an F1- Score of 66.4% on the important class of traffic lights relevant to the ego vehicle. The network is made publicly available at https://github.com/joeda/NNAD and the data at https://github.com/KIT-MRT/cityscapes-t1.",
        "primary_area": "",
        "author": "Johannes Janosovits;Johannes Janosovits",
        "authorids": "/37086451376;/37086451376",
        "aff": "Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812144/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14120730388177650549&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute of Measurement and Control Systems",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812448",
        "title": "Cluttered Food Grasping with Adaptive Fingers and Synthetic-Data Trained Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "The food packaging industry handles an immense variety of food products with wide-ranging shapes and sizes, even within one kind of food. Menus are also diverse and change frequently, making automation of pick-and-place difficult. A popular approach to bin-picking is to first identify each piece of food in the tray by using an instance segmentation method. However, human annotations to train these methods are unreli-able and error-prone since foods are packed close together with unclear boundaries and visual similarity making separation of pieces difficult. To address this problem, we propose a method that trains purely on synthetic data and successfully transfers to the real world using sim2real methods by creating datasets of filled food trays using high-quality 3d models of real pieces of food for the training instance segmentation models. Another concern is that foods are easily damaged during grasping. We address this by introducing two additional methods- a novel adaptive finger mechanism to passively retract when a collision occurs, and a method to filter grasps that are likely to cause damage to neighbouring pieces of food during a grasp. We demonstrate the effectiveness of the proposed method on several kinds of real foods.",
        "primary_area": "",
        "author": "Avinash Ummadisingu;Kuniyuki Takahashi;Naoki Fukaya;Avinash Ummadisingu;Kuniyuki Takahashi;Naoki Fukaya",
        "authorids": "/37088690436;/37086937050;/37589216200;/37088690436;/37086937050;/37589216200",
        "aff": "Preferred Networks, Inc.; Preferred Networks, Inc.; Preferred Networks, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812448/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6382460358572252071&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Preferred Networks, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.preferred-networks.com",
        "aff_unique_abbr": "PFN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811364",
        "title": "ColibriDoc: an Eye-in-Hand Autonomous Trocar Docking System",
        "track": "main",
        "status": "Poster",
        "abstract": "Retinal surgery is a complex medical procedure that requires exceptional expertise and dexterity. For this purpose, several robotic platforms are currently under development to enable or improve the outcome of microsurgical tasks. Since the control of such robots is often designed for navigation inside the eye in proximity to the retina, successful trocar docking and insertion of the instrument into the eye represents an additional cognitive effort, and is therefore one of the open challenges in robotic retinal surgery. For this purpose, we present a platform for autonomous trocar docking that combines computer vision and a robotic setup. Inspired by the Cuban Colibri (hummingbird) aligning its beak to a flower using only vision, we mount a camera onto the endeffector of a robotic system. By estimating the position and pose of the trocar, the robot is able to autonomously align and navigate the instrument towards the Trocar Entry Point (TEP) and finally perform the insertion. Our experiments show that the proposed method is able to accurately estimate the position and pose of the trocar and achieve repeatable autonomous docking. The aim of this work is to reduce the complexity of the robotic setup prior to the surgical task and therefore, increase the intuitiveness of the system integration into clinical workflow.",
        "primary_area": "",
        "author": "Shervin Dehghani;Michael Sommersperger;Junjie Yang;Mehrdad Salehi;Benjamin Busam;Kai Huang;Peter Gehlbach;Iulian Iordachita;Nassir Navab;M. Ali Nasseri;Shervin Dehghani;Michael Sommersperger;Junjie Yang;Mehrdad Salehi;Benjamin Busam;Kai Huang;Peter Gehlbach;Iulian Iordachita;Nassir Navab;M. Ali Nasseri",
        "authorids": "/37088645228;/37089447100;/37089447855;/37088710202;/37085664553;/37534912900;/37547001700;/37330620500;/37282965500;/37681019000;/37088645228;/37089447100;/37089447855;/37088710202;/37085664553;/37534912900;/37547001700;/37330620500;/37282965500;/37681019000",
        "aff": "Department of Computer Science in Technische, Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; Department of Computer Science in Technische, Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; Augenklinik und Poliklinik Klinikum rechts der Isar der Technische, Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; Department of Computer Science in Technische, Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; Department of Computer Science in Technische, Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; Key Laboratory of Machine Intelligence and Advanced Computing, Sun Yat-sen University, Guangzhou, China; Wilmer Eye Institute, Johns Hopkins Hospital, Baltimore, MD, USA; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Chair for Computer Aided Medical Procedures Augmented Reality, Technical University of Munich, Munich, Germany; Whiting School of Engineering, Johns Hopkins University, Baltimore, MD, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811364/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8422256281580823009&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;1;2;3;4;3",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Sun Yat-sen University;Johns Hopkins Hospital;Johns Hopkins University;Technical University of Munich",
        "aff_unique_dep": "Department of Computer Science;Key Laboratory of Machine Intelligence and Advanced Computing;Wilmer Eye Institute;Laboratory for Computational Sensing and Robotics;Chair for Computer Aided Medical Procedures Augmented Reality",
        "aff_unique_url": "https://www.tum.de;http://www.sysu.edu.cn;https://www.hopkinsmedicine.org;https://www.jhu.edu;https://www.tum.de",
        "aff_unique_abbr": "TUM;SYSU;JHH;JHU;TUM",
        "aff_campus_unique_index": "0;0;0;0;0;1;2;2;3;2",
        "aff_campus_unique": "M\u00fcnchen;Guangzhou;Baltimore;Munich",
        "aff_country_unique_index": "0;0;0;0;0;1;2;2;0;2",
        "aff_country_unique": "Germany;China;United States"
    },
    {
        "id": "9812102",
        "title": "Collaborative Robot Mapping using Spectral Graph Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we deal with the problem of creating globally consistent pose graphs in a centralized multi-robot SLAM framework. For each robot to act autonomously, individual onboard pose estimates and maps are maintained, which are then communicated to a central server to build an optimized global map. However, inconsistencies between onboard and server estimates can occur due to onboard odometry drift or failure. Furthermore, robots do not benefit from the collaborative map if the server provides no feedback in a computationally tractable and bandwidth-efficient manner. Motivated by this challenge, this paper proposes a novel collaborative mapping framework to enable accurate global mapping among robots and server. In particular, structural differences between robot and server graphs are exploited at different spatial scales using graph spectral analysis to generate necessary constraints for the individual robot pose graphs. The proposed approach is thoroughly analyzed and validated using several real-world multi-robot field deployments where we show improvements of the onboard system up to 90%.",
        "primary_area": "",
        "author": "Lukas Bernreiter;Shehryar Khattak;Lionel Ott;Roland Siegwart;Marco Hutter;Cesar Cadena;Lukas Bernreiter;Shehryar Khattak;Lionel Ott;Roland Siegwart;Marco Hutter;Cesar Cadena",
        "authorids": "/37086451179;/37086181358;/38251784400;/37281398300;/37545251000;/37593590400;/37086451179;/37086181358;/38251784400;/37281398300;/37545251000;/37593590400",
        "aff": "Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Robotics Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Robotics Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812102/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2197256559213886462&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9811659",
        "title": "Collision Avoidance for Multiple Quadrotors Using Elastic Safety Clearance Based Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "When multiple quadrotors fly in a cluttered environment, collision-free flight must be assured. In this paper, we propose a novel elastic safety clearance based model predictive control (ESC-MPC) for multiple maneuverable quadrotors to avoid collisions in the presence of disturbance. This is accomplished through leveraging tube based model predictive control to maintain the quadrotor in a tube of trajectories. Exponential control barrier function (ECBF) is integrated to realize the elastic safety clearance mechanism which offers a dynamic safety margin in maneuverable flight. We validate the superiority of our approach with laboratory experiments.",
        "primary_area": "",
        "author": "Tao Jin;Xinghu Wang;Haibo Ji;Jian Di;Han Yan;Tao Jin;Xinghu Wang;Haibo Ji;Jian Di;Han Yan",
        "authorids": "/37089446799;/37077730100;/37398694500;/37089178519;/37085548829;/37089446799;/37077730100;/37398694500;/37089178519;/37085548829",
        "aff": "Department of Automation, University of Science and Technology of China; Department of Automation, University of Science and Technology of China; Department of Automation, University of Science and Technology of China; Department of Automation, University of Science and Technology of China; Science and Technology on Space Intelligent Control Laboratory, Beijing Institute of Control Engineering, and Beijing SunWise Space Technology Ltd., Beijing, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811659/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2064762217690452455&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Science and Technology of China;Beijing Institute of Control Engineering",
        "aff_unique_dep": "Department of Automation;Science and Technology on Space Intelligent Control Laboratory",
        "aff_unique_url": "http://www.ustc.edu.cn;",
        "aff_unique_abbr": "USTC;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811794",
        "title": "ComOpT: Combination and Optimization for Testing Autonomous Driving Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "ComOpT is an open-source research tool for coverage-driven testing of autonomous driving systems, focusing on planning and control. Starting with (i) a meta-model characterizing discrete conditions to be considered and (ii) constraints specifying the impossibility of certain combinations, ComOpT first generates constraint-feasible abstract scenarios while maximally increasing the coverage of k-way combinatorial testing. Each abstract scenario can be viewed as a conceptual equivalence class, which is then instantiated into multiple concrete scenarios by (1) randomly picking one local map that fulfills the specified geographical condition, and (2) assigning all actors accordingly with parameters within the range. Finally, ComOpT evaluates each concrete scenario against a set of KPIs and performs local scenario variation via spawning a new agent that might lead to a collision at designated points. We use ComOpT to test the Apollo 6 autonomous driving software stack. ComOpT can generate highly diversified scenarios with limited test budgets while uncovering problematic situations such as inabilities to make simple right turns, uncomfortable accelerations, and dangerous driving patterns. ComOpT participated in the 2021 IEEE AI Autonomous Vehicle Testing Challenge and won first place among more than 110 contending teams.",
        "primary_area": "",
        "author": "Changwen Li;Chih-Hong Cheng;Tiantian Sun;Yuhang Chen;Rongjie Yan;Changwen Li;Chih-Hong Cheng;Tiantian Sun;Yuhang Chen;Rongjie Yan",
        "authorids": "/37089448923;/37086835874;/37089447415;/37087027830;/37086392499;/37089448923;/37086835874;/37089447415;/37087027830;/37086392499",
        "aff": "University of Chinese Academy of Sciences, China; Independent contributor, Germany; Beijing University of Technology, China; University of Chinese Academy of Sciences, China; University of Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811794/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17149658854466141597&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Independent contributor;Beijing University of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.ucas.ac.cn;;http://www.bjut.edu.cn",
        "aff_unique_abbr": "UCAS;;BJUT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "9812185",
        "title": "Combined Fast Control of Drifting State and Trajectory Tracking for Autonomous Vehicles Based on MPC Controller",
        "track": "main",
        "status": "Poster",
        "abstract": "Slipping may cause a vehicle out of control with serious accident potential. However, a kind of car slipping named \u201cdrifting\u201d can be seen in professional contests. So, it is reasonable to apply drift maneuvers in autonomous driving. This article proposes a controller for the particular driving skill\u2014drifting based on MPC(Model Predictive Control). Firstly, we analyze drift cornering mechanisms of the 3-state vehicle model and linearize the model at a drifting equilibrium point to build a fast controller. Then, the predicted lateral errors are brought into the MPC cost function to realize trajectory tracking. The algorithm makes use of the expert strategy in car drifting to adjust the steering angle and longitudinal drive force according to lateral errors during the trajectory following. Finally, it is experimentally verified that the proposed controller can track the reference trajectory in real time while maintaining the drifting state.",
        "primary_area": "",
        "author": "Cheng Hu;Xiaoling Zhou;Ran Duo;Haokun Xiong;Yu Qi;Zhiming Zhang;Lei Xie;Cheng Hu;Xiaoling Zhou;Ran Duo;Haokun Xiong;Yu Qi;Zhiming Zhang;Lei Xie",
        "authorids": "/37089016349;/37089016411;/37089580693;/37089583373;/37089076593;/37086521002;/37089404985;/37089016349;/37089016411;/37089580693;/37089583373;/37089076593;/37086521002;/37089404985",
        "aff": "Faculty of Control Technology, ZheJiang University, Hangzhou, China; Faculty of Control Technology, ZheJiang University, Hangzhou, China; Faculty of Control Technology, ZheJiang University, Hangzhou, China; Faculty of Control Technology, ZheJiang University, Hangzhou, China; Faculty of Control Technology, ZheJiang University, Hangzhou, China; Faculty of Control Technology, ZheJiang University, Hangzhou, China; Faculty of Control Technology, ZheJiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812185/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17668056302328287876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "Faculty of Control Technology",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811581",
        "title": "Combined Grid and Feature-based Mapping of Metal Structures with Ultrasonic Guided Waves",
        "track": "main",
        "status": "Poster",
        "abstract": "The ultrasonic mapping of plate-based facilities is an essential step towards the robotic inspection of large metal structures such as storage tanks or ship hulls. This work proposes a novel framework that exploits ultrasonic echoes to recover grid-based and feature-based spatial representations jointly. We aim to improve on a previous mapping method [1] subject to errors due to interference, and which provides plate geometry estimates without uncertainty assessment. The grid can represent, all along the mapping process, both areas identified as inside or outside the current plate and areas whose state is still unknown, making it is suitable e.g. for detecting a change of plate, or for use in a later active-sensing strategy. We also leverage the resulting spatial information to filter out candidate plate edges that are no longer relevant, mitigating the detrimental effect of interference. We test the approach in simulation, with acoustic data acquired manually and with a real robot. Results show that it is effective for building combined map representations and robust to echo misdetection, contrary to a more standard mapping approach.",
        "primary_area": "",
        "author": "Othmane-Latif Ouabi;Ayoub Ridani;Pascal Pomarede;Neil Zeghidour;Nico F. Declercq;Matthieu Geist;C\u00e9dric Pradalier;Othmane-Latif Ouabi;Ayoub Ridani;Pascal Pomarede;Neil Zeghidour;Nico F. Declercq;Matthieu Geist;C\u00e9dric Pradalier",
        "authorids": "/37088587191;/37089317551;/37088689973;/37085809113;/37271297700;/37643800600;/37279005400;/37088587191;/37089317551;/37088689973;/37085809113;/37271297700;/37643800600;/37279005400",
        "aff": "GeorgiaTech Lorraine IRL2958 GT-CNRS, Metz, France; Georgia Institute of Technology, Atlanta, GA, USA; GeorgiaTech Lorraine IRL2958 GT-CNRS, Metz, France; Google Research, Brain Team.; Georgia Institute of Technology, Atlanta, GA, USA; Google Research, Brain Team.; GeorgiaTech Lorraine IRL2958 GT-CNRS, Metz, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811581/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14610144158953248678&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;1;2;0",
        "aff_unique_norm": "Georgia Tech Lorraine;Georgia Institute of Technology;Google",
        "aff_unique_dep": "IRL2958 GT-CNRS;;Google Research",
        "aff_unique_url": "https://lorraine.gatech.edu;https://www.gatech.edu;https://research.google",
        "aff_unique_abbr": "GT Lorraine;Georgia Tech;Google",
        "aff_campus_unique_index": "0;1;0;2;1;2;0",
        "aff_campus_unique": "Metz;Atlanta;Mountain View",
        "aff_country_unique_index": "0;1;0;1;1;1;0",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "9812086",
        "title": "Combining Planning and Learning of Behavior Trees for Robotic Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Industrial robots can solve tasks in controlled environments, but modern applications require robots able to operate also in unpredictable surroundings. An increasingly popular reactive policy architecture in robotics is Behavior Trees (BTs) but as other architectures, programming time drives cost and limits flexibility. The two main branches of algorithms to generate policies automatically, automated planning and machine learning, both have their own drawbacks and have not previously been combined for generation of BTs. We propose a method for creating BTs by combining these branches, inserting the result of an automated planner into the population of a Genetic Programming algorithm. Experiments confirm that the proposed method performs well on a variety of robotic assembly problems and outperforms the base methods used separately. We also show that this high level learning of Behavior Trees can be transferred to a real system without further training.",
        "primary_area": "",
        "author": "Jonathan Styrud;Matteo Iovino;Mikael Norrl\u00f6f;M\u00e5rten Bj\u00f6rkman;Christian Smith;Jonathan Styrud;Matteo Iovino;Mikael Norrl\u00f6f;M\u00e5rten Bj\u00f6rkman;Christian Smith",
        "authorids": "/38580337300;/37089000726;/37326288000;/37283063600;/37559467400;/38580337300;/37089000726;/37326288000;/37283063600;/37559467400",
        "aff": "Division of Robotics, Perception and Learning, Royal Institute of Technology (KTH), Stockholm, Sweden; Division of Robotics, Perception and Learning, Royal Institute of Technology (KTH), Stockholm, Sweden; ABB Robotics, V\u00e4ster\u00e5s, Sweden; Division of Robotics, Perception and Learning, Royal Institute of Technology (KTH), Stockholm, Sweden; Division of Robotics, Perception and Learning, Royal Institute of Technology (KTH), Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812086/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17647626581942003850&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Royal Institute of Technology (KTH);ABB Robotics",
        "aff_unique_dep": "Division of Robotics, Perception and Learning;",
        "aff_unique_url": "https://www.kth.se;https://new.abb.com/robotics",
        "aff_unique_abbr": "KTH;ABB",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Stockholm;V\u00e4ster\u00e5s",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9811674",
        "title": "Communicating Robot Conventions through Shared Autonomy",
        "track": "main",
        "status": "Poster",
        "abstract": "When humans control robot arms these robots often need to infer the human's desired task. Prior research on assistive teleoperation and shared autonomy explores how robots can determine the desired task based on the human's joystick inputs. In order to perform this inference the robot relies on an internal mapping between joystick inputs and discrete tasks: e.g., pressing the joystick left indicates that the human wants a plate, while pressing the joystick right indicates a cup. This approach works well after the human understands how the robot interprets their inputs - but inexperienced users still have to learn these mappings through trial and error! Here we recognize that the robot's mapping between tasks and inputs is a convention. There are multiple, equally efficient conventions that the robot could use: rather than passively waiting for the human, we introduce a shared autonomy approach where the robot actively reveals its chosen convention. Across repeated interactions the robot intervenes and exaggerates the arm's motion to demonstrate more efficient inputs while also assisting for the current task. We compare this approach to a state-of-the-art baseline - where users must identify the convention by themselves - as well as written instructions. Our user study results indicate that modifying the robot's behavior to reveal its convention outperforms the baselines and reduces the amount of time that humans spend controlling the robot. See videos of our user study here: https://youtu.be/jROTVOp469I",
        "primary_area": "",
        "author": "Ananth Jonnavittula;Dylan P. Losey;Ananth Jonnavittula;Dylan P. Losey",
        "authorids": "/37088998510;/37085812055;/37088998510;/37085812055",
        "aff": "Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA; Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811674/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10825741707804460737&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811669",
        "title": "Comparison of Haptic and Augmented Reality Visual Cues for Assisting Tele- manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot teleoperation via human motion tracking has been proven to be easy to learn, intuitive to operate, and facilitate faster task execution than existing baselines. However, precise control while performing the dexterous telemanipulation tasks is still a challenge. In this paper, we implement sensory augmentation in terms of haptic and augmented reality visual cues to represent four types of information critical to the precision and performance of a telemanipulation task, namely: (1) target location; (2) constraint alert; (3) grasping affordance; and (4) grasp confirmation. We further conduct two user studies to investigate the effectiveness and preferred modality of the sensory feedback against no sensory support, and how the preference will be influenced by the different types of simulated real-world additional workload. We asked 8 participants to perform a general manipulation task using a KINOVA robotic arm. Our results indicate that: (1) the haptic and AR visual cues can significantly reduce the task completion time, occurrences of errors, the total length traversed by the robot end-effector, the operational effort while increasing the interface usability; (2) the haptic feedback trended in the direction of presenting the information that needs a prompt response, while the AR visual cues are suitable to monitor the system status; (3) the participants chose their preferred feedback with the purpose of reducing the cognitive workload despite increased extra effort.",
        "primary_area": "",
        "author": "Tsung-Chi Lin;Achyuthan Unni Krishnan;Zhi Li;Tsung-Chi Lin;Achyuthan Unni Krishnan;Zhi Li",
        "authorids": "/37087325287;/37087323052;/37085821311;/37087325287;/37087323052;/37085821311",
        "aff": "Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811669/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5833318571492240204&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Robotics Engineering",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811752",
        "title": "Compensating for Material Deformation in Foldable Robots via Deep Learning \u2015 A Case Study",
        "track": "main",
        "status": "Poster",
        "abstract": "Foldable, origami-inspired, and laminate mechanisms are highly susceptible to deformation under external loading, which can lead to position or orientation errors if idealized kinematic models are used. According to dimensional scaling laws, laminate devices can often be treated as rigid bodies at millimeter and smaller scale deformations. However, foldable mechanisms enter the territory of soft robots at larger scales. In this paper, we show the effect of external loads applied to a laminate, 2-DOF parallel robot and the corresponding errors during a pointing task. We then present two control methods, based on deep learning, that compensates for errors caused by the material deformation in foldable robots. For each proposed control method, a Deep Neural Network (DeepNN) is trained to learn the end-effector's deformation model in no-load and loaded conditions. A DeepNN called an updating network is trained and applied in real-time using measured sensor data, in order to transfer updated weights into another DeepNN called the target network. The target network generates control signals with the aim of compensating for the end-effector's error in tracking a desired trajectory. We evaluate our proposed control methods when applied to a laminate robotic end-effector under different external loading conditions in tracking spiral paths. The experimental results show the effectiveness of our proposed control methods in compensating for material deformation in foldable robots.",
        "primary_area": "",
        "author": "Mohammad Sharifzadeh;Yuhao Jiang;Amir Salimi Lafmejani;Daniel M. Aukes;Mohammad Sharifzadeh;Yuhao Jiang;Amir Salimi Lafmejani;Daniel M. Aukes",
        "authorids": "/37088688054;/37088689350;/37085690518;/37085340777;/37088688054;/37088689350;/37085690518;/37085340777",
        "aff": "Polytechnic School, Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA; School for Engineering of Matter, Transport and Energy, Fulton Schools of Engineering, Arizona State University, Tempe, AZ, USA; School of Electrical, Computer and Energy Engineering, Fulton Schools of Engineering, Arizona State University, Tempe, AZ, USA; Polytechnic School, Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811752/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13353243771068505328&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "Fulton Schools of Engineering",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Mesa;Tempe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811644",
        "title": "Complex Terrain Navigation via Model Error Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot navigation traditionally relies on building an explicit map that is used to plan collision-free trajectories to a desired target. In deformable, complex terrain, using geometric-based approaches can fail to find a path due to mischaracterizing deformable objects as rigid and impassable. Instead, we learn to predict an estimate of traversability of terrain regions and to prefer regions that are easier to navigate (e.g., short grass over small shrubs). Rather than predicting collisions, we instead regress on realized error compared to a canonical system model. We train with an on-policy approach, resulting in successful navigation policies using as little as 50 minutes of training data split across simulation and real world. Our learning-based navigation system is a sample efficient short-term planner that we demonstrate on a Clearpath Husky navigating through a variety of terrain including grassland and forest.",
        "primary_area": "",
        "author": "Adam Polevoy;Craig Knuth;Katie M. Popek;Kapil D. Katyal;Adam Polevoy;Craig Knuth;Katie M. Popek;Kapil D. Katyal",
        "authorids": "/37088996357;/37088851710;/37077733500;/38228973900;/37088996357;/37088851710;/37077733500;/38228973900",
        "aff": "Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA; Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA; Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA; Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811644/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14674954012947140414&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Applied Physics Laboratory",
        "aff_unique_url": "https://www.jhuapl.edu",
        "aff_unique_abbr": "JHU APL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Laurel",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811365",
        "title": "Composable Causality in Semantic Robot Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "Assembly tasks are challenging for robot manipulation because the robot must reason over the composed effects of actions and execute multi-objective behaviors. Robots typically use predefined priorities provided by users to determine how to compose controller behaviors, but we want the robot to autonomously select these compositions based on their composed effects within the task. We present Composable Causality in Semantic Robot Programming to allow robots to reason over the composed effects of controllers when executing multi-objective actions and autonomously compose controllers without predefined priorities. Our proposed causal control basis combines controller behaviors with causal information about how the behaviors can be used to execute high-level symbolic actions. The robot uses the causal control basis to predict the transition probability of achieving the composed effects of a multi-objective action. The composed causality estimates are used to select which action to execute within the context of a furniture assembly task. We evaluate the robot's transition probability estimates in different furniture assembly trials in simulation on the Baxter robot. The robot's ability to assemble furniture using different multi-objective connection actions demonstrates the usefulness of the composed causality estimates from our causal control basis.",
        "primary_area": "",
        "author": "Emily Sheetz;Xiaotong Chen;Zhen Zeng;Kaizhi Zheng;Qiuyu Shi;Odest Chadwicke Jenkins;Emily Sheetz;Xiaotong Chen;Zhen Zeng;Kaizhi Zheng;Qiuyu Shi;Odest Chadwicke Jenkins",
        "authorids": "/37089447595;/37087322826;/37086281797;/37089448179;/37089450853;/37297252400;/37089447595;/37087322826;/37086281797;/37089448179;/37089450853;/37297252400",
        "aff": "Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, USA; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811365/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7250726525718898298&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811835",
        "title": "Comprehensive Swing Leg Motion Predictor for Steady and Transient Walking Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "Data-driven methods based on neural networks are becoming more widespread for predicting human lower-limb motion. Until now, however, actual examples have focused on only a handful, steady locomotion behaviors. Here we explore if neural network predictors can simultaneously cover many more behaviors including transient ones. Training four common types of predictor networks on a large data set of human gait, we find that they all accommodate these behaviors similarly well, maintaining prediction errors of a few centimeters (lower-limb joint positions) and degrees (joint angles) when tested on data of previously seen subjects. We further observe that although the prediction quality drops for data of unseen subjects, overall, the predicted and actual lower-limb motions remain well aligned. While the predictors demonstrated here cover the largest range of locomotion behaviors reported to date, we achieve this improvement not by better network design but simply by training on more data. This outcome clearly supports the notion that the fastest route to obtain truly general network predictors of lower-limb motion is by focusing time and effort on the rapid growth and sharing of data sets of locomotion behaviors encountered in daily life.",
        "primary_area": "",
        "author": "Haosen Xing;Saurav Kumar;Hartmut Geyer;Haosen Xing;Saurav Kumar;Hartmut Geyer",
        "authorids": "/37088482882;/37086136727;/37408949400;/37088482882;/37086136727;/37408949400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811835/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10020116654560503481&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812095",
        "title": "Computation of Dynamic Joint Reaction Forces of PKM and its Use for Load-Minimizing Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Parallel kinematics machines (PKM) operate with maximal acceleration being designed for highly dynamic manipulation tasks. This leads to extreme loads of the joints, which is usually not accounted for in the motion planning. In this paper an extended inverse dynamics method is introduced, which allows computing the joint reaction forces along with the actuation torques, and provides a basis for time optimal motion planning and control minimizing wear of the components. To this end, PKM are modeled using absolute coordinates. The joint constraints are complemented with servo constraints so that the motion can be described by the actuator motion or by the end-effector motion. The presented method is particularly advantageous when certain model parameters are unknown and allows for model simplification, which would not be possible for the relative coordinate formulation. The sparsity of the obtained velocity constraint Jacobian matrix, due to the use of absolute coordinates, can be efficiently exploited to minimize computation time. The method is demonstrated and numerical results are reported for a time-optimal pick and place movement of a 4-DOF Delta robot.",
        "primary_area": "",
        "author": "D. Gnad;H. Gattringer;A. M\u00fcller;W. H\u00f6barth;R. Riepl;L. Messner;D. Gnad;H. Gattringer;A. M\u00fcller;W. H\u00f6barth;R. Riepl;L. Messner",
        "authorids": "/37089447565;/37085355000;/37085636420;/37089446980;/37089450849;/37089450548;/37089447565;/37085355000;/37085636420;/37089446980;/37089450849;/37089450548",
        "aff": "Institute of Robotics, Johannes Kepler University Linz, Austria; Institute of Robotics, Johannes Kepler University Linz, Austria; Institute of Robotics, Johannes Kepler University Linz, Austria; B&R Industrial Automation, Eggelsberg, Austria; B&R Industrial Automation, Eggelsberg, Austria; B&R Industrial Automation, Eggelsberg, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812095/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4904515440462298486&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;1",
        "aff_unique_norm": "Johannes Kepler University Linz;B&R Industrial Automation",
        "aff_unique_dep": "Institute of Robotics;",
        "aff_unique_url": "https://www.jku.at;https://www.br-automation.com",
        "aff_unique_abbr": "JKU;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Linz;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9811730",
        "title": "Computing Funnels Using Numerical Optimization Based Falsifiers",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an algorithm that computes funnels along trajectories of systems of ordinary differential equations. A funnel is a time-varying set of states containing the given trajectory, for which the evolution from within the set at any given time stays in the funnel. Hence it generalizes the behavior of single trajectories to sets around them, which is an important task, for example, in robot motion planning. In contrast to approaches based on sum-of-squares programming, which poorly scale to high dimensions, our approach is based on falsification and tackles the funnel computation task directly, through numerical optimization. This approach computes accurate funnel estimates far more efficiently and leaves formal verification to the end, outside all funnel size optimization loops.",
        "primary_area": "",
        "author": "Ji\u0159\u00ed Fejlek;Stefan Ratschan;Ji\u0159\u00ed Fejlek;Stefan Ratschan",
        "authorids": "/37089449050;/38127550400;/37089449050;/38127550400",
        "aff": "The Czech Academy of Sciences, Institute of Computer Science and Czech Technical University, Prague; The Czech Academy of Sciences, Institute of Computer Science",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811730/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17252294619852609795&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Czech Academy of Sciences",
        "aff_unique_dep": "Institute of Computer Science",
        "aff_unique_url": "https://www.cas.cz",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9811672",
        "title": "Concurrent Policy Blending and System Identification for Generalized Assistive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we address the problem of solving complex collaborative robotic tasks subject to multiple varying parameters. Our approach combines simultaneous policy blending with system identification to create generalized policies that are robust to changes in system parameters. We employ a blending network whose state space relies solely on parameter estimates from a system identification technique. As a result, this blending network learns how to handle parameter changes instead of trying to learn how to solve the task for a generalized parameter set simultaneously. We demonstrate our scheme's ability on a collaborative robot and human itching task in which the human has motor impairments. We then showcase our approach's efficiency with a variety of system identification techniques when compared to standard domain randomization. The code is available on Luke Bhan's Github.",
        "primary_area": "",
        "author": "Luke Bhan;Marcos Quinones-Grueiro;Gautam Biswas;Luke Bhan;Marcos Quinones-Grueiro;Gautam Biswas",
        "authorids": "/37089022902;/37085884677;/37271828100;/37089022902;/37085884677;/37271828100",
        "aff": "Vanderbilt University, Nashville, TN; Vanderbilt University, Nashville, TN; Vanderbilt University, Nashville, TN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811672/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3903672941823091680&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812404",
        "title": "Conditioned Human Trajectory Prediction using Iterative Attention Blocks",
        "track": "main",
        "status": "Poster",
        "abstract": "Human motion prediction is key to understand social environments, with direct applications in robotics, surveil-lance, etc. We present a simple yet effective pedestrian trajectory prediction model aimed at pedestrians' positions prediction in urban-like environments conditioned by the environment: map and surround agents. Our model is a neural-based architecture that can run several layers of attention blocks and transformers in an iterative sequential fashion, allowing to capture the important features in the environment that improve prediction. We show that without explicit introduction of social masks, dynamical models, social pooling layers, or complicated graph-like structures, it is possible to produce on par results with SoTA models, which makes our approach easily extendable and configurable, depending on the data available. We report results performing similarly with SoTA models on publicly available and extensible-used datasets with uni-modal prediction metrics ADE and FDE.",
        "primary_area": "",
        "author": "Aleksey Postnikov;Aleksander Gamayunov;Gonzalo Ferrer;Aleksey Postnikov;Aleksander Gamayunov;Gonzalo Ferrer",
        "authorids": "/37088806694;/37089194924;/38469245200;/37088806694;/37089194924;/38469245200",
        "aff": "Skolkovo Institute of Science and Technology, Moscow, Russia; Skolkovo Institute of Science and Technology, Moscow, Russia; Skolkovo Institute of Science and Technology, Moscow, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812404/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14804118203680444374&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Skolkovo Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.skoltech.ru",
        "aff_unique_abbr": "Skoltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Moscow",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "9812090",
        "title": "Confidence-Based Robot Navigation Under Sensor Occlusion with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers the problem of prolonged occlusions on navigation sensors due to dust, smudges, soils, etc. Such uncontrollable occlusions often cause lower visibility as well as higher uncertainty that require considerably sophisticated behavior. To secure visibility (i.e., confidence about the world), we propose a confidence-based navigation method that encourages the robot to explore the uncertain region around the robot maximizing its local confidence. To effectively extract features from the variable size of sensor occlusions, we adopt a point-cloud based representation network. Our method returns a resilient navigation policy via deep reinforcement learning, autonomously avoiding collisions under sensor occlusions while reaching a goal. We evaluate our method in simulated and real-world environments with either static or dynamic obstacles under various sensor-occlusion scenarios. The experimental result shows that our method outperforms baseline methods under the highly occurring sensor occlusion, and achieves maximum 90% and 80% success rates in the tested static and dynamic environments, respectively.",
        "primary_area": "",
        "author": "Hyeongyeol Ryu;Minsung Yoon;Daehyung Park;Sung-Eui Yoon;Hyeongyeol Ryu;Minsung Yoon;Daehyung Park;Sung-Eui Yoon",
        "authorids": "/37089447145;/37089447491;/37085429958;/37066068100;/37089447145;/37089447491;/37085429958;/37066068100",
        "aff": "School of Computing, Korea Advanced Institute of Science and Technology, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, South Korea; School of Computing, Korea Advanced Institute of Science and Technology, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812090/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9752687376141117080&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812115",
        "title": "Configuration Control for Physical Coupling of Heterogeneous Robot Swarms",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a heterogeneous robot swarm system that can physically couple with each other to form functional structures and dynamically decouple to perform individual tasks. The connection between robots can be formed with a passive coupling mechanism, ensuring minimum energy consumption during coupling and decoupling behavior. The heterogeneity of the system enables the robots to perform structural enhancement configurations based on specific environmental requirements. We propose a connection-pair oriented configuration control algorithm to form different assemblies. We show experiments of up to nine robots performing the coupling, gap-crossing, and decoupling behaviors.",
        "primary_area": "",
        "author": "Sha Yi;Zeynep Temel;Katia Sycara;Sha Yi;Zeynep Temel;Katia Sycara",
        "authorids": "/37088506867;/37088689031;/37268476900;/37088506867;/37088689031;/37268476900",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812115/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=995505455004423313&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811846",
        "title": "Consensus in Operational Space for Robotic Manipulators with Task and Input Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a real-time control framework for consensus in operational space for robotic manipulators while satisfying task and input constraints. Consensus in operational space, as compared to joint space, enables heterogeneous robotic manipulators to achieve consensus. However, traditional frameworks tend to ignore task and input constraints while achieving consensus in operational space. We address this problem by defining safe sets in operational space and then ensure task constraint by designing Control Barrier Functions (CBF) in operational space. Control barrier functions guarantees to provide collision-free behavior for the robotic manipulator by modifying the nominal controller in a minimally invasive manner such that the trajectory of the manipulator remains in the safe set. The Quadratic Programming (QP) formulation also ensures that the nominal controller is only modified when the constraints are active, and the resulting controller is optimal in a min-norm setting. Our approach contrasts the traditional potential field method, which continues to influence the nominal controller because of its attractive and repulsive field design, and is therefore unsuitable for consensus problems. We also incorporate the input constraint in our QP formulation to ensure that the resulting controller complies with the task and input constraints. We show the efficacy of the proposed approach on 7 Degree of Freedom (DoF) KUKA LBR iiwa, 6 DoF KUKA KR5 R650 and 7 DoF Flexiv Rizon robotic manipulators, each with different dynamical and kinematic models using Dynamic Animation and Robotics Toolkit (DART) physics engine.",
        "primary_area": "",
        "author": "Muhammad Ali Murtaza;Seth Hutchinson;Muhammad Ali Murtaza;Seth Hutchinson",
        "authorids": "/37088316016;/37282386200;/37088316016;/37282386200",
        "aff": "Institute of Robotics and Intelligent Machines at the Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines at the Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811846/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12421663867183121702&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Institute of Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812210",
        "title": "Constrained Variable Impedance Control using Quadratic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a quadratic programming (QP)-based variable impedance control (VIC) algorithm to solve contact-rich trajectory tracking problems with impedance, position and velocity constraints. To the best of our knowledge, the impedance constraints which are significant to ensure the worst contact compliance have never been considered in other previous works. To handle the impedance constraints of the VIC algorithm, a novel impedance model where the impedance parameters are directly served as the control input is established. The impedance-constrained VIC design problem is then formulated as a QP problem which can be efficiently solved. To handle the position and velocity constraints, a complementary force is introduced into the novel impedance model. The complementary force will appear to prevent the constraints violation when the robot approaches the constrained area. The design problem of the complementary force is also transformed into a QP problem. Combing these two QP solutions, the VIC algorithm with both impedance, position and velocity constraints can be obtained. Finally, various experiments are conducted to show the effectiveness of the proposed QP-based constrained VIC algorithm.",
        "primary_area": "",
        "author": "Zhehao Jin;Dongdong Qin;Andong Liu;Wen-An Zhang;Li Yu;Zhehao Jin;Dongdong Qin;Andong Liu;Wen-An Zhang;Li Yu",
        "authorids": "/37089009632;/37087054318;/38023129900;/37404212400;/37275541400;/37089009632;/37087054318;/38023129900;/37404212400;/37275541400",
        "aff": "Department of Information Engineering, Zhejiang University of Technology, Hangzhou, China; Department of Information Engineering, Zhejiang University of Technology, Hangzhou, China; Department of Information Engineering, Zhejiang University of Technology, Hangzhou, China; Department of Information Engineering, Zhejiang University of Technology, Hangzhou, China; Department of Information Engineering, Zhejiang University of Technology, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812210/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1304274020990669907&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University of Technology",
        "aff_unique_dep": "Department of Information Engineering",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812105",
        "title": "Constrained Visual-Inertial Localization With Application And Benchmark in Laparoscopic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel method to tackle the visual-inertial localization problem for constrained camera movements. We use residuals from the different modalities to jointly optimize a global cost function. The residuals emerge from IMU measurements, stereoscopic feature points, and constraints on possible solutions in SE(3). In settings where dynamic disturbances are frequent, the residuals reduce the complexity of the problem and make localization feasible. We verify the advantages of our method in a suitable medical use case and produce a dataset capturing a minimally invasive surgery in the abdomen. Our novel clinical dataset MITI is comparable to state-of-the-art evaluation datasets, contains calibration and synchronization and is available at [1].",
        "primary_area": "",
        "author": "Regine Hartwig;Daniel Ostler;Jean-Claude Rosenthal;Hubertus Feu\u00dfner;Dirk Wilhelm;Dirk Wollherr;Regine Hartwig;Daniel Ostler;Jean-Claude Rosenthal;Hubertus Feu\u00dfner;Dirk Wilhelm;Dirk Wollherr",
        "authorids": "/37089447224;/37085634826;/38490523600;/37687974200;/38581020900;/37295545400;/37089447224;/37085634826;/38490523600;/37687974200;/38581020900;/37295545400",
        "aff": "Department of Electrical and Computer Engineering, Chair of Automatic Control Engineering, Technical University of Munich (TUM), Germany; Surgical Department, Research Group MITI, Technical University of Munich (TUM), Germany; Fraunhofer HHI, Berlin, Germany; Surgical Department, Research Group MITI, Technical University of Munich (TUM), Germany; Surgical Department, Research Group MITI, Technical University of Munich (TUM), Germany; Department of Electrical and Computer Engineering, Chair of Automatic Control Engineering, Technical University of Munich (TUM), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812105/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12194455652513922819&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Technical University of Munich;Fraunhofer Heinrich Hertz Institute",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.tum.de;https://www.hhi.fraunhofer.de",
        "aff_unique_abbr": "TUM;HHI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berlin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811872",
        "title": "Contact Mode Guided Motion Planning for Quasidynamic Dexterous Manipulation in 3D",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents Contact Mode Guided Manipulation Planning (CMGMP) for 3D quasistatic and quasi-dynamic rigid body motion planning in dexterous manipulation. The CMGMP algorithm generates hybrid motion plans including both continuous state transitions and discrete contact mode switches, without the need for pre-specified contact sequences or pre-designed motion primitives. The key idea is to use automatically enumerated contact modes of environment-object contacts to guide the tree expansions during the search. Contact modes automatically synthesize manipulation primitives, while the sampling-based planning framework sequences those primitives into a coherent plan. We test our algorithm on fourteen 3D manipulation tasks, and validate our models by executing some plans open-loop on a real robot-manipulator system11The video is available at https://youtu.be/JuLlliG3vGc.",
        "primary_area": "",
        "author": "Xianyi Cheng;Eric Huang;Yifan Hou;Matthew T. Mason;Xianyi Cheng;Eric Huang;Yifan Hou;Matthew T. Mason",
        "authorids": "/37086574792;/37086066878;/37086454260;/37273994200;/37086574792;/37086066878;/37086454260;/37273994200",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811872/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17615316010403840172&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811739",
        "title": "Contact Transfer: A Direct, User-Driven Method for Human to Robot Transfer of Grasps and Manipulations",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel method for the direct transfer of grasps and manipulations between objects and hands through utilization of contact areas. Our method fully preserves contact shapes, and in contrast to existing techniques, is not dependent on grasp families, requires no model training or grasp sampling, makes no assumptions about manipulator morphology or kinematics, and allows user control over both transfer parameters and solution optimization. Despite these accommodations, we show that our method is capable of synthesizing kinematically-feasible whole hand poses in seconds even for poor initializations or hard-to-reach contacts. We additionally highlight the method's benefits in both response to design alterations as well as fast approximation over in-hand manipulation sequences. Finally, we demonstrate a solution generated by our method on a physical, custom-designed prosthetic hand.",
        "primary_area": "",
        "author": "Arjun Lakshmipathy;Dominik Bauer;Cornelia Bauer;Nancy S. Pollard;Arjun Lakshmipathy;Dominik Bauer;Cornelia Bauer;Nancy S. Pollard",
        "authorids": "/37088398470;/37086606269;/37089372008;/37341211200;/37088398470;/37086606269;/37089372008;/37341211200",
        "aff": "Computer Science Department, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811739/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=241130196140558362&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811940",
        "title": "Contact-Rich Manipulation of a Flexible Object based on Deep Predictive Learning using Vision and Tactility",
        "track": "main",
        "status": "Poster",
        "abstract": "We achieved contact-rich flexible object manipulation, which was difficult to control with vision alone. In the unzipping task we chose as a validation task, the gripper grasps the puller, which hides the bag state such as the direction and amount of deformation behind it, making it difficult to obtain information to perform the task by vision alone. Additionally, the flexible fabric bag state constantly changes during operation, so the robot needs to dynamically respond to the change. However, the appropriate robot behavior for all bag states is difficult to prepare in advance. To solve this problem, we developed a model that can perform contact-rich flexible object manipulation by real-time prediction of vision with tactility. We introduced a point-based attention mechanism for extracting image features, softmax transformation for predicting motions, and convolutional neural network for extracting tactile features. The results of experiments using a real robot arm revealed that our method can realize motions responding to the deformation of the bag while reducing the load on the zipper. Furthermore, using tactility improved the success rate from 56.7% to 93.3% compared with vision alone, demonstrating the effectiveness and high performance of our method.",
        "primary_area": "",
        "author": "Hideyuki Ichiwara;Hiroshi Ito;Kenjiro Yamamoto;Hiroki Mori;Tetsuya Ogata;Hideyuki Ichiwara;Hiroshi Ito;Kenjiro Yamamoto;Hiroki Mori;Tetsuya Ogata",
        "authorids": "/37089449817;/37088235935;/38127848300;/37086432927;/37273829100;/37089449817;/37088235935;/38127848300;/37086432927;/37273829100",
        "aff": "Center for Technology Innovation, Mechanical Engineering, Research & Development Group, Hitachi, Ltd., Ibaraki, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Center for Technology Innovation, Mechanical Engineering, Research & Development Group, Hitachi, Ltd., Ibaraki, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811940/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9791456548230309189&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "Hitachi, Ltd.;Waseda University",
        "aff_unique_dep": "Mechanical Engineering;Department of Intermedia Art and Science",
        "aff_unique_url": "https://www.hitachi.com;https://www.waseda.jp/top",
        "aff_unique_abbr": "Hitachi;Waseda",
        "aff_campus_unique_index": "0;1;0;1;1",
        "aff_campus_unique": "Ibaraki;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812119",
        "title": "Context is Everything: Implicit Identification for Dynamics Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding environment dynamics is necessary for robots to act safely and optimally in the world. In realistic scenarios, dynamics are non-stationary and the causal variables such as environment parameters cannot necessarily be precisely measured or inferred, even during training. We propose Implicit Identification for Dynamics Adaptation (IIDA), a simple method to allow predictive models to adapt to changing environment dynamics. IIDA assumes no access to the true variations in the world and instead implicitly infers properties of the environment from a small amount of contextual data. We demonstrate IIDA's ability to perform well in unseen environments through a suite of simulated experiments on MuJoCo environments and a real robot dynamic sliding task. In general, IIDA significantly reduces model error and results in higher task performance over commonly used methods. Our code, video of the method, and latest paper is available here https://bennevans.github.io/icra-iida/",
        "primary_area": "",
        "author": "Ben Evans;Abitha Thankaraj;Lerrel Pinto;Ben Evans;Abitha Thankaraj;Lerrel Pinto",
        "authorids": "/37089448121;/37086290151;/37085796211;/37089448121;/37086290151;/37085796211",
        "aff": "New York University; New York University; New York University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812119/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9957043926765805058&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811371",
        "title": "Context-Aware Grasp Generation in Cluttered Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Conventional methods to autonomous grasping rely on a pre-computed database with known objects to synthesize grasps, which is not possible for novel objects. On the other hand, recently proposed deep learning-based approaches have demonstrated the ability to generalize grasp for unknown objects. However, grasp generation still remains a challenging problem, especially in cluttered environments under partial occlusion. In this work, we propose an end-to-end deep learning approach for generating 6-DOF collision-free grasps given a 3D scene point cloud. To build robustness to occlusion, the proposed model generates candidates by casting votes and accumulating evidence for feasible grasp configurations. We exploit contextual information by encoding the dependency of objects in the scene into features to boost the performance of grasp generation. The contextual information enables our model to increase the likelihood that the generated grasps are collision-free. Our experimental results confirm that the proposed system performs favorably in terms of predicting object grasps in cluttered environments in comparison to the current state of the art methods.",
        "primary_area": "",
        "author": "Dinh-Cuong Hoang;Johannes A. Stork;Todor Stoyanov;Dinh-Cuong Hoang;Johannes A. Stork;Todor Stoyanov",
        "authorids": "/37087050264;/37544515300;/37601557800;/37087050264;/37544515300;/37601557800",
        "aff": "Centre for Applied Autonomous Sensor Systems (AASS), Orebro University, Sweden; Centre for Applied Autonomous Sensor Systems (AASS), Orebro University, Sweden; Centre for Applied Autonomous Sensor Systems (AASS), Orebro University, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811371/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=561305437294218497&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Orebro University",
        "aff_unique_dep": "Centre for Applied Autonomous Sensor Systems (AASS)",
        "aff_unique_url": "https://www.oru.se",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9811586",
        "title": "Continuous-Time Spline Visual-Inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a continuous-time spline-based formulation for visual-inertial odometry (VIO). Specifically, we model the poses as a cubic spline, whose temporal derivatives are used to synthesize linear acceleration and angular velocity, which are compared to the measurements from the inertial measurement unit (IMU) for optimal state estimation. The spline boundary conditions create constraints between the camera and the IMU, with which we formulate VIO as a constrained nonlinear optimization problem. Continuous-time pose representation makes it possible to address many VIO challenges, e.g., rolling shutter distortion and sensors that may lack synchronization. We conduct experiments on two publicly available datasets that demonstrate the state-of-the-art accuracy and real-time computational efficiency of our method.",
        "primary_area": "",
        "author": "Jiawei Mo;Junaed Sattar;Jiawei Mo;Junaed Sattar",
        "authorids": "/37087322233;/37546394500;/37087322233;/37546394500",
        "aff": "Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811586/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10997605496491910679&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota Twin Cities",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812403",
        "title": "Control Scheme for Sideways Walking on a User-driven Treadmill",
        "track": "main",
        "status": "Poster",
        "abstract": "For immersive interaction in a virtual reality (VR) environment, an omnidirectional treadmill (ODT) can support performance of various locomotive motions (curved walk, side walk, moving with shooting stance) in any direction. When a user performs lateral locomotive motions on an ODT, a control scheme to achieve immersive and safe interaction with the ODT should satisfy robustness in terms of position error of a user to keep a reference position of the ODT by accurately estimating intentional walking speed (IWS) of the user, and it should guarantee postural stability of the user during the control actions. Existing locomotion interface (LI) control focuses on the reference position tracking performance regarding the position of the user's center of mass (COM) in order to respond to forward locomotion that can move at high speed. However, in sideways walking, the movement of the lower extremities is different from that of forward walking, and when the conventional LI control was directly applied to sideways walking, it was observed that excessive acceleration commands caused postural instability. For appropriate interface of sideways walking, we propose an estimation scheme based on an accurate walking model including the movement of the ankle joint. The proposed observer estimates the acting torque generated by the force of both lower extremities through the position information of COM and ankle joint to more accurately predict the user's intentional walking speed (IWS). In the sideways walking experiment conducted using a 1-dimensional user-driven treadmill (UDT), the proposed method allowed more natural interface of the lateral-side locomotion with better postural stability compared to the conventional estimation method that uses only the COM position information.",
        "primary_area": "",
        "author": "Sanghun Pyo;Hoyoung Kim;Jungwon Yoon;Sanghun Pyo;Hoyoung Kim;Jungwon Yoon",
        "authorids": "/37603824100;/37089213153;/38626177600;/37603824100;/37089213153;/38626177600",
        "aff": "Integrated Institute of Technology, Gwangju Institute of Science and Technology (GIST), Gwangju, Korea; Integrated Institute of Technology, Gwangju Institute of Science and Technology (GIST), Gwangju, Korea; Integrated Institute of Technology, Gwangju Institute of Science and Technology (GIST), Gwangju, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812403/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:7_17G0V5Rf0J:scholar.google.com/&scioq=Control+Scheme+for+Sideways+Walking+on+a+User-driven+Treadmill&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Gwangju Institute of Science and Technology",
        "aff_unique_dep": "Integrated Institute of Technology",
        "aff_unique_url": "https://www.gist.ac.kr",
        "aff_unique_abbr": "GIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Gwangju",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811884",
        "title": "Control-Aware Prediction Objectives for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicle software is typically structured as a modular pipeline of individual components (e.g., perception, prediction, and planning) to help separate concerns into interpretable sub-tasks. Even when end-to-end training is possible, each module has its own set of objectives used for safety assurance, sample efficiency, regularization, or interpretability. However, intermediate objectives do not always align with overall system performance. For example, optimizing the likelihood of a trajectory prediction module might focus more on easy-to-predict agents than safety-critical or rare behaviors (e.g., jaywalking). In this paper, we present control-aware prediction objectives (CAPOs), to evaluate the down-stream effect of predictions on control without requiring the planner be differentiable. We propose two types of importance weights that weight the predictive likelihood: one using an attention model between agents, and another based on control variation when exchanging predicted trajectories for ground truth trajectories. Experimentally, we show our objectives improve overall system performance in suburban driving scenarios using the CARLA simulator.",
        "primary_area": "",
        "author": "Rowan McAllister;Blake Wulfe;Jean Mercat;Logan Ellis;Sergey Levine;Adrien Gaidon;Rowan McAllister;Blake Wulfe;Jean Mercat;Logan Ellis;Sergey Levine;Adrien Gaidon",
        "authorids": "/38540418600;/37086192739;/37088504750;/37089450657;/37085481973;/37945420900;/38540418600;/37086192739;/37088504750;/37089450657;/37085481973;/37945420900",
        "aff": "Toyota Research Institute; Toyota Research Institute; Toyota Research Institute; Toyota Research Institute; University of California, Berkeley; Toyota Research Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811884/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10818857887551147348&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Toyota Research Institute;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tri.global;https://www.berkeley.edu",
        "aff_unique_abbr": "TRI;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811926",
        "title": "Convex Model Predictive Control of Single Rigid Body Model on SO(3) for Versatile Dynamic Legged Motions",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a convex model predictive control framework for versatile dynamic legged motions with negligible leg dynamics. The framework utilizes the single rigid body model linearly approximated around the operating point. With ground reaction forces as direct control inputs to the system, no reference control trajectory needs to be specified in advance. By using the rotation matrix for the evolution of rotational dynamics, issues arising from other representations can be avoided. Moreover, the rotation matrix is parametrized using the history of angular velocity without introducing additional variables. The effect is that we can still take the orientation into consideration efficaciously without directly working on it. The framework tackles the robot reference tracking problem via trajectory optimization, which is formulated into a standard quadratic program and can be solved efficiently in real time with guaranteed optimality. It was verified on various legged robots with different numbers of legs for performing different types of dynamic motions in the simulation environment. We thus envision a promising future of the proposed convex model predictive control framework in legged robots and potentially in other applications as well.",
        "primary_area": "",
        "author": "Junjie Shen;Dennis Hong;Junjie Shen;Dennis Hong",
        "authorids": "/37087324771;/37575333900;/37087324771;/37575333900",
        "aff": "Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811926/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3149685931307035657&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811719",
        "title": "Convex strategies for trajectory optimisation: application to the Polytope Traversal Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "Non-linear trajectory optimisation methods require good initial guesses to converge to a locally optimal solution. A feasible guess can often be obtained by allocating a large amount of time for the trajectory to be complete. However for unstable dynamical systems such as humanoid robots, this quasi-static assumption does not always hold. We propose a conservative formulation of the trajectory problem that simultaneously computes a feasible path and its time allocation. The problem is solved as a convex optimisation problem guaranteed to converge to a feasible local optimum. The approach is evaluated with the computation of feasible trajectories that traverse sequentially a sequence of polytopes. We demonstrate that on instances of the problem where quasi static solutions are not admissible, our approach is able to find a feasible solution with a success rate above 80% in all the scenarios considered, in less than 10ms for problems involving traversing less than 5 polytopes and less than 1s for problems involving 20 polytopes, thus demonstrating its ability to reliably provide initial guesses to advanced non linear solvers.",
        "primary_area": "",
        "author": "Steve Tonneau;Steve Tonneau",
        "authorids": "/37085790049;/37085790049",
        "aff": "University of Edinburgh, Scotland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811719/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11995085174120783550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812182",
        "title": "Cooperative Modular Single Actuator Monocopters Capable of Controlled Passive Separation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a Modular Single Actuator Monocopter (M-SAM), which is capable of flying in both singular configuration and cooperative configuration. From singular mode, M-SAMs can be manually assembled into cooperative mode, using magnetic connectors built into the body of each M-SAM unit. The design of the connectors allow for passive separation of the units without the need for a dedicated separating actuator, by harnessing the variable centrifugal force from controlled adjustment of the rotating speed of the craft. To achieve control in both configurations, we firstly studied and analyzed their full dynamic models by introducing equilibrium state and relaxed hovering condition. Next, we derived a reduced model to approximate the dynamical behavior of both singular and cooperative configuration in flight to design a generalized cyclic-based cascaded flight controller. Finally, we validated the proposed controller and separation mechanism by conducting several flight experiments for two M-SAMs in singular mode, cooperative mode as well as mid-air separating under motion capture system.",
        "primary_area": "",
        "author": "Xinyu Cai;Shane Kyi Hla Win;Luke Soe Thura Win;Danial Sufiyan;Shaohui Foong;Xinyu Cai;Shane Kyi Hla Win;Luke Soe Thura Win;Danial Sufiyan;Shaohui Foong",
        "authorids": "/37088689871;/37086449578;/37086876778;/37086877525;/37542925800;/37088689871;/37086449578;/37086876778;/37086877525;/37542925800",
        "aff": "Engineering Product Development Pillar, Singapore University of Technology and Design (SUTD), Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design (SUTD), Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design (SUTD), Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design (SUTD), Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design (SUTD), Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812182/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12901417168497863616&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Engineering Product Development Pillar",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9811768",
        "title": "Cooperative Transportation using Multiple Single-Rotor Robots and Decentralized Control for Unknown Payloads",
        "track": "main",
        "status": "Poster",
        "abstract": "Cooperative transportation via multiple aerial robots has the potential to support various payloads and reduce the chances of them being dropped. Furthermore, autonomously controlled robots render the system scalable with respect to the payload. In this study, a cooperative transportation system was developed using rigidly attached single-rotor robots, and a decentralized controller was proposed to guarantee asymptotic stability of the error dynamics for unknown strictly positive real systems. A feedback controller was used to transform unstable systems into strictly positive real ones considering the shared attachment positions. First, the cooperative transportation of unknown payloads with different shapes larger than the carrier robots was investigated via numerical simulations. Second, cooperative transportation of an unknown payload (with a weight of approximately 2.7 kg and maximum length of 1.6 m) was demonstrated using eight robots, even under robot failure. Finally, the proposed system was shown to be capable of carrying an unknown payload, even if the attachment positions were not shared, that is, even if asymptotic stability was not strictly guaranteed.",
        "primary_area": "",
        "author": "Koshi Oishi;Yasushi Amano;Tomohiko Jimbo;Koshi Oishi;Yasushi Amano;Tomohiko Jimbo",
        "authorids": "/37088541019;/37088321232;/37569079000;/37088541019;/37088321232;/37569079000",
        "aff": "Cloud Informatics Research-Domain, Toyota Central R&D Labs., Inc., Aichi, Japan; Cloud Informatics Research-Domain, Toyota Central R&D Labs., Inc., Aichi, Japan; The author R-Frontier Division, Frontier Research Center. Toyota Motor Corporation, Toyota, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811768/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6520819815695445595&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Toyota Central R&D Labs., Inc.;Toyota Motor Corporation",
        "aff_unique_dep": "Cloud Informatics Research-Domain;R-Frontier Division, Frontier Research Center",
        "aff_unique_url": "https://www.toyota-global.com;https://www.toyota-global.com",
        "aff_unique_abbr": "Toyota R&D;Toyota",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Toyota",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812014",
        "title": "Coordinate Invariant User-Guided Constrained Path Planning with Reactive Rapidly Expanding Plane-Oriented Escaping Trees",
        "track": "main",
        "status": "Poster",
        "abstract": "As collaborative robots move closer to human environments, motion generation and reactive planning strategies that allow for elaborate task execution with minimal easy-to-implement guidance whilst coping with changes in the environment is of paramount importance. In this paper, we present a novel approach for generating real-time motion plans for point-to-point tasks using a single successful human demonstration. Our approach is based on screw linear interpolation, which allows us to respect the underlying geometric constraints that characterize the task and are implicitly present in the demonstration. We also integrate an original reactive collision avoidance approach with our planner. We present extensive experimental results to demonstrate that with our approach, by using a single demonstration of moving one block, we can generate motion plans for complex tasks like stacking multiple blocks (in a dynamic environment). Analogous generalization abilities are also shown for tasks like pouring and loading shelves. For the pouring task, we also show that a demonstration given for one-armed pouring can be used for planning pouring with a dual-armed manipulator of different kinematic structure.",
        "primary_area": "",
        "author": "Riddhiman Laha;Ruiai Sun;Wenxi Wu;Dasharadhan Mahalingam;Nilanjan Chakraborty;Luis F.C. Figueredo;Sami Haddadin;Riddhiman Laha;Ruiai Sun;Wenxi Wu;Dasharadhan Mahalingam;Nilanjan Chakraborty;Luis F.C. Figueredo;Sami Haddadin",
        "authorids": "/37089002102;/37089448539;/37089448845;/37089448262;/37314871600;/37063909900;/37542865300;/37089002102;/37089448539;/37089448845;/37089448262;/37314871600;/37063909900;/37542865300",
        "aff": "Munich Institute of Robotics & Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany; Munich Institute of Robotics & Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany; Munich Institute of Robotics & Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany; Department of Mechanical Engineering, Stony Brook University (SBU), Stony Brook, USA; Department of Mechanical Engineering, Stony Brook University (SBU), Stony Brook, USA; Munich Institute of Robotics & Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany; Munich Institute of Robotics & Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812014/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7489746805039039852&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Stony Brook University",
        "aff_unique_dep": "Munich Institute of Robotics & Machine Intelligence;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tum.de;https://www.stonybrook.edu",
        "aff_unique_abbr": "TUM;SBU",
        "aff_campus_unique_index": "0;0;0;1;1;0;0",
        "aff_campus_unique": "Munich;Stony Brook",
        "aff_country_unique_index": "0;0;0;1;1;0;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9811978",
        "title": "Coordination of two robotic manipulators for object retrieval in clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of retrieving a target object from a confined space by two robotic manipulators where overhand grasps are not allowed. If other movable obstacles occlude the target, more than one object should be relocated to clear the path to reach the target object. With two robots, the relocation could be done efficiently by simultaneously performing relocation tasks. However, the precedence constraint between the tasks (e.g, some objects at the front should be removed to manipulate the objects in the back) makes the simultaneous task execution difficult. We propose a coordination method that determines which robot relocates which object so as to perform tasks simultaneously. Given a set of objects to be relocated, the objective is to maximize the number of switches between the robots in performing relocation tasks. Thus, one robot can pick an object in the clutter while the other robot places an object in hand to the outside of the clutter. However, the object to be relocated may not be accessible to all robots, so switching could not always be achieved. Our method is based on the uniform-cost search so the number of switches can be maximized. We also propose a greedy variant whose computation time is shorter. From experiments, we show that our method reduces the completion time of the mission by at least 22.9% (at most 27.3%) compared to the methods with no consideration of switching.",
        "primary_area": "",
        "author": "Jeeho Ahn;ChangHwan Kim;Changjoo Nam;Jeeho Ahn;ChangHwan Kim;Changjoo Nam",
        "authorids": "/37088999970;/37292328800;/37086294341;/37088999970;/37292328800;/37086294341",
        "aff": "Korea Institute of Science and Technology; Korea Institute of Science and Technology; Dept. of Electronic Engineering, Sogang University.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811978/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11024996139816952703&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Korea Institute of Science and Technology;Sogang University",
        "aff_unique_dep": ";Dept. of Electronic Engineering",
        "aff_unique_url": "https://www.kist.re.kr;http://www.sogang.ac.kr",
        "aff_unique_abbr": "KIST;Sogang",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811974",
        "title": "Cost-Effective Sensing for Goal Inference: A Model Predictive Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Goal inference is of great importance for a variety of applications that involve interaction, coordination, and/or competition with goal-oriented agents. Typical goal inference approaches use as many pointwise measurements of the agent's trajectory as possible to pursue a most accurate a-posteriori estimate of the goal. However, taking frequent measurements may not be preferred in situations where sensing is associated with high cost (e.g., sensing + perception may involve high computational/bandwidth cost and sensing may raise security concerns in privacy-critical/data-sensitive applications). In such situations, a sensible tradeoff between the information gained from measurements and the cost associated with sensing actions is highly desirable. This paper introduces a cost-effective sensing strategy for goal inference tasks based on hybrid Kalman filtering and model predictive control. Our key insights include: 1) a model predictive approach can be used to predict the amount of information gained from new measurements over a horizon and thus to optimize the tradeoff between information gain and sensing action cost, and 2) the high computational efficiency of hybrid Kalman filtering can ensure real-time feasibility of such a model predictive approach. We evaluate the proposed cost-effective sensing approach in a goal-oriented task, where we show that compared to standard goal inference approaches, our approach takes a considerably reduced number of measurements while not impairing the speed, accuracy, and reliability of goal inference by taking measurements smartly.",
        "primary_area": "",
        "author": "Ran Tian;Nan Li;Anouck Girard;Ilya Kolmanovsky;Masayoshi Tomizuka;Ran Tian;Nan Li;Anouck Girard;Ilya Kolmanovsky;Masayoshi Tomizuka",
        "authorids": "/37085997198;/37086066452;/37299624700;/37301329200;/37281933000;/37085997198;/37086066452;/37299624700;/37301329200;/37281933000",
        "aff": "UC Berkeley; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; University of Michigan, Ann Arbor; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811974/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:NHV6nNzmYA8J:scholar.google.com/&scioq=Cost-Effective+Sensing+for+Goal+Inference:+A+Model+Predictive+Approach&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of California, Berkeley;University of Michigan",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.umich.edu",
        "aff_unique_abbr": "UC Berkeley;UM",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Berkeley;Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811854",
        "title": "Coverage Control in Multi-Robot Systems via Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper develops a decentralized approach to mobile sensor coverage by a multi-robot system. We consider a scenario where a team of robots with limited sensing range must position itself to effectively detect events of interest in a region characterized by areas of varying importance. Towards this end, we develop a decentralized control policy for the robots-realized via a Graph Neural Network-which uses inter-robot communication to leverage non-local information for control decisions. By explicitly sharing information between multi-hop neighbors, the decentralized controller achieves a higher quality of coverage when compared to classical approaches that do not communicate and leverage only local information available to each robot. Simulated experiments demonstrate the efficacy of multi-hop communication for multi-robot coverage and evaluate the scalability and transferability of the learning-based controllers.",
        "primary_area": "",
        "author": "Walker Gosrich;Siddharth Mayya;Rebecca Li;James Paulos;Mark Yim;Alejandro Ribeiro;Vijay Kumar;Walker Gosrich;Siddharth Mayya;Rebecca Li;James Paulos;Mark Yim;Alejandro Ribeiro;Vijay Kumar",
        "authorids": "/37088741101;/37085621013;/37088686634;/37085335548;/37274063600;/37266493600;/37280341400;/37088741101;/37085621013;/37088686634;/37085335548;/37274063600;/37266493600;/37280341400",
        "aff": "GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; Treeswift, PA, Philadelphia; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811854/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4488023778954150858&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "University of Pennsylvania;Treeswift",
        "aff_unique_dep": "GRASP Laboratory;",
        "aff_unique_url": "https://www.upenn.edu;",
        "aff_unique_abbr": "UPenn;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Philadelphia;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811941",
        "title": "Coverage Path Planning in Large-scale Multi-floor Urban Environments with Applications to Autonomous Road Sweeping",
        "track": "main",
        "status": "Poster",
        "abstract": "Coverage Path Planning is the work horse of contemporary service task automation, powering autonomous floor cleaning robots and lawn mowers in households and office sites. While steady progress has been made on indoor cleaning and outdoor mowing, these environments are small and with simple geometry compared to general urban environments such as city parking garages, highway bridges or city crossings. To pave the way for autonomous road sweeping robots to operate in such difficult and complex environments, a benchmark suite with three large-scale 3D environments representative of this task is presented. On this benchmark we evaluate a new Coverage Path Planning method in comparison with previous well performing algorithms, and demonstrate state-of-the-art performance of the proposed method. Part of the success, for all evaluated algorithms, is the usage of automated domain adaptation by in-the-loop parameter optimization using Bayesian Optimization. Apart from improving the performance, tedious and bias-prone manual tuning is made obsolete, which makes the evaluation more robust and the results even stronger.",
        "primary_area": "",
        "author": "Daniel Engelsons;Mattias Tiger;Fredrik Heintz;Daniel Engelsons;Mattias Tiger;Fredrik Heintz",
        "authorids": "/37089447580;/37085670359;/37658898500;/37089447580;/37085670359;/37658898500",
        "aff": "Department of Computer and Information Science, Link\u00f6ping University, Sweden; Department of Computer and Information Science, Link\u00f6ping University, Sweden; Department of Computer and Information Science, Link\u00f6ping University, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811941/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14423485061703180319&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Link\u00f6ping University",
        "aff_unique_dep": "Department of Computer and Information Science",
        "aff_unique_url": "https://www.liu.se",
        "aff_unique_abbr": "LiU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9811836",
        "title": "Crawling Locomotion Enabled by a Novel Actuated Rover Chassis",
        "track": "main",
        "status": "Poster",
        "abstract": "Traversing soft soils represents a major concern of planetary rover missions. In this paper, we present a new chassis mechanism capable of a crawling gait that enhances trafficability on soft soil while relying on as few actuators as possible. Articulated by two actuated joints, MARCEL is a four-wheeled rover chassis which name stands for Mobile Active Rover Chassis for Enhanced Locomotion. MARCEL's crawling leverages a continuous adjustment of the load distribution on the four wheels using an internal torque applied between two halves of the chassis by series elastic actuation. This allows the pressure on two wheels to be minimized while they are moving forward with the assistance of the chassis's articulated motion. As a result, the wheels can be propelled forward one pair after another while avoiding the bulldozing resistance of the sand. This crawling motion is tested experimentally and is shown to generate more drawbar pull than both rolling or using a mere \u201cpush-pull\u201d locomotion. Its ability to extricate the rover from deep sand entrapment is also tested successfully. This will allow future missions to deal with unforeseen terrain properties or to venture in more challenging areas while minimizing design complexity.",
        "primary_area": "",
        "author": "Arthur Bouton;Yang Gao;Arthur Bouton;Yang Gao",
        "authorids": "/37085781027;/37069689900;/37085781027;/37069689900",
        "aff": "NASA Jet Propulsion Laboratory, Pasadena, CA, USA; Surrey Space Centre, University of Surrey, Guildford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811836/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5907138221907057671&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "NASA Jet Propulsion Laboratory;University of Surrey",
        "aff_unique_dep": ";Surrey Space Centre",
        "aff_unique_url": "https://www.jpl.nasa.gov;https://www.surrey.ac.uk",
        "aff_unique_abbr": "JPL;UoS",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Pasadena;Guildford",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9811668",
        "title": "Cross Domain Robot Imitation with Invariant Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "Animals are able to imitate each others' behavior, despite their difference in biomechanics. In contrast, imitating other similar robots is a much more challenging task in robotics. This problem is called cross domain imitation learning (CDIL). In this paper, we consider CDIL on a class of similar robots. We tackle this problem by introducing an imitation learning algorithm based on invariant representation. We propose to learn invariant state and action representations, which align the behavior of multiple robots so that CDIL becomes possible. Compared with previous invariant representation learning methods for similar purposes, our method does not require human-labeled pairwise data for training. Instead, we use cycle-consistency and domain confusion to align the representation and increase its robustness. We test the algorithm on multiple robots in the simulator and show that unseen new robot instances can be trained with existing expert demonstrations successfully. Qualitative results also demonstrate that the proposed method is able to learn similar representations for different robots with similar behaviors, which is essential for successful CDIL.",
        "primary_area": "",
        "author": "Zhao-Heng Yin;Lingfeng Sun;Hengbo Ma;Masayoshi Tomizuka;Wu-Jun Li;Zhao-Heng Yin;Lingfeng Sun;Hengbo Ma;Masayoshi Tomizuka;Wu-Jun Li",
        "authorids": "/37089196259;/37087105341;/37086547315;/37281933000;/37278921900;/37089196259;/37087105341;/37086547315;/37281933000;/37278921900",
        "aff": "Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR.; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, USA; Department of Computer Science and Technology, Nanjing University, Nanjing, PRC",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811668/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8597157054423878035&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;2",
        "aff_unique_norm": "Hong Kong University of Science and Technology;University of California, Berkeley;Nanjing University",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;Department of Mechanical Engineering;Department of Computer Science and Technology",
        "aff_unique_url": "https://www.ust.hk;https://www.berkeley.edu;http://www.nju.edu.cn",
        "aff_unique_abbr": "HKUST;UC Berkeley;Nanjing U",
        "aff_campus_unique_index": "0;1;1;1;2",
        "aff_campus_unique": "Hong Kong SAR;Berkeley;Nanjing",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9812226",
        "title": "Crossmodal Transformer Based Generative Framework for Pedestrian Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Providing guidance about collision avoidance, pedestrian trajectory prediction is an important task for autonomous driving. In this paper, to produce plausible trajectory predictions in the first-person view circumstance, we propose a crossmodal transformer based generative framework which could leverage sequences of cues from multiple modalities as well as pedestrian attributes. For the encoder, crossmodal transformers are exploited during the past stage to explore the cross-relation features of four modality-modality pairs, which are then fused with the help of a branch assigning operation and a modality attention module. For the decoder, we employ a b\u00e9zier curve interpolation based method to project encoder features into trajectory results. Our training process not only considers the pedestrian's intention of crossing road but also optimizes our model to achieve more accurate predictions at the terminal time steps. Experimental results demonstrate that our framework outperforms state-of-the-art methods on both JAAD and PIE datasets. Especially, compared with the best baseline, our method could achieve 15.1%/14.3% and 14.3%/22.2% improvement for deterministic/multimodal prediction in the metric of box center final displacement error on JAAD and PIE, respectively.",
        "primary_area": "",
        "author": "Zhaoxin Su;Gang Huang;Sanyuan Zhang;Wei Hua;Zhaoxin Su;Gang Huang;Sanyuan Zhang;Wei Hua",
        "authorids": "/37089197991;/37085627794;/37277714600;/37089196345;/37089197991;/37085627794;/37277714600;/37089196345",
        "aff": "College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Zhejiang Lab, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Zhejiang Lab, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812226/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15760395409657672210&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Zhejiang University;Zhejiang Lab",
        "aff_unique_dep": "College of Computer Science and Technology;",
        "aff_unique_url": "http://www.zju.edu.cn;http://www.zhejianglab.com",
        "aff_unique_abbr": "ZJU;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811743",
        "title": "Crossview Mapping with Graph-based Geolocalization on City-Scale Street Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "3D environment mapping has been actively stud-ied recently with the development of autonomous driving and augmented reality. Although many image-based methods are proposed due to their convenience and flexibility compared to other complex sensors, few works focus on fixing the inherent scale ambiguity of image-based methods and registering the reconstructed structure to the real-world 3D map, which is very important for autonomous driving. This paper presents a low-cost mapping solution that is able to refine and align the monocular reconstructed point cloud given a public street map. Specifically, we first find the association between the street map and the reconstructed point cloud structure by a novel graph-based geolocalization method. Then, optimized with the corresponding relationship, the map accuracy is significantly improved. The rich environment information can also be associated with the point cloud by the geographical location. Experiments show that our geolocalization algorithm can locate the scene on a gigantic city-scale map (173.46 km2) in two minutes and support 3D map reconstruction with absolute scale and rich environmental information from Internet videos.",
        "primary_area": "",
        "author": "Zhichao Ye;Chong Bao;Xinyang Liu;Hujun Bao;Zhaopeng Cui;Guofeng Zhang;Zhichao Ye;Chong Bao;Xinyang Liu;Hujun Bao;Zhaopeng Cui;Guofeng Zhang",
        "authorids": "/37088507274;/37089330612;/37089450372;/37271755400;/37085646310;/37405938800;/37088507274;/37089330612;/37089450372;/37271755400;/37085646310;/37405938800",
        "aff": "State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811743/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1767176369054835527&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Lab of CAD&CG",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812174",
        "title": "Cyclops: Open Platform for Scale Truck Platooning",
        "track": "main",
        "status": "Poster",
        "abstract": "Cyclops, introduced in this paper, is an open research platform for everyone who wants to validate novel ideas and approaches in self-driving heavy-duty vehicle platooning. The platform consists of multiple 1/14 scale semi-trailer trucks equipped with associated computing, communication and control modules that enable self-driving on our scale proving ground. The perception system for each vehicle is composed of a lidar-based object tracking system and a lane detection/control system. The former maintains the gap to the leading vehicle, and the latter maintains the vehicle within the lane by steering control. The lane detection system is optimized for truck platooning, where the field of view of the front-facing camera is severely limited due to a small gap to the leading vehicle. This platform is particularly amenable to validating mitigation strategies for safety-critical situations. Indeed, the simplex architecture is adopted in the computing modules, enabling various fail-safe operations. In particular, we illustrate a scenario where the camera sensor fails in the perception system, but the vehicle is able to operate at a reduced capacity to a graceful stop. Details of Cyclops, including 3D CAD designs and algorithm source codes, are released for those who want to build similar testbeds.",
        "primary_area": "",
        "author": "Hyeongyu Lee;Jaegeun Park;Changjin Koo;Jong-Chan Kim;Yongsoon Eun;Hyeongyu Lee;Jaegeun Park;Changjin Koo;Jong-Chan Kim;Yongsoon Eun",
        "authorids": "/37089447956;/37087410358;/37089450054;/37600787300;/37411490200;/37089447956;/37087410358;/37089450054;/37600787300;/37411490200",
        "aff": "Graduate School of Automotive Engineering, Kookmin University, Seoul, Republic of Korea; Department of Information and Communication Engineering, DGIST, Daegu, Republic of Korea; Graduate School of Automotive Engineering, Kookmin University, Seoul, Republic of Korea; Graduate School of Automotive Engineering, Kookmin University, Seoul, Republic of Korea; Department of Information and Communication Engineering, DGIST, Daegu, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812174/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7334844982562580556&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "Kookmin University;Daegu Gyeongbuk Institute of Science and Technology",
        "aff_unique_dep": "Graduate School of Automotive Engineering;Department of Information and Communication Engineering",
        "aff_unique_url": "https://www.kookmin.ac.kr;https://www.dgist.ac.kr",
        "aff_unique_abbr": "KMU;DGIST",
        "aff_campus_unique_index": "0;1;0;0;1",
        "aff_campus_unique": "Seoul;Daegu",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811984",
        "title": "D2A-BSP: Distilled Data Association Belief Space Planning with Performance Guarantees Under Budget Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Unresolved data association in ambiguous and perceptually aliased environments leads to multi-modal hypotheses on both the robot's and the environment state. To avoid catastrophic results, when operating in such ambiguous environments, it is crucial to reason about data association within Belief Space Planning (BSP). However, explicitly considering all possible data associations, the number of hypotheses grows exponentially with the planning horizon and determining the optimal action sequence quickly becomes intractable. Moreover, with hard budget constraints where some non-negligible hypotheses must be pruned, achieving performance guarantees is crucial. In this work we present a computationally efficient novel approach that utilizes only a distilled subset of hypotheses to solve BSP problems while reasoning about data association. Furthermore, to provide performance guarantees, we derive error bounds with respect to the optimal solution. We then demonstrate our approach in an extremely aliased environment, where we manage to significantly reduce computation time without compromising on the quality of the solution.",
        "primary_area": "",
        "author": "Moshe Shienman;Vadim Indelman;Moshe Shienman;Vadim Indelman",
        "authorids": "/37088838175;/37541538000;/37088838175;/37541538000",
        "aff": "Technion Autonomous Systems Program (TASP), Technion - Israel Institute of Technology, Haifa, Israel; Department of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811984/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3301058868501898905&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion - Israel Institute of Technology",
        "aff_unique_dep": "Technion Autonomous Systems Program (TASP)",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9812271",
        "title": "DA-LMR: A Robust Lane Marking Representation for Data Association",
        "track": "main",
        "status": "Poster",
        "abstract": "While complete localization approaches are widely studied in the literature, their data association and data representation subprocesses usually go unnoticed. However, both are a key part of the final pose estimation. In this work, we present DA-LMR (Delta-Angle Lane Marking Representation), a robust data representation in the context of localization approaches. We propose a representation of lane markings that encodes how a curve changes in each point and includes this information in an additional dimension, thus providing a more detailed geometric structure description of the data. We also propose DC-SAC (Distance-Compatible Sample Consensus), a data association method. This is a heuristic version of RANSAC that dramatically reduces the hypothesis space by distance compatibility restrictions. We compare the presented methods with some state-of-the-art data representation and data association approaches in different noisy scenarios. The DA-LMR and DC-SAC produce the most promising combination among those compared, reaching 98.1 % in precision and 99.7% in recall for noisy data with 0.5 m of standard deviation.",
        "primary_area": "",
        "author": "Miguel \u00c1ngel Mu\u00f1oz-Ba\u00f1\u00f3n;Jan-Hendrik Pauls;Haohao Hu;Christoph Stiller;Miguel \u00c1ngel Mu\u00f1oz-Ba\u00f1\u00f3n;Jan-Hendrik Pauls;Haohao Hu;Christoph Stiller",
        "authorids": "/37087087445;/37086547128;/37086351628;/37284652100;/37087087445;/37086547128;/37086351628;/37284652100",
        "aff": "Group of Automation, Robotics and Computer Vision (AUROVA), University of Alicante, Alicante, Spain; Institute of Measurement and Control Systems, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute of Measurement and Control Systems, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute of Measurement and Control Systems, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812271/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3059248246556776362&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Alicante;Karlsruhe Institute of Technology",
        "aff_unique_dep": "Group of Automation, Robotics and Computer Vision (AUROVA);Institute of Measurement and Control Systems",
        "aff_unique_url": "https://www.ua.es;https://www.kit.edu",
        "aff_unique_abbr": ";KIT",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Alicante;Karlsruhe",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Spain;Germany"
    },
    {
        "id": "9811561",
        "title": "DC-Loc: Accurate Automotive Radar Based Metric Localization with Explicit Doppler Compensation",
        "track": "main",
        "status": "Poster",
        "abstract": "Automotive mmWave radar has been widely used in the automotive industry due to its small size, low cost, and complementary advantages to optical sensors (e.g., cameras, LiDAR, etc.) in adverse weathers, e.g., fog, raining, and snowing. On the other side, its large wavelength also poses fundamental challenges to perceive the environment. Recent advances have made breakthroughs on its inherent drawbacks, i.e., the multipath reflection and the sparsity of mmWave radar's point clouds. However, the frequency-modulated continuous wave modulation of radar signals makes it more sensitive to vehicles\u2019 mobility than optical sensors. This work focuses on the problem of frequency shift, i.e., the Doppler effect distorts the radar ranging measurements and its knock-on effect on metric localization. We propose a new radar-based metric localization framework, termed DC-Loc, which can obtain more accurate location estimation by restoring the Doppler distortion. Specifically, we first design a new algorithm that explicitly compensates the Doppler distortion of radar scans and then model the measurement uncertainty of the Doppler-compensated point cloud to further optimize the metric localization. Extensive experiments using the public nuScenes dataset and CARLA simulator demonstrate that our method outperforms the state-of-the-art approach by 25.2% and 5.6% improvements in terms of translation and rotation errors, respectively.",
        "primary_area": "",
        "author": "Pengen Gao;Shengkai Zhang;Wei Wang;Chris Xiaoxuan Lu;Pengen Gao;Shengkai Zhang;Wei Wang;Chris Xiaoxuan Lu",
        "authorids": "/37089447095;/37088219113;/37089545099;/37086107301;/37089447095;/37088219113;/37089545099;/37086107301",
        "aff": "Huazhong University of Science and Technology; Wuhan University of Technology; Huazhong University of Science and Technology; University of Edinburgh",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811561/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12839032424939771121&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Huazhong University of Science and Technology;Wuhan University of Technology;University of Edinburgh",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.hust.edu.cn;http://www.wut.edu.cn;https://www.ed.ac.uk",
        "aff_unique_abbr": "HUST;WUT;Edinburgh",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9811805",
        "title": "DEVO: Depth-Event Camera Visual Odometry in Challenging Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel real-time visual odometry framework for a stereo setup of a depth and high-resolution event camera. Our framework balances accuracy and robustness against computational efficiency towards strong performance in challenging scenarios. We extend conventional edge-based semi-dense visual odometry towards time-surface maps obtained from event streams. Semi-dense depth maps are generated by warping the corresponding depth values of the extrinsically calibrated depth camera. The tracking module updates the camera pose through efficient, geometric semi-dense 3D-2D edge alignment. Our approach is validated on both public and self-collected datasets captured under various conditions. We show that the proposed method performs comparable to state-of-the-art RGB-D camera-based alternatives in regular conditions, and eventually outperforms in challenging conditions such as high dynamics or low illumination.",
        "primary_area": "",
        "author": "Yi\u2013Fan Zuo;Jiaqi Yang;Jiaben Chen;Xia Wang;Yifu Wang;Laurent Kneip;Yi\u2013Fan Zuo;Jiaqi Yang;Jiaben Chen;Xia Wang;Yifu Wang;Laurent Kneip",
        "authorids": "/37089400248;/37089445387;/37089445560;/37966522800;/37086160259;/37569040300;/37089400248;/37089445387;/37089445560;/37966522800;/37086160259;/37569040300",
        "aff": "Key Laboratory of Optoelectronic Imaging Technology and Systems, Ministry of Education, School of Optics and Photonics, Beijing Institute of Technology, Beijing, China; Mobile Perception Lab, ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; Mobile Perception Lab, ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; Key Laboratory of Optoelectronic Imaging Technology and Systems, Ministry of Education, School of Optics and Photonics, Beijing Institute of Technology, Beijing, China; Mobile Perception Lab, ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging; Mobile Perception Lab, ShanghaiTech University, Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811805/",
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15717618819571833090&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;1;1",
        "aff_unique_norm": "Beijing Institute of Technology;ShanghaiTech University",
        "aff_unique_dep": "School of Optics and Photonics;Mobile Perception Lab",
        "aff_unique_url": "http://www.bit.edu.cn/;http://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "BIT;ShanghaiTech",
        "aff_campus_unique_index": "0;1;1;0;1;1",
        "aff_campus_unique": "Beijing;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812101",
        "title": "DKNAS: A Practical Deep Keypoint Extraction Framework Based on Neural Architecture Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Keypoint extraction including both keypoint detection and description is a fundamental step in a wide range of geometric multimedia applications. In recent years, many learning-based approaches for keypoint extraction emerge and achieve promising results. However, they usually design network architectures empirically and lack of considerations about the comprehensive performance, which leads to limited applications. In this paper, we propose a practical framework based on Neural Architecture Search (NAS) technology, DKNAS, which can search architectures automatically and maintain efficiency and effectiveness, simultaneously. To the best of our knowledge, the proposed framework is the first NAS framework for keypoint extraction. The evaluation on HPatches dataset shows that our method achieves state-of-the-art results in the metrics of repeatability, localization error, homography accuracy and matching scores. Besides, our model is applied to a traditional Simultaneous Localization and Mapping (SLAM) system, ORB-SLAM2, to replace the handcrafted keypoints. Experimental results demonstrate that the system adopting our model outperforms ORB-SLAM2 and some other deep keypoints enhanced systems.",
        "primary_area": "",
        "author": "Li Liu;Xing Cai;Ge Li;Thomas H Li;Li Liu;Xing Cai;Ge Li;Thomas H Li",
        "authorids": "/37089544855;/37086927979;/37085815762;/37086497292;/37089544855;/37086927979;/37085815762;/37086497292",
        "aff": "School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, China; School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, China; School of Electronic and Computer Engineering, Peking University Shenzhen Graduate School, China; Information Technology R&D Innovation Center of Peking University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812101/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=719572713391035705&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Peking University",
        "aff_unique_dep": "School of Electronic and Computer Engineering",
        "aff_unique_url": "http://www.pku.edu.cn",
        "aff_unique_abbr": "PKU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen Graduate School;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812237",
        "title": "DORA: Distributed Online Risk-Aware Explorer",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploration of unknown environments is an important challenge in the field of robotics. While a single robot can achieve this task alone, evidence suggests it could be accomplished more efficiently by groups of robots, with advantages in terms of terrain coverage as well as robustness to failures. Exploration can be guided through belief maps, which provide probabilistic information about which part of the terrain is interesting to explore (either based on risk management or reward). This process can be centrally coordinated by building a collective belief map on a common server. However, relying on a central processing station creates a communication bottleneck and single point of failure for the system. In this paper, we present Distributed Online Risk-Aware (DORA) Explorer, an exploration system that leverages decentralized information sharing to update a common risk belief map. DORA-Explorer allows a group of robots to explore an unknown environment discretized as a 2D grid with obstacles, with high coverage while minimizing exposure to risk, effectively reducing robot failures.",
        "primary_area": "",
        "author": "David Vielfaure;Samuel Arseneault;Pierre-Yves Lajoie;Giovanni Beltrame;David Vielfaure;Samuel Arseneault;Pierre-Yves Lajoie;Giovanni Beltrame",
        "authorids": "/37089449655;/37089449246;/37086687701;/37295768000;/37089449655;/37089449246;/37086687701;/37295768000",
        "aff": "David Vielfaure; Samuel Arseneault; Pierre-Yves Lajoie; Giovanni Beltrame",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812237/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17636246846854297960&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9811886",
        "title": "DPMPC-Planner: A real-time UAV trajectory planning framework for complex static environments with dynamic obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe UAV navigation is challenging due to the complex environment structures, dynamic obstacles, and uncertainties from measurement noises and unpredictable moving obstacle behaviors. Although plenty of recent works achieve safe navigation in complex static environments with sophisticated mapping algorithms, such as occupancy map and ESDF map, these methods cannot reliably handle dynamic environments due to the mapping limitation from moving obstacles. To address the limitation, this paper proposes a trajectory planning framework to achieve safe navigation considering complex static environments with dynamic obstacles. To reliably handle dynamic obstacles, we divide the environment representation into static mapping and dynamic object representation, which can be obtained from computer vision methods. Our framework first generates a static trajectory based on the proposed iterative corridor shrinking algorithm. Then, reactive chance-constrained model predictive control with temporal goal tracking is applied to avoid dynamic obstacles with uncertainties. The simulation results in various environments demonstrate the ability of our algorithm to navigate safely in complex static environments with dynamic obstacles.",
        "primary_area": "",
        "author": "Zhefan Xu;Di Deng;Yiping Dong;Kenji Shimada;Zhefan Xu;Di Deng;Yiping Dong;Kenji Shimada",
        "authorids": "/37088810563;/37086577056;/37089446780;/37324632500;/37088810563;/37086577056;/37089446780;/37324632500",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811886/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7311281994330855627&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811369",
        "title": "DRAGONFLY: a UAV Rapidly Deployed Micro-Profiler Array for Underwater Thermocline Observation",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater thermocline, common in the lakes and ocean, plays a vital role in meteorological forecasting in the ocean and lakes dynamics research. This letter proposes a method for rapid and multipoint observation of thermocline variations with time and space using an airdropped micro-profiler array, named the DRAGONFLY system. It comprises specially designed disposable low-cost micro-profilers, a general unmanned aerial carrier platform, and a ground control system. This system can conduct periodic profile observations at a single point or quickly survey a large area. A series of experiments to characterize the micro-profiler and the DRAGONFLY system were conducted in Qiandao Lake, China. We demonstrate the developed system with data from field experiments, which show very high flexibility, and feasibility to observe the lake thermocline, implying potential applications in ocean transient phenomena observation.",
        "primary_area": "",
        "author": "Chenxin Lyu;Zhihao Fan;Yuanbo Bi;Zheng Zeng;Lian Lian;Chenxin Lyu;Zhihao Fan;Yuanbo Bi;Zheng Zeng;Lian Lian",
        "authorids": "/37089409944;/37089448878;/37089409456;/37085795231;/37414832500;/37089409944;/37089448878;/37089409456;/37085795231;/37414832500",
        "aff": "State Key Laboratory of Ocean Engineering, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Ocean Engineering, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Ocean Engineering, Shanghai Jiao Tong University, Shanghai, China; Qingdao Collaborative Innovation Center of Marine Science and Technology, Qingdao, China; Qingdao Collaborative Innovation Center of Marine Science and Technology, Qingdao, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811369/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6079582724683117734&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "Shanghai Jiao Tong University;Qingdao Collaborative Innovation Center of Marine Science and Technology",
        "aff_unique_dep": "State Key Laboratory of Ocean Engineering;Marine Science and Technology",
        "aff_unique_url": "https://www.sjtu.edu.cn;",
        "aff_unique_abbr": "SJTU;",
        "aff_campus_unique_index": "0;0;0;1;1",
        "aff_campus_unique": "Shanghai;Qingdao",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812290",
        "title": "DRG: A Dynamic Relation Graph for Unified Prior-Online Environment Modeling in Urban Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Environment modeling is the backbone of how autonomous agents understand the world, and therefore has significant implications for decision-making and verification. Motivated by the success of relational mapping tools such as Lanelet2, we present the Dynamic Relation Graph (DRG). The DRG is a novel method for extending prior relational maps to include online observations, creating a unified en-vironment model which incorporates both prior and online data sources. Our prototype implementation models a finite set of heterogeneous features including road signage and pedestrian movement. However, the methodology behind the DRG can be expanded to a wider range of features in a fashion that does not increase the complexity of behavioral planning. Simulated stress tests indicate the DRG's effectiveness in decreasing decision-making complexity, and deployment on the University of Waterloo's WATonomous research vehicle demonstrates its practical utility. The prototype code will be released at github.com/WATonomous/DRG.",
        "primary_area": "",
        "author": "Rowan Dempster;Mohammad Al-Sharman;Yeshu Jain;Jeffery Li;Derek Rayside;William Melek;Rowan Dempster;Mohammad Al-Sharman;Yeshu Jain;Jeffery Li;Derek Rayside;William Melek",
        "authorids": "/37089446930;/37085354251;/37089449045;/37089448794;/37316266400;/38536080800;/37089446930;/37085354251;/37089449045;/37089448794;/37316266400;/38536080800",
        "aff": "Department of Electrical and Computer Engineering, WATonomous lab, University of Waterloo, ON, Canada; Department of Electrical and Computer Engineering, WATonomous lab, University of Waterloo, ON, Canada; Department of Electrical and Computer Engineering, WATonomous lab, University of Waterloo, ON, Canada; Computer Science Department, WATonomous lab, University of Waterloo, ON, Canada; Department of Electrical and Computer Engineering, WATonomous lab, University of Waterloo, ON, Canada; Department of Mechanical and Mechatronics Engineering, WATonomous lab, University of Waterloo, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812290/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6603319518627528142&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Waterloo",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://uwaterloo.ca",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Waterloo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9811607",
        "title": "DURableVS: Data-efficient Unsupervised Recalibrating Visual Servoing via online learning in a structured generative model",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual servoing enables robotic systems to perform accurate closed-loop control, which is required in many applications. However, existing methods require either precise calibration of the robot kinematic model and cameras or use neural architectures that require large amounts of data to train. In this work, we present a method for unsupervised learning of visual servoing that does not require any prior calibration and is extremely data-efficient. Our key insight is that visual servoing does not depend on identifying the veridical kinematic and camera parameters, but instead only on an accurate generative model of image feature observations from the joint positions of the robot. We demonstrate that with our model architecture and learning algorithm, we can consistently learn accurate models from less than 50 training samples (which amounts to less than 1 min of unsupervised data collection), and that such data-efficient learning is not possible with standard neural architectures. Further, we show that by using the generative model in the loop and learning online, we can enable a robotic system to recover from calibration errors and to detect and quickly adapt to possibly unexpected changes in the robot-camera system (e.g. bumped camera, new objects).",
        "primary_area": "",
        "author": "Nishad Gothoskar;Miguel Lazaro-Gredilla;Yasemin Bekiroglu;Abhishek Agarwal;Joshua B. Tenenbaum;Vikash K. Mansinghka;Dileep George;Nishad Gothoskar;Miguel Lazaro-Gredilla;Yasemin Bekiroglu;Abhishek Agarwal;Joshua B. Tenenbaum;Vikash K. Mansinghka;Dileep George",
        "authorids": "/37089448831;/38270913400;/37947356700;/37089449264;/37622583000;/37085640340;/37089448914;/37089448831;/38270913400;/37947356700;/37089449264;/37622583000;/37085640340;/37089448914",
        "aff": "Massachusetts Institute of Technology; Vicarious AI; Vicarious AI; Vicarious AI; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Vicarious AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811607/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1165489217365454007&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Vicarious AI",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.vicarious.com",
        "aff_unique_abbr": "MIT;Vicarious AI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811649",
        "title": "DanceHAT: Generate Stable Dances for Humanoid Robots with Adversarial Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Music to dance for humanoid robots is an interesting task. Robot dance generation is challenging when considering music pieces, human dancer motions, and robot stability simultaneously. Previous methods rely on human-designed motion library or stability constraints for robot postures. Hence, dance generation for humanoid robots requires expert design, which can be time-consuming across different humanoid platforms. In this work, we propose a novel method called DanceHAT, which generates stable humanoid dances by imitating human dancers with self-learning. DanceHAT is an adversarial training framework, which incorporates similarity loss and stability loss simultaneously. Furthermore, DanceHAT does not require human-designed features or robot model information. Experiments in the simulation environment and on the real robot demonstrate that our model can generate stable, diverse, and human-like dances for humanoid robots automatically. In addition, DanceHAT is a general training approach for robot imitation tasks with stability constraints, thus can be utilized in other humanoid tasks and will be researched in future works.",
        "primary_area": "",
        "author": "Buqing Nie;Yue Gao;Buqing Nie;Yue Gao",
        "authorids": "/37089447482;/37086882854;/37089447482;/37086882854",
        "aff": "Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, P.R. China; MoE Key Lab of Artificial Intelligence, AI Institute of Shanghai Jiao Tong University, Shanghai, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811649/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12034763654876358721&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812157",
        "title": "Data-Driven Control for a Milli-Scale Spiral-Type Magnetic Swimmer using MPC",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents four data-driven system models for a magnetically controlled swimmer. The models were derived directly from experimental data, and the accuracy of the models was experimentally demonstrated. Our previous study successfully implemented two non-model-based control algorithms for 3D path-following using PID and model reference adaptive controller (MRAC). This paper focuses on system identification using only experimental data and a model-based control strategy. Four system models were derived: (1) a physical estimation model, (2, 3) Sparse Identification of Nonlinear Dynamics (SINDY), linear system and nonlinear system, and (4) multilayer perceptron (MLP). All four system models were implemented as an estimator of a multi-step Kalman filter. The maximum required sensing interval was increased from 180 ms to 420 ms and the respective tracking error decreased from 9 mm to 4.6 mm. Finally, a Model Predictive Controller (MPC) implementing the linear SINDY model was tested for 3D path-following and shown to be computationally efficient and offers performances comparable to other control methods.",
        "primary_area": "",
        "author": "Haoran Zhao;Yitong Lu;Aaron T. Becker;Julien Leclerc;Haoran Zhao;Yitong Lu;Aaron T. Becker;Julien Leclerc",
        "authorids": "/37086309754;/37088686719;/37588897100;/38246174500;/37086309754;/37088686719;/37588897100;/38246174500",
        "aff": "Department of Electrical and Computer Engineering, University of Houston, Houston, TX; Department of Electrical and Computer Engineering, University of Houston, Houston, TX; Department of Electrical and Computer Engineering, University of Houston, Houston, TX; Department of Electrical and Computer Engineering, University of Houston, Houston, TX",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812157/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3019220381599316699&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Houston",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.uh.edu",
        "aff_unique_abbr": "UH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811760",
        "title": "Data-efficient learning of object-centric grasp preferences",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping made impressive progress during the last few years thanks to deep learning. However, there are many objects for which it is not possible to choose a grasp by only looking at an RGB-D image, might it be for physical reasons (e.g., a hammer with uneven mass distribution) or task constraints (e.g., food that should not be spoiled). In such situations, the preferences of experts need to be taken into account. In this paper, we introduce a data-efficient grasping pipeline (Latent Space GP Selector - LGPS) that learns grasp prefer-ences with only a few labels per object (typically 1 to 4) and generalizes to new views of this object. Our pipeline is based on learning a latent space of grasps with a dataset generated with any state-of-the-art grasp generator (e.g., Dex-Net). This latent space is then used as a low-dimensional input for a Gaussian process classifier that selects the preferred grasp among those proposed by the generator. The results show that our method outperforms both GR-ConvNet and GG-CNN (two state-of-the-art methods that are also based on labeled grasps) on the Cornell dataset, especially when only a few labels are used: only 80 labels are enough to correctly choose 80% of the grasps (885 scenes, 244 objects). Results are similar on our dataset (91 scenes, 28 objects).",
        "primary_area": "",
        "author": "Yoann Fleytoux;Anji Ma;Serena Ivaldi;Jean-Baptiste Mouret;Yoann Fleytoux;Anji Ma;Serena Ivaldi;Jean-Baptiste Mouret",
        "authorids": "/37089450100;/37086028187;/38534379600;/37586421200;/37089450100;/37086028187;/38534379600;/37586421200",
        "aff": "Universit\u00e9 de Lorraine, CNRS, Inria, France; School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Universit\u00e9 de Lorraine, CNRS, Inria, France; Universit\u00e9 de Lorraine, CNRS, Inria, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811760/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7627160474042363316&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Universit\u00e9 de Lorraine;Beijing Institute of Technology",
        "aff_unique_dep": ";School of Mechatronical Engineering",
        "aff_unique_url": "https://www.univ-lorraine.fr;http://www.bit.edu.cn",
        "aff_unique_abbr": "UL;BIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Beijing",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "France;China"
    },
    {
        "id": "9812241",
        "title": "De-snowing LiDAR Point Clouds With Intensity and Spatial-Temporal Features",
        "track": "main",
        "status": "Poster",
        "abstract": "Point clouds from 3D light detection and ranging (LiDAR) are widely used. Noise caused by falling snow reduces the availability of point clouds. Due to the sparseness of LiDAR point clouds and the fact that the snow point clouds are easily affected by multi factors such as wind or snowfall conditions, it is difficult to accurately remove the snow while preserving the details of the point clouds. To solve the problem, this paper presents a de-snowing approach combining the intensity and spatial-temporal features. An intensity-based filter firstly removes the snow. Then a repairing method restores the non-snow points based on the spatial-temporal features. Experimental results demonstrate that our approach outperforms existing work in the literature and performs the least damage to the point clouds in different snowfall scenarios.",
        "primary_area": "",
        "author": "Boyang Li;Jieling Li;Gang Chen;Hejun Wu;Kai Huang;Boyang Li;Jieling Li;Gang Chen;Hejun Wu;Kai Huang",
        "authorids": "/37086489018;/37087325050;/38244159000;/37405488300;/37534912900;/37086489018;/37087325050;/38244159000;/37405488300;/37534912900",
        "aff": "Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, Guangzhou, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, Guangzhou, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, Guangzhou, China; Key Laboratory of Machine Intelligence and Advanced Computing, Ministry of Education, Guangzhou, China; Sun Yat-sen University, Shenzhen Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812241/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1362069068445562039&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Key Laboratory of Machine Intelligence and Advanced Computing;Sun Yat-sen University",
        "aff_unique_dep": "Ministry of Education;Shenzhen Institute",
        "aff_unique_url": ";http://www.sysu.edu.cn/",
        "aff_unique_abbr": ";SYSU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812163",
        "title": "Decentralized Global Connectivity Maintenance for Multi-Robot Navigation: A Reinforcement Learning Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of multi-robot navigation of connectivity maintenance is challenging in multi-robot applications. This work investigates how to navigate a multi-robot team in unknown environments while maintaining connectivity. We propose a reinforcement learning (RL) approach to develop a decentralized policy, which is shared among multiple robots. Given range sensor measurements and the positions of other robots, the policy aims to generate control commands for navigation and preserve the global connectivity of the robot team. We incorporate connectivity concerns into the RL framework as constraints and introduce behavior cloning to reduce the exploration complexity of policy optimization. The policy is optimized with all transition data collected by multiple robots in random simulated scenarios. We validate the effectiveness of the proposed approach by comparing different combinations of connectivity constraints and behavior cloning. We also show that our policy can generalize to unseen scenarios in both simulation and holonomic robots experiments.",
        "primary_area": "",
        "author": "Minghao Li;Yingrui Jie;Yang Kong;Hui Cheng;Minghao Li;Yingrui Jie;Yang Kong;Hui Cheng",
        "authorids": "/37089449410;/37089449999;/37088540480;/38008557800;/37089449410;/37089449999;/37088540480;/38008557800",
        "aff": "School of Eletronics and Communication Engineering, Sun Yat-sen University, Shenzhen, China; School of Eletronics and Communication Engineering, Sun Yat-sen University, Shenzhen, China; School of Eletronics and Communication Engineering, Sun Yat-sen University, Shenzhen, China; School of Eletronics and Communication Engineering, Sun Yat-sen University, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812163/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14509985639840113376&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Sun Yat-sen University",
        "aff_unique_dep": "School of Electronics and Communication Engineering",
        "aff_unique_url": "http://www.sysu.edu.cn",
        "aff_unique_abbr": "SYSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811726",
        "title": "Decentralized Model Predictive Control for Equilibrium-based Collaborative UAV Bar Transportation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we analyze the equilibrium points of a collaborative transportation task, composed of two unmanned aerial vehicles and a payload - in this case, a bar. Moreover, centralized and decentralized linear model predictive controllers are designed, where the nonlinear dynamics are linearized around the equilibrium points previously analyzed. A comparison between the centralized and decentralized formulations is provided, based on experimental results for both setups, and considering the time to solution and performance of each controller. Our findings provide new operational equilibrium points that can be paired with predictive model-based controllers for efficient operation.",
        "primary_area": "",
        "author": "Roberto C. Sundin;Pedro Roque;Dimos V. Dimarogonas;Roberto C. Sundin;Pedro Roque;Dimos V. Dimarogonas",
        "authorids": "/37089447840;/37086198375;/37282084700;/37089447840;/37086198375;/37282084700",
        "aff": "Ericsson Research, Stockholm, Sweden; Division of Decision and Control Systems, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Decision and Control Systems, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811726/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13950505228437294310&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Ericsson Research;KTH Royal Institute of Technology",
        "aff_unique_dep": ";Division of Decision and Control Systems",
        "aff_unique_url": "https://www.ericsson.com/research;https://www.kth.se",
        "aff_unique_abbr": "Ericsson;KTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9811596",
        "title": "Decentralized Ride-sharing of Shared Autonomous Vehicles Using Graph Neural Network-Based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Ride-sharing has important implications for improving the efficiency of mobility-on-demand systems. However, it remains a challenge due to the complex dynamics between vehicles and requests. This paper presents a decentralized ride-sharing algorithm suitable for shared autonomous vehicles (SAVs) deployment. The ride-sharing problem is formulated as a multi-agent reinforcement learning problem. We explore state representation with the request-vehicle graph to encode shareability and potential coordination information. We use a graph attention network to build a hierarchical structure that unifies ride-sharing assignments with rebalancing and handles real-world scenarios where hundreds of user requests can be associated with vehicles. We show results in both generic grid-world and SUMO simulation with real-world data from the Manhattan area. We empirically demonstrate that our proposed approach can achieve similar performance compared with a state-of-the-art centralized optimization method and higher computation efficiency.",
        "primary_area": "",
        "author": "Boqi Li;Nejib Ammar;Prashant Tiwari;Huei Peng;Boqi Li;Nejib Ammar;Prashant Tiwari;Huei Peng",
        "authorids": "/37086592399;/37089447251;/37087104382;/37273793500;/37086592399;/37089447251;/37087104382;/37273793500",
        "aff": "Mechanical Engineering Department, University of Michigan, Ann Arbor, MI, USA; Toyota Motor North America; Toyota Motor North America; Mechanical Engineering Department, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811596/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5674364137390788605&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Michigan;Toyota Motor Corporation",
        "aff_unique_dep": "Mechanical Engineering Department;",
        "aff_unique_url": "https://www.umich.edu;https://www.toyota.com",
        "aff_unique_abbr": "UM;Toyota",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ann Arbor;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811692",
        "title": "Decoupling of Inertia Effect in Angular Momentum of a Humanoid and its Application to Resolved Viscoelasticity Control",
        "track": "main",
        "status": "Poster",
        "abstract": "As a basic part of the centroidal dynamics, an-gular momentum plays a critical role in humanoid motion control. Therefore, how to explicitly express and control an-gular momentum through whole-body motion is an important topic for researchers. This study discusses the selection of the generalized velocity corresponding to whole-body angular momentum. Based on the discussion, we present a method that decouples the inertia effect in centroidal angular momentum and applies it in resolved viscoelasticity control, which achieves the angular momentum control by whole-body compliance in an interpretable way without complicated calculation. At last, we validate the feasibility and effectiveness of proposed method in forward dynamics simulation of balancing control in the double and single support states and landing motion after hopping.",
        "primary_area": "",
        "author": "Zewen He;Ko Yamamoto;Zewen He;Ko Yamamoto",
        "authorids": "/37089447156;/37536641800;/37089447156;/37536641800",
        "aff": "Department of Mechanical Engineering, Univ. of Tokyo, Tokyo, Japan; Department of Mechanical Engineering, Univ. of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811692/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4746547895028187696&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811899",
        "title": "Deep Bayesian ICP Covariance Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Covariance estimation for the Iterative Closest Point (ICP) point cloud registration algorithm is essential for state estimation and sensor fusion purposes. We argue that a major source of error for ICP is in the input data itself, from the sensor noise to the scene geometry. Benefiting from recent developments in deep learning for point clouds, we propose a data-driven approach to learn an error model for ICP. We estimate covariances modeling data-dependent heteroscedastic aleatoric uncertainty, and epistemic uncertainty using a variational Bayesian approach. The system evaluation is performed on LiDAR odometry on different datasets, highlighting good results in comparison to the state of the art.",
        "primary_area": "",
        "author": "Andrea De Maio;Simon Lacroix;Andrea De Maio;Simon Lacroix",
        "authorids": "/37088469398;/37278650100;/37088469398;/37278650100",
        "aff": "LAAS-CNRS, Universite de Toulouse, Toulouse, France; LAAS-CNRS, Universite de Toulouse, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811899/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=72283552025540869&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universite de Toulouse",
        "aff_unique_dep": "LAAS-CNRS",
        "aff_unique_url": "https://www.laas.fr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toulouse",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812413",
        "title": "Deep Curiosity Driven Multicamera 3D Viewpoint Adjustment for Robot-Assisted Minimally Invasive Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Maneuverable multicamera systems offer potential benefits in abdominal minimally-invasive procedures, including multi-view scene reconstruction and optimal viewpoint capture. Effective autonomous movement and re-positioning of such systems, however, remains an open challenge due to dynamic motion constraints, deforming surgical scenes, and visual artifacts such as motion blur, specular reflections, and blood stains [1]. Despite these existing roadblocks, multicamera systems have been used both to provide surgeons with stable and analytically optimized viewpoints [2] and to enable 3D surgical scene reconstruction [3] that directly contributes towards the possibility of task autonomy [4] and AR-enhanced surgical procedures [5]. These methods, however, often require extensive, high-dimensional continuous data sets, and may not value scene discovery. To that end, this project presents a novel curiosity driven multicamera viewpoint adjustment framework, Ac, that aims to simultaneously (a) explore and maximize weighted 3D reconstructable coverage; (b) limit unnecessary camera motion; and (c) relieve data-intensiveness through dimension-reduced state representations. The developed algorithms are comparatively evaluated against three baseline methods on simulated surgical sequences, and results demonstrate performance enhancements with the presented methods.",
        "primary_area": "",
        "author": "Yun-Hsuan Su;Heidi Zhang;Wenfan Jiang;Khanh Ngo;Kevin Huang;Yun-Hsuan Su;Heidi Zhang;Wenfan Jiang;Khanh Ngo;Kevin Huang",
        "authorids": "/37086366130;/37089449349;/37089227992;/37089449810;/37085541904;/37086366130;/37089449349;/37089227992;/37089449810;/37085541904",
        "aff": "Department of Computer Science, Mount Holyoke College, South Hadley, MA, USA; Department of Computer Science, Mount Holyoke College, South Hadley, MA, USA; Department of Computer Science, Mount Holyoke College, South Hadley, MA, USA; Department of Computer Science, Mount Holyoke College, South Hadley, MA, USA; Dept. of Engineering, Trinity College, Hartford, CT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812413/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12628378143201082060&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Mount Holyoke College;Trinity College",
        "aff_unique_dep": "Department of Computer Science;Dept. of Engineering",
        "aff_unique_url": "https://www.mtholyoke.edu;https://www.trincoll.edu",
        "aff_unique_abbr": "MHC;Trinity College",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "South Hadley;Hartford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812249",
        "title": "Deep Drifting: Autonomous Drifting of Arbitrary Trajectories using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a Deep Neural Network is trained using Reinforcement Learning in order to drift on arbitrary trajectories which are defined by a sequence of waypoints. In a first step, a highly accurate vehicle simulation is used for the training process. Then, the obtained policy is refined and validated on a self-built model car. The chosen reward function is inspired by the scoring process of real life drifting competitions. It is kept simple and thus applicable to very general scenarios. The experimental results demonstrate that a relatively small network, given only a few measurements and control inputs, already achieves an outstanding performance. In simulation, the learned controller is able to reliably hold a steady state drift. Moreover, it is capable of generalizing to arbitrary, previously unknown trajectories and different driving conditions. After transferring the learned controller to the model car, it also performs surprisingly well given the physical constraints.",
        "primary_area": "",
        "author": "Fabian Domberg;Carlos Castelar Wembers;Hiren Patel;Georg Schildbach;Fabian Domberg;Carlos Castelar Wembers;Hiren Patel;Georg Schildbach",
        "authorids": "/37089450348;/37089449497;/37089449635;/38232682600;/37089450348;/37089449497;/37089449635;/38232682600",
        "aff": "Institute for Electrical Engineering in Medicine, University of L\u00fcbeck, L\u00fcbeck, Germany; Institute for Electrical Engineering in Medicine, University of L\u00fcbeck, L\u00fcbeck, Germany; Institute for Electrical Engineering in Medicine, University of L\u00fcbeck, L\u00fcbeck, Germany; Institute for Electrical Engineering in Medicine, University of L\u00fcbeck, L\u00fcbeck, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812249/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11687652018728687068&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of L\u00fcbeck",
        "aff_unique_dep": "Institute for Electrical Engineering in Medicine",
        "aff_unique_url": "https://www.uni-luebeck.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "L\u00fcbeck",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811910",
        "title": "Deep Learning-driven Front-Following within Close Proximity: a Hands-Free Control Model on a Smart Walker",
        "track": "main",
        "status": "Poster",
        "abstract": "With the ever-increasing elderly population, elder walking assistance is in strong demand. Instead of receiving assistance from a human carer, a smart walker can bring an elder user a more convenient and autonomous walking experience. Towards intelligent and safe walking assistance, we propose a close-proximity front-following model for smart walkers, which analyzes the walking gait and detects the walking intention of the user, and intelligently follows the user in the front to provide walking support, without the user pushing the walker. We design a deep learning model named Front-Following Net (FFLNet), consisting of CNN and LSTM networks to extract spatial and temporal features of the elder walking gait, collected in time windows through a thermal camera and a 2D LiDAR, for effective walking intention detection. As compared to other walking intention detection approaches, our model can explore more effective information in the gait data within a short walking period, and achieve accurate hands-free tracking of the user. Experiments show that our FFLNet can achieve over 77% detection accuracy among six representative walking intentions and more than 90% accuracy for turning intentions. Combined with a carefully designed walker control policy, our smart walker can achieve high front-following correctness with the user.",
        "primary_area": "",
        "author": "Zhao Chongyu;Guo Wenzhi;Wen Rongwei;Zheng Wang;Chuan Wu;Zhao Chongyu;Guo Wenzhi;Wen Rongwei;Zheng Wang;Chuan Wu",
        "authorids": "/37089449295;/37089448264;/37089448246;/37089448265;/37308270500;/37089449295;/37089448264;/37089448246;/37089448265;/37308270500",
        "aff": "Department of Computer Science, the University of Hong Kong; Department of the Mechanical Engineering, the University of Hong Kong; Department of Computer Science, the University of Hong Kong; Department of Mechanical and Energy Engineering, South-ern University of Science and Technology, Shenzhen, China; Department of Computer Science, the University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811910/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12026408257610715398&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Hong Kong;South University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science;Department of Mechanical and Energy Engineering",
        "aff_unique_url": "https://www.hku.hk;https://www.sustech.edu.cn",
        "aff_unique_abbr": "HKU;SUSTech",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811595",
        "title": "Deep Networks for Point Cloud Map Validation",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern SLAM engines typically rely on high-end sensor rigs and robust algorithms to guarantee the high-quality requirements that self-driving cars and other complex autonomous systems require from 3D point cloud maps. Nonetheless, multiple factors can impact the reconstruction quality and it is not uncommon to end up with generally consistent maps affected by local distortions and artifacts, especially when mapping increasingly larger environments. We tackle the problem of identifying these low-consistency areas in point cloud maps by analyzing the quality of pair-wise point cloud alignments. Rather than relying on geometric consistency analysis or visual inspection, we leverage on deep point networks and formulate the validation as a binary classification problem, allowing us to quickly and effectively identify areas of improvement.",
        "primary_area": "",
        "author": "Nicole Camous;Sergi Adipraja Widjaja;Venice Erin Liong;Taigo Maria Bonanni;Nicole Camous;Sergi Adipraja Widjaja;Venice Erin Liong;Taigo Maria Bonanni",
        "authorids": "/37089449481;/37089447717;/37990606800;/37086069401;/37089449481;/37089447717;/37990606800;/37086069401",
        "aff": "MOTIONAL SINGAPORE PTE. LIMITED; MOTIONAL SINGAPORE PTE. LIMITED; MOTIONAL SINGAPORE PTE. LIMITED; MOTIONAL SINGAPORE PTE. LIMITED",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811595/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17532583114132153902&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Motional",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.motional.com",
        "aff_unique_abbr": "Motional",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9811800",
        "title": "Deep Reinforcement Learning for Next-Best-View Planning in Agricultural Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated agricultural applications, i.e., fruit picking require spatial information about crops and, especially, their fruits. In this paper, we present a novel deep reinforcement learning (DRL) approach to determine the next best view for automatic exploration of 3D environments with a robotic arm equipped with an RGB-D camera. We process the obtained images into an octree with labeled regions of interest (ROIs), i.e., fruits. We use this octree to generate 3D observation maps that serve as encoded input to the DRL network. We hereby do not only rely on known information about the environment, but explicitly also represent information about the unknown space to force exploration. Our network takes as input the encoded 3D observation map and the temporal sequence of camera view pose changes, and outputs the most promising camera movement direction. Our experimental results show an improved ROI targeted exploration performance resulting from our learned network in comparison to a state-of-the-art method.",
        "primary_area": "",
        "author": "Xiangyu Zeng;Tobias Zaenker;Maren Bennewitz;Xiangyu Zeng;Tobias Zaenker;Maren Bennewitz",
        "authorids": "/37089449730;/37088540533;/37324765000;/37089449730;/37088540533;/37324765000",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811800/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2333933363440249242&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811618",
        "title": "Deep Surrogate Q-Learning for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Open challenges for deep reinforcement learning systems are their adaptivity to changing environments and their efficiency w.r.t. computational resources and data. In the application of learning lane-change behavior for autonomous driving, the number of required transitions imposes a bottleneck, since test drivers cannot perform an arbitrary amount of lane changes in the real world. In the off-policy setting, additional information on solving the task can be gained by observing actions from others. While in the classical RL setup this knowledge remains unused, we use other drivers as surrogates to learn the agent's value function more efficiently. We propose Surrogate Q-learning that deals with the aforementioned problems and reduces the required driving time drastically. We further propose an efficient implementation based on a permutation equivariant deep neural network architecture of the Q-function to estimate action-values for a variable number of vehicles in sensor range. We evaluate our method in the open traffic simulator SUMO and learn well performing driving policies on the real highD dataset.",
        "primary_area": "",
        "author": "Maria Kalweit;Gabriel Kalweit;Moritz Werling;Joschka Boedecker;Maria Kalweit;Gabriel Kalweit;Moritz Werling;Joschka Boedecker",
        "authorids": "/37089447424;/37087323482;/37542759200;/37888921900;/37089447424;/37087323482;/37542759200;/37888921900",
        "aff": "Neurorobotics Lab, University of Freiburg, Germany; Neurorobotics Lab, University of Freiburg, Germany; BMWGroup, Unterschleissheim, Germany; BrainLinks-BrainTools, University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811618/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4581323611682609244&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Freiburg;BMW Group",
        "aff_unique_dep": "Neurorobotics Lab;",
        "aff_unique_url": "https://www.uni-freiburg.de;https://www.bmwgroup.com",
        "aff_unique_abbr": "Uni Freiburg;BMW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Freiburg;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811598",
        "title": "Deep Visual Navigation under Partial Observability",
        "track": "main",
        "status": "Poster",
        "abstract": "How can a robot navigate successfully in rich and diverse environments, indoors or outdoors, along office corridors or trails on the grassland, on the flat ground or the staircase? To this end, this work aims to address three challenges: (i) complex visual observations, (ii) partial observability of local visual sensing, and (iii) multimodal robot behaviors conditioned on both the local environment and the global navigation objective. We propose to train a neural network (NN) controller for local navigation via imitation learning. To tackle complex visual observations, we extract multi-scale spatial representations through CNNs. To tackle partial observability, we aggregate multi-scale spatial information over time and encode it in LSTMs. To learn multimodal behaviors, we use a separate memory module for each behavior mode. Importantly, we integrate the multiple neural network modules into a unified controller that achieves robust performance for visual navigation in complex, partially observable environments. We implemented the controller on the quadrupedal Spot robot and evaluated it on three challenging tasks: adversarial pedestrian avoidance, blind-spot obstacle avoidance, and elevator riding. The experiments show that the proposed NN architecture significantly improves navigation performance.",
        "primary_area": "",
        "author": "Bo Ai;Wei Gao;Vinay;David Hsu;Bo Ai;Wei Gao;Vinay;David Hsu",
        "authorids": "/37089446987;/37089448869;/37089447295;/37421581500;/37089446987;/37089448869;/37089447295;/37421581500",
        "aff": "School of Computing, National University of Singapore, Singapore, Singapore; School of Computing, National University of Singapore, Singapore, Singapore; School of Computing, National University of Singapore, Singapore, Singapore; School of Computing, National University of Singapore, Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811598/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=440415992554937034&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9812240",
        "title": "Deep-CNN based Robotic Multi-Class Under-Canopy Weed Control in Precision Farming",
        "track": "main",
        "status": "Poster",
        "abstract": "Smart weeding systems to perform plant-specific operations can contribute to the sustainability of agriculture and the environment. Despite monumental advances in autonomous robotic technologies for precision weed management in recent years, work on under-canopy weeding in fields is yet to be realized. A prerequisite of such systems is reliable detection and classification of weeds to avoid mistakenly spraying and, thus, damaging the surrounding plants. Real-time multi-class weed identification enables species-specific treatment of weeds and significantly reduces the amount of herbicide use. Here, our first contribution is the first adequately large realistic image dataset AIWeeds (one/multiple kinds of weeds in one image), a library of about 10,000 annotated images of flax and the 14 most common weeds in fields and gardens taken from 20 different locations in North Dakota, California, and Central China. Second, we provide a full pipeline from model training with maximum efficiency to deploying the TensorRT-optimized model onto a single board computer. Based on AIWeeds and the pipeline, we present a baseline for classification performance using five benchmark CNN models. Among them, MobileNetV2, with both the shortest inference time and lowest memory consumption, is the qualified candidate for real-time applications. Finally, we deploy MobileNetV2 onto our own compact autonomous robot SAMBot for real-time weed detection. The 90% test accuracy realized in previously unseen scenes in flax fields (with a row spacing of 0.2-0.3 m), with crops and weeds, distortion, blur, and shadows, is a milestone towards precision weed control in the real world. We have publicly released the dataset and code to generate the results at https://github.com/StructuresComp/Multi-class-Weed-Classification.",
        "primary_area": "",
        "author": "Yayun Du;Guofeng Zhang;Darren Tsang;Mohammad Khalid Jawed;Yayun Du;Guofeng Zhang;Darren Tsang;Mohammad Khalid Jawed",
        "authorids": "/37088689145;/37089449995;/37089448396;/37088686728;/37088689145;/37089449995;/37089448396;/37088686728",
        "aff": "Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812240/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15216327248976845956&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical & Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811820",
        "title": "Deliberation in autonomous robotic surgery: a framework for handling anatomical uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robotic surgery requires deliberation, i.e. the ability to plan and execute a task adapting to uncer-tain and dynamic environments. Uncertainty in the surgical domain is mainly related to the partial pre-operative knowledge about patient-specific anatomical properties. In this paper, we introduce a logic-based framework for surgical tasks with deliberative functions of monitoring and learning. The DE-liberative Framework for Robot-Assisted Surgery (DEFRAS) estimates a pre-operative patient-specific plan, and executes it while continuously measuring the applied force obtained from a biomechanical pre-operative model. Monitoring module compares this model with the actual situation reconstructed from sensors. In case of significant mismatch, the learning module is invoked to update the model, thus improving the estimate of the exerted force. DEFRAS is validated both in simulated and real environment with da Vinci Research Kit executing soft tissue retraction. Compared with state-of-the-art related works, the success rate of the task is improved while minimizing the interaction with the tissue to prevent unintentional damage.",
        "primary_area": "",
        "author": "Eleonora Tagliabue;Daniele Meli;Diego Dall'Alba;Paolo Fiorini;Eleonora Tagliabue;Daniele Meli;Diego Dall'Alba;Paolo Fiorini",
        "authorids": "/37088649344;/37087465814;/38540860700;/37279139000;/37088649344;/37087465814;/38540860700;/37279139000",
        "aff": "Dept. of Computer Science, University of Verona, Italy; Dept. of Computer Science, University of Verona, Italy; Dept. of Computer Science, University of Verona, Italy; Dept. of Computer Science, University of Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811820/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7248520096991327899&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Verona",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.univr.it",
        "aff_unique_abbr": "UniVR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9812122",
        "title": "Demonstration-Efficient Guided Policy Search via Imitation of Robust Tube MPC",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a demonstration-efficient strategy to compress a computationally expensive Model Predictive Controller (MPC) into a more computationally efficient representation based on a deep neural network and Imitation Learning (IL). By generating a Robust Tube variant (RTMPC) of the MPC and leveraging properties from the tube, we introduce a data augmentation method that enables high demonstration-efficiency, capable of compensating the distribution shifts typically encountered in IL. Our approach opens the possibility of zero-shot transfer from a single demonstration collected in a nominal domain, such as a simulation or a robot in a lab/controlled environment, to a domain with bounded model errors/perturbations. Numerical and experimental evaluations performed on a trajectory tracking MPC for a multirotor show that our method outperforms strategies commonly employed in IL, such as DAgger and Domain Randomization, in terms of demonstration-efficiency and robustness to perturbations unseen during training.",
        "primary_area": "",
        "author": "Andrea Tagliabue;Dong-Ki Kim;Michael Everett;Jonathan P. How;Andrea Tagliabue;Dong-Ki Kim;Michael Everett;Jonathan P. How",
        "authorids": "/37086131568;/37087324178;/37418751400;/37276347700;/37086131568;/37087324178;/37418751400;/37276347700",
        "aff": "MIT Department of Aeronautics and Astronautics; MIT Department of Aeronautics and Astronautics; MIT Department of Aeronautics and Astronautics; MIT Department of Aeronautics and Astronautics",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812122/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3211315462923835855&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811966",
        "title": "DenseTact: Optical Tactile Sensor for Dense Shape Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "Increasing the performance of tactile sensing in robots enables versatile, in-hand manipulation. Vision-based tactile sensors have been widely used as rich tactile feedback has been shown to be correlated with increased performance in manipulation tasks. Existing tactile sensor solutions with high resolution have limitations that include low accuracy, expensive components, or lack of scalability. In this paper, an inexpensive, scalable, and compact tactile sensor with high-resolution surface deformation modeling for surface reconstruction of the 3D sensor surface is presented. By observing the contact surface with a fisheye camera, it is shown that the surface deformation can be estimated in real-time (1.8 ms) using deep convolutional neural networks. This sensor in its design and sensing abilities represents a significant step toward better object in-hand localization, classification, and surface estimation all enabled by calibrated, high-resolution shape reconstruction.",
        "primary_area": "",
        "author": "Won Kyung Do;Monroe Kennedy;Won Kyung Do;Monroe Kennedy",
        "authorids": "/37086922065;/37089500447;/37086922065;/37089500447",
        "aff": "ARMLab in the Mechanical Engineering Department, Stanford University, Stanford, CA, USA; ARMLab in the Mechanical Engineering Department, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811966/",
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7470214820610465335&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811912",
        "title": "Deploying Traffic Smoothing Cruise Controllers Learned from Trajectory Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicle-based traffic smoothing con-trollers are often not transferred to real-world use due to challenges in calibrating many-agent traffic simulators. We show a pipeline to sidestep such calibration issues by collecting trajectory data and learning controllers directly from trajectory data that are then deployed zero-shot onto the highway. We construct a dataset of 772.3 kilometers of recorded drives on the I\u201324. We then construct a simple simulator using the recorded drives as the lead vehicle in front of a simulated platoon consisting of one autonomous vehicle and five human followers. Using policy-gradient methods with an asymmetric critic to learn the controller, we show that we are able to improve average MPG by 11% in simulation on congested trajectories. We deploy this controller to a mixed platoon of 4 autonomous Toyota RAV-4's and 7 human drivers in a validation experiment and demonstrate that the expected time-gap of the controller is maintained in the real world test. Finally, we release the driving dataset [1], the simulator, and the trained controller at https://github.com/nathanlct/trajectory-training-icra.",
        "primary_area": "",
        "author": "Nathan Lichtl\u00e9;Eugene Vinitsky;Matthew Nice;Benjamin Seibold;Dan Work;Alexandre M. Bayen;Nathan Lichtl\u00e9;Eugene Vinitsky;Matthew Nice;Benjamin Seibold;Dan Work;Alexandre M. Bayen",
        "authorids": "/37089006246;/37086351408;/37088874400;/37085802092;/37572726600;/37299705000;/37089006246;/37086351408;/37088874400;/37085802092;/37572726600;/37299705000",
        "aff": "Department of Computer Science, ENS Paris-Saclay, Paris-Saclay University; Department of Mechanical Engineering, UC Berkeley; Department of Civil and Environmental Engineering, Vanderbilt University; Department of Physics, Temple University; Department of Civil and Environmental Engineering, Vanderbilt University; Institute for Transportation Studies, UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811912/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5573651033145302858&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;2;1",
        "aff_unique_norm": "Paris-Saclay University;University of California, Berkeley;Vanderbilt University;Temple University",
        "aff_unique_dep": "Department of Computer Science;Department of Mechanical Engineering;Department of Civil and Environmental Engineering;Department of Physics",
        "aff_unique_url": "https://www.ens-paris-saclay.fr;https://www.berkeley.edu;https://www.vanderbilt.edu;https://www.temple.edu",
        "aff_unique_abbr": "ENS Paris-Saclay;UC Berkeley;Vanderbilt;Temple",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Paris-Saclay;Berkeley;",
        "aff_country_unique_index": "0;1;1;1;1;1",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "9811556",
        "title": "Depth Completion Using Geometry-Aware Embedding",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploiting internal spatial geometric constraints of sparse LiDARs is beneficial to depth completion, however, has been not explored well. This paper proposes an efficient method to learn geometry-aware embedding, which encodes the local and global geometric structure information from 3D points, e.g., scene layout, object's sizes and shapes, to guide dense depth estimation. Specifically, we utilize the dynamic graph representation to model generalized geometric relationship from irregular point clouds in a flexible and efficient manner. Further, we joint this embedding and corresponded RGB appearance information to infer missing depths of the scene with well structure-preserved details. The key to our method is to integrate implicit 3D geometric representation into a 2D learning architecture, which leads to a better trade-off between the performance and efficiency. Extensive experiments demonstrate that the proposed method outperforms previous works and could reconstruct fine depths with crisp boundaries in regions that are over-smoothed by them. The ablation study gives more insights into our method that could achieve significant gains with a simple design, while having better generalization capability and stability. The code is available at https://github.com/Wenchao-Du/GAENet.",
        "primary_area": "",
        "author": "Wenchao du;Hu Chen;Hongyu Yang;Yi Zhang;Wenchao du;Hu Chen;Hongyu Yang;Yi Zhang",
        "authorids": "/37086874439;/37085852723;/37596713000;/37085456795;/37086874439;/37085852723;/37596713000;/37085456795",
        "aff": "College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China; College of Computer Science, Sichuan University, Chengdu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811556/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1918132783311070019&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Sichuan University",
        "aff_unique_dep": "College of Computer Science",
        "aff_unique_url": "https://www.scu.edu.cn",
        "aff_unique_abbr": "SCU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chengdu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811689",
        "title": "Depth Distribution Split Labeling for Rubble Recognition of Crushing Machine",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes rubble recognition using a depth image sensor and an automatic rubble crushing system using a construction machine for automatic rubble crushing at a building demolition site. Depth Distribution Split Labeling (DDSL) is proposed to recognize irregularly shaped rubble using depth images and to identify the largest rubble in the workspace. In DDSL, we focused on the fact that the depth of the contact area of adjacent rubble is lower, and labeling by dividing the depth makes it possible to identify the rubble. The automatic rubble crushing system enables to avoid excessive pushing and to grasp objects based on the cylinder driving force calculated from the hydraulic cylinder internal pressure of the construction machine. Through evaluation experiments simulating the crushing environment, it was confirmed that the proposed system can identify and automatically crush rubble.",
        "primary_area": "",
        "author": "Takahiro Ikeda;Satoshi Ueki;Kazuma Shinkai;Hironao Yamada;Takahiro Ikeda;Satoshi Ueki;Kazuma Shinkai;Hironao Yamada",
        "authorids": "/37089736454;/37295009600;/37089450916;/37280269800;/37089736454;/37295009600;/37089450916;/37280269800",
        "aff": "Faculty of Engineering, Gifu University, Gifu, Japan; Faculty of Engineering, Gifu University, Gifu, Japan; Sumitomo Heavy Industries, Ltd., Tokyo, Japan; Faculty of Engineering, Gifu University, Gifu, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811689/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7970991012028802772&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Gifu University;Sumitomo Heavy Industries, Ltd.",
        "aff_unique_dep": "Faculty of Engineering;",
        "aff_unique_url": "https://www.gifu-u.ac.jp;https://www.shi.co.jp",
        "aff_unique_abbr": ";SHI",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Gifu;Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811749",
        "title": "Depth Estimation Matters Most: Improving Per-Object Depth Estimation for Monocular 3D Detection and Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular image-based 3D perception has become an active research area in recent years owing to its applications in autonomous driving. Approaches to monocular 3D perception including detection and tracking, however, often yield inferior performance when compared to LiDAR-based techniques. Through systematic analysis, we identified that per-object depth estimation accuracy is a major factor bounding the performance. Motivated by this observation, we propose a multi-level fusion method that combines different representations (RGB and pseudo-LiDAR) and temporal information across multiple frames for objects (tracklets) to enhance per-object depth estimation. Our proposed fusion method achieves the state-of-the-art performance of per-object depth estimation on the Waymo Open Dataset, the KITTI detection dataset, and the KITTI MOT dataset. We further demonstrate that by simply replacing estimated depth with fusion-enhanced depth, we can achieve significant improvements in monocular 3D perception tasks, including detection and tracking.",
        "primary_area": "",
        "author": "Longlong Jing;Ruichi Yu;Henrik Kretzschmar;Kang Li;Charles R. Qi;Hang Zhao;Alper Ayvaci;Xu Chen;Dillon Cower;Yingwei Li;Yurong You;Han Deng;Congcong Li;Dragomir Anguelov;Longlong Jing;Ruichi Yu;Henrik Kretzschmar;Kang Li;Charles R. Qi;Hang Zhao;Alper Ayvaci;Xu Chen;Dillon Cower;Yingwei Li;Yurong You;Han Deng;Congcong Li;Dragomir Anguelov",
        "authorids": "/37086340509;/37086250792;/37868427900;/37089448705;/37085643547;/37090018633;/37392227900;/37089248412;/37089448158;/37088459268;/37086571297;/37089450477;/37088454829;/37278026400;/37086340509;/37086250792;/37868427900;/37089448705;/37085643547;/37090018633;/37392227900;/37089248412;/37089448158;/37088459268;/37086571297;/37089450477;/37088454829;/37278026400",
        "aff": "Waymo LLC; Waymo LLC; Waymo LLC; Waymo LLC; Waymo LLC; Waymo LLC; Waymo LLC; Waymo LLC; Waymo LLC; Johns Hopkins University; Cornell University; Waymo LLC; Waymo LLC; Waymo LLC",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811749/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12914270605380583070&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 28,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;1;2;0;0;0",
        "aff_unique_norm": "Waymo;Johns Hopkins University;Cornell University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.waymo.com;https://www.jhu.edu;https://www.cornell.edu",
        "aff_unique_abbr": "Waymo;JHU;Cornell",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811921",
        "title": "Depth-Aware Vision-and-Language Navigation using Scene Query Attention Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-and-language navigation (VLN) has been an important task in the field of Robotics and Computer Vision. However, most existing vision-and-language navigation models only use features extracted from RGB observation as input, while robots can utilize depth sensors in the real world. Existing research has also shown that simply adding a depth stream to neural models could only provide a marginal improvement to the performance of the VLN task. Therefore, in our work, we develop a novel method for the VLN task using semantic map observations built from RGB-D input. We use vision-pretraining to efficiently encode the semantic map with CNN and scene query attention network by answering queries about semantic information of specific regions of a scene. The proposed method could be used with a simple model and does not require large-scale vision-language transformer pretraining, bringing a more than 10% increase in the success rate compared with a baseline model. When used together with the Speaker-Follower training technique, it achieves a success rate of 58 % on the test set for the R2R dataset in single-run setting, outperforming the previous RGB-D method and most existing RGB-only models that do not use large-scale vision-language transformers pretraining.",
        "primary_area": "",
        "author": "Sinan Tan;Mengmeng Ge;Di Guo;Huaping Liu;Fuchun Sun;Sinan Tan;Mengmeng Ge;Di Guo;Huaping Liu;Fuchun Sun",
        "authorids": "/37089447513;/37089449900;/37085360957;/37310126400;/37279269000;/37089447513;/37089449900;/37085360957;/37310126400;/37279269000",
        "aff": "Department of Computer Science and Technology, Tsinghua University, the National Research Center for Information Science and Technology, Beijing, China; Department of Computer Science and Technology, Tsinghua University, the National Research Center for Information Science and Technology, Beijing, China; Department of Computer Science and Technology, Tsinghua University, the National Research Center for Information Science and Technology, Beijing, China; Department of Computer Science and Technology, Tsinghua University, the National Research Center for Information Science and Technology, Beijing, China; Department of Computer Science and Technology, Tsinghua University, the National Research Center for Information Science and Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811921/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7142725575988990330&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811569",
        "title": "Depth-SIMS: Semi-Parametric Image and Depth Synthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a compositing image synthesis method that generates RGB canvases with well aligned segmentation maps and sparse depth maps, coupled with an in-painting network that transforms the RGB canvases into high quality RGB images and the sparse depth maps into pixel-wise dense depth maps. We benchmark our method in terms of structural alignment and image quality, showing an increase in mIoU over SOTA by 3.7 percentage points and a highly competitive FID. Furthermore, we analyse the quality of the generated data as training data for semantic segmentation and depth completion, and show that our approach is more suited for this purpose than other methods.",
        "primary_area": "",
        "author": "Valentina Musat;Daniele De Martini;Matthew Gadd;Paul Newman;Valentina Musat;Daniele De Martini;Matthew Gadd;Paul Newman",
        "authorids": "/37089159752;/37086404606;/37085439081;/37335903100;/37089159752;/37086404606;/37085439081;/37335903100",
        "aff": "Mobile Robotics Group (MRG), University of Oxford; Mobile Robotics Group (MRG), University of Oxford; Mobile Robotics Group (MRG), University of Oxford; Mobile Robotics Group (MRG), University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811569/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9128828295139528734&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Mobile Robotics Group",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812275",
        "title": "Design Exploration and Experimental Characterization of a 6 Degrees-of-Freedom Robotic Manipulator Powered by Cable-Driven Semi-Delocalized Magnetorheological Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robots need to work closely and safely with users while being fast and strong. Fulfilling both these needs simultaneously presents a significant challenge, if not a roadblock, for conventional geared motor technology. Magnetorheological (MR) actuation is an alternative technology that has the potential to exhibit both safety and speed at the same time in a compact and cost-effective envelope. MR actuation has demonstrated great potential for low-DOF mechatronic devices in close collaboration with humans such as exoskeletons and flight control systems but its potential for high-DOF collaborative robots remains widely unexplored. This paper presents the design and experimental validation of a 6 DOF manipulator prototype actuated by semi-delocalized MR clutches. The manipulator is designed with the objective of matching or exceeding the performance requirements of today's cobots in order to verify the potential of MR actuation for such applications. Experimental results show that the prototype has a mass in motion of 5.3 kg and can move a 4.5 kg payload at 1 m/s in a range of 0.885 m. Force bandwidth is above 50 Hz and backdriving forces less than 10% of the joints maximum torque, assuring excellent dynamic performance. Furthermore, the manipulator prototype is shown to be inherently safe and impact-tolerant. In all, results suggest that semi-delocalized MR actuation is a promising solution for high performance cobots although future work is needed for the MR technology to reach full-maturity in robotics.",
        "primary_area": "",
        "author": "Mathieu Gervais;Louis-Philippe Lebel;Jean-S\u00e9bastien Plante;Mathieu Gervais;Louis-Philippe Lebel;Jean-S\u00e9bastien Plante",
        "authorids": "/37089450850;/37086423021;/37282435300;/37089450850;/37086423021;/37282435300",
        "aff": "Facult\u00e9 de g\u00e9nie, Universit\u00e9 de Sherbrooke, Sherbrooke, Qc, Canada; Facult\u00e9 de g\u00e9nie, Universit\u00e9 de Sherbrooke, Sherbrooke, Qc, Canada; Exonetik Inc., Sherbrooke, Qc, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812275/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3671425633648792124&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Universit\u00e9 de Sherbrooke;Exonetik Inc.",
        "aff_unique_dep": "Facult\u00e9 de g\u00e9nie;",
        "aff_unique_url": "https://www.usherbrooke.ca;",
        "aff_unique_abbr": "UdeS;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sherbrooke",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9811731",
        "title": "Design and Analysis of a Long-range Magnetic Actuated and Guided Endoscope for Uniport VATS",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a long-range magnetic actuated and guided endoscope for uniport video-assisted thoracic surgery (VATS). In VATS, the incision is quite narrow and part of the chest wall may be very thick. So, the magnetic endoscope system is required to produce sufficient attractive force at a considerable distance with a compact dimension. In this paper, a magnetic endoscope system is developed to meet the aforementioned clinical demands. In the system, both the internal and external units consist of two cylindrical magnets at both ends and a semi-cylindrical magnet in the middle. Coupled with the magnetic field from the external unit, the internal endoscope can achieve anchoring, tilting, panning, and translating to provide the desired view for the surgeon. The rotation of the endoscope is dynamically modeled by combining magnetic theory and coordinate transformation. The prototype is made with a boundary box of 10\u00d714\u00d756 mm, which can be inserted through the narrow incision in VATS. In the experiment, the developed models of anchoring, tilting, and panning were verified. The magnet configuration in the system can achieve a static anchoring distance of 95 mm and exhibits enhancement in attractive force compared with other designs.",
        "primary_area": "",
        "author": "Jixiu Li;Tao Zhang;Truman Cheng;Yehui Li;Heng Zhang;Yisen Huang;Calvin Sze Hang Ng;Philip Wai Yan Chiu;Zheng Li;Jixiu Li;Tao Zhang;Truman Cheng;Yehui Li;Heng Zhang;Yisen Huang;Calvin Sze Hang Ng;Philip Wai Yan Chiu;Zheng Li",
        "authorids": "/37088834308;/37089447150;/37086268080;/37088535100;/37086798405;/37088832156;/37086264227;/37085379340;/38469473900;/37088834308;/37089447150;/37086268080;/37088535100;/37086798405;/37088832156;/37086264227;/37085379340;/38469473900",
        "aff": "Department of Surgery, The Chinese University of Hong Kong, Hong Kong; Multiscale Medical Robotics Center Ltd., The Chinese University of Hong Kong, Hong Kong; Department of Surgery, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, The Chinese University of Hong Kong, Hong Kong; Department of Surgery and the Chow Yuk Ho Technology Centre for Innovative Medicine, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, Chow Yuk Ho Technology Centre of Innovative Medicine, Li Ka Shing Institute of Health Science, and Multi-scale Medical Robotics Center Ltd., The Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811731/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5126603841418653109&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Surgery",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811790",
        "title": "Design and Control of a Miniature Bipedal Robot with Proprioceptive Actuation for Dynamic Behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "As the study of humanoid robots becomes a world-wide interdisciplinary research field, the demand for a cost-effective bipedal robot system capable of dynamic behaviors is growing exponentially. This paper presents a miniature bipedal robot named Bipedal Robot Unit with Compliance Enhanced (BRUCE). Each leg of BRUCE has five degrees of freedom (DoFs), which includes a spherical hip joint, a knee joint, and an ankle joint. To lower the leg inertia, a cable-driven differential pulley system and a linkage mechanism are applied to the hip and ankle joints, respectively. With the proposed design, BRUCE is able to achieve a similar range of motion to a human's lower body. The proprioceptive actuation and contact sensing further prepare BRUCE for interactions with unstructured environments. For real-time control of dynamic motions, a convex formulation for model hierarchy predictive control (MHPC) is introduced. MHPC plans with whole-body dynamics in the near horizon and simplified dynamics in the long horizon to benefit from both model accuracy and computational efficiency. A series of experiments were conducted to evaluate the overall system performance including hip joint analysis, walking, push recovery, and vertical jumping.",
        "primary_area": "",
        "author": "Yeting Liu;Junjie Shen;Jingwen Zhang;Xiaoguang Zhang;Taoyuanmin Zhu;Dennis Hong;Yeting Liu;Junjie Shen;Jingwen Zhang;Xiaoguang Zhang;Taoyuanmin Zhu;Dennis Hong",
        "authorids": "/37088446251;/37087324771;/37087323024;/37086605911;/37086599307;/37575333900;/37088446251;/37087324771;/37087323024;/37086605911;/37086599307;/37575333900",
        "aff": "the Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; the Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; the Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; the Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; the Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; the Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811790/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14749206453915635101&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811683",
        "title": "Design and Development for Humanoid-Vehicle Transformer Platform with Plastic Resin Structure and Distributed Redundant Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "The humanoid robot that can transform itself into a form according to its purpose requires whole-body motions with complex contact state transitions such as recovery from a fall and transition to the target form. To make the robot behavior in simulations closer to that in the real world for planning complex target trajectories, we need a platform that can measure the body stiffness during the motion and verify its application without being damaged by repeated motions that are prone to tipping over. In this study, we propose a small, inexpensive, and robust humanoid-vehicle transformer platform with redundant sensors and a low rigidity multi degree-of-freedom body and observe the effects of body deflection and internal forces during whole-body posture transition. By comparing the results obtained from experiments in several environments with different friction and from the simulator using a rigid body model, we were able to verify the influence of body flexibility on whole-body motion and the relationship between deflection and wrench observed by redundant sensors and movement failure.",
        "primary_area": "",
        "author": "Tasuku Makabe;Naoki Hiraoka;Shintaro Noda;Tomoki Anzai;Kohei Kimura;Mirai Hattori;Hiroya Sato;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Tasuku Makabe;Naoki Hiraoka;Shintaro Noda;Tomoki Anzai;Kohei Kimura;Mirai Hattori;Hiroya Sato;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37086579382;/37087325306;/37085354213;/37086287194;/37085737047;/37088688261;/37089448273;/37085651948;/38242437800;/37280639000;/37286658200;/37086579382;/37087325306;/37085354213;/37086287194;/37085737047;/37088688261;/37089448273;/37085651948;/38242437800;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811683/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9193592142849741341&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812171",
        "title": "Design and Evaluation of Object Classifiers for Probabilistic Decision-Making in Autonomous Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Object classification is a key element that enables effective decision-making in many autonomous systems. A more sophisticated system may also utilize the probability distribution over the classes instead of basing its decision only on the most likely class. This paper introduces new performance metrics: the absolute class error (ACE), expectation of absolute class error (EACE) and variance of absolute class error (VACE) for evaluating the accuracy of such probabilities. We test this metric using different neural network architectures and datasets. Furthermore, we present a new task-based neural network for object classification and compare its performance with a typical probabilistic classification model to show the improvement with threshold-based probabilistic decision-making.",
        "primary_area": "",
        "author": "Hamad Ullah;Weisi Fan;Tichakorn Wongpiromsarn;Hamad Ullah;Weisi Fan;Tichakorn Wongpiromsarn",
        "authorids": "/37089449897;/37089448117;/37547924000;/37089449897;/37089448117;/37547924000",
        "aff": "Department of Computer Science, Iowa State University; Department of Computer Science, Iowa State University; Department of Computer Science, Iowa State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812171/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3584984543417062640&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811907",
        "title": "Design and Modeling of a Compact Advancement Mechanism for a Modified COAST Guidewire Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Peripheral vascular intervention remains a challenging procedure mainly due to the tortuosity of the vessels needing to be traversed by guidewires and catheters. In addition, handling long guidewires while navigating tortuous vasculature requires extensive time and skill from the surgeon. In this work, a compact guidewire advancement mechanism is proposed that is able to dispense guidewires up to 150 cm in length. The mechanism is adapted to actuate a prototype of the modified COaxially Aligned STeerable (COAST) guidewire robot to perform follow-the-leader (FTL) motion. The design of this mechanism consists of a spool, with actuation components nested inside to vary the bending length, actuate the tendon, and deflect the tip of the guidewire. The spool is mounted onto a lead screw that dispenses the guidewire with a tolerance of \u00b12mm. A modified bending joint kinematics and statics model is developed to characterize and validate the relationship between the tendon stroke and the desired curvature. The model is further used in a control system to navigate the distal tip through an ex vivo porcine aorta.",
        "primary_area": "",
        "author": "Patrick Lis;Achraj Sarma;Grace Trimpe;Timothy A. Brumfiel;Ronghuai Qi;Jaydev P. Desai;Patrick Lis;Achraj Sarma;Grace Trimpe;Timothy A. Brumfiel;Ronghuai Qi;Jaydev P. Desai",
        "authorids": "/37088935686;/37088588173;/37089447314;/37089028721;/37089449698;/37282117700;/37088935686;/37088588173;/37089447314;/37089028721;/37089449698;/37282117700",
        "aff": "Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811907/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16660092629324430809&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Wallace H. Coulter Department of Biomedical Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812148",
        "title": "Design and Modeling of a Spherical Robot Actuated by a Cylindrical Drive",
        "track": "main",
        "status": "Poster",
        "abstract": "Rolling spherical robots have been studied in the past few years as an alternative to legged and wheeled robots in unstructured environments. These systems are of uttermost interest for space exploration: fast, robust to collision and able to handle various terrain topologies. This paper introduces a novel barycentric spherical robot, dubbed the Autonomous Robotic Intelligent Explorer Sphere (ARIES). Equipped with an actuated cylindrical joint acting as a pendulum with two degrees-of-freedom (DoF), the ARIES has a continuous differential transmission to allow simultaneous rolling and steering. This mechanism allows an unprecedented mass allocation optimization, notably to provide a low center of mass. Kinematics and dynamics of this novel system are detailed. An analysis of the steering mechanism proves that it is more efficient than a more conventional 2-DoF tilting mechanism, while also retaining more space for a payload, for instance to host sensors for simultaneous localization and mapping, in the upper part of the sphere. Moreover, the kinematic input/output equations obtained significantly simplify the device's control. Finally, we present a first complete prototype with preliminary experimental tests.",
        "primary_area": "",
        "author": "Bruno Belzile;David St-Onge;Bruno Belzile;David St-Onge",
        "authorids": "/37085446321;/38295079700;/37085446321;/38295079700",
        "aff": "Department of Mechanical Engineering, \u00c9cole de technologie sup\u00e9rieure, Montr\u00e9al; Department of Mechanical Engineering, \u00c9cole de technologie sup\u00e9rieure, Montr\u00e9al",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812148/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15512976679917495769&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "\u00c9cole de technologie sup\u00e9rieure",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.etsmtl.ca",
        "aff_unique_abbr": "ETS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Montr\u00e9al",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812270",
        "title": "Design and Optimization of a Magnetic Catcher for UAV Landing on Disturbed Aquatic Surface Platforms",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a new capture system for UAV precision landing in a disturbed environment is proposed. Compared with the traditional visual guided landing methods, perching mechanism based methods, and tethered landing methods, the proposed system takes into account the stability during landing process and retains the high accessibility of the UAV. The proposed system consists of a winch subsystem and a magnetic catcher device. They establish an automatic tethered-UAV system for landing before the UAV touchdown. We analyzed the design principle as well as the feasibility of the magnetic catcher. An optimization problem is formulated to obtain a better layout of magnets on the catcher. The problem is relaxed based on interpolation simulation of attraction force. Experiments are conducted both in indoor and outdoor environments based on different UAV platforms respectively. The results validate that the catcher design and the capture system can achieve a successful landing in both cases.",
        "primary_area": "",
        "author": "Chongfeng Liu;Zixing Jiang;Ruoyu Xu;Xiaoqiang Ji;Lianxin Zhang;Huihuan Qian;Chongfeng Liu;Zixing Jiang;Ruoyu Xu;Xiaoqiang Ji;Lianxin Zhang;Huihuan Qian",
        "authorids": "/37087049736;/37089448245;/37087047735;/37088954362;/37086801017;/37549401900;/37087049736;/37089448245;/37087047735;/37088954362;/37086801017;/37549401900",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812270/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9235169634469852056&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_url": "https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811897",
        "title": "Design and Quasistatic Modelling of Hybrid Continuum Multi-Arm Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Continuum surgical robots can navigate anatomical pathways to reach pathological locations deep inside the human body. Their flexibility, however, generally comes with reduced dexterity at their tip and limited workspace. Building on recent work on eccentric tube robots, this paper proposes a new continuum robot architecture and theoretical framework that combines the flexibility of push/pull actuated snake robots and the dexterity offered by concentric tube robotic end-effectors. We designed and present a prototype system as a proof-of-concept, and developed a tailored quasistatic mechanics-based model that describes the shape and end-effector's pose for this new type robotic architecture. The model can accommodate an arbitrary number of arms placed eccentrically with respect to the backbone's neutral axis. Our experiments show that the error between model and experiment is on average 3.56% of the manipulator's overall length. This is in agreement with state of the art models of single type continuum architecture.",
        "primary_area": "",
        "author": "Zisos Mitros;S.M.Hadi Sadati;Sotirios Nousias;Lyndon Da Cruz;Christos Bergeles;Zisos Mitros;S.M.Hadi Sadati;Sotirios Nousias;Lyndon Da Cruz;Christos Bergeles",
        "authorids": "/37085871075;/37085509620;/37086327755;/37086454723;/37399073100;/37085871075;/37085509620;/37086327755;/37086454723;/37399073100",
        "aff": "Department of Medical Physics and Biomedical Engineering, University College London, London, UK; Department of Medical Physics and Biomedical Engineering, University College London, London, UK; Department of Medical Physics and Biomedical Engineering, University College London, London, UK; Moorfields Eye Hospital, London, UK; Department of Medical Physics and Biomedical Engineering, University College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811897/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9661369716048655224&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University College London;Moorfields Eye Hospital",
        "aff_unique_dep": "Department of Medical Physics and Biomedical Engineering;",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.moorfields.nhs.uk",
        "aff_unique_abbr": "UCL;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811826",
        "title": "Design and Tests of a Novel Adjustable-stiffness Force Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a novel adjustable-stiffness force sensor is developed for multitask measurements requiring different force resolutions and ranges. The applied force of the force sensor is indirectly measured through the linear deformation instead of the structure strain through an optical linear encoder. The main structure of the force sensor is actually a linear variable stiffness mechanism with a compact size and a large stiffness change. Its stiffness can be continuously adjusted by changing the effective second moment of area of the structure. Thus, the force sensor has an adjustable range and resolution since the displacement resolution of the optical linear encoder is constant. The stiffness modeling of the sensor is performed based on the matrix method, which is then evaluated by the finite element analysis. A principle prototype is finally fabricated for the adjustable-stiffness test and a concrete application example. The testing results show that the stiffness and resolution of the force sensor can be changed by the proposed stiffness adjustment. Moreover, it is effective to measure different-resolution forces. This adjustable-stiffness approach can be also extended to the design of a torque sensor or a force/torque sensor.",
        "primary_area": "",
        "author": "Xiantao Sun;Xiaoyu Xiong;Wenjie Chen;Yali Zhi;Weihai Chen;Yan Jin;Xiantao Sun;Xiaoyu Xiong;Wenjie Chen;Yali Zhi;Weihai Chen;Yan Jin",
        "authorids": "/37959843100;/37089449752;/37421822700;/37088507546;/37279188000;/37895977500;/37959843100;/37089449752;/37421822700;/37088507546;/37279188000;/37895977500",
        "aff": "School of Electrical Engineering and Automation, Anhui University, Hefei, China; School of Electrical Engineering and Automation, Anhui University, Hefei, China; School of Electrical Engineering and Automation, Anhui University, Hefei, China; School of Electrical Engineering and Automation, Anhui University, Hefei, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Mechanical and Aerospace Engineering, Queen's University, Belfast, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811826/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:mvP7EwYOr1oJ:scholar.google.com/&scioq=Design+and+Tests+of+a+Novel+Adjustable-stiffness+Force+Sensor&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "Anhui University;Beihang University;Queen's University Belfast",
        "aff_unique_dep": "School of Electrical Engineering and Automation;School of Automation Science and Electrical Engineering;School of Mechanical and Aerospace Engineering",
        "aff_unique_url": "http://www.ahu.edu.cn;http://www.buaa.edu.cn;https://www.qub.ac.uk",
        "aff_unique_abbr": "AHU;BUAA;QUB",
        "aff_campus_unique_index": "0;0;0;0;1;2",
        "aff_campus_unique": "Hefei;Beijing;Belfast",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9812117",
        "title": "Design and experimental investigation of a vibro-impact self-propelled capsule robot with orientation control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel design and experimental investigation for a self-propelled capsule robot that can be used for painless colonoscopy during a retrograde progression from the patient's rectum. The steerable robot is driven forward and backward via its internal vibration and impact with orientation control by using an electromagnetic actuator. The actuator contains four sets of coils and a shaft made by permanent magnet. The shaft can be excited linearly in a controllable and tilted angle, so guide the progression orientation of the robot. Two control strategies are studied in this work and compared via simulation and experiment. Extensive results are presented to demonstrate the progression efficiency of the robot and its potential for robotic colonoscopy.",
        "primary_area": "",
        "author": "Jiajia Zhang;Jiyuan Tian;Dibin Zhu;Yang Liu;Shyam Prasad;Jiajia Zhang;Jiyuan Tian;Dibin Zhu;Yang Liu;Shyam Prasad",
        "authorids": "/37089449691;/37089448569;/37929606500;/37089449709;/37089449433;/37089449691;/37089448569;/37929606500;/37089449709;/37089449433",
        "aff": "College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, UK; College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, UK; College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, UK; College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, UK; Royal Devon and Exeter NHS Foundation Trust, Exeter, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812117/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7321084301430656789&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Exeter;Royal Devon and Exeter NHS Foundation Trust",
        "aff_unique_dep": "College of Engineering, Mathematics and Physical Sciences;",
        "aff_unique_url": "https://www.exeter.ac.uk;https://www.royaldevonandexeter.nhs.uk",
        "aff_unique_abbr": "Exeter;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Exeter",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812314",
        "title": "Design by Robot: A Human-Robot Collaborative Framework for Improving Productivity of a Floor Cleaning Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, a rising trend of floor cleaning robots could be observed in the consumer electronic market. Area coverage performance is a crucial factor that determines the overall productivity of a floor cleaning robot. Nevertheless, the area coverage performance of commercially available floor cleaning robots is limited due to narrow spaces resulting from complex furniture arrangements. Traditionally, new robot designs (both hardware and algorithmic) are explored to over-come the coverage limitations. Developments of reconfiguration mechanisms and path planning algorithms for floor cleaning robots could be considered as examples. This paper proposes a novel concept called \u201cdesign by robot,\u201d enabling a floor cleaning robot to make suggestions on workspace modifications to maximize its area coverage performance in a given workspace. In this regard, the robot analyzes a workspace to be cleaned through internal simulations based on the metric map of the workspace. A metaheuristic optimization technique determines the optimum placings of objects. Particle Swarm Optimization (PSO), Surrogate Optimization (SO), and Generalized Pattern Search (GPS) are individually used in this regard. Experiments, including scenarios of robot deployments, have been considered for validation. The statistical outcomes of the experimental results validate that the area coverage performance of a floor cleaning robot could be significantly improved by considering the workspace modifications suggested by the robot. Moreover, the proposed concept \u201cdesign by robot\u201d enables users to gain significantly improved performance from floor cleaning robots through collaboration.",
        "primary_area": "",
        "author": "M. A. Viraj J. Muthugala;S. M. Bhagya P. Samarakoon;Mohan Rajesh Elara;M. A. Viraj J. Muthugala;S. M. Bhagya P. Samarakoon;Mohan Rajesh Elara",
        "authorids": "/37085785341;/37086182161;/37546093700;/37085785341;/37086182161;/37546093700",
        "aff": "Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore; Engineering Product Development Pillar, Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812314/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3730296866536166201&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Engineering Product Development Pillar",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9811755",
        "title": "Design of KAIST HOUND, a Quadruped Robot Platform for Fast and Efficient Locomotion with Mixed-Integer Nonlinear Optimization of a Gear Train",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a design method for an efficient and agile quadruped robot. A mixed-integer optimization formulation including the number of gear teeth is derived to obtain the optimal gear ratio that minimizes cost for a running-trot with the target speed of 3 m/s. With the inclusion of integer constraints related to the number of gear teeth, detailed design considerations of gear trains can be included in the optimization process. Thermal dissipation of the motor controller is also taken into account in the optimization to consider heat generation during high-speed running. KAIST Hound, a 45 kg robot, designed with the obtained design parameters has successfully demonstrated a 3 m/s running-trot using a nonlinear model predictive controller (NMPC). Furthermore, the robot has proved its robustness by the demonstration of additional experiments such as 22\u00b0 slope climbing, 3.2 km walking, and traversing a 35 cm obstacle.",
        "primary_area": "",
        "author": "Young-Ha Shin;Seungwoo Hong;Sangyoung Woo;JongHun Choe;Harim Son;Gijeong Kim;Joon-Ha Kim;KangKyu Lee;Jemin Hwangbo;Hae-Won Park;Young-Ha Shin;Seungwoo Hong;Sangyoung Woo;JongHun Choe;Harim Son;Gijeong Kim;Joon-Ha Kim;KangKyu Lee;Jemin Hwangbo;Hae-Won Park",
        "authorids": "/37405271100;/37086581983;/37089449957;/37086085969;/37089448032;/37089446621;/37087322590;/37086014885;/37085428218;/37086265865;/37405271100;/37086581983;/37089449957;/37086085969;/37089448032;/37089446621;/37087322590;/37086014885;/37085428218;/37086265865",
        "aff": "Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Yuseong-gu, Daejeon, Republic of Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Yuseong-gu, Daejeon, Republic of Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Yuseong-gu, Daejeon, Republic of Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Yuseong-gu, Daejeon, Republic of Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Yuseong-gu, Daejeon, Republic of Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Yuseong-gu, Daejeon, Republic of Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Yuseong-gu, Daejeon, Republic of Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Yuseong-gu, Daejeon, Republic of Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Yuseong-gu, Daejeon, Republic of Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Yuseong-gu, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811755/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18405293652082452639&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Humanoid Robot Research Center",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811543",
        "title": "Design of a Biomimetic Tactile Sensor for Material Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensing typically involves active exploration of unknown surfaces and objects, making it especially effective at processing the characteristics of materials and textures. A key property extracted by human tactile perception in material classification is surface roughness, which relies on measuring vibratory signals using the multi-layered fingertip structure. Existing robotic systems lack tactile sensors that are able to provide high dynamic sensing ranges, perceive material properties, and maintain a low hardware cost. In this work, we introduce the reference design and fabrication procedure of a miniature and low-cost tactile sensor consisting of a biomimetic cutaneous structure, including the artificial fingerprint, dermis, epidermis, and an embedded magnet-sensor structure which serves as a mechanoreceptor for converting mechanical information to digital signals. The presented sensor is capable of detecting high-resolution magnetic field data through the Hall effect and creating high-dimensional time-frequency domain features for material texture classification. Additionally, we investigate the effects of different superficial sensor fingerprint patterns for classifying materials through both simulation and physical experimentation. After extracting time series and frequency domain features, we assess a k-nearest neighbors classifier for distinguishing between different materials. The results from our experiments show that our biomimetic tactile sensors with fingerprint ridges can classify materials with more than 7.7% higher accuracy and lower variability than ridge-less sensors. These results, along with the low cost and customizability of our sensor, demonstrate high potential for lowering the barrier to entry for a wide array of robotic applications, including modelless tactile sensing for texture classification, material inspection, and object recognition.",
        "primary_area": "",
        "author": "Kevin Dai;Xinyu Wang;Allison M. Rojas;Evan Harber;Yu Tian;Nicholas Paiva;Joseph Gnehm;Evan Schindewolf;Howie Choset;Victoria A. Webster-Wood;Lu Li;Kevin Dai;Xinyu Wang;Allison M. Rojas;Evan Harber;Yu Tian;Nicholas Paiva;Joseph Gnehm;Evan Schindewolf;Howie Choset;Victoria A. Webster-Wood;Lu Li",
        "authorids": "/37089447235;/37089451012;/37089446856;/37088575556;/37089448113;/37085479986;/37089448452;/37088574262;/37281322200;/37088689130;/37086315375;/37089447235;/37089451012;/37089446856;/37088575556;/37089448113;/37085479986;/37089448452;/37088574262;/37281322200;/37088689130;/37086315375",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, PA, United States; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States; Department of Mechanical Engineering, Carnegie Mellon University, PA, United States; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States; Department of Mechanical Engineering, Carnegie Mellon University, PA, United States; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811543/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13083722283021101622&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811754",
        "title": "Design of an Autonomous Latching System for Surface Vessels",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous latching is essential for autonomous surface vessels (ASV) to reach full independence from human intervention. As part of the ASV Roboat project, a new solution for self-latching maneuvers has been developed and is presented here. We propose a system that has the key requirements of full integration with the navigation control system and zero-gap connection with the dock, the latter being essential for wireless charging of the ASV. Dedicated markers are used to identify docking targets, relying on computer vision algorithms to determine distance and bearing to the target. In its idle state, the locking solution uses mechanical power-off brakes, minimizing energy consumption while ensuring the boat stays in position indefinitely once docked. A prototype of the proposed mechanism has been built and installed in Roboat. Experimental tests showing the mechanism performance and capability to autonomously approach the docking station are discussed in this work.",
        "primary_area": "",
        "author": "David Fern\u00e1ndez-Guti\u00e9rrez;Niklas Hagemann;Wei Wang;Rens Doornbusch;Joshua Jordan;Jonathan Schiphorst;Pietro Leoni;Fabio Duarte;Carlo Ratti;Daniela Rus;David Fern\u00e1ndez-Guti\u00e9rrez;Niklas Hagemann;Wei Wang;Rens Doornbusch;Joshua Jordan;Jonathan Schiphorst;Pietro Leoni;Fabio Duarte;Carlo Ratti;Daniela Rus",
        "authorids": "/37088686421;/37089000190;/37073346500;/37086454509;/37089448069;/37089450631;/37086455112;/37086125892;/37590016800;/37279652300;/37088686421;/37089000190;/37073346500;/37086454509;/37089448069;/37089450631;/37086455112;/37086125892;/37590016800;/37279652300",
        "aff": "SENSEable City Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial In-telligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; Amsterdam Institute for Advanced Metropolitan Solutions (AMS), Amsterdam, JA, The Netherlands; Amsterdam Institute for Advanced Metropolitan Solutions (AMS), Amsterdam, JA, The Netherlands; Amsterdam Institute for Advanced Metropolitan Solutions (AMS), Amsterdam, JA, The Netherlands; SENSEable City Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial In-telligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811754/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13026211374333005380&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;1;1;1;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Amsterdam Institute for Advanced Metropolitan Solutions",
        "aff_unique_dep": "SENSEable City Lab;",
        "aff_unique_url": "https://web.mit.edu;",
        "aff_unique_abbr": "MIT;AMS",
        "aff_campus_unique_index": "0;0;0;1;1;1;0;0;0;0",
        "aff_campus_unique": "Cambridge;Amsterdam",
        "aff_country_unique_index": "0;0;0;1;1;1;0;0;0;0",
        "aff_country_unique": "United States;Netherlands"
    },
    {
        "id": "9812308",
        "title": "Designing a Highly Backdrivable and Kinematic Compatible Magneto-Rheological Knee Exoskeleton",
        "track": "main",
        "status": "Poster",
        "abstract": "Lower limb exoskeletons have been successfully used in robotic-assisted rehabilitation. However, the design limitations of exoskeletons mechanics, such as weight and the lack of kinematic compatibility relative to the user's joints, limit the outcomes of treatment. To address these shortcomings, this work presents the design of a magneto-rheological fluid-based actuator for a knee exoskeleton, namely MRKE. The system was designed to ensure better mobility of the user, presenting high backdrivability and kinematic compatibility with the knee joint. The power train of system is a BLDC 70 W motor integrated to a harmonic drive gearbox. To improve kinematic compatibility relative to the user's knee, a four-bar crossed linkage mechanism (FBLM) was designed to follow the trajectory of the knee center of motion. A customized MR clutch was projected to decouple the motor-reducer from the FBLM, thus enabling high backdrivability. Preliminary results showed a small error (< 3 mm) between the FBLM and the knee center of rotation. Moreover, the MR clutch allowed for low backdrive torque (1.0 N.m) compared to the torque to backdrive the motor-reducer (16.6 N.m).",
        "primary_area": "",
        "author": "Rafhael M. Andrade;Pedro H. F. Ulhoa;Claysson B. S. Vimieiro;Rafhael M. Andrade;Pedro H. F. Ulhoa;Claysson B. S. Vimieiro",
        "authorids": "/37086919620;/37089211670;/37087469830;/37086919620;/37089211670;/37087469830",
        "aff": "Department of Mechanical Engineering and the Graduate Program in Mechanical Engineering, Universidade Federal do Espirito Santo, ES, Brazil; Department of Mechanical Engineering and the Graduate Program in Mechanical Engineering, Universidade Federal do Espirito Santo, ES, Brazil; Graduate Program in Mechanical Engineering, Pontifical Catholic University of Minas Gerais, Belo Horizonte, MG, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812308/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18014609142361951682&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Universidade Federal do Espirito Santo;Pontifical Catholic University of Minas Gerais",
        "aff_unique_dep": "Department of Mechanical Engineering;Graduate Program in Mechanical Engineering",
        "aff_unique_url": "http://www.ufes.br/;https://www.pucminas.edu.br",
        "aff_unique_abbr": "UFES;PUC Minas",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Belo Horizonte",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "id": "9811589",
        "title": "Detection of Slip from Vision and Touch",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting the onset/ongoing of slip, i.e. if a grasped object is slipping or will slip from the gripper while being lifted, is crucial. Conventionally, it is regarded as a tactile sensing related problem. However, recently multi-modal robotic learning has become popular and is expected to boost the performance. In this paper we propose a novel CNN-TCN model to fuse tactile and visual information for detecting the onset/ongoing of slip. In our experiments, two uSkin tactile sensors and one Realsense435i camera are used. Data is collected by randomly grasping and lifting 35 daily objects 1050 times in total. Furthermore, we compare our CNN-TCN model with the widely used CNN-LSTM model. As a result, our proposed model achieves a 88.75% detection accuracy and outperforms the CNN-LSTM model combined with different pretrained vision networks.",
        "primary_area": "",
        "author": "Gang Yan;Alexander Schmitz;Tito Pradhono Tomo;Sophon Somlor;Satoshi Funabashi;Shigeki Sugano;Gang Yan;Alexander Schmitz;Tito Pradhono Tomo;Sophon Somlor;Satoshi Funabashi;Shigeki Sugano",
        "authorids": "/37086935752;/37587110100;/37085618711;/37085510233;/37085727304;/37274050800;/37086935752;/37587110100;/37085618711;/37085510233;/37085727304;/37274050800",
        "aff": "Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811589/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13668119343599804519&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Dept. of Modern Mechanical Engineering",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811759",
        "title": "Developing The Bottom-up Attentional System of A Social Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes the development of a 3- stage signalling framework to trigger a social robot's bottom- up reactive behavior inspired by a biological model. In the first stage, low-level firing of stimuli due to external sources is constructed through perception grounding. This is followed by a saliency classifier which fires-up high level salient signals that require attention and are used to trigger the robot's reactive behavior. The whole framework evolves primarily on the knowledge ontology that defines the characteristics of the social robot and the querying mechanism that correlates the perceived stimuli with the ontology to trigger the reactive behavior. We evaluated the performance of our system with timing metrics and we achieved good results for our application.",
        "primary_area": "",
        "author": "Randy Gomez;\u00c1lvaro P\u00e1ez;Yu Fang;Serge Thill;Luis Merino;Eric Nichols;Keisuke Nakamura;Heike Brock;Randy Gomez;\u00c1lvaro P\u00e1ez;Yu Fang;Serge Thill;Luis Merino;Eric Nichols;Keisuke Nakamura;Heike Brock",
        "authorids": "/37979526500;/37089447532;/37088945872;/37085473887;/37282385100;/324054555661300;/37534198900;/37086009097;/37979526500;/37089447532;/37088945872;/37085473887;/37282385100;/324054555661300;/37534198900;/37086009097",
        "aff": "Honda Research Institute Japan Co., Ltd.; Universidad Pablo de Olavide; Honda Research Institute Japan Co., Ltd.; Radboud University Ni- jmegen; Universidad Pablo de Olavide; Honda Research Institute Japan Co., Ltd.; Honda Research Institute Japan Co., Ltd.; Honda Research Institute Japan Co., Ltd.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811759/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17810758829170699866&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;2;1;0;0;0",
        "aff_unique_norm": "Honda Research Institute Japan Co., Ltd.;Universidad Pablo de Olavide;Radboud University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.honda-ri.jp/english/;https://www.upo.es;https://www.ru.nl/",
        "aff_unique_abbr": "HRI-JP;UPO;RU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Nijmegen",
        "aff_country_unique_index": "0;1;0;2;1;0;0;0",
        "aff_country_unique": "Japan;Spain;Netherlands"
    },
    {
        "id": "9811962",
        "title": "Development and Analysis of a Biped Robot with Prismatic Compliance",
        "track": "main",
        "status": "Poster",
        "abstract": "Previous studies suggest that bipedal robots that have prismatic compliance in the legs can achieve efficient walking. However, how this efficiency can be achieved still remains an open research problem. In this study, we developed a 2-degree-of-freedom planar bipedal robot comprising Neidhart springs and five-bar parallel mechanisms. The five-bar parallel mechanism allows the robot to achieve prismatic compliance. In addition, a lightweight torque limiter function is achieved by Neidhart springs with an original design. We implemented a simple controller and conducted walking experiments. Experimental results showed that the robot walked effectively using the regenerative energy stored in the prismatic springs.",
        "primary_area": "",
        "author": "Takumi Kamioka;Hirofumi Shin;Ryo Yamaguchi;Masaaki Muromachi;Takumi Kamioka;Hirofumi Shin;Ryo Yamaguchi;Masaaki Muromachi",
        "authorids": "/37085690761;/37088341243;/37088479709;/37086455229;/37085690761;/37088341243;/37088479709;/37086455229",
        "aff": "Honda R&D Co., Ltd., Saitama, Japan; Honda R&D Co., Ltd., Saitama, Japan; Honda R&D Co., Ltd., Saitama, Japan; Honda R&D Co., Ltd., Saitama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811962/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17242719039283874222&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Honda R&D Co., Ltd.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.honda.com",
        "aff_unique_abbr": "Honda R&D",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812307",
        "title": "Development and Evaluation of a Gait Assistance System Based on Haptic Cane and Active Knee Orthosis",
        "track": "main",
        "status": "Poster",
        "abstract": "Post-stroke gait rehabilitation is necessary to aid social re-integration. An active knee orthosis (AKO) can aid gait training through the provision of bodyweight support and assistive knee torque. However, its use may cause instability and it does not ensure improved gait symmetry and speed. Use of a speed regulation device such as a robotic cane in conjunction with and AKO may overcome these limitations. Therefore, to combine the beneficial effects of an AKO and speed regulation, we have devised a gait assistance system (GAS) that combines our developed AKO with our Haptic cane (HC) to provide combined knee assistance and speed regulation. The system can provide constant speed regulation and proprioceptive input to improve gait speed, symmetry and balance, while providing assistive torque to improve knee range of motion. The system is evaluated through tests with nine healthy subjects who wore ankle weights on one leg to simulate hemiparesis. The results show that for majority of the outcome measures (gait and balance parameters), use of the GAS and HC generated significantly better results than use of only the AKO. However, for nearly all the measures there were no significant differences between GAS and HC. Thus, the results indicate that the HC and GAS may be used according to patient's condition, where more severe patients who require assistive torque may use the GAS and less severe patients may use only the HC.",
        "primary_area": "",
        "author": "Hosu Lee;Amre Eizad;Junyeong Lee;Jungwon Yoon;Hosu Lee;Amre Eizad;Junyeong Lee;Jungwon Yoon",
        "authorids": "/37085713825;/37085663756;/37089213576;/38626177600;/37085713825;/37085663756;/37089213576;/38626177600",
        "aff": "School of Integrated Technology, Gwangju Institute of Science and Technology (GIST), Gwangju, Korea; School of Integrated Technology, Gwangju Institute of Science and Technology (GIST), Gwangju, Korea; School of Integrated Technology, Gwangju Institute of Science and Technology (GIST), Gwangju, Korea; School of Integrated Technology, Gwangju Institute of Science and Technology (GIST), Gwangju, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812307/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:euayU3epHIQJ:scholar.google.com/&scioq=Development+and+Evaluation+of+a+Gait+Assistance+System+Based+on+Haptic+Cane+and+Active+Knee+Orthosis&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Gwangju Institute of Science and Technology",
        "aff_unique_dep": "School of Integrated Technology",
        "aff_unique_url": "https://www.gist.ac.kr",
        "aff_unique_abbr": "GIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Gwangju",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812006",
        "title": "Development of a Collaborative Wheeled Mobile Robot: Design Considerations, Drive Unit Torque Control, and Preliminary Result",
        "track": "main",
        "status": "Poster",
        "abstract": "Nowadays, wheeled mobile robots constitute a considerable portion of robots in industrial applications. Generally, regardless of their purpose, these systems are not designed to physically interact with humans, other robots, or the environment. In this study, we present a novel safe autonomous mobile - SAM - robot, which is a torque-controlled compliant robot that is conceived for safe human-robot interaction. This work provides an overview of the development philosophy of the system, its mechanical and mechatronics structure along with control and navigation architecture. Preliminary results show the advantages of the proposed mobile robot while interacting with its surroundings. We believe that this study will bring the wheeled mobile robots one step closer to the proactive interaction with their environment and humans surrounding them.",
        "primary_area": "",
        "author": "Mehmet C. Yildirim;Mohamadreza Sabaghian;Thore Goll;Clemens K\u00f6ssler;Christoph J\u00e4hne;Abdalla Swikir;Andriy Sarabakha;Sami Haddadin;Mehmet C. Yildirim;Mohamadreza Sabaghian;Thore Goll;Clemens K\u00f6ssler;Christoph J\u00e4hne;Abdalla Swikir;Andriy Sarabakha;Sami Haddadin",
        "authorids": "/37085627474;/37088889287;/37086577926;/37089448932;/37086040696;/37085861833;/37085894614;/37542865300;/37085627474;/37088889287;/37086577926;/37089448932;/37086040696;/37085861833;/37085894614;/37542865300",
        "aff": "Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Munich, Germany; Franka Emika GmbH, Munich, Germany; Franka Emika GmbH, Munich, Germany; Franka Emika GmbH, Munich, Germany; Franka Emika GmbH, Munich, Germany; Department of Electrical and Electronic Engineering, Omar Al-Mukhtar University (OMU), AlBaida, Libya; School of Electrical and Electronic Engineering (EEE), Nanyang Technological University (NTU), Singapore; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812006/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16939723038126574569&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;1;2;3;0",
        "aff_unique_norm": "Technical University of Munich;Franka Emika GmbH;Omar Al-Mukhtar University;Nanyang Technological University",
        "aff_unique_dep": "Munich Institute of Robotics and Machine Intelligence;;Department of Electrical and Electronic Engineering;School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.tum.de;https://www.franka.de;;https://www.ntu.edu.sg",
        "aff_unique_abbr": "TUM;;OMU;NTU",
        "aff_campus_unique_index": "0;0;0;0;0;1;2;0",
        "aff_campus_unique": "Munich;AlBaida;Singapore",
        "aff_country_unique_index": "0;0;0;0;0;1;2;0",
        "aff_country_unique": "Germany;Libya;Singapore"
    },
    {
        "id": "9811804",
        "title": "Development of a Stereo-vision based High-throughput Robotic System for Mouse Tail Vein Injection",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a robotic device for mouse tail vein injection. We propose a mouse holding mechanism to realize vein injection without anesthetizing the mouse, which consists of a tourniquet, vacuum port, and adaptive tail-end fixture. The position of the target vein in 3D space is reconstructed from a high-resolution stereo vision. The vein is detected by a simple but robust vein line detector. Thanks to the proposed two-staged calibration process, the total time for the injection process is limited to 1.5 minutes, despite that the position of needle and tail vein varies for each trial. We performed an injection experiment targeting 40 mice and succeeded to inject saline to 37 of them, resulting 92.5% success ratio.",
        "primary_area": "",
        "author": "Tianyi Ko;Koichi Nishiwaki;Koji Terada;Yusuke Tanaka;Shun Mitsumata;Ryuichi Katagiri;Junko Taketo;Naoshi Horiba;Hideyoshi Igata;Kazue Mizuno;Tianyi Ko;Koichi Nishiwaki;Koji Terada;Yusuke Tanaka;Shun Mitsumata;Ryuichi Katagiri;Junko Taketo;Naoshi Horiba;Hideyoshi Igata;Kazue Mizuno",
        "authorids": "/37088440210;/37089447289;/37089450936;/37089447301;/37089447438;/37089448586;/37089449567;/37089448345;/37089447263;/37089478997;/37088440210;/37089447289;/37089450936;/37089447301;/37089447438;/37089448586;/37089449567;/37089448345;/37089447263;/37089478997",
        "aff": "Preferred Networks Inc., Chiyoda-Ku, Tokyo, Japan; Preferred Networks Inc., Chiyoda-Ku, Tokyo, Japan; Preferred Networks Inc., Chiyoda-Ku, Tokyo, Japan; Preferred Networks Inc., Chiyoda-Ku, Tokyo, Japan; Fuji Gotemba Research Labs, Chugai Pharmaceutical Co., Ltd., Gotemba, Shizuoka, Japan; Fuji Gotemba Research Labs, Chugai Pharmaceutical Co., Ltd., Gotemba, Shizuoka, Japan; Fuji Gotemba Research Labs, Chugai Pharmaceutical Co., Ltd., Gotemba, Shizuoka, Japan; Fuji Gotemba Research Labs, Chugai Pharmaceutical Co., Ltd., Gotemba, Shizuoka, Japan; Preferred Networks Inc., Chiyoda-Ku, Tokyo, Japan; Preferred Networks Inc., Chiyoda-Ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811804/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:0rC2olY8rBEJ:scholar.google.com/&scioq=Development+of+a+Stereo-vision+based+High-throughput+Robotic+System+for+Mouse+Tail+Vein+Injection&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;1;1;1;1;0;0",
        "aff_unique_norm": "Preferred Networks Inc.;Chugai Pharmaceutical Co., Ltd.",
        "aff_unique_dep": ";Fuji Gotemba Research Labs",
        "aff_unique_url": "https://www.preferred-networks.com;https://www.chugai-pharm.co.jp",
        "aff_unique_abbr": ";Chugai",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Gotemba",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811573",
        "title": "Diff-Net: Image Feature Difference Based High-Definition Map Change Detection for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Up-to-date High-Definition (HD) maps are essential for self-driving cars. To achieve constantly updated HD maps, we present a deep neural network (DNN), Diff-Net, to detect changes in them. Compared to traditional methods based on object detectors, the essential design in our work is a parallel feature difference calculation structure that infers map changes by comparing features extracted from the camera and rasterized images. To generate these rasterized images, we project map elements onto images in the camera view, yielding meaningful map representations that can be consumed by a DNN accordingly. As we formulate the change detection task as an object detection problem, we leverage the anchor-based structure that predicts bounding boxes with different change status categories. To the best of our knowledge, the proposed method is the first end-to-end network that tackles the high-definition map change detection task, yielding a single stage solution. Furthermore, rather than relying on single frame input, we introduce a spatio-temporal fusion module that fuses features from history frames into the current, thus improving the overall performance. Finally, we comprehensively validate our method's effectiveness using freshly collected datasets. Results demonstrate that our Diff-Net achieves better performance than the baseline methods and is ready to be integrated into a map production pipeline maintaining an up-to-date HD map.",
        "primary_area": "",
        "author": "Lei He;Shengjie Jiang;Xiaoqing Liang;Ning Wang;Shiyu Song;Lei He;Shengjie Jiang;Xiaoqing Liang;Ning Wang;Shiyu Song",
        "authorids": "/37089447012;/37089446873;/37089447021;/37089292085;/37086455081;/37089447012;/37089446873;/37089447021;/37089292085;/37086455081",
        "aff": "Baidu Autonomous Driving Technology Department; Baidu; Baidu; Baidu; Baidu Autonomous Driving Technology Department",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811573/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14368261394372319358&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Autonomous Driving Technology Department",
        "aff_unique_url": "https://www.baidu.com",
        "aff_unique_abbr": "Baidu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812004",
        "title": "Digital Twin with Integrated Robot-Human/Environment Interaction Dynamics for an Industrial Mobile Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "To achieve real-time dynamic simulation analysis and optimization design, a dynamic digital twin of a nonholonomic mobile manipulator (one UR5e mounted on an industrial mobile robot MIR 200) has been developed in this paper. First, the digital twin integrated with dynamics of a mobile manipulator is established. The framework of the dynamic digital twin is presented in detail. Then, the dynamic model of the system has been established with the consideration of the physical interaction between the robot and humans/environments using Lagrange formulation. Finally, the experimental testing has been conducted to validate the dynamic model and evaluate the performances (such as real-time property, accuracy, etc.) of the dynamic digital twin that is integrated with the physical human/environment-robot interaction.",
        "primary_area": "",
        "author": "Zhengxue Zhou;Xingyu Yang;Hao Wang;Xuping Zhang;Zhengxue Zhou;Xingyu Yang;Hao Wang;Xuping Zhang",
        "authorids": "/37088572103;/37089448853;/37089001401;/37085664403;/37088572103;/37089448853;/37089001401;/37085664403",
        "aff": "Department of Mechanical and Production Engineering, Aarhus University; Department of Mechanical and Production Engineering, Aarhus University; Department of Mechanical and Production Engineering, Aarhus University; Department of Mechanical and Production Engineering, Aarhus University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812004/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1673248075536816252&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Aarhus University",
        "aff_unique_dep": "Department of Mechanical and Production Engineering",
        "aff_unique_url": "https://www.au.dk",
        "aff_unique_abbr": "AU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9812064",
        "title": "Dilated Continuous Random Field for Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Mean field approximation methodology has laid the foundation of modern Continuous Random Field (CRF) based solutions for the refinement of semantic segmentation. In this paper, we propose to relax the hard constraint of mean field approximation - minimizing the energy term of each node from probabilistic graphical model, by a global optimization with the proposed dilated sparse convolution module (DSConv). In addition, adaptive global average-pooling and adaptive global max-pooling are implemented as replacements of fully connected layers. In order to integrate DSConv, we design an end-to-end, time-efficient DilatedCRF pipeline. The unary energy term is derived either from pre-softmax and post-softmax features, or the predicted affordance map using a conventional classifier, making it easier to implement DilatedCRF for varieties of classifiers. We also present superior experimental results of proposed approach on the suction dataset comparing to other CRF-based approaches.",
        "primary_area": "",
        "author": "Xi Mo;Xiangyu Chen;Cuncong Zhong;Rui Li;Kaidong Li;Usman Sajid;Xi Mo;Xiangyu Chen;Cuncong Zhong;Rui Li;Kaidong Li;Usman Sajid",
        "authorids": "/37089238479;/37089547268;/37088582294;/37089449886;/37088446823;/37088401312;/37089238479;/37089547268;/37088582294;/37089449886;/37088446823;/37088401312",
        "aff": "School of Engineering, University of Kansas, Lawrence, KS, USA; School of Engineering, University of Kansas, Lawrence, KS, USA; School of Engineering, University of Kansas, Lawrence, KS, USA; Wetland Studies and Solutions, Inc., Virginia Beach, VA, USA; School of Engineering, University of Kansas, Lawrence, KS, USA; School of Engineering, University of Kansas, Lawrence, KS, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812064/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15476731030081908388&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "University of Kansas;Wetland Studies and Solutions, Inc.",
        "aff_unique_dep": "School of Engineering;",
        "aff_unique_url": "https://www.ku.edu;",
        "aff_unique_abbr": "KU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Lawrence;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812170",
        "title": "Discovering Synergies for Robot Manipulation with Multi-Task Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Controlling robotic manipulators with high-dimensional action spaces for dexterous tasks is a challenging problem. Inspired by human manipulation, researchers have studied generating and using postural synergies for robot hands to accomplish manipulation tasks, leveraging the lower dimensional nature of synergistic action spaces. However, many of these works require pre-collected data from an existing controller in order to derive such a subspace by means of dimensionality reduction. In this paper, we present a framework that simultaneously discovers both a synergy space and a multi-task policy that operates on this low-dimensional action space to accomplish diverse manipulation tasks. We demonstrate that our end-to-end method is able to perform multiple tasks using few synergies, and outperforms sequential methods that apply dimensionality reduction to independently collected data. We also show that deriving synergies using multiple tasks can lead to a subspace that enables robots to efficiently learn new manipulation tasks and interactions with new objects.",
        "primary_area": "",
        "author": "Zhanpeng He;Matei Ciocarlie;Zhanpeng He;Matei Ciocarlie",
        "authorids": "/37088687305;/37297485500;/37088687305;/37297485500",
        "aff": "Department of Computer Science, Columbia University, New York, USA; Department of Mechanical Engineering, Columbia University, New York, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812170/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15329705611003630718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812050",
        "title": "Distributed Swarm Trajectory Optimization for Formation Flight in Dense Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "For aerial swarms, navigation in a prescribed formation is widely practiced in various scenarios. However, the associated planning strategies typically lack the capability of avoiding obstacles in cluttered environments. To address this deficiency, we present an optimization-based method that ensures collision-free trajectory generation for formation flight. In this paper, a novel differentiable metric is proposed to quantify the overall similarity distance between formations. We then formulate this metric into an optimization framework, which achieves spatial-temporal planning using polynomial trajectories. Minimization over collision penalty is also incorporated into the framework, so that formation preservation and obstacle avoidance can be handled simultaneously. To validate the efficiency of our method, we conduct benchmark comparisons with other cutting-edge works. Integrated with an autonomous distributed aerial swarm system, the proposed method demonstrates its efficiency and robustness in real-world experiments with obstacle-rich surroundings11https://www.youtube.com/watch?v=lFumtOrJci4. We will release the source code for the reference of the community22https://github.com/ZJU-FAST-Lab/Swarm-Formation.",
        "primary_area": "",
        "author": "Lun Quan;Longji Yin;Chao Xu;Fei Gao;Lun Quan;Longji Yin;Chao Xu;Fei Gao",
        "authorids": "/37088998553;/37089447214;/37404060100;/37086045143;/37088998553;/37089447214;/37404060100;/37086045143",
        "aff": "Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812050/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17356402527305946959&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "Huzhou Institute",
        "aff_unique_url": "https://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Huzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811633",
        "title": "Distributed Three Dimensional Flocking of Autonomous Drones",
        "track": "main",
        "status": "Poster",
        "abstract": "Potential field approaches have been often used to describe and model interactions within a swarm of robots performing collective motion, also called flocking. Despite the high number of proposed approaches, most have only been tested in simulation and among the minority tested on real robots, even fewer abandoned the laboratory boundaries in favor of real-world scenarios. In this work, we propose a decentralized flocking approach that builds over the classical potential field models and that is proved to work well both in simulated and real-world environments. Each robot in the swarm relies on limited information and can only perceive its local neighbors through limited communication of noisy position information. No information on individual drone orientations, velocities, or accelerations is exchanged or needed. The novel experimental achievement of this paper is the realization of collective motion in three dimensions with the above sensing limitations. The swarm dynamically adapts to the environment by keeping a preferred distance from the ground and by changing formation. To show the general applicability of the proposed control algorithm, we study how it performs with the use of different potential functions proposed in the literature and by comparing them via extensive evaluation of the results in a realistic simulated environment. Lastly, we compare the performances of the proposed approach and of the different potentials on a real-drone swarm of up to fourteen robots flying both in two and three dimensional formations and in a challenging outdoor environment.",
        "primary_area": "",
        "author": "Dario Albani;Tiziano Manoni;Martin Saska;Eliseo Ferrante;Dario Albani;Tiziano Manoni;Martin Saska;Eliseo Ferrante",
        "authorids": "/37086252934;/37089449286;/37298817800;/38230571500;/37086252934;/37089449286;/37298817800;/38230571500",
        "aff": "Autonomous Robotics Research Centre, Technology Innovation Institute, Abu Dhabi, United Arab Emirates; Department of Computer Science, Vrije Universiteit, Amsterdam, The Netherlands; Department of Cybernetics, Czech Technical University in Prague, Prague, Czech Republic; Department of Computer Science, Vrije Universiteit, Amsterdam, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811633/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5396884704959599515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Technology Innovation Institute;Vrije Universiteit;Czech Technical University in Prague",
        "aff_unique_dep": "Autonomous Robotics Research Centre;Department of Computer Science;Department of Cybernetics",
        "aff_unique_url": ";https://www.vu.nl;https://www.cvut.cz",
        "aff_unique_abbr": ";VU;CTU",
        "aff_campus_unique_index": "0;1;2;1",
        "aff_campus_unique": "Abu Dhabi;Amsterdam;Prague",
        "aff_country_unique_index": "0;1;2;1",
        "aff_country_unique": "United Arab Emirates;Netherlands;Czech Republic"
    },
    {
        "id": "9811762",
        "title": "Distributed Timed Elastic Band (DTEB) Planner: Trajectory Sharing and Collision Prediction for Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation of mobile robots is a well-studied problem in robotics. However, the navigation task becomes challenging when multi-robot systems have to cooperatively navigate dynamic environments with deadlock-prone layouts. We present a Distributed Timed Elastic Band (DTEB) Planner that combines Prioritized Planning with the online TEB trajectory Planner, in order to extend the capabilities of the latter to multi-robot systems. The proposed planner is able to reactively avoid imminent collisions as well as predictively resolve potential deadlocks among a team of robots, while navigating in a complex environment. The results of our simulation demonstrate the reliable performance and the versatility of the planner in different environment settings. The code and tests for our approach are available online.",
        "primary_area": "",
        "author": "Yiu Ming Chung;Hazem Youssef;Moritz Roidl;Yiu Ming Chung;Hazem Youssef;Moritz Roidl",
        "authorids": "/37089447835;/37089449268;/37085470989;/37089447835;/37089449268;/37085470989",
        "aff": "Faculty of Electrical Engineering and Information Technology, Technis-che Universit\u00e4t Dortmund, Dortmund, Germany; Chair of Material Handling and Warehousing, Faculty of Mechanical Engineering, Technische Universit\u00e4t Dortmund, Dortmund, Germany; Chair of Material Handling and Warehousing, Faculty of Mechanical Engineering, Technische Universit\u00e4t Dortmund, Dortmund, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811762/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8198379374749870665&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Dortmund",
        "aff_unique_dep": "Faculty of Electrical Engineering and Information Technology",
        "aff_unique_url": "https://www.tu-dortmund.de",
        "aff_unique_abbr": "TU Dortmund",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Dortmund",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812376",
        "title": "Disturbance-injected Robust Imitation Learning with Task Achievement",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust imitation learning using disturbance injections overcomes issues of limited variation in demonstrations. However, these methods assume demonstrations are optimal, and that policy stabilization can be learned via simple augmentations. In real-world scenarios, demonstrations are often of diverse-quality, and disturbance injection instead learns sub-optimal policies that fail to replicate desired behavior. To address this issue, this paper proposes a novel imitation learning framework that combines both policy robustification and optimal demonstration learning. Specifically, this combinatorial approach forces policy learning and disturbance injection optimization to focus on mainly learning from high task achievement demonstrations, while utilizing low achievement ones to decrease the number of samples needed. The effectiveness of the proposed method is verified through experiments using an excavation task in both simulations and a real robot, resulting in high-achieving policies that are more stable and robust to diverse-quality demonstrations. In addition, this method utilizes all of the weighted sub-optimal demonstrations without eliminating them, resulting in practical data efficiency benefits.",
        "primary_area": "",
        "author": "Hirotaka Tahara;Hikaru Sasaki;Hanbit Oh;Brendan Michael;Takamitsu Matsubara;Hirotaka Tahara;Hikaru Sasaki;Hanbit Oh;Brendan Michael;Takamitsu Matsubara",
        "authorids": "/37089447910;/37086937467;/37088999484;/37085555241;/37533262700;/37089447910;/37086937467;/37088999484;/37085555241;/37533262700",
        "aff": "Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology, Japan; Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology, Japan; Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology, Japan; Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology, Japan; Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812376/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12484281380285871708&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Nara Institute of Science and Technology",
        "aff_unique_dep": "Division of Information Science, Graduate School of Science and Technology",
        "aff_unique_url": "https://www.nist.go.jp",
        "aff_unique_abbr": "NIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812070",
        "title": "Domain Generalization for Vision-based Driving Trajectory Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the challenges in vision-based driving trajectory generation is dealing with out-of-distribution scenarios. In this paper, we propose a domain generalization method for vision-based driving trajectory generation for autonomous vehicles in urban environments, which can be seen as a solution to extend the Invariant Risk Minimization (IRM) method in complex problems. We leverage an adversarial learning approach to train a trajectory generator as the decoder. Based on the pre-trained decoder, we infer the latent variables corresponding to the trajectories, and pre-train the encoder by regressing the inferred latent variable. Finally, we fix the decoder but fine-tune the encoder with the final trajectory loss. We compare our proposed method with the state-of-the-art trajectory generation method and some recent domain generalization methods on both datasets and simulation, demonstrating that our method has better generalization ability. Our project is available at https://sites.google.com/view/dg-traj-gen.",
        "primary_area": "",
        "author": "Yunkai Wang;Dongkun Zhang;Yuxiang Cui;Zexi Chen;Wei Jing;Junbo Chen;Rong Xiong;Yue Wang;Yunkai Wang;Dongkun Zhang;Yuxiang Cui;Zexi Chen;Wei Jing;Junbo Chen;Rong Xiong;Yue Wang",
        "authorids": "/37088600631;/37087886680;/37088954385;/37088601253;/37085809046;/37089196396;/37271511300;/37072299700;/37088600631;/37087886680;/37088954385;/37088601253;/37085809046;/37089196396;/37271511300;/37072299700",
        "aff": "State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China; Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812070/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17382196358978384438&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;1;1;0;0",
        "aff_unique_norm": "Zhejiang University;Alibaba DAMO Academy",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control;Department of Autonomous Driving Lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://damo.alibaba.com",
        "aff_unique_abbr": "ZJU;Alibaba DAMO",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811852",
        "title": "Driving Swarm: A Swarm Robotics Framework for Intelligent Navigation in a Self-organized World",
        "track": "main",
        "status": "Poster",
        "abstract": "Implementing and conducting reproducible experiments on multi-robot hardware platforms are challenging tasks due to variations in hardware, software, and most importantly the intensive implementation effort. In this paper, we aim to present the Driving Swarm software framework which is developed to facilitate the implementation, deployment, supervision, and analysis of multi-robot experiments. We use this framework with the TurtleBot3 hardware platform and measure its performance for two example scenarios: trajectory tracking and flocking behavior, with 5 and 6 robots. The goal of our experiments is to validate the simulation comparing to hardware implementations and to provide a baseline data for further experiments. While the simulated and real robots show similar behavior, we could observe that the simulated behavior is more robust than the real behavior in both scenarios. This effect is observed in the lower tracking error and better obstacle avoidance in both experiments. While the simulation proved to be a valuable tool during the development of the behaviors, the results confirm the importance of conducting experiments on a real-world test bed.",
        "primary_area": "",
        "author": "Sebastian Mai;Nele Traichel;Sanaz Mostaghim;Sebastian Mai;Nele Traichel;Sanaz Mostaghim",
        "authorids": "/37086612077;/37089447830;/37276347400;/37086612077;/37089447830;/37276347400",
        "aff": "Computational Intelligence Otto-von-Guericke University, Magdeburg, Germany; Otto-von-Guericke Universty, Magdeburg, Germany; Otto-von-Guericke Universty, Magdeburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811852/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12672029835139891337&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Otto-von-Guericke University",
        "aff_unique_dep": "Computational Intelligence",
        "aff_unique_url": "https://www.ovgu.de",
        "aff_unique_abbr": "OVGU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Magdeburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812217",
        "title": "Dual Regression for Efficient Hand Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Hand pose estimation constitutes prime attainment for human-machine interaction-based applications. Real-time operation is vital in such tasks. Thus, a reliable estimator should exhibit low computational complexity and high precision at the same time. Previous works have explored the regression techniques, including the coordinate regression and heatmap regression methods. Primarily incorporating ideas from them, in this paper, we propose a novel, fast and accurate method for hand pose estimation, which adopts a lightweight network architecture and a post-processing scheme. Hence, our architecture uses a Dual Regression strategy, consisting of two regression branches, namely the coordinate and the heatmap ones, and we refer to the proposed method as DRHand. By carefully selecting the branches' characteristics, the proposed structure has been designed to exploit the benefits of the two methods mentioned above while impoverishing their weaknesses to some extent. The two branches are supervised separately during training, and a post-processing module estimates their outputs to boost reliability. This way, our novel pipeline is considerably faster, reaching 44.39 frames-per-second on an NVIDIA Jetson TX2 graphics processing unit, offering a beyond real-time performance for any custom robotics application. Lastly, extensive experiments conducted on two publicly-available datasets demonstrate that the proposed framework outperforms previous state-of-the-art techniques and can generalize on various hand pose scenarios.",
        "primary_area": "",
        "author": "Dong Wei;Shan An;Xiajie Zhang;Jiayi Tian;Konstantinos A. Tsintotas;Antonios Gasteratos;Haogang Zhu;Dong Wei;Shan An;Xiajie Zhang;Jiayi Tian;Konstantinos A. Tsintotas;Antonios Gasteratos;Haogang Zhu",
        "authorids": "/37089514657;/37086923915;/37089515826;/37089414194;/37086455006;/37303793300;/37086553313;/37089514657;/37086923915;/37089515826;/37089414194;/37086455006;/37303793300;/37086553313",
        "aff": "Tech. & Data Center, JD.COM Inc., Beijing, China; Tech. & Data Center, JD.COM Inc., Beijing, China; Tech. & Data Center, JD.COM Inc., Beijing, China; Tech. & Data Center, JD.COM Inc., Beijing, China; Department of Production and Management Engineering, Democritus University of Thrace, Xanthi, Greece; Department of Production and Management Engineering, Democritus University of Thrace, Xanthi, Greece; School of Computer Science and Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812217/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7179555279681068047&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;2",
        "aff_unique_norm": "JD.com Inc.;Democritus University of Thrace;Beihang University",
        "aff_unique_dep": "Tech. & Data Center;Department of Production and Management Engineering;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.jd.com;https://www.duth.gr;http://www.buaa.edu.cn",
        "aff_unique_abbr": "JD;;BUAA",
        "aff_campus_unique_index": "0;0;0;0;1;1;0",
        "aff_campus_unique": "Beijing;Xanthi",
        "aff_country_unique_index": "0;0;0;0;1;1;0",
        "aff_country_unique": "China;Greece"
    },
    {
        "id": "9812365",
        "title": "Dual-scale robotic solution for middle ear surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with the control of a redundant robotic system for middle ear surgery (i.e., cholesteatoma tissues removal). The targeted robotic system is a macro-micro-scale robot composed of a redundant seven degrees of freedom (DoFs) on which is attached a two DoFs robotized flexible fiberscope. Two different control architectures are proposed to achieve a defined surgical procedure to remove the pathological tissue inside the middle ear cavity. The first proposed control mode is based on the position-based tele-operation of the entire system using a joystick (Phantom Omni) as a master arm. The second one combines comanipulation of the seven DoFs robotic arm using an embedded force/torque sensor and an end-frame tele-operation of the remaining two DoFs fiberscope using a lab-made in-hand joystick. Experimental validation is performed to evaluate and compare the performance of both developed control schemes. The obtained results using the lab-made platform and the proposed controllers are discussed.",
        "primary_area": "",
        "author": "Jae-Hun So;Brahim Tamadazte;Naresh Marturi;J\u00e9r\u00f4me Szewczyk;Jae-Hun So;Brahim Tamadazte;Naresh Marturi;J\u00e9r\u00f4me Szewczyk",
        "authorids": "/37088564418;/37681656800;/37085558507;/37541684100;/37088564418;/37681656800;/37085558507;/37541684100",
        "aff": "CNRS UMR 7222, INSERM U1150, ISIR, Sorbonne Universit\u00e9, Paris, France; CNRS UMR 7222, INSERM U1150, ISIR, Sorbonne Universit\u00e9, Paris, France; Extreme Robotics Laboratory, University of Birmingham, Birmingham, U.K.; CNRS UMR 7222, INSERM U1150, ISIR, Sorbonne Universit\u00e9, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812365/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3930891474911085746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Sorbonne Universit\u00e9;University of Birmingham",
        "aff_unique_dep": ";Extreme Robotics Laboratory",
        "aff_unique_url": "https://www.sorbonne-universite.fr;https://www.birmingham.ac.uk",
        "aff_unique_abbr": "Sorbonne U;UoB",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Paris;Birmingham",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "France;United Kingdom"
    },
    {
        "id": "9812438",
        "title": "Dynamic Human-Robot Role Allocation based on Human Ergonomics Risk Prediction and Robot Actions Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Even though cobots have high potential in bringing several benefits in the manufacturing and logistic processes, their rapid (re-)deployment in changing environments is still limited. To enable fast adaptation to new product demands and to boost the fitness of the human workers to the allocated tasks, we propose a novel method that optimizes assembly strategies and distributes the effort among the workers in human-robot cooperative tasks. The cooperation model exploits AND/OR Graphs that we adapted to solve also the role allocation problem. The allocation algorithm considers quantitative measurements that are computed online to describe human operators' ergonomic status and task properties. We conducted preliminary experiments to demonstrate that the proposed approach succeeds in controlling the task allocation process to ensure safe and ergonomic conditions for the human worker.",
        "primary_area": "",
        "author": "Elena Merlo;Edoardo Lamon;Fabio Fusaro;Marta Lorenzini;Alessandro Carfi;Fulvio Mastrogiovanni;Arash Ajoudani;Elena Merlo;Edoardo Lamon;Fabio Fusaro;Marta Lorenzini;Alessandro Carfi;Fulvio Mastrogiovanni;Arash Ajoudani",
        "authorids": "/37089449934;/37086599073;/37088464502;/37086249968;/37086509662;/37546428500;/37945239900;/37089449934;/37086599073;/37088464502;/37086249968;/37086509662;/37546428500;/37945239900",
        "aff": "Dept. of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Genoa, Italy; Human-Robot Interfaces and physical Interaction, Istituto Italiano di Tecnologia, Genoa, Italy; Dept. of Electronics, Information and Bioengineering, Politecnico di Milano, Italy; Human-Robot Interfaces and physical Interaction, Istituto Italiano di Tecnologia, Genoa, Italy; Dept. of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Genoa, Italy; Dept. of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Genoa, Italy; Human-Robot Interfaces and physical Interaction, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812438/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=473643478274290249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;1;0;0;1",
        "aff_unique_norm": "University of Genoa;Istituto Italiano di Tecnologia;Politecnico di Milano",
        "aff_unique_dep": "Dept. of Informatics, Bioengineering, Robotics, and Systems Engineering;Human-Robot Interfaces and physical Interaction;Dept. of Electronics, Information and Bioengineering",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it;https://www.polimi.it",
        "aff_unique_abbr": "UniGe;IIT;Politecnico di Milano",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Genoa;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9812089",
        "title": "Dynamic Mirror Descent based Model Predictive Control for Accelerating Robot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent works in Reinforcement Learning (RL) combine model-free (Mf)-RL algorithms with model-based (Mb)-RL approaches to get the best from both: asymptotic performance of Mf-RL and high sample-efficiency of Mb-RL. Inspired by these works, we propose a hierarchical framework that integrates online learning for the Mb-trajectory optimization with off-policy methods for the Mf-RL. In particular, two loops are proposed, where the Dynamic Mirror Descent based Model Predictive Control (DMD-MPC) is used as the inner loop Mb-RL to obtain an optimal sequence of actions. These actions are in turn used to significantly accelerate the outer loop Mf-RL. We show that our formulation is generic for a broad class of MPC based policies and objectives, and includes some of the well-known Mb-Mf approaches. We finally introduce a new algorithm: Mirror-Descent Model Predictive RL (M-DeMoRL), which uses Cross-Entropy Method (CEM) with elite fractions for the inner loop. Our experiments show faster convergence of the proposed hierarchical approach on benchmark MuJoCo tasks. We also demonstrate hardware training for trajectory tracking in a 2R leg, and hardware transfer for robust walking in a quadruped. We show that the inner-loop Mb-RL significantly decreases the number of training iterations required in the hardware setting, thereby validating the proposed approach.",
        "primary_area": "",
        "author": "Utkarsh A. Mishra;Soumya R. Samineni;Prakhar Goel;Chandravaran Kunjeti;Himanshu Lodha;Aman Singh;Aditya Sagi;Shalabh Bhatnagar;Shishir Kolathaya;Utkarsh A. Mishra;Soumya R. Samineni;Prakhar Goel;Chandravaran Kunjeti;Himanshu Lodha;Aman Singh;Aditya Sagi;Shalabh Bhatnagar;Shishir Kolathaya",
        "authorids": "/37088490178;/37089449488;/37088537623;/37089448233;/37089448522;/37089448031;/37087235772;/37276335900;/37060909000;/37088490178;/37089449488;/37088537623;/37089448233;/37089448522;/37089448031;/37087235772;/37276335900;/37060909000",
        "aff": "Department of Computer Science and Automation, Indian Institute of Science, Bangalore; Department of Computer Science and Automation, Indian Institute of Science, Bangalore; Electronics and Communication Engineering Department, Manipal Institute of Technology, India; Electronics and Communication Engineering Department, National Institute of Technology, Karnataka, India; Department of Computer Science and Automation, Indian Institute of Science, Bangalore; Department of Computer Science and Automation, Indian Institute of Science, Bangalore; Department of Computer Science and Automation, Indian Institute of Science, Bangalore; Department of Computer Science and Automation, Indian Institute of Science, Bangalore; Department of Computer Science and Automation, Indian Institute of Science, Bangalore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812089/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3309377030738311629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;2;0;0;0;0;0",
        "aff_unique_norm": "Indian Institute of Science;Manipal Institute of Technology;National Institute of Technology, Karnataka",
        "aff_unique_dep": "Department of Computer Science and Automation;Electronics and Communication Engineering Department;Electronics and Communication Engineering Department",
        "aff_unique_url": "https://www.iisc.ac.in;;https://www.nitk.edu.in",
        "aff_unique_abbr": "IISc;;NITK",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Bangalore;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9812458",
        "title": "Dynamic Modeling and Digital Twin of a Harmonic Drive Based Collaborative Robot Joint",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robots are gradually taking over the leading position in automating the production and manufacturing of the SMEs, where the human-robot collaboration is highly emphasized. Therefore, estimating the force and simulating the performance of robots are of great importance. As a newly introduced technology, digital twin, has gained more attentions for simulation, process evaluation, real-time monitoring, etc. However, the current state-of-the-art of digital twin for robots still remains on the kinematic level, and the integrated robot system dynamics is too complex to be incorporated into the digital twin. Therefore, this research starts with the perspective of harmonic drive based robot joint, and proposes a dynamic model of robot joint by analyzing the composition, transmission principle, and internal interactions. Then the experimental parameter identification is performed to obtain the inherent parameters, which can reflect the system performance characteristics. Finally, a preliminary digital twin of robot joint integrated with dynamic model is established with Gazebo and MATLAB. The proposed approach could be used to simulate the dynamic behavior of robot joint in real time and make contributions to the state of the art for digital twin.",
        "primary_area": "",
        "author": "Xingyu Yang;Dong Qiang;Zixuan Chen;Hao Wang;Zhengxue Zhou;Xuping Zhang;Xingyu Yang;Dong Qiang;Zixuan Chen;Hao Wang;Zhengxue Zhou;Xuping Zhang",
        "authorids": "/37089448853;/37085789395;/37089448543;/37089001401;/37088572103;/37085664403;/37089448853;/37085789395;/37089448543;/37089001401;/37088572103;/37085664403",
        "aff": "Department of Mechanical and Production Engineering, Aarhus University, Aarhus, Denmark; Department of Electrical Engineering, City University of Hong Kong, Hong Kong SAR, China; Department of Electrical Engineering, City University of Hong Kong, Hong Kong SAR, China; Department of Mechanical and Production Engineering, Aarhus University, Aarhus, Denmark; Department of Mechanical and Production Engineering, Aarhus University, Aarhus, Denmark; Department of Mechanical and Production Engineering, Aarhus University, Aarhus, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812458/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14915796180769319585&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0;0",
        "aff_unique_norm": "Aarhus University;City University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Production Engineering;Department of Electrical Engineering",
        "aff_unique_url": "https://www.au.dk;https://www.cityu.edu.hk",
        "aff_unique_abbr": "AU;CityU",
        "aff_campus_unique_index": "0;1;1;0;0;0",
        "aff_campus_unique": "Aarhus;Hong Kong SAR",
        "aff_country_unique_index": "0;1;1;0;0;0",
        "aff_country_unique": "Denmark;China"
    },
    {
        "id": "9811625",
        "title": "Dynamic Robot Chain Networks for Swarm Foraging",
        "track": "main",
        "status": "Poster",
        "abstract": "The objective of foraging robot swarms is to search for and collect resources in an unknown arena as quickly as possible. To avoid the congestion near the central collection zone, we previously proposed an extension to the multiple-place foraging in which robot chains are deployed dynamically so that foraging robots can deliver to the robot chains instead of the central collection zone. However, a robot chain can only reach one location at a time, and congestion can occur at the end of the robot chain. This paper presents an extension to dynamic robot chains called dynamic robot chain networks, which extends robot chains with branches, each of which reaches different resource clusters. We formulate the problem of finding the smallest dynamic robot chain networks as the Euclidean Steiner tree problem and explain how Steiner trees can be utilized to optimize the efficiency of the foraging operations. We implemented our foraging robot swarms in a simulator called ARGoS. Our experiments showed that dynamic robot chain networks can avoid obstacles and collect more resources when compared with the original robot chain design.",
        "primary_area": "",
        "author": "Dohee Lee;Qi Lu;Tsz-Chiu Au;Dohee Lee;Qi Lu;Tsz-Chiu Au",
        "authorids": "/37088998317;/37086209357;/37597553100;/37088998317;/37086209357;/37597553100",
        "aff": "Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology, South Korea; Department of Computer Science, University of Texas, San Antonio, USA; Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811625/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16440746219918496851&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology;University of Texas, San Antonio",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.unist.ac.kr;https://www.utsa.edu",
        "aff_unique_abbr": "UNIST;UTSA",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";San Antonio",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "9812191",
        "title": "Dynamic Underactuated Manipulator Using a Flexible Body with a Structural Anisotropy",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel manipulation method utilizing dynamic deformation of a flexible body with a structural anisotropy. Employing a spiral flexible body, a dynamic underactuated manipulation using its various vibrational patterns is proposed. First, the orbit of the tip of flexible body for the vibrational input to its root is theoretically derived. Subsequently, for flexible bodies with and without the structural anisotropy, structural stiffness and vibrational orbit of the tip of body are analyzed. Through this analysis, the generation mechanism of the orbit change effect according to the input frequency is revealed. Finally, the proposed method is experimentally validated. After confirming the orbit change effect in a spiral flexible body, this effect is applied to an underactuated nonprehensile manipulation where three-Dof motion of an object is controlled by a single actuator.",
        "primary_area": "",
        "author": "Akihiro Maruo;Akihide Shibata;Mitsuru Higashimori;Akihiro Maruo;Akihide Shibata;Mitsuru Higashimori",
        "authorids": "/37089450159;/38255144900;/37394385100;/37089450159;/38255144900;/37394385100",
        "aff": "Dept. of Mechanical Engineering, Graduate School of Engineering, Osaka University, Suita, Japan; Dept. of Mechanical Engineering, Graduate School of Engineering, Osaka University, Suita, Japan; Dept. of Mechanical Engineering, Graduate School of Engineering, Osaka University, Suita, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812191/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11728006677051189340&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Osaka University",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Osaka U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Suita",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812356",
        "title": "DynamicFilter: an Online Dynamic Objects Removal Framework for Highly Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Emergence of massive dynamic objects will diversify spatial structures when robots navigate in urban environments. Therefore, the online removal of dynamic objects is critical. In this paper, we introduce a novel online removal framework for highly dynamic urban environments. The framework consists of the scan-to-map front-end and the map-to-map back-end modules. Both the front- and back-ends deeply integrate the visibility-based approach and map-based approach. The experiments validate the framework in highly dynamic simulation scenarios and real-world dataset.",
        "primary_area": "",
        "author": "Tingxiang Fan;Bowen Shen;Hua Chen;Wei Zhang;Jia Pan;Tingxiang Fan;Bowen Shen;Hua Chen;Wei Zhang;Jia Pan",
        "authorids": "/37086615218;/37089447536;/37086195529;/37089656248;/37535628800;/37086615218;/37089447536;/37086195529;/37089656248;/37535628800",
        "aff": "University of Hong Kong; Southern University of Science and Technology; Southern University of Science and Technology; Southern University of Science and Technology; University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812356/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3400913306478964007&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of Hong Kong;Southern University of Science and Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.hku.hk;https://www.sustech.edu.cn",
        "aff_unique_abbr": "HKU;SUSTech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811559",
        "title": "Dynamics-Aware Quality-Diversity for Efficient Learning of Skill Repertoires",
        "track": "main",
        "status": "Poster",
        "abstract": "Quality-Diversity (QD) algorithms are powerful exploration algorithms that allow robots to discover large repertoires of diverse and high-performing skills. However, QD algorithms are sample inefficient and require millions of evaluations. In this paper, we propose Dynamics-Aware Quality-Diversity (DA-QD), a framework to improve the sample efficiency of QD algorithms through the use of dynamics models. We also show how DA-QD can then be used for continual acquisition of new skill repertoires. To do so, we incrementally train a deep dynamics model from experience obtained when performing skill discovery using QD. We can then perform QD exploration in imagination with an imagined skill repertoire. We evaluate our approach on three robotic experiments. First, our experiments show DA-QD is 20 times more sample efficient than existing QD approaches for skill discovery. Second, we demonstrate learning an entirely new skill repertoire in imagination to perform zero-shot learning. Finally, we show how DA-QD is useful and effective for solving a long horizon navigation task and for damage adaptation in the real world. Videos and source code are available at: https://sites.google.com/view/da-qd.",
        "primary_area": "",
        "author": "Bryan Lim;Luca Grillotti;Lorenzo Bernasconi;Antoine Cully;Bryan Lim;Luca Grillotti;Lorenzo Bernasconi;Antoine Cully",
        "authorids": "/37088504437;/37089447752;/37089449761;/37085649925;/37088504437;/37089447752;/37089449761;/37085649925",
        "aff": "Imperial College London, United Kingdom; Imperial College London, United Kingdom; Imperial College London, United Kingdom; Imperial College London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811559/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5693962499071278174&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812133",
        "title": "EDPLVO: Efficient Direct Point-Line Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces an efficient direct visual odometry (VO) algorithm using points and lines. Pixels on lines are generally adopted in direct methods. However, the original photometric error is only defined for points. It seems difficult to extend it to lines. In previous works, the collinear constraints for points on lines are either ignored [1] or introduce heavy computational load into the resulting optimization system [2]. This paper extends the photometric error for lines. We prove that the 3D points of the points on a 2D line are determined by the inverse depths of the endpoints of the 2D line, and derive a closed-form solution for this problem. This property can significantly reduce the number of variables to speed up the optimization, and can make the collinear constraint exactly satisfied. Furthermore, we introduce a two-step method to further accelerate the optimization, and prove the convergence of this method. The experimental results show that our algorithm outperforms the state-of-the-art direct VO algorithms.",
        "primary_area": "",
        "author": "Lipu Zhou;Guoquan Huang;Yinian Mao;Shengze Wang;Michael Kaess;Lipu Zhou;Guoquan Huang;Yinian Mao;Shengze Wang;Michael Kaess",
        "authorids": "/37088198282;/37077670600;/37089321433;/37088504574;/37324200400;/37088198282;/37077670600;/37089321433;/37088504574;/37324200400",
        "aff": "Meituan, Beijing, China; Meituan, Beijing, China; Meituan, Beijing, China; Department of Computer Science, University of North Carolina, Chapel Hill, NC, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812133/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14404004448969006904&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Meituan;University of North Carolina;Carnegie Mellon University",
        "aff_unique_dep": ";Department of Computer Science;Robotics Institute",
        "aff_unique_url": "https://www.meituan.com;https://www.unc.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Meituan;UNC;CMU",
        "aff_campus_unique_index": "0;0;0;1;2",
        "aff_campus_unique": "Beijing;Chapel Hill;Pittsburgh",
        "aff_country_unique_index": "0;0;0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9811631",
        "title": "Easing Reliance on Collision-free Planning with Contact-aware Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We believe that the future of robot motion planning will look very different than how it looks today: instead of complex collision avoidance trajectories with a brittle dependence on sensing and estimation of the environment, motion plans should consist of smooth, simple trajectories and be executed by robots that are not afraid of making contact. Here we present a \u201ccontact-aware\u201d controller which continues to execute a given trajectory despite unexpected collisions while keeping the contact force stable and small. We introduce a quadratic programming (QP) formulation, which minimizes a trajectory-tracking error subject to quasistatic dynamics and contact-force constraints. Compared with the classical null-space projection technique, the inequality constraint on contact forces in the proposed QP controller allows for more gentle release when the robot comes out of contact. In the quasistatic dynamics model, control actions consist only of commanded joint positions, allowing the QP controller to run on stiffness-controlled robots which do not have a straightforward torque-control interface nor accurate dynamic models. The effectiveness of the proposed QP controller is demonstrated on a KUKA iiwa arm. Project video: https://youtu.be/M-7JMQRkiPk.",
        "primary_area": "",
        "author": "Tao Pang;Russ Tedrake;Tao Pang;Russ Tedrake",
        "authorids": "/37089309719;/37283152200;/37089309719;/37283152200",
        "aff": "Tao Pang; Russ Tedrake",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811631/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18198444550838517734&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9812080",
        "title": "Effectiveness of Augmented Reality for Human Swarm Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-Swarm Interaction (HSI) is a fast-growing research area in swarm robotics. One challenging aspect of HSI is facilitating effective handling of the many degrees-of-freedom present in robot swarms by humans. One emergent option is the use of Augmented Reality (AR) systems to encode information. AR based interfaces can help provide human operators with visual cues about the swarm's states and control to facilitate decision-making. In research settings, AR systems can address issues such as limited availability of lab spaces, limited access to robotics resources, and the need for the ability to simulate dynamic environments with which robots and humans can interact. Further, to make swarm robotics more accessible and ubiquitous, HSI systems that support remote interaction would allow humans to interact with robot swarms and multi-robot systems regardless of the geographical distance between humans and swarms. Taking these into consideration, we aim to investigate the effectiveness of AR based interfaces as tools for remote interaction in HSI systems. We developed a simple AR based interface and evaluated its effectiveness against an unaugmented interface, by means of remote human user studies where a human operator would control a team of robots remotely through a video call. Our finding suggests that augmentation can improve control accuracy and reduce collision safety violations when performing navigation tasks. Through experimental surveys, it is shown that operators with varying levels of robotics and technology experience overwhelmingly prefer the augmented interface to facilitate swarm control. These results suggest that AR-based interfaces are effective in improving the control experience in remote HSI.",
        "primary_area": "",
        "author": "Sarjana Oradiambalam Sachidanandam;Sara Honarvar;Yancy Diaz-Mercado;Sarjana Oradiambalam Sachidanandam;Sara Honarvar;Yancy Diaz-Mercado",
        "authorids": "/37089450862;/37089450483;/38352376400;/37089450862;/37089450483;/38352376400",
        "aff": "Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812080/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12463297993393547281&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811538",
        "title": "Effects of Interfaces on Human-Robot Trust: Specifying and Visualizing Physical Zones",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we investigate the influence interfaces and feedback have on human-robot trust levels when operating in a shared physical space. The task we use is specifying a \u201cno-go\u201d region for a robot in an indoor environment. We evaluate three styles of interface (physical, AR, and map-based) and four feedback mechanisms (no feedback, robot drives around the space, an AR \u201cfence\u201d, and the region marked on the map). Our evaluation looks at both usability and trust. Specifically, if the participant trusts that the robot \u201cknows\u201d where the no-go region is and their confidence in the robot's ability to avoid that region. We use both self-reported and indirect measures of trust and usability. Our key findings are: 1) interfaces and feedback do influence levels of trust; 2) the participants largely preferred a mixed interface-feedback pair, where the modality for the interface differed from the feedback.",
        "primary_area": "",
        "author": "Marisa Hudspeth;Sogol Balali;Cindy Grimm;Ross T. Sowell;Marisa Hudspeth;Sogol Balali;Cindy Grimm;Ross T. Sowell",
        "authorids": "/37089448860;/37089447334;/37085798146;/37089448101;/37089448860;/37089447334;/37085798146;/37089448101",
        "aff": "Department of Computer Science, Rhodes College, Memphis, USA; School of Mechanical, Industrial, Manufacturing, and Engineering, Oregon State University, Corvallis, USA; School of Mechanical, Industrial, Manufacturing, and Engineering, Oregon State University, Corvallis, USA; Department of Computer Science, Rhodes College, Memphis, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811538/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5356677614155415549&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Rhodes College;Oregon State University",
        "aff_unique_dep": "Department of Computer Science;School of Mechanical, Industrial, Manufacturing, and Engineering",
        "aff_unique_url": "https://www.rhodes.edu;https://oregonstate.edu",
        "aff_unique_abbr": ";OSU",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Memphis;Corvallis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811547",
        "title": "Efficient Object Manipulation to an Arbitrary Goal Pose: Learning-Based Anytime Prioritized Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We focus on the task of object manipulation to an arbitrary goal pose, in which a robot is supposed to pick an assigned object to place at the goal position with a specific orientation. However, limited by the execution space of the manipulator with gripper, one-step picking, moving and releasing might be failed, where a reorientation object pose is required as a transition. In this paper, we propose a learning-driven anytime prioritized search-based solver to find a feasible solution with low path cost in a short time. In our work, the problem is formulated as a hierarchical learning problem, with the high level finding a reorientation object pose, and the low level planning paths between adjacent grasps. We learn an offline-training path cost estimator to predict approximate path planning costs, which serve as pseudo rewards to allow for pre-training the high-level planner without interacting with the simulator. To deal with the problem of distribution mismatch of the cost net and the actual execution cost space, a refined training stage is conducted with simulation interaction. A series of experiments carried out in simulation and real world indicate that our system can achieve better performances in the object manipulation task with less time and less cost.",
        "primary_area": "",
        "author": "Kechun Xu;Hongxiang Yu;Renlang Huang;Dashun Guo;Yue Wang;Rong Xiong;Kechun Xu;Hongxiang Yu;Renlang Huang;Dashun Guo;Yue Wang;Rong Xiong",
        "authorids": "/37088916597;/37086345520;/37089449301;/37089196655;/37072299700;/37271511300;/37088916597;/37086345520;/37089449301;/37089196655;/37072299700;/37271511300",
        "aff": "State Key Laboratory of Industrial Control Technology, Institute of CyberSystems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of CyberSystems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of CyberSystems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of CyberSystems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of CyberSystems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of CyberSystems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811547/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14042310794056369890&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology, Institute of CyberSystems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811934",
        "title": "Efficient and High-quality Prehensile Rearrangement in Cluttered and Confined Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Prehensile object rearrangement in cluttered and confined spaces has broad applications but is also challenging. For instance, rearranging products in a grocery shelf means that the robot cannot directly access all objects and has limited free space. This is harder than tabletop rearrangement where objects are easily accessible with top-down grasps, which simplifies robot-object interactions. This work focuses on problems where such interactions are critical for completing tasks. It proposes a new efficient and complete solver under general constraints for monotone instances, which can be solved by moving each object at most once. The monotone solver reasons about robot-object constraints and uses them to effectively prune the search space. The new monotone solver is integrated with a global planner to solve non-monotone instances with high-quality solutions fast. Furthermore, this work contributes an effective pre-processing tool to significantly speed up online motion planning queries for rearrangement in confined spaces. Experiments further demonstrate that the proposed monotone solver, equipped with the pre-processing tool, results in 57.3% faster computation and 3 times higher success rate than state-of-the-art methods. Similarly, the resulting global planner is computationally more efficient and has a higher success rate, while producing high-quality solutions for non-monotone instances (i.e., only 1.3 additional actions are needed on average). Videos of demonstrating solutions on a real robotic system and codes can be found at https://github.com/Rui1223/uniform_object_rearrangement.",
        "primary_area": "",
        "author": "Rui Wang;Yinglong Miao;Kostas E. Bekris;Rui Wang;Yinglong Miao;Kostas E. Bekris",
        "authorids": "/37088013751;/37088664214;/37282424700;/37088013751;/37088664214;/37282424700",
        "aff": "Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811934/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14752502603917242693&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812205",
        "title": "Efficient and Robust Semantic Mapping for Indoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "A key proficiency an autonomous mobile robot must have to perform high-level tasks is a strong understanding of its environment. This involves information about what types of objects are present, where they are, what their spatial extend is, and how they can be reached, i.e., information about free space is also crucial. Semantic maps are a powerful instrument providing such information. However, applying semantic segmentation and building 3D maps with high spatial resolution is challenging given limited resources on mobile robots. In this paper, we incorporate semantic information into efficient occupancy normal distribution transform (NDT) maps to enable real-time semantic mapping on mobile robots. On the publicly available dataset Hypersim, we show that, due to their sub-voxel accuracy, semantic NDT maps are superior to other approaches. We compare them to the recent state-of-the-art approach based on voxels and semantic Bayesian spatial kernel inference (S-BKI) and to an optimized version of it derived in this paper. The proposed semantic NDT maps can represent semantics to the same level of detail, while mapping is 2.7 to 17.5 times faster. For the same grid resolution, they perform significantly better, while mapping is up to more than 5 times faster. Finally, we prove the real-world applicability of semantic NDT maps with qualitative results in a domestic application.",
        "primary_area": "",
        "author": "Daniel Seichter;Patrick Langer;Tim Wengefeld;Benjamin Lewandowski;Dominik H\u00f6chemer;Horst-Michael Gross;Daniel Seichter;Patrick Langer;Tim Wengefeld;Benjamin Lewandowski;Dominik H\u00f6chemer;Horst-Michael Gross",
        "authorids": "/37085814238;/37089448939;/37085449849;/37086317277;/37088530949;/37270612700;/37085814238;/37089448939;/37085449849;/37086317277;/37088530949;/37270612700",
        "aff": "Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812205/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5056262098922824902&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Ilmenau",
        "aff_unique_dep": "Neuroinformatics and Cognitive Robotics Lab",
        "aff_unique_url": "https://www.tu-ilmenau.de",
        "aff_unique_abbr": "TU Ilmenau",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Ilmenau",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812274",
        "title": "Efficient and Robust Training of Dense Object Nets for Multi-Object Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a framework for robust and efficient training of Dense Object Nets (DON) [1] with a focus on industrial multi-object robot manipulation scenarios. DON is a popular approach to obtain dense, view-invariant object descriptors, which can be used for a multitude of downstream tasks in robot manipulation, such as, pose estimation, state representation for control, etc. However, the original work [1] focused training on singulated objects, with limited results on instance-specific, multi-object applications. Additionally, a complex data collection pipeline, including 3D reconstruction and mask annotation of each object, is required for training. In this paper, we further improve the efficacy of DON with a simplified data collection and training regime, that consistently yields higher precision and enables robust tracking of keypoints with less data requirements. In particular, we focus on training with multi-object data instead of singulated objects, combined with a well-chosen augmentation scheme. We additionally propose an alternative loss formulation to the original pixel wise formulation that offers better results and is less sensitive to hyperparameters. Finally, we demonstrate the robustness and accuracy of our proposed framework on a real-world robotic grasping task.",
        "primary_area": "",
        "author": "David B. Adrian;Andras Gabor Kupcsik;Markus Spies;Heiko Neumann;David B. Adrian;Andras Gabor Kupcsik;Markus Spies;Heiko Neumann",
        "authorids": "/37089449143;/37086548878;/37086300067;/37343707700;/37089449143;/37086548878;/37086300067;/37343707700",
        "aff": "Institute of Neural Information Processing, Ulm University, Ulm, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Bosch Center for Artificial Intelligence, Renningen, Germany; Institute of Neural Information Processing, Ulm University, Ulm, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812274/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14153369771519791114&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Ulm University;Bosch Center for Artificial Intelligence",
        "aff_unique_dep": "Institute of Neural Information Processing;Artificial Intelligence",
        "aff_unique_url": "https://www.uni-ulm.de;https://www.bosch-ai.com",
        "aff_unique_abbr": ";BCAI",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Ulm;Renningen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811688",
        "title": "Elastic Tracker: A Spatio-temporal Trajectory Planner for Flexible Aerial Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes Elastic Tracker, a flexible trajectory planning framework that can deal with challenging tracking tasks with guaranteed safety and visibility. Firstly, an object detection and intension-free motion prediction method is designed. Then an occlusion-aware path finding method is proposed to provide a proper topology. A smart safe flight corridor generation strategy is designed with the guiding path. An analytical occlusion cost is evaluated. Finally, an effective trajectory optimization approach enables to generate a spatio-temporal optimal trajectory within the resultant flight corridor. Particular formulations are designed to guarantee both safety and visibility, with all the above requirements optimized jointly. The experimental results show that our method works more robustly but with less computation than the existing methods, even in some challenging tracking tasks.",
        "primary_area": "",
        "author": "Jialin Ji;Neng Pan;Chao Xu;Fei Gao;Jialin Ji;Neng Pan;Chao Xu;Fei Gao",
        "authorids": "/37088999913;/37088986697;/37404060100;/37086045143;/37088999913;/37088986697;/37404060100;/37086045143",
        "aff": "The State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China; The State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China; The State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China; The State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811688/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13241866530502651603&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "College of Control Science and Engineering",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811746",
        "title": "ElectroVoxel: Electromagnetically Actuated Pivoting for Scalable Modular Self-Reconfigurable Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a cube-based reconfigurable robot that utilizes an electromagnet-based actuation framework to reconfigure in three dimensions via pivoting. While a variety of actuation mechanisms for self-reconfigurable robots have been explored, they often suffer from cost, complexity, assembly and sizing requirements that prevent scaled production of such robots. To address this challenge, we use an actuation mechanism based on electromagnets embedded into the edges of each cube to interchangeably create identically or oppositely polarized electromagnet pairs, resulting in repulsive or attractive forces, respectively. By leveraging attraction for hinge formation, and repulsion to drive pivoting maneuvers, we can reconfigure the robot by voxelizing it and actuating its constituent modules-termed Electrovoxels-via electromagnetically actuated pivoting. To demonstrate this, we develop fully untethered, three-dimensional self-reconfigurable robots and demonstrate 2D and 3D self-reconfiguration using pivot and traversal maneuvers on an air-table and in microgravity on a parabolic flight. This paper describes the hardware design of our robots, its pivoting framework, our reconfiguration planning software, and an evaluation of the dynamical and electrical characteristics of our system to inform the design of scalable self-reconfigurable robots.",
        "primary_area": "",
        "author": "Martin Nisser;Leon Cheng;Yashaswini Makaram;Ryo Suzuki;Stefanie Mueller;Martin Nisser;Leon Cheng;Yashaswini Makaram;Ryo Suzuki;Stefanie Mueller",
        "authorids": "/37086210728;/37089446625;/37089450450;/37086092004;/37086319276;/37086210728;/37089446625;/37089450450;/37086092004;/37086319276",
        "aff": "MIT CSAIL, Cambridge, MA; MIT CSAIL, Cambridge, MA; MIT CSAIL, Cambridge, MA; University of Calgary, Calgary, AB; MIT CSAIL, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811746/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3351426040332585516&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Calgary",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.ucalgary.ca",
        "aff_unique_abbr": "MIT CSAIL;U of C",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Cambridge;Calgary",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9811860",
        "title": "Energy Sharing Mechanism for a Freeform Robotic System - FreeBOT",
        "track": "main",
        "status": "Poster",
        "abstract": "Energy sharing in modular self-reconfigurable robots ensures the energy balance of the modules, thus allowing the system to work sustainably. This paper proposes an energy sharing mechanism for a novel modular self-reconfigurable robot that allows free connections among modules, termed as FreeBOT, such that each FreeBOT can share energy with peers through surface contact. Corresponding energy sharing rules are proposed to achieve an energy sharing network structure without invalid components. As alternative choices, several types of networks subjected to the above requirements are provided, which also maximize the number of FreeBOTs joining to share energy. We implement and test the prototype of the energy sharing mechanism on FreeBOT. The experimental results show that the mechanism can effectively achieve energy sharing among FreeBOTs.",
        "primary_area": "",
        "author": "Guanqi Liang;Yuxiao Tu;Lijun Zong;Junfeng Chen;Tin Lun Lam;Guanqi Liang;Yuxiao Tu;Lijun Zong;Junfeng Chen;Tin Lun Lam",
        "authorids": "/37088687610;/37089000919;/37088367008;/37089393433;/37571111600;/37088687610;/37089000919;/37088367008;/37089393433;/37571111600",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811860/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14091545836755932520&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_url": "https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812342",
        "title": "Energy Tank-Based Policies for Robust Aerial Physical Interaction with Moving Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Although manipulation capabilities of aerial robots greatly improved in the last decade, only few works addressed the problem of aerial physical interaction with dynamic environments, proposing strongly model-based approaches. However, in real scenarios, modeling the environment with high accuracy is often impossible. In this work, we aim at developing a control framework for Omnidirectional Micro Aerial Vehicles (OMAVs) for reliable physical interaction tasks with articulated and movable objects in the presence of possibly unforeseen disturbances, and without relying on an accurate model of the environment. Inspired by previous applications of energy-based controllers for physical interaction, we propose a passivity-based impedance and wrench tracking controller in combination with a momentum-based wrench estimator. This is combined with an energytank framework to guarantee the stability of the system, while energy and power flow-based adaptation policies are deployed to enable safe interaction with any type of passive environment. The control framework provides formal guarantees of stability, which is validated in practice considering the challenging task of pushing a cart of unknown mass, moving on a surface of unknown friction, as well as subjected to unknown disturbances. For this scenario, we present, evaluate and discuss three different policies.",
        "primary_area": "",
        "author": "Maximilian Brunner;Livio Giacomini;Roland Siegwart;Marco Tognon;Maximilian Brunner;Livio Giacomini;Roland Siegwart;Marco Tognon",
        "authorids": "/37086325079;/37089450056;/37281398300;/37085377048;/37086325079;/37089450056;/37281398300;/37085377048",
        "aff": "Autonomous Systems Lab at ETH Zurich; Autonomous Systems Lab at ETH Zurich; Autonomous Systems Lab at ETH Zurich; Autonomous Systems Lab at ETH Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812342/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12001637765618461126&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9811838",
        "title": "Enhanced Prototypical Learning for Unsupervised Domain Adaptation in LiDAR Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite its importance, unsupervised domain adaptation (UDA) on LiDAR semantic segmentation is a task that has not received much attention from the research community. Only recently, a completion-based 3 DD method has been proposed to tackle the problem and formally set up the adaptive scenarios. However, the proposed pipeline is complex, voxel-based and requires multi-stage inference, which inhibits it for real-time inference. We propose a range image-based, effective and efficient method for solving UDA on LiDAR segmentation. The method exploits class prototypes from the source domain to pseudo label target domain pixels, which is a research direction showing good performance in UDA for natural image semantic segmentation. Applying such approaches to LiDAR scans has not been considered because of the severe domain shift and lack of pre-trained feature extractor that is unavailable in the LiDAR segmentation setup. However, we show that proper strategies, including reconstruction-based pre-training, enhanced prototypes, and selective pseudo labeling based on distance to prototypes, is sufficient enough to enable the use of prototypical approaches. We evaluate the performance of our method on the recently proposed LiDAR segmentation UDA scenarios. Our method achieves remarkable performance among contemporary methods.",
        "primary_area": "",
        "author": "Eojindl Yi;JuYoung Yang;Junmo Kim;Eojindl Yi;JuYoung Yang;Junmo Kim",
        "authorids": "/37088689760;/37088688781;/37407301400;/37088689760;/37088688781;/37407301400",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST), Korea; Korea Advanced Institute of Science and Technology (KAIST), Korea; Korea Advanced Institute of Science and Technology (KAIST), Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811838/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12269194239320569183&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812322",
        "title": "Enhanced Spatial Attention Graph for Motion Planning in Crowded, Partially Observable Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Collision-free navigation while moving amongst static and dynamic obstacles with a limited sensor range is still a great challenge for modern mobile robots. Therefore, the ability to avoid collisions with obstacles in crowded, partially observable environments is one of the most important indicators to measure the navigation performance of a mobile robot. In this paper, we propose a novel deep reinforcement learning architecture that combines a spatial graph and attention rea-soning to tackle this problem. We take the relative positions and velocities of observed humans as nodes of the spatial graph and robot-human pairs as nodes of the attention graph to capture the spatial relations between the robot and the humans. In this way, our approach enhances the modeling of the relationship between the moving robot, static obstacles, and the people in the surrounding. As a result, our proposed navigation framework significantly outperforms state-of-the-art approaches [1], [2] in crowded scenarios when the robot has only a limited sensor range in terms of a reduced collision rate. Furthermore, we realize a seriously decreased training time by applying parallel Double Deep Q-Learning.",
        "primary_area": "",
        "author": "Weixian Shi;Yanying Zhou;Xiangyu Zeng;Shijie Li;Maren Bennewitz;Weixian Shi;Yanying Zhou;Xiangyu Zeng;Shijie Li;Maren Bennewitz",
        "authorids": "/37089447446;/37089320495;/37089449730;/37088698453;/37324765000;/37089447446;/37089320495;/37089449730;/37088698453;/37324765000",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812322/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7061873002280215321&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811706",
        "title": "Enhancing Data-Driven Reachability Analysis using Temporal Logic Side Information",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents algorithms for performing data-driven reachability analysis under temporal logic side information. In certain scenarios, the data-driven reachable sets of a robot can be prohibitively conservative due to the inherent noise in the robot's historical measurement data. In the same scenarios, we often have side information about the robot's expected motion (e.g., limits on how much a robot can move in a one-time step) that could be useful for further specifying the reachability analysis. In this work, we show that if we can model this side information using a signal temporal logic (STL) fragment, we can constrain the data-driven reachability analysis and safely limit the conservatism of the computed reachable sets. Moreover, we provide formal guarantees that, even after incorporating side information, the computed reachable sets still properly over-approximate the robot's future states. Lastly, we empirically validate the prac-ticality of the over-approximation by computing constrained, data-driven reachable sets for the Small- Vehicles-for-Autonomy (SVEA) hardware platform in two driving scenarios.",
        "primary_area": "",
        "author": "Amr Alanwar;Frank J. Jiang;Maryam Sharifi;Dimos V. Dimarogonas;Karl H. Johansson;Amr Alanwar;Frank J. Jiang;Maryam Sharifi;Dimos V. Dimarogonas;Karl H. Johansson",
        "authorids": "/37085626722;/37088333632;/37085631972;/37282084700;/37270842500;/37085626722;/37088333632;/37085631972;/37282084700;/37270842500",
        "aff": "Division of Decision and Control Systems, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Decision and Control Systems, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Decision and Control Systems, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Decision and Control Systems, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Decision and Control Systems, EECS, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811706/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16454322832112461305&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "Division of Decision and Control Systems",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9812341",
        "title": "Enhancing Deep Reinforcement Learning Approaches for Multi-Robot Navigation via Single-Robot Evolutionary Policy Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent Multi-Agent Deep Reinforcement Learning approaches factorize a global action-value to address non-stationarity and favor cooperation. These methods, however, hinder exploration by introducing constraints (e.g., additive value-decomposition) to guarantee the factorization. Our goal is to enhance exploration and improve sample efficiency of multi-robot mapless navigation by incorporating a periodical Evolutionary Policy Search (EPS). In detail, the multi-agent training \u201cspecializes\u201d the robots' policies to learn the collision avoidance skills that are mandatory for the task. Concurrently, in this work we propose the use of Evolutionary Algorithms to explore different regions of the policy space in an environment with only a single robot. The idea is that core navigation skills, originated by the multi-robot policies using mutation operators, improve faster in the single-robot EPS. Hence, policy parameters can be injected into the multi-robot setting using crossovers, leading to improved performance and sample efficiency. Experiments in tasks with up to 12 robots confirm the beneficial transfer of navigation skills from the EPS to the multi-robot setting, improving the performance of prior methods.",
        "primary_area": "",
        "author": "Enrico Marchesini;Alessandro Farinelli;Enrico Marchesini;Alessandro Farinelli",
        "authorids": "/37086805241;/37266396700;/37086805241;/37266396700",
        "aff": "Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812341/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1132603487349232313&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Verona",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.univr.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Verona",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9812225",
        "title": "Enhancing Flexibility and Adaptability in Conjoined Human-Robot Industrial Tasks with a Minimalist Physical Interface",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a physical interface for collaborative mobile manipulators in industrial manufacturing and logistics applications. The proposed work builds on our earlier MOCA-MAN interface, through which an operator could be physically coupled to a mobile manipulator to be assisted in performing daily activities. The previous interface was based on a magnetic clamp attached to one arm of the user for the coupling stage, and a bracelet based on EMG sensors on the other arm for human-robot communication via gestures. The new interface instead presents the following additions: i) An industrial-like design that allows the worker to couple/decouple easily and to operate mobile manipulators locally; ii) A simplistic communication channel via a simple buttons board that allows controlling the robot with one hand only; iii) The interface offers enhanced loco-manipulation capabilities that do not compromise the worker mobility. In addition, an experimental evaluation with six human subjects is carried out to analyze the enhanced locomotion and flexibility of the proposed interface in terms of mobility constraint, usability, and physical load reduction.",
        "primary_area": "",
        "author": "Juan M. Gandarias;Pietro Balatti;Edoardo Lamon;Marta Lorenzini;Arash Ajoudani;Juan M. Gandarias;Pietro Balatti;Edoardo Lamon;Marta Lorenzini;Arash Ajoudani",
        "authorids": "/37086294706;/37086577439;/37086599073;/37086249968;/37945239900;/37086294706;/37086577439;/37086599073;/37086249968;/37945239900",
        "aff": "HRI2 Lab, Istituto Italiano di Tecnologia, Genoa, Italy; HRI2 Lab, Istituto Italiano di Tecnologia, Genoa, Italy; HRI2 Lab, Istituto Italiano di Tecnologia, Genoa, Italy; HRI2 Lab, Istituto Italiano di Tecnologia, Genoa, Italy; HRI2 Lab, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812225/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5832163629811501938&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "HRI2 Lab",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9812061",
        "title": "Enhancing Maneuverability via Gait Design",
        "track": "main",
        "status": "Poster",
        "abstract": "The gaits of locomoting systems are typically designed to maximize some sort of efficiency, such as cost of transport or speed. Equally important is the ability to modulate such a gait to effect turning maneuvers. For drag-dominated systems, geometric mechanics provides an elegant and practical framework for both ends\u2014gait design and gait modulation. Within this framework, \u201cconstraint curvature\u201d maps can be used to approximate the net displacement of robotic systems over cyclic gaits. Gait optimization is made possible under a previously reported \u201csoap-bubble\u201d algorithm. In this work, we propose both local and global gait morphing algorithms to modify a nominal gait to provide single-parameter steering control. Using a simplified swimmer, we numerically compare the two approaches and show that for modest turns, the local approach, while suboptimal, nevertheless proves effective for steering control. A potential advantage of the local approach is that it can be readily applied to soft robots or other systems where local approximations to the constraint curvature can be garnered from data, but for which obtaining an exact global model is infeasible.",
        "primary_area": "",
        "author": "Siming Deng;Ross L. Hatton;Noah J. Cowan;Siming Deng;Ross L. Hatton;Noah J. Cowan",
        "authorids": "/37089450605;/37542919100;/37326414200;/37089450605;/37542919100;/37326414200",
        "aff": "Department of Mechanical Engineering, Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical, Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Industrial & Manufacturing Engineering, Oregon State University, Corvallis, OR, USA; Department of Mechanical Engineering, Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812061/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11357959748453314577&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Johns Hopkins University;Oregon State University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical, Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Industrial & Manufacturing Engineering",
        "aff_unique_url": "https://www.jhu.edu;https://oregonstate.edu",
        "aff_unique_abbr": "JHU;OSU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Baltimore;Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811710",
        "title": "Ensemble Kalman Filter Based LiDAR Odometry for Skewed Point Clouds Using Scan Slicing",
        "track": "main",
        "status": "Poster",
        "abstract": "In the presence of fast motion, point clouds obtained from mechanical spinning LiDAR can be easily distorted due to the slow scanning speed of the LiDAR. Existing LiDAR-only odometry algorithms generally ignore this distortion or compensate by linearly interpolating the estimated relative motion between scans. However, when there are abrupt and nonlinear motion changes, the linear interpolation method poorly compensates for the distortions, which can cause significant drift in motion estimates. In this work, we present a LiDAR-only odometry algorithm that estimates motion by slicing LiDAR scans into shorter times to compensate more agilely for point cloud distortions. Observations from only one small scan slice inevitably lack spatial uniqueness, so the multimodal problem needs to be addressed. For LiDAR-only odometry with small scan slices, we introduce the ensemble Kalman filter, a kind of Monte Carlo-based Bayesian filter. The proposed method makes it possible to perform odometry with only a very narrow field of view (FoV), and the robustness to point cloud distortion is improved. We demonstrate the effectiveness of the proposed method through Monte Carlo simulations and several tests with fast-moving scenarios. The experimental results prove the possibility of odometry with a very narrow FoV of down to 10 degrees and robustness against motion distortion.",
        "primary_area": "",
        "author": "Yeongkwon Choe;Jae Hyung Jung;Chan Gook Park;Yeongkwon Choe;Jae Hyung Jung;Chan Gook Park",
        "authorids": "/37089176308;/37086436394;/37614648200;/37089176308;/37086436394;/37614648200",
        "aff": "Mobility Platform Research Center, Korea Electronics Technology Institute (KETI), Seongnam, Republic of Korea; Department of Aerospace Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, Republic of Korea; Department of Aerospace Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811710/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1798288164192662882&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Korea Electronics Technology Institute;Seoul National University",
        "aff_unique_dep": "Mobility Platform Research Center;Department of Aerospace Engineering, Automation and Systems Research Institute",
        "aff_unique_url": "http://www.keti.re.kr;https://www.snu.ac.kr",
        "aff_unique_abbr": "KETI;SNU",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Seongnam;Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811778",
        "title": "Equivariant Filter Design for Inertial Navigation Systems with Input Measurement Biases",
        "track": "main",
        "status": "Poster",
        "abstract": "Inertial Navigation Systems (INS) are a key technology for autonomous vehicles applications. Recent advances in estimation and filter design for the INS problem have exploited geometry and symmetry to overcome limitations of the classical Extended Kalman Filter (EKF) approach that formed the mainstay of INS systems since the mid-twentieth century. The industry standard INS filter, the Multiplicative Extended Kalman Filter (MEKF), uses a geometric construction for attitude estimation coupled with classical Euclidean construction for position, velocity and bias estimation. The recent Invariant Extended Kalman Filter (IEKF) provides a geometric framework for the full navigation states, integrating attitude, position and velocity, but still uses the classical Euclidean construction to model the bias states. In this paper, we use the recently proposed Equivariant Filter (EqF) framework to derive a novel observer for biased inertial-based navigation in a fully geometric framework. The introduction of virtual velocity inputs with associated virtual bias leads to a full equivariant symmetry on the augmented system. The resulting filter performance is evaluated with both simulated and real-world data, and demonstrates increased robustness to a wide range of erroneous initial conditions, and improved accuracy when compared with the industry standard Multiplicative EKF (MEKF) approach.",
        "primary_area": "",
        "author": "Alessandro Fornasier;Yonhon Ng;Robert Mahony;Stephan Weiss;Alessandro Fornasier;Yonhon Ng;Robert Mahony;Stephan Weiss",
        "authorids": "/37088685957;/37086203065;/37283743600;/37535323400;/37088685957;/37086203065;/37283743600;/37535323400",
        "aff": "Alessandro Fornasier and Stephan Weiss are with the Control of Networked Systems Group, University of Klagenfurt, Austria; Yonhon Ng and Robert Mahony are with the System Theory and Robotics Lab, Australian National University, Australia; Yonhon Ng and Robert Mahony are with the System Theory and Robotics Lab, Australian National University, Australia; Alessandro Fornasier and Stephan Weiss are with the Control of Networked Systems Group, University of Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811778/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2847004566321309646&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Klagenfurt;Australian National University",
        "aff_unique_dep": "Control of Networked Systems Group;System Theory and Robotics Lab",
        "aff_unique_url": "https://www.uni-klagenfurt.at;https://www.anu.edu.au",
        "aff_unique_abbr": ";ANU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Austria;Australia"
    },
    {
        "id": "9811733",
        "title": "Estimation of Upper Limb Kinematics with a Magnetometer-Free Egocentric Visual-Inertial System",
        "track": "main",
        "status": "Poster",
        "abstract": "Most human activities in daily living or professional work rely on upper body motion. Measuring upper body motion is essential for many applications such as health evaluation, rehabilitation, human power augmentation, skill transferring, etc. Computer vision-based systems have been widely used to directly capture upper limb motion but are usually constrained in a restricted area. Wearable sensors such as inertial measurement units (IMUs) are promising to enable ambulant and out-of-lab measurements but also suffer from issues such as magnetic distortion and drifting. Some visual-inertial systems have been proposed recently to fuse these two complementary measurements but mostly apply in a restricted area. In this paper, we propose a fully wearable egocentric visual-inertial system to estimate the upper-limb pose. Magnetometers are not used to allow the system to work in complex industrial and daily living scenarios or to be integrated with motorized assistive devices. Methods to automatically calibrate the sensor-to-segment alignment and estimate upper body motion is presented and validated with an optical motion capture system. Experimental results showed the system can estimate the joint angles without drift and obtain accurate wrist position even with occlusion, verifying the efficacy of the proposed system and method.",
        "primary_area": "",
        "author": "Tong Li;Xiaoyu Wu;Huixu Dong;Haoyong Yu;Tong Li;Xiaoyu Wu;Huixu Dong;Haoyong Yu",
        "authorids": "/37085584021;/37087004766;/37086340778;/37711526800;/37085584021;/37087004766;/37086340778;/37711526800",
        "aff": "Department of Biomedical Engineering, National University of Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811733/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17849513426011549595&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9811924",
        "title": "Evaluation of Runtime Monitoring for UAV Emergency Landing",
        "track": "main",
        "status": "Poster",
        "abstract": "To certify UAV operations in populated areas, risk mitigation strategies - such as Emergency Landing (EL) - must be in place to account for potential failures. EL aims at reducing ground risk by finding safe landing areas using on-board sensors. The first contribution of this paper is to present a new EL approach, in line with safety requirements introduced in recent research. In particular, the proposed EL pipeline includes mechanisms to monitor learning based components during execution. This way, another contribution is to study the behavior of Machine Learning Runtime Monitoring (MLRM) approaches within the context of a real-world critical system. A new evaluation methodology is introduced, and applied to assess the practical safety benefits of three MLRM mechanisms. The proposed approach is compared to a default mitigation strategy (open a parachute when a failure is detected), and appears to be much safer.",
        "primary_area": "",
        "author": "Joris Guerin;Kevin Delmas;J\u00e9r\u00e9mie Guiochet;Joris Guerin;Kevin Delmas;J\u00e9r\u00e9mie Guiochet",
        "authorids": "/37086105036;/37086004252;/37937604500;/37086105036;/37086004252;/37937604500",
        "aff": "ONERA, Toulouse, France; ONERA, Toulouse, France; LAAS-CNRS",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811924/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9272880908976035587&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "ONERA;LAAS-CNRS",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.onera.fr;https://www.laas.fr/",
        "aff_unique_abbr": "ONERA;LAAS-CNRS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toulouse;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812326",
        "title": "Event-Triggered Tracking Control Scheme for Quadrotors with External Disturbances: Theory and Validations",
        "track": "main",
        "status": "Poster",
        "abstract": "This article studies the tracking control of a quadrotor unmanned aerial vehicle (UAV) under time-varying external disturbances. An event-triggered sliding mode control (SMC) strategy is proposed by introducing a new triggering condition form of desired trajectory, quadrotor position, and velocity. In the sense of Lyapunov theory, the stability of the entire closed-loop control system is analyzed, and it is proved that the tracking error is adjusted to an adjustable set around zero. We show that the Zeno phenomenon can be avoided; that is, a positive minimum inter-event time is assured. One of the salient features of the proposed strategy is that it can reduce the update frequency of the control efforts, thereby ensuring desirable tracking performance under limited communication bandwidth. Comparative simulation and experimental results are provided to show the efficacy of our framework.",
        "primary_area": "",
        "author": "Pengcheng Gao;Gang Wang;Yunfeng Ji;Qingdu Li;Jianwei Zhang;Yantao Shen;Peng Li;Pengcheng Gao;Gang Wang;Yunfeng Ji;Qingdu Li;Jianwei Zhang;Yantao Shen;Peng Li",
        "authorids": "/37089447092;/37085379673;/37087324684;/37089197601;/37281460600;/37274462800;/534978802022421;/37089447092;/37085379673;/37087324684;/37089197601;/37281460600;/37274462800;/534978802022421",
        "aff": "University of Shanghai for Science and Technology, Shanghai, China; University of Shanghai for Science and Technology, Shanghai, China; University of Shanghai for Science and Technology, Shanghai, China; University of Shanghai for Science and Technology, Shanghai, China; Department of Informatics, University of Hamburg, Germany; Department of Electrical & Biomedical Engineering, University of Nevada, Reno, NV, USA; HIT-Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812326/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5798974813875586973&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;3",
        "aff_unique_norm": "University of Shanghai for Science and Technology;University of Hamburg;University of Nevada, Reno;Harbin Institute of Technology",
        "aff_unique_dep": ";Department of Informatics;Department of Electrical & Biomedical Engineering;",
        "aff_unique_url": "https://www.ust.sh.cn;https://www.uni-hamburg.de;https://www.unr.edu;http://www.hit.edu.cn/",
        "aff_unique_abbr": "USST;;UNR;HIT",
        "aff_campus_unique_index": "0;0;0;0;2;3",
        "aff_campus_unique": "Shanghai;;Reno;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;1;2;0",
        "aff_country_unique": "China;Germany;United States"
    },
    {
        "id": "9812149",
        "title": "Evolved neuromorphic radar-based altitude controller for an autonomous open-source blimp",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic airships offer significant advantages in terms of safety, mobility, and extended flight times. However, their highly restrictive weight constraints pose a major challenge regarding the available computational resources to perform the required control tasks. Neuromorphic computing stands for a promising research direction for addressing such problem. By mimicking the biological process for transferring information between neurons using spikes or impulses, spiking neural networks (SNNs) allow for low power consumption and asynchronous event-driven processing. In this paper, we propose an evolved altitude controller based on an SNN for a robotic airship which relies solely on the sensory feedback provided by an airborne radar. Starting from the design of a lightweight, low-cost, open-source airship, we also present an SNN-based controller architecture, an evolutionary framework for training the network in a simulated environment, and a control strategy for ameliorating the gap with reality. The system's performance is evaluated through real-world experiments, demonstrating the advantages of our approach by comparing it with an artificial neural network and a linear controller. The results show an accurate tracking of the altitude command with an efficient control effort.",
        "primary_area": "",
        "author": "Marina Gonz\u00e1lez-\u00c1lvarez;Julien Dupeyroux;Federico Corradi;Guido C.H.E. De Croon;Marina Gonz\u00e1lez-\u00c1lvarez;Julien Dupeyroux;Federico Corradi;Guido C.H.E. De Croon",
        "authorids": "/37089447705;/37086222518;/38548217900;/37698062600;/37089447705;/37086222518;/38548217900;/37698062600",
        "aff": "Micro Air Vehicle Laboratory, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Micro Air Vehicle Laboratory, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Ultra Low Power Systems for IoT, Stichting IMEC Nederland, Eindhoven, The Netherlands; Micro Air Vehicle Laboratory, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812149/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13844609793645641465&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Delft University of Technology;Stichting IMEC Nederland",
        "aff_unique_dep": "Faculty of Aerospace Engineering;Ultra Low Power Systems for IoT",
        "aff_unique_url": "https://www.tudelft.nl;https://www.imec-int.com",
        "aff_unique_abbr": "TU Delft;IMEC",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Delft;Eindhoven",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9812301",
        "title": "Ex-DoF: Expansion of Action Degree-of-Freedom with Virtual Camera Rotation for Omnidirectional Image",
        "track": "main",
        "status": "Poster",
        "abstract": "Inter-robot transfer of training data is a little explored topic in learning- and vision-based robot control. Here we propose a transfer method from a robot with a lower Degree-of-Freedom (DoF) to one with a higher DoF utilizing the omnidirectional camera image. The virtual rotation of the robot camera enables data augmentation in this transfer learning process. As an experimental demonstration, a vision-based control policy for a 6- DoF robot is trained using a dataset collected by a wheeled ground robot with only three DoFs. Towards the application of robotic manipulations, we also demonstrate a control system of a 6- DoF arm robot using multiple policies with different fields of view to enable object reaching tasks.",
        "primary_area": "",
        "author": "Kosuke Tahara;Noriaki Hirose;Kosuke Tahara;Noriaki Hirose",
        "authorids": "/37087107692;/37574851500;/37087107692;/37574851500",
        "aff": "Toyota Central R&D Labs.; Toyota Central R&D Labs.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812301/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=46039465561228100&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Toyota Central R&D Labs",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.toyota-global.com",
        "aff_unique_abbr": "Toyota R&D",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811913",
        "title": "Exact-likelihood User Intention Estimation for Scene-compliant Shared-control Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "A predictive model for mobility systems capable of understanding the trajectory a user intends to follow in the environment is proposed. Understanding user intention is paramount for any shared-control navigation strategy between a user and an active robotic agent. Equally important however is being able to go beyond simple sample generation to assign probabilistic meaning to the set of possible future trajectories, so most likely scenarios can be assumed. The framework estimates a distribution over possible intentions, proposing a novel generative model predicated on Normalizing Flows which accounts for past behaviours, as traditionally reported in the literature, but also incorporates visual scene information. As the model permits trajectories to be assigned exact likelihoods, tractable density estimates can be readily exploited to finalize an executable intention. Baseline comparisons with the publicly available and widely used KITTI navigational dataset show significant improvements (up to 11.08%) with respect to traditional metrics such as Average and Final Displacement Errors. A novel metric that stands independent of the number of samples is also proposed as a more fitting comparison for future works.",
        "primary_area": "",
        "author": "Kavindie Katuwandeniya;Stefan H. Kiss;Lei Shi;Jaime Valls Miro;Kavindie Katuwandeniya;Stefan H. Kiss;Lei Shi;Jaime Valls Miro",
        "authorids": "/37086555084;/37088995973;/37589838200;/37411105600;/37086555084;/37088995973;/37589838200;/37411105600",
        "aff": "Robotics Institute, University of Technology, Sydney, Australia; Robotics Institute, University of Technology, Sydney, Australia; Robotics Institute, University of Technology, Sydney, Australia; Robotics Institute, University of Technology, Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811913/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13648163963074765774&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9812156",
        "title": "Expanding the Design Space for Electrically-Driven Soft Robots Through Handed Shearing Auxetics",
        "track": "main",
        "status": "Poster",
        "abstract": "Handed Shearing Auxetics (HSA) are a promising structure for making electrically driven robots with distributed compliance that convert a motors rotation and torque into extension and force. These structures expand and contract by changing an internal angle between links, the evolution of the structure as this angle changes is known as the auxetic trajectory. We overcome past limitations on the range of actuation, blocked force, and stiffness by focusing on two key design parameters: the point of an HSA's auxetic trajectory that is energetically preferred, and the number of cells along the HSAs length. Modeling the HSA as a programmable spring, we characterize the effect of both on blocked force, minimum energy length, spring constant, angle range and holding torque. We also examined the effect viscoelasticity has on actuation forces over time. By varying the preferred auxetic trajectory point, we were able to make actuators that can push, pull, or do both. We expanded the range of forces possible from 5 N to 150 N, and the range of stiffness from 2 N/mm to 89 N/mm. For a fixed point on the auxetic trajectory, we found decreasing length can improve force output, at the expense of needing higher torques, and having a shorter throw. We also found that the viscoelastic effects can limit the amount of force a 3D printed HSA can apply over time.",
        "primary_area": "",
        "author": "Ian Good;Tosh Brown-Moore;Aditya Patil;Daniel Revier;Jeffrey Ian Lipton;Ian Good;Tosh Brown-Moore;Aditya Patil;Daniel Revier;Jeffrey Ian Lipton",
        "authorids": "/37089372037;/37089449113;/37089450225;/37085466295;/37086014107;/37089372037;/37089449113;/37089450225;/37085466295;/37086014107",
        "aff": "Mechanical Engineering Department, University of Washington, Seattle, WA, USA; Mechanical Engineering Department, University of Washington, Seattle, WA, USA; Mechanical Engineering Department, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science and Engineering, The University of Washington, Seattle, WA; Paul G. Allen School of Computer Science and Engineering, The University of Washington, Seattle, WA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812156/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17393222800178350018&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811546",
        "title": "Experimental Validation of the Usage of Kinematic Singularities to Produce Periodic High-Powered Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper reports on preliminary experimental results of recently proposed mechanism kinematics for a legged robot. The proposed kinematics creates a mapping from a series-elastic actuator to a foot motion that includes a pair of singularities within a fully rotatable kinematic circuit. Such a circuit is less common and only possible with certain multi-loop linkages. A slice of the configuration space displaying series-elastic rotation versus linear foot motion presents a characteristic \u201cS\u201d shape, motivating the name S-curve kinematics. Our experimental results show that S-curve kinematics can enhance the energetic output of a series-elastic actuator in a hopping task versus the usage of a conventional rotary-to-linear mechanism. This is possible because S-curve kinematics enable elastic energy storage outside of stance that is released through a mechanical reflex. Compared to a conventional rotary-to-linear actuator, S-curve kinematics demonstrated up to a 4x increase in kinetic output.",
        "primary_area": "",
        "author": "Chang Liu;Mark Plecnik;Chang Liu;Mark Plecnik",
        "authorids": "/37089194305;/37085786438;/37089194305;/37085786438",
        "aff": "Department of Aerospace & Mechanical Engineering, University of Notre Dame; Department of Aerospace & Mechanical Engineering, University of Notre Dame",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811546/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:hxrwEvKAxKsJ:scholar.google.com/&scioq=Experimental+Validation+of+the+Usage+of+Kinematic+Singularities+to+Produce+Periodic+High-Powered+Motion&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace & Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812235",
        "title": "Experiments in Adaptive Replanning for Fast Autonomous Flight in Forests",
        "track": "main",
        "status": "Poster",
        "abstract": "Fast, autonomous flight in unstructured, cluttered environments such as forests is challenging because it requires the robot to compute new plans in realtime on a computationally-constrained platform. In this paper, we enable this capability with a search-based planning framework that adapts sampling density in realtime to find dynamically-feasible plans while remaining computationally tractable. A paramount challenge in search-based planning is that dense obstacles both necessitate large graphs (to guarantee completeness) and reduce the efficiency of graph search (as heuristics become less accurate). To address this, we develop a planning framework with two parts: one that maximizes planner completeness for a given graph size, and a second that dynamically maximizes graph size subject to computational constraints. This framework is enabled by motion planning graphs that are defined by a single parameter-dispersion-which quantifies the maximum trajectory cost to reach an arbitrary state from the graph. We show through real and simulated experiments how the dispersion can be adapted to different environments in realtime, allowing operation in environments with varying density. The simulated experiment demonstrates improved performance over a baseline search-based planning algorithm. We also demonstrate flight speeds of up to 2.5m/s in real-world cluttered pine forests.",
        "primary_area": "",
        "author": "Laura Jarin-Lipschitz;Xu Liu;Yuezhan Tao;Vijay Kumar;Laura Jarin-Lipschitz;Xu Liu;Yuezhan Tao;Vijay Kumar",
        "authorids": "/37087015656;/37086578226;/37089337827;/37280341400;/37087015656;/37086578226;/37089337827;/37280341400",
        "aff": "GRASP Laboratory, University of Pennsylvania, PA, USA; GRASP Laboratory, University of Pennsylvania, PA, USA; GRASP Laboratory, University of Pennsylvania, PA, USA; GRASP Laboratory, University of Pennsylvania, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812235/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12163703483652816212&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811652",
        "title": "Exploiting Abstract Symmetries in Reinforcement Learning for Complex Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning is rapidly establishing itself as the foremost choice for optimization of sequential autonomous decision-making problems. Encumbered by its sample inefficiency, the extension of the field to large state space and dynamic environments remains an open problem. We present a novel concept that exploits abstract spatial symmetry in complex environments for extending the skills of na\u00efvely trained agents in local abstractions of the environment. The concept of EASE (Exploitation of Abstract Symmetry of Environments), when incorporated, improves the sample efficiency of traditional reinforcement learning algorithms. The presented work exemplifies the concept of EASE by presenting three distinct settings; EASE with heuristics-based planning, EASE with learning from demonstrations and EASE with state-space abstraction and proposes a novel algorithm for each setting.",
        "primary_area": "",
        "author": "Kashish Gupta;Homayoun Najjaran;Kashish Gupta;Homayoun Najjaran",
        "authorids": "/37086323141;/37284326900;/37086323141;/37284326900",
        "aff": "School of Engineering, The University of British Columbia, Kelowna, BC, Canada; School of Engineering, The University of British Columbia, Kelowna, BC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811652/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5448048298754325466&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of British Columbia",
        "aff_unique_dep": "School of Engineering",
        "aff_unique_url": "https://www.ubc.ca",
        "aff_unique_abbr": "UBC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kelowna",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9811722",
        "title": "Exploiting Playbacks in Unsupervised Domain Adaptation for 3D Object Detection in Self-Driving Cars",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-driving cars must detect other traffic participants like vehicles and pedestrians in 3D in order to plan safe routes and avoid collisions. State-of-the-art 3D object detectors, based on deep learning, have shown promising accuracy but are prone to over-fit domain idiosyncrasies, making them fail in new environments-a serious problem for the robustness of self-driving cars. In this paper, we propose a novel learning approach that reduces this gap by fine-tuning the detector on high-quality pseudo-labels in the target domain - pseudo-labels that are automatically generated after driving based on replays of previously recorded driving sequences. In these replays, object tracks are smoothed forward and backward in time, and detections are interpolated and extrapolated-crucially, leveraging future information to catch hard cases such as missed detections due to occlusions or far ranges. We show, across five autonomous driving datasets, that fine-tuning the object detector on these pseudo-labels substantially reduces the domain gap to new driving environments, yielding strong improvements detection reliability and accuracy.",
        "primary_area": "",
        "author": "Yurong You;Carlos Andres Diaz-Ruiz;Yan Wang;Wei-Lun Chao;Bharath Hariharan;Mark Campbell;Kilian Q Weinberger;Yurong You;Carlos Andres Diaz-Ruiz;Yan Wang;Wei-Lun Chao;Bharath Hariharan;Mark Campbell;Kilian Q Weinberger",
        "authorids": "/37086571297;/37087012336;/37086565708;/37086876034;/38232046900;/37272971700;/37282690200;/37086571297;/37087012336;/37086565708;/37086876034;/38232046900;/37272971700;/37282690200",
        "aff": "Computer Science Department, Cornell University; Mechanical and Aerospace Engineering Department, Cornell University; Computer Science Department, Cornell University; Department of Computer Science and Engineering, Ohio State University; Computer Science Department, Cornell University; Mechanical and Aerospace Engineering Department, Cornell University; Computer Science Department, Cornell University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811722/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18399924851470756445&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "Cornell University;Ohio State University",
        "aff_unique_dep": "Computer Science Department;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.cornell.edu;https://www.osu.edu",
        "aff_unique_abbr": "Cornell;OSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811892",
        "title": "Exploration with Global Consistency Using Real-Time Re-integration and Active Loop Closure",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite recent progress of robotic exploration, most methods assume that drift-free localization is available, which is problematic in reality and causes severe distortion of the reconstructed map. In this work, we present a systematic exploration mapping and planning framework that deals with drifted localization, allowing efficient and globally consistent reconstruction. A real-time re-integration-based mapping approach along with a frame pruning mechanism is proposed, which rectifies map distortion effectively when drifted localization is corrected upon detecting loop-closure. Besides, an exploration planning method considering historical viewpoints is presented to enable active loop closing, which promotes a higher opportunity to correct localization errors and further improves the mapping quality. We evaluate both the mapping and planning methods as well as the entire system comprehensively in simulation and real-world experiments, showing their effectiveness in practice. The implementation of the proposed method will be made open-source for the benefit of the robotics community.",
        "primary_area": "",
        "author": "Yichen Zhang;Boyu Zhou;Luqi Wang;Shaojie Shen;Yichen Zhang;Boyu Zhou;Luqi Wang;Shaojie Shen",
        "authorids": "/37088504984;/37086574790;/37086690004;/37954847200;/37088504984;/37086574790;/37086690004;/37954847200",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811892/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16539115164091650203&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812344",
        "title": "Explore-Bench: Data Sets, Metrics and Evaluations for Frontier-based and Deep-reinforcement-learning-based Autonomous Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous exploration and mapping of unknown terrains employing single or multiple robots is an essential task in mobile robotics and has therefore been widely investigated. Nevertheless, given the lack of unified data sets, metrics, and platforms to evaluate the exploration approaches, we develop an autonomous robot exploration benchmark en-titled Explore-Bench. The benchmark involves various explo-ration scenarios and presents two types of quantitative metrics to evaluate exploration efficiency and multi-robot cooperation. Explore-Bench is extremely useful as, recently, deep rein-forcement learning (DRL) has been widely used for robot exploration tasks and achieved promising results. However, training DRL-based approaches requires large data sets, and additionally, current benchmarks rely on realistic simulators with a slow simulation speed, which is not appropriate for training exploration strategies. Hence, to support efficient DRL training and comprehensive evaluation, the suggested Explore-Bench designs a 3-level platform with a unified data flow and 12 \u00d7 speed-up that includes a grid-based simulator for fast evaluation and efficient training, a realistic Gazebo simulator, and a remotely accessible robot testbed for high-accuracy tests in physical environments. The practicality of the proposed benchmark is highlighted with the application of one DRL-based and three frontier-based exploration approaches. Fur-thermore, we analyze the performance differences and provide some insights about the selection and design of exploration methods. Our benchmark is available at https://github.com/efc-robot/Explore-Bench.",
        "primary_area": "",
        "author": "Yuanfan Xu;Jincheng Yu;Jiahao Tang;Jiantao Qiu;Jian Wang;Yuan Shen;Yu Wang;Huazhong Yang;Yuanfan Xu;Jincheng Yu;Jiahao Tang;Jiantao Qiu;Jian Wang;Yuan Shen;Yu Wang;Huazhong Yang",
        "authorids": "/37088526163;/37086203732;/37089292464;/37085859616;/37406476300;/37400482800;/37293645500;/37291236500;/37088526163;/37086203732;/37089292464;/37085859616;/37406476300;/37400482800;/37293645500;/37291236500",
        "aff": "Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812344/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=908825885425509639&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Electronic Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811704",
        "title": "Extrinsic Calibration and Verification of Multiple Non-overlapping Field of View Lidar Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "We demonstrate a multi-lidar calibration frame-work for large mobile platforms that jointly calibrate the extrinsic parameters of non-overlapping Field-of-View (FoV) lidar sensors, without the need for any external calibration aid. The method starts by estimating the pose of each lidar in its corresponding sensor frame in between subsequent timestamps. Since the pose estimates from the lidars are not necessarily synchronous, we first align the poses using a Dual Quaternion (DQ) based Screw Linear Interpolation. Afterward, a Hand-Eye based calibration problem is solved using the DQ-based formulation to recover the extrinsics. Furthermore, we verify the extrinsics by matching chosen lidar semantic features, obtained by projecting the lidar data into the camera perspective after time alignment using vehicle kinematics. Experimental results on the data collected from a Scania vehicle [~ 1 Km sequence] demonstrate the ability of our approach to obtain better calibration parameters than the provided vehicle CAD model calibration parameters. This setup can also be scaled to any combination of multiple lidars.",
        "primary_area": "",
        "author": "Sandipan Das;Navid Mahabadi;Addi Djikic;Cesar Nassir;Saikat Chatterjee;Maurice Fallon;Sandipan Das;Navid Mahabadi;Addi Djikic;Cesar Nassir;Saikat Chatterjee;Maurice Fallon",
        "authorids": "/37088698440;/37089447807;/37089447078;/37089449060;/37626130500;/37540365100;/37088698440;/37089447807;/37089447078;/37089449060;/37626130500;/37540365100",
        "aff": "Scania CV AB, Sweden; Scania CV AB, Sweden; Scania CV AB, Sweden; Scania CV AB, Sweden; KTH EECS, Sweden; Oxford Robotics Institute, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811704/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17376776944317515949&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "Scania CV AB;KTH Royal Institute of Technology;University of Oxford",
        "aff_unique_dep": ";School of Electrical Engineering and Computer Science;Oxford Robotics Institute",
        "aff_unique_url": "https://www.scania.com;https://www.kth.se;https://www.ox.ac.uk",
        "aff_unique_abbr": ";KTH;Oxford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Oxford",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "Sweden;United Kingdom"
    },
    {
        "id": "9812049",
        "title": "FD-SLAM: 3-D Reconstruction Using Features and Dense Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "It is well known that visual SLAM systems based on dense matching are locally accurate but are also susceptible to long-term drift and map corruption. In contrast, feature matching methods can achieve greater long-term consistency but can suffer from inaccurate local pose estimation when feature information is sparse. Based on these observations, we propose an RGB-D SLAM system that leverages the advantages of both approaches: using dense frame-to-model odometry to build accurate sub-maps and on-the-fly feature-based matching across sub-maps for global map optimisation. In addition, we incorporate a learning-based loop closure component based on 3-D features which further stabilises map building. We have evaluated the approach on indoor sequences from public datasets, and the results show that it performs on par or better than state-of-the-art systems in terms of map reconstruction quality and pose estimation. The approach can also scale to large scenes where other systems often fail.",
        "primary_area": "",
        "author": "Xingrui Yang;Yuhang Ming;Zhaopeng Cui;Andrew Calway;Xingrui Yang;Yuhang Ming;Zhaopeng Cui;Andrew Calway",
        "authorids": "/37085952161;/37089196703;/37085646310;/37326243500;/37085952161;/37089196703;/37085646310;/37326243500",
        "aff": "Department of Computer Science, Visual Information Laboratory, University of Bristol, Bristol, U.K.; Department of Computer Science, Visual Information Laboratory, University of Bristol, Bristol, U.K.; State Key Laboratory of CAD&CG, Zhejiang University, Hangzhou, China; Department of Computer Science, Visual Information Laboratory, University of Bristol, Bristol, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812049/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1356205710911072230&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Bristol;Zhejiang University",
        "aff_unique_dep": "Department of Computer Science;State Key Laboratory of CAD&CG",
        "aff_unique_url": "https://www.bristol.ac.uk;http://www.zju.edu.cn",
        "aff_unique_abbr": "UoB;ZJU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Bristol;Hangzhou",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9811831",
        "title": "FEJ2: A Consistent Visual-Inertial State Estimator Design",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel consistent state estimator design for visual-inertial systems. Motivated by first-estimates Jacobian (FEJ) based estimators - which uses the first-ever estimates as linearization points to preserve proper observability properties of the linearized estimator thereby improving the consistency - we carefully model measurement linearization errors due to its Jacobian evaluation and propose a methodology which still leverages FEJ to ensure the estimator's observability properties, but additionally explicitly compensate for linearization errors caused by poor first estimates. We term this estimator FEJ2, which directly addresses the discrepancy between the best Jacobian evaluated at the latest state estimate and the first-estimates Jacobian evaluated at the first-time-ever state estimate. We show that this process explicitly models that the FEJ used is imperfect and thus contributes additional error which, as in FEJ2, should be modeled and consistently increase the state covariance during update. The proposed FEJ2 is evaluated against state-of-the-art visual-inertial estimators in both Monte-Carlo simulations and real-world experiments, which has been shown to outperform existing methods and to robustly handle poor first estimates and high measurement noises.",
        "primary_area": "",
        "author": "Chuchu Chen;Yulin Yang;Patrick Geneva;Guoquan Huang;Chuchu Chen;Yulin Yang;Patrick Geneva;Guoquan Huang",
        "authorids": "/37088486425;/37085990232;/37086125563;/37077670600;/37088486425;/37085990232;/37086125563;/37077670600",
        "aff": "Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811831/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17673174722117328807&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Robot Perception and Navigation Group",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811666",
        "title": "FFHNet: Generating Multi-Fingered Robotic Grasps for Unknown Objects in Real-time",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping unknown objects with multi-fingered hands at high success rates and in real-time is an unsolved problem. Existing methods are limited in the speed of grasp synthesis or the ability to synthesize a variety of grasps from the same observation. We introduce Five-finger Hand Net (FFHNet), an ML model which can generate a wide variety of high-quality multi-fingered grasps for unseen objects from a single view. Generating and evaluating grasps with FFHNet takes only 30ms on a commodity GPU. To the best of our knowledge, FFHNet is the first ML-based real-time system for multi-fingered grasping with the ability to perform grasp inference at 30 frames per second (FPS). For training, we synthetically generate 180k grasp samples for 129 objects. We are able to achieve 91% grasping success for unknown objects in simulation and we demonstrate the model's capabilities of synthesizing high-quality grasps also for real unseen objects.",
        "primary_area": "",
        "author": "Vincent Mayer;Qian Feng;Jun Deng;Yunlei Shi;Zhaopeng Chen;Alois Knoll;Vincent Mayer;Qian Feng;Jun Deng;Yunlei Shi;Zhaopeng Chen;Alois Knoll",
        "authorids": "/37088570143;/37088504248;/38248056200;/37088999645;/37404312400;/37276234100;/37088570143;/37088504248;/38248056200;/37088999645;/37404312400;/37276234100",
        "aff": "Chair for Robotics and Embedded Systems, Technische Universit\u00e4t M\u00fcnchen; Chair for Robotics and Embedded Systems, Technische Universit\u00e4t M\u00fcnchen; Agile Robots AG; Agile Robots AG; Agile Robots AG; Chair for Robotics and Embedded Systems, Technische Universit\u00e4t M\u00fcnchen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811666/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3901559808691020810&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Agile Robots AG",
        "aff_unique_dep": "Chair for Robotics and Embedded Systems;",
        "aff_unique_url": "https://www.tum.de;https://www.agilerobots.com",
        "aff_unique_abbr": "TUM;Agile Robots",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812361",
        "title": "FP-Loc: Lightweight and Drift-free Floor Plan-assisted LiDAR Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel framework for floor plan-based, full six degree-of-freedom LiDAR localization. Our approach relies on robust ceiling and ground plane detection, which solves part of the pose and supports the segmentation of vertical structure elements such as walls and pillars. Our core contribution is a novel nearest neighbour data structure for an efficient look-up of nearest vertical structure elements from the floor plan. The registration is realized as a pair-wise regularized windowed pose graph optimization. Highly efficient, accurate and drift-free long-term localization is demonstrated on multiple scenes.",
        "primary_area": "",
        "author": "Ling Gao;Laurent Kneip;Ling Gao;Laurent Kneip",
        "authorids": "/37088504769;/37569040300;/37088504769;/37569040300",
        "aff": "University of Chinese Academy of Sciences; Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812361/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12859505194117827901&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.ucas.ac.cn;",
        "aff_unique_abbr": "UCAS;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811795",
        "title": "Fabrication of PEDOT:PSS based Soft Sensor for Feedback Control of Modular Bio-actuator",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we fabricated a soft sensor based on PEDOT:PSS for thin film structure. The developed soft sensor can measure the contraction force at real time to be embedded in a modular bio-actuator [1]. The modular actuator generated contraction forces at 0.3 mN when applying electric pulse stimulation. To measure millinewton contraction forces and make a built in sensor, we fabricated a soft sensor using PEDOT:PSS-PDMS film. To verify that the sensor can measure the force of the actuator and can be integrated to the actuator, we analyzed characteristic of the sensor. First, we measure Young's modulus of the sensor and compare them with the bio-actuator. From the previous research [2], the Young's modulus of the bio-actuator and sensor were 45.8 kPa and 165 kPa, respectively. In addition, we simulated the sensors to estimate the change of the displacement according to the applied force. Next, we have experiments by stretching sensors using stepping motor to measure the resistance change of the sensor. From the simulation data, the displacement change is 23 \u00b5m when applying 0.3 mN of forces and then we detect the displacement change smaller than is 20 \u00b5m from the experiments. Finally, we analyzed the movement of the bio-actuator when applying stimulation using high speed camera and time response of the developed sensor. The actuator was contracted to the maximum after 150 ms from the electrical stimulation and the sensor detected the repeated motion at 10 Hz without time delay. As a result, the proposed sensor can measure the force of bioactuator at real time.",
        "primary_area": "",
        "author": "Eunhye Kim;Masaru Takeuchi;Takuto Nomura;Yasuhisa Hasegawa;Qiang Huang;Toshio Fukuda;Eunhye Kim;Masaru Takeuchi;Takuto Nomura;Yasuhisa Hasegawa;Qiang Huang;Toshio Fukuda",
        "authorids": "/37086347339;/37573622500;/37086346854;/37272575600;/37279982900;/37279174500;/37086347339;/37573622500;/37086346854;/37272575600;/37279982900;/37279174500",
        "aff": "Department of Mechatronics Engineering, Meijo University, Nagoya, Japan; Department of M icro-Nano Systems Engineering, Nagoya University, Nagoya, Japan; Department of M icro-Nano Systems Engineering, Nagoya University, Nagoya, Japan; Department of M icro-Nano Systems Engineering, Nagoya University, Nagoya, Japan; Beijing Institute of Technology, Beijing, China; Department of Micro-Nano Systems Engineering, Nagoya University, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811795/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9165767326429290943&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;2;1",
        "aff_unique_norm": "Meijo University;Nagoya University;Beijing Institute of Technology",
        "aff_unique_dep": "Department of Mechatronics Engineering;Department of Micro-Nano Systems Engineering;",
        "aff_unique_url": "https://www.meijo-u.ac.jp;https://www.nagoya-u.ac.jp;http://www.bit.edu.cn/",
        "aff_unique_abbr": "Meijo;Nagoya U;BIT",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Nagoya;Beijing",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Japan;China"
    },
    {
        "id": "9812273",
        "title": "Failure is an option: Task and Motion Planning with Failing Executions",
        "track": "main",
        "status": "Poster",
        "abstract": "Future robotic deployments will require robots to be able to repeatedly solve a variety of tasks in application domains. Task and motion planning addresses complex robotic problems that combine discrete reasoning over states and actions and geometric interactions during action executions. Moving beyond deterministic settings, stochastic actions can be handled by modeling the problem as a Markov Decision Process. The underlying probabilities however are typically hard to model since failures might be caused by hardware imperfections, sensing noise, or physical interactions. We pro-pose a framework to address a task and motion planning setting where actions can fail during execution. To achieve a task goal actions need to be computed and executed despite failures. The robot has to infer which actions are robust and for each new problem effectively choose a solution that reduces expected execution failures. The key idea is to continually recover and refine the underlying beliefs associated with actions across multiple different problems in the domain. Our proposed method can find solutions that reduce the expected number of discrete, executed actions. Results in physics-based simulation indicate that our method outperforms baseline replanning strategies to deal with failing executions.",
        "primary_area": "",
        "author": "Tianyang Pan;Andrew M. Wells;Rahul Shome;Lydia E. Kavraki;Tianyang Pan;Andrew M. Wells;Rahul Shome;Lydia E. Kavraki",
        "authorids": "/37086938153;/37086687629;/37085557993;/37279015600;/37086938153;/37086687629;/37085557993;/37279015600",
        "aff": "Department of Computer Science, Rice University; Department of Computer Science, Rice University; Department of Computer Science, Rice University; Department of Computer Science, Rice University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812273/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9153460517247086450&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811857",
        "title": "Fast Collision Checking for Dual-Arm Collaborative Robots Working in Close Proximity",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a fast collision checking/avoidance algorithm for collaborative robot arms that work in close proximity. We formulate forward kinematics and separating distance function using DH convention and Taylor models (the tight enclosure of a function), and then compute their tight bounds for determining interference between robot arms. Our algorithm allows the collaborative robot arms to perform fine and dexterous tasks in close spatial proximity.",
        "primary_area": "",
        "author": "Miaoying Zhou;Xinyu Zhang;Miaoying Zhou;Xinyu Zhang",
        "authorids": "/37089449307;/37558390400;/37089449307;/37558390400",
        "aff": "Shanghai Key Laboratory of Trustworthy Computing, Intelligent Robotics Laboratory, School of Software Engineering, East China Normal University, Shanghai; Shanghai Key Laboratory of Trustworthy Computing, Intelligent Robotics Laboratory, School of Software Engineering, East China Normal University, Shanghai",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811857/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10313460297146467630&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "East China Normal University",
        "aff_unique_dep": "School of Software Engineering",
        "aff_unique_url": "http://www.ecnu.edu.cn",
        "aff_unique_abbr": "ECNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812264",
        "title": "Fast Footstep Planning on Uneven Terrain Using Deep Sequential Models",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the fundamental challenges in realizing the potential of legged robots is generating plans to traverse challenging terrains. Control actions must be carefully selected so the robot will not crash or slip. The high dimensionality of the joint space makes directly planning low-level actions from onboard perception difficult, and control stacks that do not consider the low-level mechanisms of the robot in planning are ill-suited to handle fine-grained obstacles. One method for dealing with this is selecting footstep locations based on terrain characteristics. However, incorporating robot dynamics into footstep planning requires significant computation, much more than in the quasi-static case. In this work, we present an LSTM-based planning framework that learns probability distributions over likely footstep locations using both terrain lookahead and the robot's dynamics, and leverages the LSTM's sequential nature to find footsteps in linear time. Our framework can also be used as a module to speed up sampling-based planners. We validate our approach on a simulated one-legged hopper over a variety of uneven terrains.",
        "primary_area": "",
        "author": "Hersh Sanghvi;Camillo Jose Taylor;Hersh Sanghvi;Camillo Jose Taylor",
        "authorids": "/37089450673;/37277248500;/37089450673;/37277248500",
        "aff": "School of Engineering and Applied Science, University of Pennsylvania; School of Engineering and Applied Science, University of Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812264/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12021299448421966040&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "School of Engineering and Applied Science",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811742",
        "title": "Fast Graph Refinement and Implicit Neural Representation for Tissue Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Tracking of tissue in the surgical environment is often done via locating frame-to-frame keypoint correspondences, and then using these correspondences to warp a prior underlying model such as a spline, mesh, or embedded deformation. We introduce a novel learned model which takes keypoint correspondences as input and enables a prior-free estimation of deformation at any location. For fast point tracking, our model allows for sparse queries, unlike dense grid based CNNs, which run on full images. Our model begins with a novel graph-based point refinement scheme which refines matched keypoints, updating their features and movement instead of discarding possible outliers. Then, we use these refined matches to learn a novel neural implicit representation for estimating movement of any location given its k-nearest neighbor (k-NN) keypoints. We name our implicit deformation model KINFlow (k-NN implicit neural flow). We demonstrate the performance of KINFlow photometrically on three different datasets. KINFlow is the first model to use a graph network to estimate flow of arbitrary query points, and can estimate movement of 1024 points in under 3 ms.",
        "primary_area": "",
        "author": "Adam Schmidt;Omid Mohareri;Simon DiMaio;Septimiu E. Salcudean;Adam Schmidt;Omid Mohareri;Simon DiMaio;Septimiu E. Salcudean",
        "authorids": "/37087469099;/37568797800;/37283155300;/37283169300;/37087469099;/37568797800;/37283155300;/37283169300",
        "aff": "Department of Electrical and Computer Engineering, The Uni-versitv of British Columbia, Vancouver, Canada; Advanced Research, Intuitive Surgical, Sunnyvale, CA, USA; Advanced Research, Intuitive Surgical, Sunnyvale, CA, USA; Department of Electrical and Computer Engineering, The Uni-versitv of British Columbia, Vancouver, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811742/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12193552811468585262&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of British Columbia;Intuitive Surgical",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Advanced Research",
        "aff_unique_url": "https://www.ubc.ca;https://www.intuitivesurgical.com",
        "aff_unique_abbr": "UBC;Intuitive Surgical",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Vancouver;Sunnyvale",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9812367",
        "title": "Fast High-Quality Tabletop Rearrangement in Bounded Workspace",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we examine the problem of rearranging many objects on a tabletop in a cluttered setting using overhand grasps. Efficient solutions for the problem, which capture a common task that we solve on a daily basis, are essential in enabling truly intelligent robotic manipulation. In a given instance, objects may need to be placed at temporary positions (\u201cbuffers\u201d) to complete the rearrangement, but allocating these buffer locations can be highly challenging in a cluttered environment. To tackle the challenge, a two-step baseline planner is first developed, which generates a primitive plan based on inherent combinatorial constraints induced by start and goal poses of the objects and then selects buffer locations assisted by the primitive plan. We then employ the \u201clazy\u201d planner in a tree search framework which is further sped up by adapting a novel preprocessing routine. Simulation experiments show our methods can quickly generate high-quality solutions and are more robust in solving large-scale instances than existing state-of-the-art approaches. source: github.com/arc-l/TRLB",
        "primary_area": "",
        "author": "Kai Gao;Darren Lau;Baichuan Huang;Kostas E. Bekris;Jingjin Yu;Kai Gao;Darren Lau;Baichuan Huang;Kostas E. Bekris;Jingjin Yu",
        "authorids": "/37088997464;/37089449441;/37088981654;/37282424700;/37536570700;/37088997464;/37089449441;/37088981654;/37282424700;/37536570700",
        "aff": "Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Cornell University, NY, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812367/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13621778593128466396&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Rutgers University;Cornell University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu;https://www.cornell.edu",
        "aff_unique_abbr": "Rutgers;Cornell",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "New Brunswick;Ithaca",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9916213",
        "title": "Fast Object Inertial Parameter Identification for Collaborative Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robots (cobots) are machines designed to work safely alongside people in human-centric environments. Providing cobots with the ability to quickly infer the inertial parameters of manipulated objects will improve their flexibility and enable greater usage in manufacturing and other areas. To ensure safety, cobots are subject to kinematic limits that result in low signal-to-noise ratios (SNR) for velocity, acceleration, and force-torque data. This renders existing inertial parameter identification algorithms prohibitively slow and inaccurate. Motivated by the desire for faster model acquisition, we investigate the use of an approximation of rigid body dynamics to improve the SNR. Additionally, we introduce a mass discretization method that can make use of shape information to quickly identify plausible inertial parameters for a manipulated object. We present extensive simulation studies and real-world experiments demonstrating that our approach complements existing inertial parameter identification methods by specifically targeting the typical cobot operating regime.",
        "primary_area": "",
        "author": "Philippe Nadeau;Matthew Giamou;Jonathan Kelly;Philippe Nadeau;Matthew Giamou;Jonathan Kelly",
        "authorids": "/37088507489;/37085674428;/37085364182;/37088507489;/37085674428;/37085364182",
        "aff": "STARS Laboratory at the University of Toronto Institute for Aerospace Studies, Toronto, Ontario, Canada; Vector Institute Postgraduate Affiliate; Vector Institute Faculty Affiliate",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9916213/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16723145029062679216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Toronto Institute for Aerospace Studies;Vector Institute",
        "aff_unique_dep": "STARS Laboratory;Postgraduate Affiliate",
        "aff_unique_url": "https://www.ias.uToronto.ca;https://vectorinstitute.ai",
        "aff_unique_abbr": "UTIAS;Vector Institute",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Toronto;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9811914",
        "title": "Fast Point Clouds Upsampling with Uncertainty Quantification for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "3D LiDAR is widely used in autonomous systems such as self-driving cars and autonomous robots because it provides accurate 3D point clouds of the surrounding environment under harsh conditions. However, a high-resolution LiDAR is expensive and bulky. Although a low-resolution LiDAR is compact and affordable, the obtained point clouds are so sparse that it is difficult to extract features that are meaningful for highlevel tasks. To solve this problem, several upsampling-based approaches have been proposed by estimating high-resolution point clouds from low-resolution point clouds. However, most works have focused on upsampling object-level or synthetic point clouds obtained from CAD models. Additionally, these approaches have a high computational cost, which makes them unusable in real-time applications such as autonomous driving vehicles. In this paper, we propose a real-time upsampling method with LiDAR for outdoor environments. The proposed method builds on conditional neural processes that are capable of uncertainty quantification. With this probabilistic property, we can remove the upsampled points that have high uncertainty, thus achieving high accuracy. Additionally, the proposed method can be trained in a simulated environment, and then directly applied to the real world. The experimental results on a simulated environment and a real-world dataset show that the proposed method is significantly faster than the state-of-the-art methods while achieving comparable performance.",
        "primary_area": "",
        "author": "Younghwa Jung;Seung-Woo Seo;Seong-Woo Kim;Younghwa Jung;Seung-Woo Seo;Seong-Woo Kim",
        "authorids": "/37088477860;/37271925900;/37537386000;/37088477860;/37271925900;/37537386000",
        "aff": "Seoul National University, South Korea; Seoul National University, South Korea; Seoul National University, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811914/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16131642672698428153&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812452",
        "title": "Fast Road Segmentation via Uncertainty-aware Symmetric Network",
        "track": "main",
        "status": "Poster",
        "abstract": "The high performance of RGB-D based road segmentation methods contrasts with their rare application in commercial autonomous driving, which is owing to two reasons: 1) the prior methods cannot achieve high inference speed and high accuracy in both ways; 2) the different properties of RGB and depth data are not well-exploited, limiting the reliability of predicted road. In this paper, based on the evidence theory, an uncertainty-aware symmetric network (USNet) is proposed to achieve a trade-off between speed and accuracy by fully fusing RGB and depth data. Firstly, cross-modal feature fusion operations, which are indispensable in the prior RGB-D based methods, are abandoned. We instead separately adopt two light-weight subnetworks to learn road representations from RGB and depth inputs. The light-weight structure guarantees the real-time inference of our method. Moreover, a multi-scale evidence collection (MEC) module is designed to collect evidence in multiple scales for each modality, which provides sufficient evidence for pixel class determination. Finally, in uncertainty-aware fusion (UAF) module, the uncertainty of each modality is perceived to guide the fusion of the two sub-networks. Experimental results demonstrate that our method achieves a state-of-the-art accuracy with real-time inference speed of 43+43+ FPS. The source code is available at https://github.com/morancyc/USNet.",
        "primary_area": "",
        "author": "Yicong Chang;Feng Xue;Fei Sheng;Wenteng Liang;Anlong Ming;Yicong Chang;Feng Xue;Fei Sheng;Wenteng Liang;Anlong Ming",
        "authorids": "/37089448944;/37086936532;/37089447118;/37089449662;/37293972600;/37089448944;/37086936532;/37089447118;/37089449662;/37293972600",
        "aff": "Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812452/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12763284964571181020&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Beijing University of Posts and Telecommunications",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.bupt.edu.cn/",
        "aff_unique_abbr": "BUPT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812126",
        "title": "Fast and Optimal Trajectory Planning for Multiple Vehicles in a Nonconvex and Cluttered Environment: Benchmarks, Methodology, and Experiments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper is focused on the cooperative trajectory planning problem for multiple car-like robots in a cluttered and unstructured environment narrowed by static obstacles. The concerned multi-vehicle trajectory planning (MVTP) problem is challenging because i) the scenario is nonconvex and tiny; ii) the vehicle kinematics is nonconvex; and iii) a feasible homotopy class is unavailable a priori. We propose a two-stage MVTP method: Stage 1 identifies a feasible homotopy class, and Stage 2 quickly finds a local optimum based on the identified homotopy class. Numerical optimal control, adaptive scaling, grouping, and trust region construction strategies are integrated into the proposed planner. Our planner is extensively compared in 100 benchmark cases with the state-of-the-art MVTP methods such as incremental sequential convex programming, numerical optimal control, conflict-based search, priority-based trajectory optimizer, and optimal reciprocal collision avoidance. The simulation results demonstrate our method's superiority in runtime and optimality. Experiments with three car-like robots demonstrate the efficiency of our proposed planner. Source codes are in https://github.com/libai1943/MVTP_benchmark.",
        "primary_area": "",
        "author": "Yakun Ouyang;Bai Li;Youmin Zhang;Tankut Acarman;Yuqing Guo;Tantan Zhang;Yakun Ouyang;Bai Li;Youmin Zhang;Tankut Acarman;Yuqing Guo;Tantan Zhang",
        "authorids": "/37088799433;/37085459453;/37405807400;/37332972700;/37088349736;/37089447165;/37088799433;/37085459453;/37405807400;/37332972700;/37088349736;/37089447165",
        "aff": "College of Mechanical and Vehicle Engineering, Hunan University, Changsha, China; College of Mechanical and Vehicle Engineering, Hunan University, Changsha, China; Department of Mechanical, Industrial and Aerospace Engineering, Concordia Institute of Aerospace Design and Innovation, Concordia University, Montreal, Canada; Computer Engineering Department, Galatasaray University, Istanbul, Turkey; Department of Automation, Tsinghua University, Beijing, China; College of Mechanical and Vehicle Engineering, Hunan University, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812126/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=477014373383625277&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;3;0",
        "aff_unique_norm": "Hunan University;Concordia University;Galatasaray University;Tsinghua University",
        "aff_unique_dep": "College of Mechanical and Vehicle Engineering;Department of Mechanical, Industrial and Aerospace Engineering;Computer Engineering Department;Department of Automation",
        "aff_unique_url": "http://www.hnu.edu.cn;https://www.concordia.ca;https://www.gsu.edu.tr;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": ";Concordia;GSU;THU",
        "aff_campus_unique_index": "0;0;1;2;3;0",
        "aff_campus_unique": "Changsha;Montreal;Istanbul;Beijing",
        "aff_country_unique_index": "0;0;1;2;0;0",
        "aff_country_unique": "China;Canada;T\u00fcrkiye"
    },
    {
        "id": "9812063",
        "title": "Fast-MbyM: Leveraging Translational Invariance of the Fourier Transform for Efficient and Accurate Radar Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Masking by Moving (MByM), provides robust and accurate radar odometry measurements through an exhaustive correlative search across discretised pose candidates. However, this dense search creates a significant computational bottleneck which hinders real-time performance when high-end GPUs are not available. Utilising the translational invariance of the Fourier Transform, in our approach, Fast Masking by Moving (f-MByM), we decouple the search for angle and translation. By maintaining end-to-end differentiability a neural network is used to mask scans and trained by supervising pose prediction directly. Training faster and with less memory, utilising a decoupled search allows f-MbyM to achieve significant run-time performance improvements on a CPU (168 %) and to run in real-time on embedded devices, in stark contrast to MbyM. Throughout, our approach remains accurate and competitive with the best radar odometry variants available in the literature \u2013 achieving an end-point drift of 2.01 % in translation and 6.3 deg /km on the Oxford Radar RobotCar Dataset.",
        "primary_area": "",
        "author": "Rob Weston;Matthew Gadd;Daniele De Martini;Paul Newman;Ingmar Posner;Rob Weston;Matthew Gadd;Daniele De Martini;Paul Newman;Ingmar Posner",
        "authorids": "/37086936297;/37085439081;/37086404606;/37335903100;/37601368300;/37086936297;/37085439081;/37086404606;/37335903100;/37601368300",
        "aff": "Applied Artificial Intelligence Lab (A2I); Mobile Robotics Group (MRG), University of Oxford; Mobile Robotics Group (MRG), University of Oxford; Mobile Robotics Group (MRG), University of Oxford; Applied Artificial Intelligence Lab (A2I)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812063/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17745701286441157459&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Applied Artificial Intelligence Lab;University of Oxford",
        "aff_unique_dep": "Artificial Intelligence;Mobile Robotics Group",
        "aff_unique_url": ";https://www.ox.ac.uk",
        "aff_unique_abbr": "A2I;Oxford",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Oxford",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9812209",
        "title": "Few-Shot Keypoint Detection as Task Adaptation via Latent Embeddings",
        "track": "main",
        "status": "Poster",
        "abstract": "Dense object tracking, the ability to localize specific object points with pixel-level accuracy, is an important computer vision task with numerous downstream applications in robotics. Existing approaches either compute dense keypoint embeddings in a single forward pass, meaning the model is trained to track everything at once, or allocate their full capacity to a sparse predefined set of points, trading generality for accuracy. In this paper we explore a middle ground based on the observation that the number of relevant points at a given time are typically relatively few, e.g. grasp points on a target object. Our main contribution is a novel architecture, inspired by few-shot task adaptation, which allows a sparse-style network to condition on a keypoint embedding that indicates which point to track. Our central finding is that this approach provides the generality of dense-embedding models, while offering accuracy significantly closer to sparse-keypoint approaches. We present results illustrating this capacity vs. accuracy trade-off, and demonstrate the ability to zero-shot transfer to new object instances (within-class) using a real-robot pick-and-place task.",
        "primary_area": "",
        "author": "Mel Vecerik;Jackie Kay;Raia Hadsell;Lourdes Agapito;Jon Scholz;Mel Vecerik;Jackie Kay;Raia Hadsell;Lourdes Agapito;Jon Scholz",
        "authorids": "/37086933926;/37088504649;/37418234300;/37550424100;/37970047400;/37086933926;/37088504649;/37418234300;/37550424100;/37970047400",
        "aff": "DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; University College London, UK; DeepMind, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812209/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10956379612816912475&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "DeepMind;University College London",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://deepmind.com;https://www.ucl.ac.uk",
        "aff_unique_abbr": "DeepMind;UCL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812066",
        "title": "FishGym: A High-Performance Physics-based Simulation Framework for Underwater Robot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Bionic underwater robots have demonstrated their superiority in many applications. Yet, training their intelligence for a variety of tasks that mimic the behavior of underwater creatures poses a number of challenges in practice, mainly due to lack of a large amount of available training data as well as the high cost in real physical environment. Alternatively, simulation has been considered as a viable and important tool for acquiring datasets in different environments, but it mostly targeted rigid and soft body systems. There is currently dearth of work for more complex fluid systems interacting with immersed solids that can be efficiently and accurately simulated for robot training purposes. In this paper, we propose a new platform called \u201cFishGym\u201d, which can be used to train fish-like underwater robots. The framework consists of a robotic fish modeling module using articulated body with skinning, a GPU-based high-performance localized two-way coupled fluid-structure interaction simulation module that handles both finite and infinitely large domains, as well as a reinforcement learning module. We leveraged existing training methods with adaptations to underwater fish-like robots and obtained learned control policies for multiple benchmark tasks. The training results are demonstrated with reasonable motion trajectories, with comparisons and analyses to empirical models as well as known real fish swimming behaviors to highlight the advantages of the proposed platform.",
        "primary_area": "",
        "author": "Wenji Liu;Kai Bai;Xuming He;Shuran Song;Changxi Zheng;Xiaopei Liu;Wenji Liu;Kai Bai;Xuming He;Shuran Song;Changxi Zheng;Xiaopei Liu",
        "authorids": "/38239959600;/37086926271;/37900363800;/37085613509;/37086120559;/37086091876;/38239959600;/37086926271;/37900363800;/37085613509;/37086120559;/37086091876",
        "aff": "ShanghaiTech University; ShanghaiTech University; ShanghaiTech University; Columbia University; Columbia University; ShanghaiTech University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812066/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1757896542677913778&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "ShanghaiTech University;Columbia University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.shanghaitech.edu.cn;https://www.columbia.edu",
        "aff_unique_abbr": "ShanghaiTech;Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9811947",
        "title": "Fixed and Sliding FBG Sensors-Based Triaxial Tip Force Sensing for Cable-Driven Continuum Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Tip force sensing for cable-driven continuum robots are vital to provide the force information for safe and reliable human-robot interaction. However, traditional triaxial force sensors usually have a complicated structure occupying its inner lumen, without enough space for additional instrumental tools. To solve this, this paper proposes a fixed and sliding fiber Bragg grating (FBG) sensors-based triaxial force sensing method for cable-driven continuum robots. The fixed FBG sensors are attached to the circumferential surface of continuum robot at the tip and base, and the sliding optical fibers with FBG sensors are located in the actuation channels as the sensing integrated pulling cables. This configuration guarantees a compact structure and large inner lumen. Two five-degreed-of-freedom (5-DOF) electromagnetic (EM) and a 6-DOF EM sensors are assembled to the tip and the base of the robot respectively, which can obtain the pose of the tip with respect to the base. The tip force in three directions can be decoupled using the information of the Bragg wavelength changes and EM sensors. Results show that the mean errors of force sensing along x-direction, y-direction, and z-direction are 4.1%, 4.7%, and 9.8%, respectively. The proposed sensing method does not rely on the elasticity of continuum robot, enabling its wide applicability for other cable-driven pseudo-continuum robots.",
        "primary_area": "",
        "author": "Zecai Lin;Hao Wu;Huan Jia;Huanghua Liu;Xiaojie Ai;Yun Zou;Zhenglong Sun;Weidong Chen;Guang-Zhong Yang;Anzhu Gao;Zecai Lin;Hao Wu;Huan Jia;Huanghua Liu;Xiaojie Ai;Yun Zou;Zhenglong Sun;Weidong Chen;Guang-Zhong Yang;Anzhu Gao",
        "authorids": "/37088837962;/37089495475;/37089510172;/37089510587;/37088839699;/37085849314;/37086799406;/37279187800;/37276270800;/38027228000;/37088837962;/37089495475;/37089510172;/37089510587;/37088839699;/37085849314;/37086799406;/37279187800;/37276270800;/38027228000",
        "aff": "Department of Automation, Key Laboratory of System Control and Information Processing, Ministry of Education, Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P. R. China; China Ear institute, Shanghai Jiao Tong University School of Medicine, Shanghai, China; China Ear institute, Shanghai Jiao Tong University, School of Medicine, Shanghai, China; Department of Automation, Key Laboratory of System Control and Information Processing, Ministry of Education, Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P. R. China; Department of Automation, Key Laboratory of System Control and Information Processing, Ministry of Education, Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P. R. China; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P. R. China; School of Science and Engineering, The Chinese University of Hong Kong Shenzhen, Shenzhen, China; Department of Automation, Key Laboratory of System Control and Information Processing, Ministry of Education, Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P. R. China; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P. R. China; Department of Automation, Key Laboratory of System Control and Information Processing, Ministry of Education, Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811947/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6702082018264119969&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;1;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Chinese University of Hong Kong Shenzhen",
        "aff_unique_dep": "Department of Automation;School of Science and Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.cuhk.edu.cn",
        "aff_unique_abbr": "SJTU;CUHK Shenzhen",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;0;0;0",
        "aff_campus_unique": "Shanghai;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811680",
        "title": "Flow Supervised Neural Radiance Fields for Static-Dynamic Decomposition",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an approach to synthesize novel views from dynamics scenes captured by multi-view videos of cameras mounted on a driving vehicle. We unify existing methods and propose a new training loss to explicitly disentangle the static background from the dynamic foreground objects using scene flow's magnitude, learnt only from proxy 2D optical flow supervision. We obtain high quality static and dynamic contents separately, which allow us to combine them freely for novel view and time syntheses. We establish a dataset consisting of 5 dynamic scenes with varying difficulties on which we conduct experiments, and show that our method is able to handle challenging scenarios in real-world traffics and create high quality novel view and time syntheses.",
        "primary_area": "",
        "author": "Quei-An Chen;Akihiro Tsukada;Quei-An Chen;Akihiro Tsukada",
        "authorids": "/37086955782;/37089466933;/37086955782;/37089466933",
        "aff": "DENSO Corporation; DENSO Corporation",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811680/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11748851845865521600&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "DENSO Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.denso.com",
        "aff_unique_abbr": "DENSO",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812331",
        "title": "Flow-Based Control of Marine Robots in Gyre-Like Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a flow-based control strategy that enables resource-constrained marine robots to patrol gyre-like flow environments on an orbital trajectory with a periodicity in a given range. The controller does not require a detailed model of the flow field and relies only on the robot's location relative to the center of the gyre. Instead of precisely tracking a pre-defined trajectory, the robots are tasked to stay in between two bounding trajectories with known periodicity. Furthermore, the proposed strategy leverages the surrounding flow field to minimize control effort. We prove that the proposed strategy enables robots to cycle in the flow satisfying the desired periodicity requirements. Our method is tested and validated both in simulation and in experiments using a low-cost, underactuated, surface swimming robot, i.e. the Modboat.",
        "primary_area": "",
        "author": "Gedaliah Knizhnik;Peihan Li;Xi Yu;M. Ani Hsieh;Gedaliah Knizhnik;Peihan Li;Xi Yu;M. Ani Hsieh",
        "authorids": "/37086285239;/37089447950;/37086960337;/38238444800;/37086285239;/37089447950;/37086960337;/38238444800",
        "aff": "GRASP Laboratory, University of Pensylvannia, Philadelphia, PA; GRASP Laboratory, University of Pensylvannia, Philadelphia, PA; Department of Mechanical and Aerospace Engineering, West Virginia University, Morgantown, WV; GRASP Laboratory, University of Pensylvannia, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812331/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3395857627049330063&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Pennsylvania;West Virginia University",
        "aff_unique_dep": "GRASP Laboratory;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.upenn.edu;https://www.wvu.edu",
        "aff_unique_abbr": "UPenn;WVU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Philadelphia;Morgantown",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812434",
        "title": "Foothold Evaluation Criterion for Dynamic Transition Feasibility for Quadruped Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "To traverse complex scenarios reliably a legged robot needs to move its base aided by the ground reaction forces, which can only be generated by the legs that are momentarily in contact with the ground. A proper selection of footholds is crucial for maintaining balance. In this paper, we propose a foothold evaluation criterion that considers the transition feasibility for both linear and angular dynamics to overcome complex scenarios. We devise convex and nonlinear formulations as a direct extension of [1] in a receding-horizon fashion to grant dynamic feasibility for future behaviours. The criterion is integrated with a Vision-based Foothold Adaptation (VFA) strategy that takes into account the robot kinematics, leg collisions and terrain morphology. We verify the validity of the selected footholds and the generated trajectories in simulation and experiments with the 90kg quadruped robot HyQ.",
        "primary_area": "",
        "author": "Luca Clemente;Octavio Villarreal;Angelo Bratta;Michele Focchi;Victor Barasuol;Giovanni Gerardo Muscolo;Claudio Semini;Luca Clemente;Octavio Villarreal;Angelo Bratta;Michele Focchi;Victor Barasuol;Giovanni Gerardo Muscolo;Claudio Semini",
        "authorids": "/37089450339;/37088504544;/37088503906;/37542633600;/37071707300;/37394417000;/37542633100;/37089450339;/37088504544;/37088503906;/37542633600;/37071707300;/37394417000;/37542633100",
        "aff": "Department of Electronics and Telecommunications, Collegio di Ingegneria Informatica, del Cinema e Meccatronica, Politecnico di Torino, Turin, (Italy); Dynamic Legged Systems (DLS) lab, Istituto Italiano di Tecnologia (IIT), Genova, (Italy); Dynamic Legged Systems (DLS) lab, Istituto Italiano di Tecnologia (IIT), Genova, (Italy); Dynamic Legged Systems (DLS) lab, Istituto Italiano di Tecnologia (IIT), Genova, (Italy); Dynamic Legged Systems (DLS) lab, Istituto Italiano di Tecnologia (IIT), Genova, (Italy); Department of Computer Science, University of Verona, Verona, (Italy); Dynamic Legged Systems (DLS) lab, Istituto Italiano di Tecnologia (IIT), Genova, (Italy)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812434/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9155974778005601067&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;2;1",
        "aff_unique_norm": "Politecnico di Torino;Istituto Italiano di Tecnologia;University of Verona",
        "aff_unique_dep": "Department of Electronics and Telecommunications;Dynamic Legged Systems (DLS) lab;Department of Computer Science",
        "aff_unique_url": "https://www.polito.it;https://www.iit.it;https://www.univr.it",
        "aff_unique_abbr": "Politecnico di Torino;IIT;",
        "aff_campus_unique_index": "0;1;1;1;1;2;1",
        "aff_campus_unique": "Turin;Genova;Verona",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9811866",
        "title": "Formal Verification of Stochastic Systems with ReLU Neural Network Controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we address the problem of formal safety verification for stochastic cyber-physical systems (CPS) equipped with ReLU neural network (NN) controllers. Our goal is to find the set of initial states from where, with a predetermined confidence, the system will not reach an unsafe configuration within a specified time horizon. Specifically, we consider discrete-time LTI systems with Gaussian noise, which we abstract by a suitable graph. Then, we formulate a Satisfiability Modulo Convex (SMC) problem to estimate upper bounds on the transition probabilities between nodes in the graph. Using this abstraction, we propose a method to compute tight bounds on the safety probabilities of nodes in this graph, despite possible over-approximations of the transition probabilities between these nodes. Additionally, using the proposed SMC formula, we devise a heuristic method to refine the abstraction of the system in order to further improve the estimated safety bounds. Finally, we corroborate the efficacy of the proposed method with simulation results considering a robot navigation example and comparison against a state-of-the-art verification scheme.",
        "primary_area": "",
        "author": "Shiqi Sun;Yan Zhang;Xusheng Luo;Panagiotis Vlantis;Miroslav Pajic;Michael M. Zavlanos;Shiqi Sun;Yan Zhang;Xusheng Luo;Panagiotis Vlantis;Miroslav Pajic;Michael M. Zavlanos",
        "authorids": "/37089448425;/37086552784;/37088337711;/37085537903;/37294788600;/37300758300;/37089448425;/37086552784;/37088337711;/37085537903;/37294788600;/37300758300",
        "aff": "Department of Mechanical Engineering and Materials Science, Duke University, Durham, NC, USA; Department of Mechanical Engineering and Materials Science, Duke University, Durham, NC, USA; Department of Mechanical Engineering and Materials Science, Duke University, Durham, NC, USA; Department of Mechanical Engineering and Materials Science, Duke University, Durham, NC, USA; Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA; Department of Mechanical Engineering and Materials Science, Duke University, Durham, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811866/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6119666530833741347&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "Department of Mechanical Engineering and Materials Science",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Durham",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812172",
        "title": "Formation-containment tracking and scaling for multiple quadcopters with an application to choke-point navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates the cooperative control problem of choke-point navigation for multiple quadcopters when only their subgroup is equipped with obstacle detecting sensors. We define a quadcopter as a leader if it is equipped with an obstacle detecting sensor; otherwise, it is a follower. In addition, we introduce a virtual leader agent to create the group motion. First, we apply the leader-follower approach and propose a formation-containment tracking controller for multiple quadcopters to track the time-varying velocity of the virtual leader agent. At the same time, the leader quadcopters form the prescribed formation while the follower quadcopters converge inside a safe region, which is the convex hull spanned by those leaders. Then, we introduce a scaling vector into the displacement-based formation constraints. When the leader quadcopters identify the choke-point via their obstacle detecting sensors, they update the scaling variable to adjust the size of the formation (i.e. the safe region) and guide all quadcopters to safely pass through the choke-point. The proposed cooperative controllers are distributed because each quadcopter's control command only relies on the information states from its neighbours. Finally, two autonomous flight experiments, including formation-containment tracking and choke-point navigation, are provided to validate the effectiveness of the proposed cooperative control laws.",
        "primary_area": "",
        "author": "Yu-Hsiang Su;Alexander Lanzon;Yu-Hsiang Su;Alexander Lanzon",
        "authorids": "/37089446765;/38493292500;/37089446765;/38493292500",
        "aff": "Department of Electrical and Electronic Engineering, School of Engineering, The University of Manchester, Manchester, UK; Department of Electrical and Electronic Engineering, School of Engineering, The University of Manchester, Manchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812172/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15769041025002850715&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Manchester",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.manchester.ac.uk",
        "aff_unique_abbr": "UoM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Manchester",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812098",
        "title": "Forward Kinematics and Control of a Segmented Tunable-Stiffness 3-D Continuum Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we consider the problem of controlling the end effector position of a continuum manipulator through local stiffness changes. Continuum manipulators offer the advantage of continuous deformation along their lengths, and recent advances in smart material actuators further enable local compliance changes, which can affect the manipulator's bulk motion. However, leveraging local stiffness change to control motion remains lightly explored. We build a kinematic model of a continuum manipulator as a sequence of segments consisting of symmetrically arranged springs around the perimeter of every segment, and we show that this system has a closed form solution to its forward kinematics. The model includes common constraints such as restriction of torsional or shearing movement. Based on this model, we propose a controller on the spring stiffnesses for a single segment and provide provable guarantees on convergence to a desired goal position. The results are verified in simulation and compared to physical hardware.",
        "primary_area": "",
        "author": "Shivangi Misra;Cynthia Sung;Shivangi Misra;Cynthia Sung",
        "authorids": "/37088073413;/37086639646;/37088073413;/37086639646",
        "aff": "General Robotics, Automation, Sensing & Perception (GRASP) Lab, The University of Pennsylvania, Philadelphia, PA, USA; General Robotics, Automation, Sensing & Perception (GRASP) Lab, The University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812098/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10634830312161022499&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "General Robotics, Automation, Sensing & Perception (GRASP) Lab",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812035",
        "title": "Forward Models That Integrate High-Dimensional and Localized Sensing of Peripheral Muscle Behavior Enable Task-Independent Prediction of Lower-Limb Joint Torque and Position Future States",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop a task-independent predictive framework that estimates hip, knee and ankle future behavior from sonomyographic sensing of quadriceps musculature. Two regression models, support vector regression and Gaussian process regression, were trained and tested such that no ambulation mode recognition was required. Sonomyography features of the anterior thigh musculature were extracted during the swing phase of level, incline and stair ambulation tasks as inputs to the two models for continuous prediction of the future stance phase hip, knee and ankle moments. Next, sonomyography features of the anterior thigh musculature were extracted during the stance phase and used to predict the following swing phase hip, knee and ankle angles. Leave-one-stride-out cross-validation is used to evaluate this continuous prediction framework. Additionally, initial, peak and terminal joint moment and angle parameters are extracted from trajectories and evaluated. Both regression models were able to accurately predict continuous future joint moments and angles, as well as initial, peak and terminal value parameters of future joint moments and angles. However, the support vector regression model required relatively lower computational cost. Thus, we recommend the support vector regression model as an optimal model for forward prediction of joint mechanics from sonomyographic sensing during ambulation.",
        "primary_area": "",
        "author": "Kaitlin G. Rabe;Nicholas P. Fey;Kaitlin G. Rabe;Nicholas P. Fey",
        "authorids": "/37086922993;/37085470083;/37086922993;/37085470083",
        "aff": "Department of Biomedical Engineering, The University of Texas at Austin, Austin, TX, USA; Walker Department of Mechanical Engineering, The University of Texas at Austin, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812035/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812415",
        "title": "Free Energy Principle for State and Input Estimation of a Quadcopter Flying in Wind",
        "track": "main",
        "status": "Poster",
        "abstract": "The free energy principle from neuroscience provides a brain-inspired perception scheme through a data-driven model learning algorithm called Dynamic Expectation Maximization (DEM). This paper aims at introducing an exper-imental design to provide the first experimental confirmation of the usefulness of DEM as a state and input estimator for real robots. Through a series of quadcopter flight experiments under unmodelled wind dynamics, we prove that DEM can leverage the information from colored noise for accurate state and input estimation through the use of generalized coordinates. We demonstrate the superior performance of DEM for state es-timation under colored noise with respect to other benchmarks like State Augmentation, SMIKF and Kalman Filtering through its minimal estimation error. We demonstrate the similarities in the performance of DEM and Unknown Input Observer (UIO) for input estimation. The paper concludes by showing the influence of prior beliefs in shaping the accuracy-complexity trade-off during DEM's estimation.",
        "primary_area": "",
        "author": "Fred Bos;Ajith Anil Meera;Dennis Benders;Martijn Wisse;Fred Bos;Ajith Anil Meera;Dennis Benders;Martijn Wisse",
        "authorids": "/37089745857;/37086937664;/37089450646;/37295531600;/37089745857;/37086937664;/37089450646;/37295531600",
        "aff": "Cognitive Robotics department at TU Delft, The Netherlands; Cognitive Robotics department at TU Delft, The Netherlands; Cognitive Robotics department at TU Delft, The Netherlands; Cognitive Robotics department at TU Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812415/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9444447264997537046&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Cognitive Robotics department",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9812306",
        "title": "Free-Space Ellipsoid Graphs for Multi-Agent Target Monitoring",
        "track": "main",
        "status": "Poster",
        "abstract": "We apply a novel framework for decomposing and reasoning about free space in an environment to a multi-agent persistent monitoring problem. Our decomposition method represents free space as a collection of ellipsoids associated with a weighted connectivity graph. The same ellipsoids used for reasoning about connectivity and distance during high level planning can be used as state constraints in a Model Predictive Control algorithm to enforce collision-free motion. This structure allows for streamlined implementation in distributed multi-agent tasks in 2D and 3D environments. We illustrate its effectiveness for a team of tracking agents tasked with monitoring a group of target agents. Our algorithm uses the ellipsoid decomposition as a primitive for the coordination, path planning, and control of the tracking agents. Simulations with four tracking agents monitoring fifteen dynamic targets in obstacle-rich environments demonstrate the performance of our algorithm.",
        "primary_area": "",
        "author": "Aaron Ray;Alyssa Pierson;Daniela Rus;Aaron Ray;Alyssa Pierson;Daniela Rus",
        "authorids": "/37086573512;/37085345711;/37279652300;/37086573512;/37085345711;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Mas-sachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Boston University, Boston, MA, USA; Computer Science and Artificial Intelligence Laboratory, Mas-sachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812306/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16338762748901890503&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Boston University",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mit.edu;https://www.bu.edu",
        "aff_unique_abbr": "MIT;BU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Cambridge;Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811583",
        "title": "FreeSN: A Freeform Strut-node Structured Modular Self-reconfigurable Robot - Design and Implementation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel freeform strut-node structured modular self-reconfigurable robot (MSRR) called FreeSN, consisting of strut and node modules. A node module is mainly a low-carbon steel spherical shell. A strut module contains two freeform connectors, which provide strong magnetic connections and flexible spherical motions. The FreeSN system shares the benefits of freeform connection and strut-node structures. The freeform connection brings good adaptability to the environment. The triangle substructures inside the system configuration significantly improve the structural stability. The parallel execution of module motions can superpose the module capabilities and makes the system more scalable. The modules can combine these robot features by selecting the system configuration and better fit different circumstances and tasks. Four demonstrations, including assembly, obstacle crossing, transportation, and object manipulation, are designed to show the capabilities of the FreeSN system in different aspects. The results show the great performance and versatility of this MSRR system.",
        "primary_area": "",
        "author": "Yuxiao Tu;Guanqi Liang;Tin Lun Lam;Yuxiao Tu;Guanqi Liang;Tin Lun Lam",
        "authorids": "/37089000919;/37088687610;/37571111600;/37089000919;/37088687610;/37571111600",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811583/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17496784135186353409&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.siarfs.org/",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811858",
        "title": "From Scratch to Sketch: Deep Decoupled Hierarchical Reinforcement Learning for Robotic Sketching Agent",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an automated learning framework for a robotic sketching agent that is capable of learning stroke-based rendering and motor control simultaneously. We formulate the robotic sketching problem as a deep decoupled hierarchical reinforcement learning; two policies for stroke-based rendering and motor control are learned independently to achieve sub-tasks for drawing, and form a hierarchy when cooperating for real-world drawing. Without hand-crafted features, drawing sequences or trajectories, and inverse kinematics, the proposed method trains the robotic sketching agent from scratch. We performed experiments with a 6-DoF robot arm with 2F gripper to sketch doodles. Our experimental results show that the two policies successfully learned the sub-tasks and collaborated to sketch the target images. Also, the robustness and flexibility were examined by varying drawing tools and surfaces.",
        "primary_area": "",
        "author": "Ganghun Lee;Minji Kim;Minsu Lee;Byoung-Tak Zhang;Ganghun Lee;Minji Kim;Minsu Lee;Byoung-Tak Zhang",
        "authorids": "/37089449386;/37089450354;/37676142400;/37336068500;/37089449386;/37089450354;/37676142400;/37336068500",
        "aff": "Interdisciplinary Program in Cognitive Science, Seoul National University, Seoul, Korea; Interdisciplinary Program in Neuroscience, Seoul National University; AIIS, Seoul National University; AIIS, Seoul National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811858/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2873427635698779932&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Interdisciplinary Program in Cognitive Science",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812114",
        "title": "Fully Automatic and Real-Time Microrobot Detection and Tracking based on Ultrasound Imaging using Deep Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Micro-scale robots introduce great prospective into many different medical applications such as targeted drug delivery, minimally invasive surgery and localized bio-metric diagnostics. This research presents a method for object detection and tracking system of a chain-like magnetic microsphere robots using ultrasound imaging in an in-vitro environment. The method estimates the position of the microrobot in real-time using deep learning techniques. The experiments showed that a spherical microrobot with about 500 m in diameter can be detected and tracked in real-time with a high accuracy in dynamic environments. The results exhibit a high detection and tracking accuracy for one, two and three sphere microrobots with the highest accuracy in detection and tracking around 95 % and 93% respectively.",
        "primary_area": "",
        "author": "Karim Botros;Mohammad Alkhatib;David Folio;Antoine Ferreira;Karim Botros;Mohammad Alkhatib;David Folio;Antoine Ferreira",
        "authorids": "/37089446645;/37086949597;/37295566600;/37273658200;/37089446645;/37086949597;/37295566600;/37273658200",
        "aff": "Karim Botros; Mohammad Alkhatib; David Folio; Antoine Ferreira",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812114/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10149911428803828956&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9812173",
        "title": "Fully Persistent Spatial Data Structures for Efficient Queries in Path-Dependent Motion Planning Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning is a ubiquitous problem that is often a bottleneck in robotic applications. We demonstrate that motion planning problems such as minimum constraint removal, belief-space planning, and visibility-aware motion planning (VAMP) benefit from a path-dependent formulation, in which the state at a search node is represented implicitly by the path to that node. A na\u00efve approach to computing the feasibility of a successor node in such a path-dependent formulation takes time linear in the path length to the node, in contrast to a (possibly very large) constant time for a more typical search formulation. For long-horizon plans, performing this linear-time computation, which we call the lookback, for each node becomes prohibitive. To improve upon this, we introduce the use of a fully persistent spatial data structure (FPSDS), which bounds the size of the lookback. We then focus on the application of the FPSDS in VAMP, which involves incremental geometric computations that can be accelerated by filtering configurations with bounding volumes using nearest-neighbor data structures. We demonstrate an asymptotic and practical improvement in the runtime of finding VAMP solutions in several illustrative domains. To the best of our knowledge, this is the first use of a fully persistent data structure for accelerating motion planning.",
        "primary_area": "",
        "author": "Sathwik Karnik;Tom\u00e1s Lozano-P\u00e9rez;Leslie Pack Kaelbling;Gustavo Nunes Goretkin;Sathwik Karnik;Tom\u00e1s Lozano-P\u00e9rez;Leslie Pack Kaelbling;Gustavo Nunes Goretkin",
        "authorids": "/37089448371;/38273814000;/37269373600;/37077671800;/37089448371;/38273814000;/37269373600;/37077671800",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812173/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:e28wqzInFg8J:scholar.google.com/&scioq=Fully+Persistent+Spatial+Data+Structures+for+Efficient+Queries+in+Path-Dependent+Motion+Planning+Applications&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812059",
        "title": "Fusing Event-based and RGB camera for Robust Object Detection in Adverse Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to detect objects, under image corruptions and different weather conditions is vital for deep learning models especially when applied to real-world applications such as autonomous driving. Traditional RGB-based detection fails under these conditions and it is thus important to design a sensor suite that is redundant to failures of the primary frame-based detection. Event-based cameras can complement frame-based cameras in low-light conditions and high dynamic range scenarios that an autonomous vehicle can encounter during navigation. Accordingly, we propose a redundant sensor fusion model of event-based and frame-based cameras that is robust to common image corruptions. The method utilizes a voxel grid representation for events as input and proposes a two-parallel feature extractor network for frames and events. Our sensor fusion approach is more robust to corruptions by over 30% compared to only frame-based detections and outperforms the only event-based detection. The model is trained and evaluated on the publicly released DSEC dataset.",
        "primary_area": "",
        "author": "Abhishek Tomy;Anshul Paigwar;Khushdeep S. Mann;Alessandro Renzaglia;Christian Laugier;Abhishek Tomy;Anshul Paigwar;Khushdeep S. Mann;Alessandro Renzaglia;Christian Laugier",
        "authorids": "/37089449253;/37085996873;/37089448149;/37590277500;/37273327000;/37089449253;/37085996873;/37089448149;/37590277500;/37273327000",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812059/",
        "gs_citation": 76,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6490120945141520558&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10
    },
    {
        "id": "9811821",
        "title": "Fusion-FlowNet: Energy-Efficient Optical Flow Estimation using Sensor Fusion and Deep Fused Spiking-Analog Network Architectures",
        "track": "main",
        "status": "Poster",
        "abstract": "Standard frame-based cameras that sample light intensity frames are heavily impacted by motion blur for high-speed motion and fail to perceive scene accurately in high-dynamic range environments. Event-based cameras, on the other hand, overcome these limitations by asynchronously detecting the variation in individual pixel intensities. However, event cameras only capture pixels in motion, leading to sparse information. Hence, estimating the overall dense behavior of pixels is difficult. To address aforementioned issues associated with both sensors, we present Fusion-FlowNet, a sensor fusion framework for energy -efficient optical flow estimation. Fusion-FlowNet utilizes both frame- and event-based sensors, leveraging their complementary characteristics. Our proposed network architecture is also a fusion of Spiking Neural Net-works (SNNs) and Analog Neural Networks (ANNs) where each network is designed to simultaneously process asynchronous event streams and regular frame-based images, respectively. We perform end-to-end training using unsupervised learning to avoid expensive video annotations. Our method generalizes well across distinct environments (rapid motion and challenging lighting conditions) and demonstrates state-of-the-art optical flow prediction on the Multi-Vehicle Stereo Event Camera (MVSEC) dataset. Furthermore, the usage of SNNs in our architecture offers substantial savings in terms of the number of network parameters and computational energy cost.",
        "primary_area": "",
        "author": "Chankyu Lee;Adarsh Kumar Kosta;Kaushik Roy;Chankyu Lee;Adarsh Kumar Kosta;Kaushik Roy",
        "authorids": "/37086494899;/37087935885;/37274519700;/37086494899;/37087935885;/37274519700",
        "aff": "Purdue University, West Lafayette, IN, USA; Purdue University, West Lafayette, IN, USA; Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811821/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17914175182579589779&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811945",
        "title": "FusionNet: Coarse-to-Fine Extrinsic Calibration Network of LiDAR and Camera with Hierarchical Point-pixel Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel network, Fusion-Net, which can estimate the extrinsic calibration matrix between LiDAR and a monocular RGB camera with high accuracy and robustness. FusionNet is a coarse-to-fine method, providing an online and end-to-end solution that can automatically detect and correct the decalibration without any specially designed targets or environments. First, the network applies deep-learning-based technologies to extract the features of LiDAR point clouds and RGB images. Then a novel method is adopted to fuse the features got from different sensors by projecting LiDAR features onto RGB feature maps, searching for the RGB features with the projected points as centers and concatenating the extracted RGB features with LiDAR features. To increase the accuracy, we apply a coarse-to-fine method in the network, by transforming LiDAR points and estimating the extrinsic calibration matrices from the coarse scale to the fine scale. The network is trained on random artificial decalibration matrices. Compared to existing approaches, our method doesn't need to train additional iterative networks, but it can also adapt to different ranges of decalibration.",
        "primary_area": "",
        "author": "Guangming Wang;Jiahao Qiu;Yanfeng Guo;Hesheng Wang;Guangming Wang;Jiahao Qiu;Yanfeng Guo;Hesheng Wang",
        "authorids": "/37086937116;/37089448591;/37089448979;/37292567100;/37086937116;/37089448591;/37089448979;/37292567100",
        "aff": "Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811945/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4130835807389376955&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812336",
        "title": "GCLO: Ground Constrained LiDAR Odometry with Low-drifts for GPS-denied Indoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR is widely adopted in Simultaneous Localization And Mapping (SLAM) and High Definition (HD) map production. The accuracy of LiDAR Odometry (LO) is of great importance, especially in GPS-denied environments. However, we found typical LO results are prone to drift upwards along the vertical direction in underground parking lots, leading to poor mapping results. This paper proposes a Ground Constrained LO method named GCLO, which exploits planar grounds in these specific environments to compress the vertical pose drifts. GCLO is divided into three parts. First, a sensor-centric sliding map is maintained, and the point-to-plane ICP method is implemented to perform the scan-to-map registration. Then, at each key-frame, the sliding map is recorded as a local map. Ground points nearby are segmented and modeled as a planar landmark in the form of Closest Point (CP) parameterization. Finally, planar ground landmarks observed at different key-frames are associated. The ground landmark observation constraints are fused into the pose graph optimization framework to improve the LO performance. Experimental results in HIK and KITTI datasets demonstrate GCLO's superior performances in terms of accuracy in indoor multi-floor parking lots and flat outdoor sites. The limitation of GCLO in adaptability for other environments is also discussed.",
        "primary_area": "",
        "author": "Xin Wei;Jixin Lv;Jie Sun;Erbao Dong;Shiliang Pu;Xin Wei;Jixin Lv;Jie Sun;Erbao Dong;Shiliang Pu",
        "authorids": "/37085809986;/38548389500;/37089315488;/37969776300;/37085657816;/37085809986;/38548389500;/37089315488;/37969776300;/37085657816",
        "aff": "Hikvision Research Institute (HRI), Hangzhou Hikvision Digital Technology Co.,Ltd., Hangzhou, China; Hikvision Research Institute (HRI), Hangzhou Hikvision Digital Technology Co.,Ltd., Hangzhou, China; Hikvision Research Institute (HRI), Hangzhou Hikvision Digital Technology Co.,Ltd., Hangzhou, China; University of Science and Technology of China (USTC), Hefei, China; Hikvision Research Institute (HRI), Hangzhou Hikvision Digital Technology Co.,Ltd., Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812336/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5748128026562398898&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Hikvision Research Institute;University of Science and Technology of China",
        "aff_unique_dep": "Research Institute;",
        "aff_unique_url": "https://www.hikvision.com/cn/;http://www.ustc.edu.cn",
        "aff_unique_abbr": "HRI;USTC",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Hangzhou;Hefei",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812253",
        "title": "GOHOME: Graph-Oriented Heatmap Output for future Motion Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose GOHOME, a method leveraging graph representations of the High Definition Map and sparse projections to generate a heatmap output representing the future position probability distribution for a given agent in a traffic scene. This heatmap output yields an unconstrained 2D grid representation of agent future possible locations, allowing inherent multimodality and a measure of the uncertainty of the prediction. Our graph-oriented model avoids the high computation burden of representing the surrounding context as squared images and processing it with classical CNNs, but focuses instead only on the most probable lanes where the agent could end up in the immediate future. GOHOME reaches 2nd on Argoverse Motion Forecasting Benchmark on the Misskate6metric while achieving significant speed-up and memory burden diminution compared to Argoverse 1st place method HOME. We also highlight that heatmap output enables multimodal ensembling and improve 1st place MissRate6by more than 15% with our best ensemble on Argoverse. Finally, we evaluate and reach state-of-the-art performance on the other trajectory prediction datasets nuScenes and Interaction, demonstrating the generalizability of our method.",
        "primary_area": "",
        "author": "Thomas Gilles;Stefano Sabatini;Dzmitry Tsishkou;Bogdan Stanciulescu;Fabien Moutarde;Thomas Gilles;Stefano Sabatini;Dzmitry Tsishkou;Bogdan Stanciulescu;Fabien Moutarde",
        "authorids": "/37088505584;/37089610490;/37078665400;/37688379600;/37571724400;/37088505584;/37089610490;/37078665400;/37688379600;/37571724400",
        "aff": "MINES ParisTech, PSL University, Center for robotics; IoV team, Paris Research Center, Huawei Technologies, France; IoV team, Paris Research Center, Huawei Technologies, France; MINES ParisTech, PSL University, Center for robotics; MINES ParisTech, PSL University, Center for robotics",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812253/",
        "gs_citation": 306,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15665020915072024669&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 19,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "MINES ParisTech;Huawei",
        "aff_unique_dep": "Center for robotics;IoV team",
        "aff_unique_url": "https://www.mines-paristech.fr;https://www.huawei.com",
        "aff_unique_abbr": "MPT;Huawei",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Paris",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812387",
        "title": "GOMP-FIT: Grasp-Optimized Motion Planning for Fast Inertial Transport",
        "track": "main",
        "status": "Poster",
        "abstract": "High-speed motions in pick-and-place operations are critical to making robots cost-effective in many automation scenarios, from warehouses and manufacturing to hospitals and homes. However, motions can be too fast-such as when the object being transported has an open-top, is fragile, or both. One way to avoid spills or damage, is to move the arm slowly. We propose an alternative: Grasp-Optimized Motion Planning for Fast Inertial Transport (GOMP-FIT), a time-optimizing motion planner based on our prior work, that includes con-straints based on accelerations at the robot end-effector. With GOMP-FIT, a robot can perform high-speed motions that avoid obstacles and use inertial forces to its advantage. In experiments transporting open-top containers with varying tilt tolerances, whereas GOMP computes sub-second motions that spill up to 90 % of the contents during transport, GOMP-FIT generates motions that spill 0 % of contents while being slowed by as little as 0 % when there are few obstacles, 30 % when there are high obstacles and 45-degree tolerances, and 50 % when there 15-degree tolerances and few obstacles. Videos and more at: https://berkeleyautomation.github.io/gomp-fit/.",
        "primary_area": "",
        "author": "Jeffrey Ichnowski;Yahav Avigal;Yi Liu;Ken Goldberg;Jeffrey Ichnowski;Yahav Avigal;Yi Liu;Ken Goldberg",
        "authorids": "/38541287200;/37088504860;/37089448999;/37273026700;/38541287200;/37088504860;/37089448999;/37273026700",
        "aff": "AUTOLab, University of California, Berkeley, CA; AUTOLab, University of California, Berkeley, CA; AUTOLab, University of California, Berkeley, CA; AUTOLab, University of California, Berkeley, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812387/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10708596353613280396&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "AUTOLab",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812364",
        "title": "GPS-Denied Global Visual-Inertial Ground Vehicle State Estimation via Image Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic systems such as unmanned ground vehicles (UGVs) often depend on GPS for navigation in outdoor environments. In GPS-denied environments, one approach to maintain a global state estimate is localizing based on preexisting georeferenced aerial or satellite imagery. However, this is inherently challenged by the significantly differing perspectives between the UGV and reference images. In this paper, we introduce a system for global localization of UGVs in remote, natural environments. We use multi-stereo visual inertial odometry (MSVIO) to provide local tracking. To overcome the challenge of differing viewpoints we use a probabilistic occupancy model to generate synthetic orthographic images from color images taken by the UGV. We then derive global information by scan matching local images to existing reference imagery and then use a pose graph to fuse the measurements to provide uninterrupted global positioning after loss of GPS signal. We show that our system generates visually accurate orthographic images of the environment, provides reliable global measurements, and maintains an accurate global state estimate in GPS-denied conditions.",
        "primary_area": "",
        "author": "Yehonathan Litman;Daniel McGann;Eric Dexheimer;Michael Kaess;Yehonathan Litman;Daniel McGann;Eric Dexheimer;Michael Kaess",
        "authorids": "/37087322119;/37086862643;/37088688319;/37324200400;/37087322119;/37086862643;/37088688319;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812364/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6118674217016535154&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811876",
        "title": "GPU-Accelerated Policy Optimization via Batch Automatic Differentiation of Gaussian Processes for Real-World Control",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability of Gaussian processes (GPs) to predict the behavior of dynamical systems as a more sample-efficient alternative to parametric models seems promising for real-world robotics research. However, the computational complexity of GPs has made policy search a highly time and memory consuming process that has not been able to scale to larger problems. In this work, we develop a policy optimization method by leveraging fast predictive sampling methods to process batches of trajectories in every forward pass, and compute gradient updates over policy parameters by automatic differentiation of Monte Carlo evaluations, all on GPU. We demonstrate the effectiveness of our approach in training policies on a set of reference-tracking control experiments with a heavy-duty machine. Benchmark results show a significant speedup over exact methods and showcase the scalability of our method to larger policy networks, longer horizons, and up to thousands of trajectories with a sublinear drop in speed.",
        "primary_area": "",
        "author": "Abdolreza Taheri;Joni Pajarinen;Reza Ghabcheloo;Abdolreza Taheri;Joni Pajarinen;Reza Ghabcheloo",
        "authorids": "/37089008360;/37398592200;/37298989400;/37089008360;/37398592200;/37298989400",
        "aff": "Control Systems R&D, HIAB, Sweden; Intelligent Autonomous Systems, TU Darmstadt, Germany; Faculty of Engineering and Natural Sciences, Tampere University, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811876/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11703480526659278787&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "HIAB;Technische Universit\u00e4t Darmstadt;Tampere University",
        "aff_unique_dep": "Control Systems R&D;Intelligent Autonomous Systems;Faculty of Engineering and Natural Sciences",
        "aff_unique_url": ";https://www.tu-darmstadt.de;https://www.tuni.fi",
        "aff_unique_abbr": ";TU Darmstadt;Tuni",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "Sweden;Germany;Finland"
    },
    {
        "id": "9812384",
        "title": "GRiD: GPU-Accelerated Rigid Body Dynamics with Analytical Gradients",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce GRiD: a GPU-accelerated library for computing rigid body dynamics with analytical gradients. GRiD was designed to accelerate the nonlinear trajectory opti-mization subproblem used in state-of-the-art robotic planning, control, and machine learning, which requires tens to hundreds of naturally parallel computations of rigid body dynamics and their gradients at each iteration. GRiD leverages URDF parsing and code generation to deliver optimized dynamics kernels that not only expose GPU-friendly computational patterns, but also take advantage of both fine-grained parallelism within each computation and coarse-grained parallelism between computations. Through this approach, when performing multiple computations of rigid body dynamics algorithms, GRiD provides as much as a 7.2x speedup over a state-of-the-art, multi-threaded CPU implementation, and maintains as much as a 2.5x speedup when accounting for I/O overhead. We release GRiD as an open-source library for use by the wider robotics community.",
        "primary_area": "",
        "author": "Brian Plancher;Sabrina M. Neuman;Radhika Ghosal;Scott Kuindersma;Vijay Janapa Reddi;Brian Plancher;Sabrina M. Neuman;Radhika Ghosal;Scott Kuindersma;Vijay Janapa Reddi",
        "authorids": "/37086069939;/37062893900;/37089023714;/37990645600;/37293801200;/37086069939;/37062893900;/37089023714;/37990645600;/37293801200",
        "aff": "School of Engineering and Applied SciencesM Harvard University, Cambridge, MA; School of Engineering and Applied SciencesM Harvard University, Cambridge, MA; School of Engineering and Applied SciencesM Harvard University, Cambridge, MA; Boston Dynamics, Waltham, MA; School of Engineering and Applied SciencesM Harvard University, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812384/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4932851364842638595&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Harvard University;Boston Dynamics",
        "aff_unique_dep": "School of Engineering and Applied Sciences;",
        "aff_unique_url": "https://www.harvard.edu;https://www.bostondynamics.com",
        "aff_unique_abbr": "Harvard;BD",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Cambridge;Waltham",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812008",
        "title": "GTGraffiti: Spray Painting Graffiti Art from Human Painting Motions with a Cable Driven Parallel Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "We present GTGraffiti, a graffiti painting system from Georgia Tech that tackles challenges in art, hardware, and human-robot collaboration. The problem of painting graffiti in a human style is particularly challenging and requires a system-level approach because the robotics and art must be designed around each other. The robot must be highly dynamic over a large workspace while the artist must work within the robot's limitations. Our approach consists of three stages: artwork capture, robot hardware, and planning & control. We use motion capture to capture collaborator painting motions which are then composed and processed into a time-varying linear feedback controller for a cable-driven parallel robot (CDPR) to execute. In this work, we will describe the capturing process, the design and construction of a purpose-built CDPR, and the software for turning an artist's vision into control commands. Our work represents an important step towards faithfully recreating human graffiti artwork by demonstrating that we can reproduce artist motions up to 2m/s and 20m/s2 within 9.3mm RMSE to paint artworks.",
        "primary_area": "",
        "author": "Gerry Chen;Sereym Baek;Juan-Diego Florez;Wanli Qian;Sang-Won Leigh;Seth Hutchinson;Frank Dellaert;Gerry Chen;Sereym Baek;Juan-Diego Florez;Wanli Qian;Sang-Won Leigh;Seth Hutchinson;Frank Dellaert",
        "authorids": "/37089000441;/37089447230;/37089446750;/37089436919;/38261095400;/37282386200;/37282902200;/37089000441;/37089447230;/37089446750;/37089436919;/38261095400;/37282386200;/37282902200",
        "aff": "Institute for Robotics and Intelligent Machines, College of Computing, Georgia Institute of Technology, Atlanta, GA; Institute for Robotics and Intelligent Machines, College of Computing, Georgia Institute of Technology, Atlanta, GA; Institute for Robotics and Intelligent Machines, College of Computing, Georgia Institute of Technology, Atlanta, GA; Institute for Robotics and Intelligent Machines, College of Computing, Georgia Institute of Technology, Atlanta, GA; Institute for Robotics and Intelligent Machines, College of Computing, Georgia Institute of Technology, Atlanta, GA; Institute for Robotics and Intelligent Machines, College of Computing, Georgia Institute of Technology, Atlanta, GA; Institute for Robotics and Intelligent Machines, College of Computing, Georgia Institute of Technology, Atlanta, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812008/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2239794299709188929&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "College of Computing",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811865",
        "title": "Game-Theoretic Planning for Autonomous Driving among Risk-Aware Human Drivers",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel approach for risk-aware planning with human agents in multi-agent traffic scenarios. Our approach takes into account the wide range of human driver behaviors on the road, from aggressive maneuvers like speeding and overtaking, to conservative traits like driving slowly and conforming to the right-most lane. In our approach, we learn a mapping from a data-driven human driver behavior model called the CMetric to a driver's entropic risk preference. We then use the derived risk preference within a game-theoretic risk-sensitive planner to model risk-aware interactions among human drivers and an autonomous vehicle in various traffic scenarios. We demonstrate our method in a merging scenario, where our results show that the final trajectories obtained from the risk-aware planner generate desirable emergent behaviors. Particularly, our planner recognizes aggressive human drivers and yields to them while maintaining a greater distance from them. In a user study, participants were able to distinguish between aggressive and conservative simulated drivers based on trajectories generated from our risk-sensitive planner. We also observe that aggressive human driving results in more frequent lane-changing in the planner. Finally, we compare the performance of our modified risk-aware planner with existing methods and show that modeling human driver behavior leads to safer navigation.",
        "primary_area": "",
        "author": "Rohan Chandra;Mingyu Wang;Mac Schwager;Dinesh Manocha;Rohan Chandra;Mingyu Wang;Mac Schwager;Dinesh Manocha",
        "authorids": "/37086365992;/37086454215;/37424620600;/37267825600;/37086365992;/37086454215;/37424620600;/37267825600",
        "aff": "Department of Computer Science, University of Maryland, USA; Department of Mechanical Engineering, Stanford University, Stanford, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, USA; Department of Electrical and Computer Engineering, University of Maryland, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811865/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6800127962832783223&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Maryland;Stanford University",
        "aff_unique_dep": "Department of Computer Science;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.umd.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UMD;Stanford",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812343",
        "title": "Gaussian Belief Trees for Chance Constrained Asymptotically Optimal Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the problem of sampling-based motion planning under motion and measurement un-certainty with probabilistic guarantees. We generalize traditional sampling-based, tree-based motion planning algorithms for deterministic systems and propose belief-A, a framework that extends any kinodynamical tree-based planner to the belief space for linear (or linearizable) systems. We introduce appropriate sampling techniques and distance metrics for the belief space that preserve the probabilistic completeness and asymptotic optimality properties of the underlying planner. We demonstrate the efficacy of our approach for finding safe low-cost paths efficiently and asymptotically optimally in simulation, for both holonomic and non-holonomic systems.",
        "primary_area": "",
        "author": "Qi Heng Ho;Zachary N. Sunberg;Morteza Lahijanian;Qi Heng Ho;Zachary N. Sunberg;Morteza Lahijanian",
        "authorids": "/37087321977;/38488385500;/37398443600;/37087321977;/38488385500;/37398443600",
        "aff": "department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812343/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14201547632715683211&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Aerospace Engineering Sciences",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811781",
        "title": "Gaussian Process Self-triggered Policy Search in Weakly Observable Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The environments of such large industrial machines as waste cranes in waste incineration plants are often weakly observable, where little information about the environ-mental state is contained in the observations due to technical difficulty or maintenance cost (e.g., no sensors for observing the state of the garbage to be handled). Based on the findings that skilled operators in such environments choose predetermined control strategies (e.g., grasping and scattering) and their durations based on sensor values, we propose a novel non-parametric policy search algorithm: Gaussian process self-triggered policy search (GPSTPS). GPSTPS has two types of control policies: action and duration. A gating mechanism either maintains the action selected by the action policy for the duration specified by the duration policy or updates the action and duration by passing new observations to the policy; therefore, it is categorized as self-triggered. GPSTPS simultaneously learns both policies by trial and error based on sparse GP priors and variational learning to maximize the return. To verify the performance of our proposed method, we conducted experiments on garbage-grasping-scattering task for a waste crane with weak observations using a simulation and a robotic waste crane system. As experimental results, the proposed method acquired suitable policies to determine the action and duration based on the garbage's characteristics.",
        "primary_area": "",
        "author": "Hikaru Sasaki;Terushi Hirabayashi;Kaoru Kawabata;Takamitsu Matsubara;Hikaru Sasaki;Terushi Hirabayashi;Kaoru Kawabata;Takamitsu Matsubara",
        "authorids": "/37086937467;/37088428190;/37087010650;/37533262700;/37086937467;/37088428190;/37087010650;/37533262700",
        "aff": "Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology (NAIST), Japan; Hitachi Zosen Corporation, Japan; Hitachi Zosen Corporation, Japan; Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology (NAIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811781/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3420391134570936537&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Nara Institute of Science and Technology;Hitachi Zosen Corporation",
        "aff_unique_dep": "Division of Information Science, Graduate School of Science and Technology;",
        "aff_unique_url": "https://www.naist.edu/;https://www.hitachi-zosen.com",
        "aff_unique_abbr": "NAIST;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811832",
        "title": "GelSlim 3.0: High-Resolution Measurement of Shape, Force and Slip in a Compact Tactile-Sensing Finger",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a new version of tactile-sensing finger, GelSlim 3.0, which integrates the ability to sense high-resolution shape, force, and slip in a more compact form factor than previous implementations, designed for cluttered bin-picking scenarios. The novel design integrates real-time model-based algorithms to measure shape, estimate the 3-D contact force distribution, and detect incipient slip. The constraints imposed by the photometric stereo algorithm used for depth reconstruction and the implementation of a planar sensing surface make the miniaturization of previous designs nontrivial. To achieve a compact integration, we optimize the optical path from illumination source to camera. Using an optical simulation environment, we develop an illumination shaping lens and position the source LEDs and camera. The optimized optical configuration is integrated into a finger design composed of a robust and easily replaceable snap-to-fit fingertip module that facilitates manufacture, assembly, use, and repair. To stimulate future research in tactile-sensing and provide the robotics community access to a reliable and easily reproducible tactile finger with a diversity of sensing modalities, we open-source the design, fabrication methods, and software at https://github.com/mcubelab/gelslim.",
        "primary_area": "",
        "author": "Ian H. Taylor;Siyuan Dong;Alberto Rodriguez;Ian H. Taylor;Siyuan Dong;Alberto Rodriguez",
        "authorids": "/37087390549;/37086249096;/38194796600;/37087390549;/37086249096;/38194796600",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811832/",
        "gs_citation": 219,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=121522194962169407&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812195",
        "title": "Generalizable task representation learning from human demonstration videos: a geometric approach",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of generalizable task learning from human demonstration videos without extra training on the robot or pre-recorded robot motions. Given a set of human demonstration videos showing a task with different objects/tools (categorical objects), we aim to learn a representation of visual observation that generalizes to categorical objects and enables efficient controller design. We propose to introduce a geometric task structure to the representation learning problem that geometrically encodes the task specification from human demonstration videos, and that enables generalization by building task specification correspondence between categorical objects. Specifically, we propose CoVGS-IL, which uses a graph-structured task function to learn task representations under structural constraints. Our method enables task generalization by selecting geometric features from different objects whose inner connection relationships define the same task in geometric constraints. The learned task representation is then transferred to a robot controller using uncalibrated visual servoing (UVS); thus, the need for extra robot training or pre-recorded robot motions is removed.",
        "primary_area": "",
        "author": "Jun Jin;Martin Jagersand;Jun Jin;Martin Jagersand",
        "authorids": "/37086574802;/37269568300;/37086574802;/37269568300",
        "aff": "Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812195/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1090690746780331829&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Department of Computing Science",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edmonton",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812395",
        "title": "Generalized 3D Rigid Point Set Registration with Anisotropic Positional Error Based on Bayesian Coherent Point Drift",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel, robust, and accurate three-dimensional (3D) rigid point set registration (PSR) method, which is achieved by generalizing the state-of-the-art (SOTA) Bayesian coherent point drift (BCPD) theory to the scenario that high-dimensional point sets(PSs) are aligned and that the anisotropic positional noise is considered. Our contributions in this paper are three folds. First, the problem of rigidly aligning two general point sets (PSs) with normal vectors is incorporated into a variational Bayesian inference framework, which is solved by generalizing the BCPD approach while the anisotropic positional noise is considered. Second, the updated parameters during the algorithm's iterations are given in closed-form or iterative solutions. Third, extensive experiments have been done to validate the proposed approach and its significant improvements over the BCPD.",
        "primary_area": "",
        "author": "Ang Zhang;Zhe Min;Xing Yang;Zhengyan Zhang;Jin Pan;Max Q.-H. Meng;Ang Zhang;Zhe Min;Xing Yang;Zhengyan Zhang;Jin Pan;Max Q.-H. Meng",
        "authorids": "/37087246928;/37086002886;/37086953087;/37089016419;/37087244420;/37274117000;/37087246928;/37086002886;/37086953087;/37089016419;/37087244420;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong, N.T., Hong Kong, China; Wellcome/EPSRC Centre for Surgical and Interventional Sciences. University College London, UK; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; Department of Electronic Engineering, The Chinese University of Hong Kong, N.T., Hong Kong, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812395/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4502373786255801698&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;0;3",
        "aff_unique_norm": "Chinese University of Hong Kong;University College London;Harbin Institute of Technology;Southern University of Science and Technology",
        "aff_unique_dep": "Department of Electronic Engineering;Wellcome/EPSRC Centre for Surgical and Interventional Sciences;School of Mechanical Engineering and Automation;Department of Electronic and Electrical Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.ucl.ac.uk;http://www.hit.edu.cn/;https://www.sustech.edu.cn",
        "aff_unique_abbr": "CUHK;UCL;HIT;SUSTech",
        "aff_campus_unique_index": "0;2;2;0;2",
        "aff_campus_unique": "N.T.;;Shenzhen",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9812082",
        "title": "Generalized Affordance Templates for Mobile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents recent advances to the Affordance Template (AT) task description language. Affordance Templates provide standardized, easy-to-use tools for defining robot manipulation tasks that provide a high level of augmented reality capabilities to facilitate human-in-the-loop operation, but can also be used to support robot autonomy when coupled with various planning tools. While initially defined in terms of end effector waypoint sequences for bimanual robots, such as the NASA Valkyrie and Robonaut 2, this paper extends the original specification to support integrated mobile manipulation, object-centric template definitions, autonomous grasp determination, and integration with custom and off-the-shelf collision free motion planners. ATs have proved highly adaptable to new robots and new domains by both the authors and third-party groups, and have been used in numerous contexts for NASA, DOD, and industry. As such, we believe that the AT framework provides a strong foundation for robot development in multiple real-world contexts that can be increasingly built upon and expanded to meet the challenges of many new applications.",
        "primary_area": "",
        "author": "Stephen Hart;Ana Huam\u00e1n Quispe;Michael W. Lanighan;Seth Gee;Stephen Hart;Ana Huam\u00e1n Quispe;Michael W. Lanighan;Seth Gee",
        "authorids": "/37279717400;/37085525122;/37085550092;/38244306100;/37279717400;/37085525122;/37085550092;/38244306100",
        "aff": "TRACLabs, Inc., Webster, TX; TRACLabs, Inc., Webster, TX; TRACLabs, Inc., Webster, TX; TRACLabs, Inc., Webster, TX",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812082/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13144039893968834525&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "TRACLabs, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811929",
        "title": "Generalized Omega Turn Gait Enables Agile Limbless Robot Turning in Complex Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Reorientation (turning in plane) plays a critical role for all robots in any field application, especially those that in confined spaces. While important, reorientation remains a relatively unstudied problem for robots, including limbless mechanisms, often called snake robots. Instead of looking at snakes, we take inspiration from observations of the turning behavior of tiny nematode worms C. elegans. Our previous work presented an in-place and in-plane turning gait for limbless robots, called an omega turn, and prescribed it using a novel two-wave template [1]. In this work, we advance omega turn-inspired controllers in three aspects: 1) we use geometric methods to vary joint angle amplitudes and forward wave spatial frequency in our turning equation to establish a wide and precise amplitude modulation and frequency modulation on omega turn; 2) we use this new relationship to enable robots with fewer internal degrees of freedom (i.e., fewer joints in the body) to achieve desirable performance, and 3) we apply compliant control methods to this relationship to handle unmodelled effects in the environment. We experimentally validate our approach on a limbless robot that the omega turn can produce effective and robust turning motion in various types of environments, such as granular media and rock pile.",
        "primary_area": "",
        "author": "Tianyu Wang;Baxi Chong;Yuelin Deng;Ruijie Fu;Howie Choset;Daniel I. Goldman;Tianyu Wang;Baxi Chong;Yuelin Deng;Ruijie Fu;Howie Choset;Daniel I. Goldman",
        "authorids": "/37088483378;/37088489862;/37088924289;/37089195227;/37281322200;/38182137200;/37088483378;/37088489862;/37088924289;/37089195227;/37281322200;/38182137200",
        "aff": "Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811929/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1253981297427380899&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gatech.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Georgia Tech;CMU",
        "aff_campus_unique_index": "0;0;1;1;1;0",
        "aff_campus_unique": "Atlanta;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812169",
        "title": "Generalizing to New Domains by Mapping Natural Language to Lifted LTL",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work on using natural language to specify commands to robots has grounded that language to LTL. However, mapping natural language task specifications to LTL task specifications using language models require probability distributions over finite vocabulary. Existing state-of-the-art methods have extended this finite vocabulary to include unseen terms from the input sequence to improve output generalization. However, novel out-of-vocabulary atomic propositions cannot be generated using these methods. To overcome this, we introduce an intermediate contextual query representation which can be learned from single positive task specification examples, associating a contextual query with an LTL template. We demonstrate that this intermediate representation allows for generalization over unseen object references, assuming accurate groundings are available. We compare our method of mapping natural language task specifications to intermediate contextual queries against state-of-the-art CopyNet models capable of translating natural language to LTL, by evaluating whether correct LTL for manipulation and navigation task specifications can be output, and show that our method outperforms the CopyNet model on unseen object references. We demonstrate that the grounded LTL our method outputs can be used for planning in a simulated OO-MDP environment. Finally, we discuss some common failure modes encountered when translating natural language task specifications to grounded LTL.",
        "primary_area": "",
        "author": "Eric Hsiung;Hiloni Mehta;Junchi Chu;Xinyu Liu;Roma Patel;Stefanie Tellex;George Konidaris;Eric Hsiung;Hiloni Mehta;Junchi Chu;Xinyu Liu;Roma Patel;Stefanie Tellex;George Konidaris",
        "authorids": "/37089447198;/37089448079;/37089450779;/37089450089;/37089448355;/37402794800;/38318614200;/37089447198;/37089448079;/37089450779;/37089450089;/37089448355;/37402794800;/38318614200",
        "aff": "Department of Computer Science, Brown University, Providence, RI; Department of Computer Science, Brown University, Providence, RI; Department of Computer Science, Brown University, Providence, RI; Department of Computer Science, Brown University, Providence, RI; Department of Computer Science, Brown University, Providence, RI; Department of Computer Science, Brown University, Providence, RI; Department of Computer Science, Brown University, Providence, RI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812169/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15621031456354189568&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Providence",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812385",
        "title": "Globally Consistent and Tightly Coupled 3D LiDAR Inertial Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a real-time 3D mapping framework based on global matching cost minimization and LiDAR-IMU tight coupling. The proposed framework comprises a preprocessing module and three estimation modules: odometry estimation, local mapping, and global mapping, which are all based on the tight coupling of the GPU-accelerated voxelized GICP matching cost factor and the IMU preintegration factor. The odometry estimation module employs a keyframe-based fixed-lag smoothing approach for efficient and low-drift trajectory estimation, with a bounded computation cost. The global mapping module constructs a factor graph that minimizes the global registration error over the entire map with the support of IMU constraints, ensuring robust optimization in feature-less environments. The evaluation results on the Newer College dataset and KAIST urban dataset show that the proposed framework enables accurate and robust localization and mapping in challenging environments.",
        "primary_area": "",
        "author": "Kenji Koide;Masashi Yokozuka;Shuji Oishi;Atsuhiko Banno;Kenji Koide;Masashi Yokozuka;Shuji Oishi;Atsuhiko Banno",
        "authorids": "/37086179385;/38230409400;/37085895378;/37391486400;/37086179385;/38230409400;/37085895378;/37391486400",
        "aff": "Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan; Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Tsukuba, Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812385/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8318074698424157856&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Department of Information Technology and Human Factors",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tsukuba",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812380",
        "title": "Globally Optimal Relative Pose Estimation for Multi-Camera Systems with Known Gravity Direction",
        "track": "main",
        "status": "Poster",
        "abstract": "Multiple-camera systems have been widely used in self-driving cars, robots, and smartphones. In addition, they are typically also equipped with IMUs (inertial measurement units). Using the gravity direction extracted from the IMU data, the y-axis of the body frame of the multi-camera system can be aligned with this common direction, reducing the original three degree-of-freedom(DOF) relative rotation to a single DOF one. This paper presents a novel globally optimal solver to compute the relative pose of a generalized camera. Existing optimal solvers based on LM (Levenberg-Marquardt) method or SDP (semidefinite program) are either iterative or have high computational complexity. Our proposed optimal solver is based on minimizing the algebraic residual objective function. According to our derivation, using the least-squares algorithm, the original optimization problem can be converted into a system of two polynomials with only two variables. The proposed solvers have been tested on synthetic data and the KITTI benchmark. The experimental results show that the proposed methods have competitive robustness and accuracy compared with the existing state-of-the-art solvers.",
        "primary_area": "",
        "author": "Qianliang Wu;Yaqing Ding;Xinlei Qi;Jin Xie;Jian Yang;Qianliang Wu;Yaqing Ding;Xinlei Qi;Jin Xie;Jian Yang",
        "authorids": "/37089449866;/37088220065;/37089450885;/37085622059;/37280205100;/37089449866;/37088220065;/37089450885;/37085622059;/37280205100",
        "aff": "Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering; Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering; Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering; Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering; Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812380/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3040063526733553344&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "School of Computer Science and Engineering",
        "aff_unique_dep": "Computer Science and Engineering",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811786",
        "title": "Go With the Flow: Energy Minimising Periodic Trajectories for UVMS",
        "track": "main",
        "status": "Poster",
        "abstract": "For Underwater Vehicle Manipulator Systems (UVMS), the ability to keep a fixed end effector pose is required for intervention tasks. Maintaining a static configuration in a dynamic underwater environment requires significant amounts of energy over time, limiting the operational time for battery powered systems. In this work we consider learning the periodic components of the dynamic flow in order to generate periodic trajectories which keep the end effector fixed, yet minimise the energy expenditure over time. We compare this proposed \u2018go with the flow\u2019 approach to the static configuration case for a fixed end effector pose, and show a significant reduction in energy use.",
        "primary_area": "",
        "author": "Wilhelm J. Marais;Stefan B. Williams;Oscar Pizarro;Wilhelm J. Marais;Stefan B. Williams;Oscar Pizarro",
        "authorids": "/37088920935;/37275821600;/37265974600;/37088920935;/37275821600;/37265974600",
        "aff": "Australian Centre for Field Robotics, University of Sydney, NSW, Australia; Australian Centre for Field Robotics, University of Sydney, NSW, Australia; Australian Centre for Field Robotics, University of Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811786/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5663719881769586502&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Sydney",
        "aff_unique_dep": "Australian Centre for Field Robotics",
        "aff_unique_url": "https://www.sydney.edu.au",
        "aff_unique_abbr": "USYD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9811809",
        "title": "Google Scanned Objects: A High-Quality Dataset of 3D Scanned Household Items",
        "track": "main",
        "status": "Poster",
        "abstract": "Interactive 3D simulations have enabled break-throughs in robotics and computer vision, but simulating the broad diversity of environments needed for deep learning requires large corpora of photo-realistic 3D object models. To address this need, we present Google Scanned Objects, an open-source collection of over one thousand 3D-scanned household items released under a Creative Commons license; these models are preprocessed for use in Ignition Gazebo and the Bullet simulation platforms, but are easily adaptable to other simulators. We describe our object scanning and curation pipeline, then provide statistics about the contents of the dataset and its usage. We hope that the diversity, quality, and flexibility of Google Scanned Objects will lead to advances in interactive simulation, synthetic perception, and robotic learning.",
        "primary_area": "",
        "author": "Laura Downs;Anthony Francis;Nate Koenig;Brandon Kinman;Ryan Hickman;Krista Reymann;Thomas B. McHugh;Vincent Vanhoucke;Laura Downs;Anthony Francis;Nate Koenig;Brandon Kinman;Ryan Hickman;Krista Reymann;Thomas B. McHugh;Vincent Vanhoucke",
        "authorids": "/37088723468;/37086453418;/37401781000;/37089446770;/37089450236;/37089447074;/37089449171;/37426058000;/37088723468;/37086453418;/37401781000;/37089446770;/37089450236;/37089447074;/37089449171;/37426058000",
        "aff": "Robotics at Google, Mountain View, CA, USA; Robotics at Google, Mountain View, CA, USA; Nate Koenig is with Open Robotics, Mountain View, CA, USA; Robotics at Google, Mountain View, CA, USA; Robotics at Google, Mountain View, CA, USA; Robotics at Google, Mountain View, CA, USA; Northwestern University, Evanston, IL, USA; Robotics at Google, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811809/",
        "gs_citation": 482,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12158371212936938028&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;0;0;2;0",
        "aff_unique_norm": "Google;Open Robotics;Northwestern University",
        "aff_unique_dep": "Robotics;;",
        "aff_unique_url": "https://www.google.com;http://openrobotics.org;https://www.northwestern.edu",
        "aff_unique_abbr": "Google;Open Robotics;NU",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;0",
        "aff_campus_unique": "Mountain View;Evanston",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811808",
        "title": "Graph Grammar-Based Automatic Design for Heterogeneous Fleets of Underwater Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous underwater vehicles (AUVs) are spe-cialized robots that are commonly used for seafloor surveying and ocean water sampling. Computational design approaches have emerged to reduce the effort required to design both individual AUVs as well as fleets. As the number and scale of underwater missions increases beyond the capabilities of a single vehicle, fleet level design will become more important. Depending on the mission, the optimal fleet may consist of multiple distinct types of AUVs designed to a variety of specifications. Moreover, the AUVs may differ in both continuous parameters (such as battery capacity) and discrete parameters (such as number and model of thrusters). In this work, we present a computational pipeline for designing these heterogeneous AUV fleets. Using a novel shape design space based on a graph grammar and deformation cages, we can express a variety of AUV architectures with different topologies, component selections, and dimensions. We search this space using a combination of discrete graph search and gradient-based continuous optimization, enabled by a differentiable AUV simulator. Finally, we formulate heterogeneous fleet design as a modified knapsack problem, and solve it using an efficient backtracking-based algorithm. We evaluate our pipeline on a simulated mission with nonuniform design requirements-surveying a section of seafloor with varying depth-and show that the best heterogeneous fleet outperforms the best fleet composed of a single vehicle type.",
        "primary_area": "",
        "author": "Allan Zhao;Jie Xu;Juan Salazar;Wei Wang;Pingchuan Ma;Daniela Rus;Wojciech Matusik;Allan Zhao;Jie Xu;Juan Salazar;Wei Wang;Pingchuan Ma;Daniela Rus;Wojciech Matusik",
        "authorids": "/37088827263;/37088996337;/37089450321;/37073346500;/37089448038;/37279652300;/37295070400;/37088827263;/37088996337;/37089450321;/37073346500;/37089448038;/37279652300;/37295070400",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811808/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3480619921922909506&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812411",
        "title": "Graph Neural Network Based Relation Learning for Abnormal Perception Information Detection in Self-Driving Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Robustness and safety concerns of perception systems are of great importance for autonomous vehicle navigation applications. Recent researches demonstrate that the surrounding dynamic object detection results of current perception systems can be easily interfered or attacked to mislead the navigation performance of the victim vehicle. In this paper, we develop a GNN based relation learning network to detect the abnormal information in the vehicle perception results, by investigating the relations among the surrounding dynamic objects and also the overall scenario information. Our underlying logic is that the motion of each surrounding object is also affected by its neighbors as well as the whole traffic scenario information, so there should exist a certain amount of consistency among those agents. Learning their spatiotemporal relations provides critical information for detecting the abnormal perception information. Experimental results on the standard CARLA simulator demonstrate our effectiveness in various scenarios and scalability to unseen cases.",
        "primary_area": "",
        "author": "Kefan Jin;Hongye Wang;Changxing Liu;Yu Zhai;Ling Tang;Kefan Jin;Hongye Wang;Changxing Liu;Yu Zhai;Ling Tang",
        "authorids": "/37088963780;/37089449357;/37089449896;/37088600529;/37089449873;/37088963780;/37089449357;/37089449896;/37088600529;/37089449873",
        "aff": "MOE Key Laboratory of Marine Intelligent Equipment and System, State Key Laboratory of Ocean Engineering, Shanghai Jiao Tong University, China; Department of Automation, Shanghai Jiao Tong University, China; Department of Electronic Engineering, Shanghai Jiao Tong University, China; School of Information and Control Engineering China University of mining and technology, China; Department of Automation, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812411/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16767507426196603031&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;China University of Mining and Technology",
        "aff_unique_dep": "MOE Key Laboratory of Marine Intelligent Equipment and System, State Key Laboratory of Ocean Engineering;School of Information and Control Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn;http://www.cumt.edu.cn/",
        "aff_unique_abbr": "SJTU;CUMT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811874",
        "title": "Graph-based Cluttered Scene Generation and Interactive Exploration using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a novel method to teach a robotic agent to interactively explore cluttered yet structured scenes, such as kitchen pantries and grocery shelves, by leveraging the physical plausibility of the scene. We propose a novel learning framework to train an effective scene exploration policy to discover hidden objects with minimal interactions. First, we define a novel scene grammar to represent structured clutter. Then we train a Graph Neural Network (GNN) based Scene Generation agent using deep reinforcement learning (deep RL), to manipulate this Scene Grammar to create a diverse set of stable scenes, each containing multiple hidden objects. Given such cluttered scenes, we then train a Scene Exploration agent, using deep RL, to uncover hidden objects by interactively rearranging the scene. We show that our learned agents hide and discover significantly more objects than the baselines. We present quantitative results that prove the generalization capabilities of our agents. We also demonstrate sim-to-real transfer by successfully deploying the learned policy on a real UR10 robot to explore real-world cluttered scenes. The supplemental video can be found at: https://www.youtube.com/watch?v=T2Jo7wwaXss.",
        "primary_area": "",
        "author": "K. Niranjan Kumar;Irfan Essa;Sehoon Ha;K. Niranjan Kumar;Irfan Essa;Sehoon Ha",
        "authorids": "/37089450433;/37282740400;/37086314268;/37089450433;/37282740400;/37086314268",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811874/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15042131473889326801&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812386",
        "title": "Graph-based Multi-sensor Fusion for Consistent Localization of Autonomous Construction Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling autonomous operation of large-scale construction machines, such as excavators, can bring key benefits for human safety and operational opportunities for applications in dangerous and hazardous environments. To facilitate robot autonomy, robust and accurate state-estimation remains a core component to enable these machines for operation in a diverse set of complex environments. In this work, a method for multi-modal sensor fusion for robot state-estimation and localization is presented, enabling operation of construction robots in real-world scenarios. The proposed approach presents a graph-based prediction-update loop that combines the benefits of filtering and smoothing in order to provide consistent state estimates at high update rate, while maintaining accurate global localization for large-scale earth-moving excavators. Furthermore, the proposed approach enables a flexible integration of asynchronous sensor measurements and provides consistent pose estimates even during phases of sensor dropout. For this purpose, a dual-graph design for switching between two distinct optimization problems is proposed, directly addressing temporary failure and the subsequent return of global position estimates. The proposed approach is implemented on-board two Menzi Muck walking excavators and validated during real-world tests conducted in representative operational environments.",
        "primary_area": "",
        "author": "Julian Nubert;Shehryar Khattak;Marco Hutter;Julian Nubert;Shehryar Khattak;Marco Hutter",
        "authorids": "/37088229353;/37086181358;/37545251000;/37088229353;/37086181358;/37545251000",
        "aff": "Max Planck ETH Center for Learning Systems; Max Planck ETH Center for Learning Systems; Robotic Systems Lab, ETH Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812386/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2916209122304129725&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Max Planck ETH Center for Learning Systems;ETH Zurich",
        "aff_unique_dep": "Center for Learning Systems;Robotic Systems Lab",
        "aff_unique_url": "https://learning-systems.org;https://www.ethz.ch",
        "aff_unique_abbr": ";ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9812084",
        "title": "Grasp Pose Selection Under Region Constraints for Dirty Dish Grasps Based on Inference of Grasp Success Probability through Self-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In the literature on object grasping, the robot often determines the grasp point and posture from visual information. They predict the grasping point uniquely from the object's shape characteristics. However, as a practical matter, there are cases where there are constraints on grasp point due to the object states, the limitation of the robot's hardware and the surrounding environment. In this study, we propose a neural network that can easily constrain the input. It determines the grasp pose from visual information and outputs the grasp success probability. The grasp pose is modified using backpropagation to increase the success rate of the grasp. As for the target object, we deal with some dirty tableware scattered on the table. We have developed a system that autonomously collects supervised data so that the robot can learn by itself whether it has succeeded in a grasp attempt. Finally, the robot can grasp an object which avoids dirty parts and find the suboptimal grasp pose.",
        "primary_area": "",
        "author": "Shumpei Wakabayashi;Shingo Kitagawa;Kento Kawaharazuka;Takayuki Murooka;Kei Okada;Masayuki Inaba;Shumpei Wakabayashi;Shingo Kitagawa;Kento Kawaharazuka;Takayuki Murooka;Kei Okada;Masayuki Inaba",
        "authorids": "/37089450177;/37086575668;/37086101930;/37088341446;/37280639000;/37286658200;/37089450177;/37086575668;/37086101930;/37088341446;/37280639000;/37286658200",
        "aff": "JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; JSK Laboratory, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812084/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2284773928643826202&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812141",
        "title": "Grasp Transfer for Deformable Objects by Functional Map Correspondence",
        "track": "main",
        "status": "Poster",
        "abstract": "Handling object deformations for robotic grasping is still a major problem to solve. In this paper, we propose an efficient learning-free solution for this problem where generated grasp hypotheses of a region of an object are adapted to its deformed configurations. To this end, we investigate the applicability of functional map (FM) correspondence, where the shape matching problem is treated as searching for correspondences between geometric functions in a reduced basis. For a user selected region of an object, a ranked list of grasp candidates is generated with local contact moment (LoCoMo) based grasp planner. The proposed FM-based methodology maps these candidates to an instance of the object that has suffered arbitrary level of deformation. The best grasp, by analysing its kinematic feasibility while respecting the original finger configuration as much as possible, is then executed on the object. We have compared the performance of our method with two different state-of-the-art correspondence mapping techniques in terms of grasp stability and region grasping accuracy for 4 different objects with 5 different deformations.",
        "primary_area": "",
        "author": "Cristiana De Farias;Brahim Tamadazte;Rustam Stolkin;Naresh Marturi;Cristiana De Farias;Brahim Tamadazte;Rustam Stolkin;Naresh Marturi",
        "authorids": "/37088812520;/37681656800;/37424300500;/37085558507;/37088812520;/37681656800;/37424300500;/37085558507",
        "aff": "Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, Birmingham, United Kingdom; Sorbonne Universit\u00e9, CNRS UMR 7222, INSERM U1150, ISIR, Paris, France; Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, Birmingham, United Kingdom; Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, Birmingham, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812141/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12770279334199861281&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 18,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Birmingham;Sorbonne Universit\u00e9",
        "aff_unique_dep": "School of Metallurgy and Materials;",
        "aff_unique_url": "https://www.birmingham.ac.uk;https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "UoB;Sorbonne U",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Birmingham;Paris",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United Kingdom;France"
    },
    {
        "id": "9812304",
        "title": "Gripper positioning for object deformation tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Shape control involves bringing a deformable object to a desired shape. In the shape control literature, the positioning of the grippers on the object is usually predefined (user-defined) and therefore considered as input information. In this paper we address the gripper positioning problem for shape control. We propose a deformation process within a simulated fully-actuated scenario and introduce multi-scale centroid paths as geometry describing points for which we prove individual control feasibility. Analysis on the evolution of multi-scale centroid paths through the fully-actuated deformation process allows us to define an importance metric for gripper candidates. Final gripper positions, based on the importance metric, are obtained through optimisation. We present simulation results for global and local shape control problems.",
        "primary_area": "",
        "author": "Ignacio Cuiral-Zueco;Gonzalo L\u00f3pez-Nicol\u00e1s;Helder Araujo;Ignacio Cuiral-Zueco;Gonzalo L\u00f3pez-Nicol\u00e1s;Helder Araujo",
        "authorids": "/37088489245;/37546413100;/37267404100;/37088489245;/37546413100;/37267404100",
        "aff": "Instituto de In-vestigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Spain; Instituto de In-vestigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Spain; Institute for Systems and Robotics, Universidade de Coimbra, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812304/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7926048432128822453&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Universidad de Zaragoza;Universidade de Coimbra",
        "aff_unique_dep": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n;Institute for Systems and Robotics",
        "aff_unique_url": "https://www.unizar.es;https://www.uc.pt",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Spain;Portugal"
    },
    {
        "id": "9812016",
        "title": "Grounding Predicates through Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "Symbols representing abstract states such as \u201cdish in dishwasher\u201d or \u201ccup on table\u201d allow robots to reason over long horizons by hiding details unnecessary for high-level planning. Current methods for learning to identify symbolic states in visual data require large amounts of labeled training data, but manually annotating such datasets is prohibitively expensive due to the combinatorial number of predicates in images. We propose a novel method for automatically labeling symbolic states in large-scale video activity datasets by exploiting known pre- and post-conditions of actions. This automatic labeling scheme only requires weak supervision in the form of an action label that describes which action is demonstrated in each video. We use our framework to train predicate classifiers to identify symbolic relationships between objects when prompted with object bounding boxes, and demonstrate that such predicate classifiers can match the performance of those trained with full supervision at a fraction of the labeling cost. We also apply our framework to an existing large-scale human activity dataset, and demonstrate the ability of these predicate classifiers trained on human data to enable closed-loop task planning in the real world.",
        "primary_area": "",
        "author": "Toki Migimatsu;Jeannette Bohg;Toki Migimatsu;Jeannette Bohg",
        "authorids": "/37086141343;/37591153900;/37086141343;/37591153900",
        "aff": "Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812016/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4018387014807808116&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811585",
        "title": "Grouptron: Dynamic Multi-Scale Graph Convolutional Networks for Group-Aware Dense Crowd Trajectory Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate, long-term forecasting of pedestrian trajectories in highly dynamic and interactive scenes is a longstanding challenge. Recent advances in using data-driven approaches have achieved significant improvements in terms of prediction accuracy. However, the lack of group-aware analysis has limited the performance of forecasting models. This is especially nonnegligible in highly crowded scenes, where pedestrians are moving in groups and the interactions between groups are extremely complex and dynamic. In this paper, we present Grouptron, a multi-scale dynamic forecasting framework that leverages pedestrian group detection and utilizes individual-level, group-level and scene-level information for better understanding and representation of the scenes. Our approach employs spatio-temporal clustering algorithms to identify pedestrian groups, creates spatio-temporal graphs at the individual, group, and scene levels. It then uses graph neural networks to encode dynamics at different scales and aggregate the embeddings for trajectory prediction. We conducted extensive comparisons and ablation experiments to demonstrate the effectiveness of our approach. Our method achieves 9.3% decrease in final displacement error (FDE) compared with state-of-the-art methods on ETH/UCY benchmark datasets, and 16.1% decrease in FDE in more crowded scenes where extensive human group interactions are more frequently present.",
        "primary_area": "",
        "author": "Rui Zhou;Hongyu Zhou;Huidong Gao;Masayoshi Tomizuka;Jiachen Li;Zhuo Xu;Rui Zhou;Hongyu Zhou;Huidong Gao;Masayoshi Tomizuka;Jiachen Li;Zhuo Xu",
        "authorids": "/37089449109;/37089001983;/37088922572;/37281933000;/37086309095;/37086544987;/37089449109;/37089001983;/37088922572;/37281933000;/37086309095;/37086544987",
        "aff": "Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA; Department of Aerospace Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Aeronautics & Astronautics, Stanford University, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811585/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6688670046721635183&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;0",
        "aff_unique_norm": "University of California, Berkeley;University of Michigan;Stanford University",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;Department of Aerospace Engineering;Department of Aeronautics & Astronautics",
        "aff_unique_url": "https://www.berkeley.edu;https://www.umich.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UC Berkeley;UM;Stanford",
        "aff_campus_unique_index": "0;1;0;0;2;0",
        "aff_campus_unique": "Berkeley;Ann Arbor;Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812227",
        "title": "HATP/EHDA: A Robot Task Planner Anticipating and Eliciting Human Decisions and Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "The variety and complexity of tasks autonomous robots can tackle is constantly increasing, yet we seldom see robots collaborating with humans. Indeed, humans are either requested for punctual help or are given the lead on the whole task. We propose a human-aware task planning approach allowing the robot to plan for a task while also considering and emulating the human decision, action, and reaction processes. Our approach, named Human-Aware Task Planner with Emulation of Human Decisions and Actions (HATP/EHDA), is based on the exploration of multiple hierarchical tasks networks albeit differently whether the agent is considered to be controllable (the robot) or uncontrollable (the human). We present the rationale of our approach along with a formalization and show its potential on an illustrative example.",
        "primary_area": "",
        "author": "Guilhem Buisan;Anthony Favier;Amandine Mayima;Rachid Alami;Guilhem Buisan;Anthony Favier;Amandine Mayima;Rachid Alami",
        "authorids": "/37088529065;/37088448627;/37088528193;/37278643600;/37088529065;/37088448627;/37088528193;/37278643600",
        "aff": "LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812227/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9008253525641827793&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "LAAS-CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.laas.fr/",
        "aff_unique_abbr": "LAAS-CNRS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toulouse",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9811977",
        "title": "HD Ground - A Database for Ground Texture Based Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the HD Ground Database, a comprehensive database for ground texture based localization. It contains sequences of a variety of textures, obtained using a downward facing camera. In contrast to existing databases of ground images, the HD Ground Database is larger, has a greater variety of textures, and has a higher image resolution with less motion blur. Also, our database enables the first systematic study of how natural changes of the ground that occur over time affect localization performance, and it allows to examine a teach-and-repeat navigation scenario. We use the HD Ground Database to evaluate four state-of-the-art localization approaches for global localization, localization with the approximate pose being known, and relative localization.",
        "primary_area": "",
        "author": "Jan Fabian Schmid;Stephan F. Simon;Raaghav Radhakrishnan;Simone Frintrop;Rudolf Mester;Jan Fabian Schmid;Stephan F. Simon;Raaghav Radhakrishnan;Simone Frintrop;Rudolf Mester",
        "authorids": "/37087324095;/37342166200;/37089450696;/37402784100;/37266486000;/37087324095;/37342166200;/37089450696;/37402784100;/37266486000",
        "aff": "CS Dept., VSI Lab, Goethe University, Frankfurt am Main, Germany; Robert Bosch GmbH, Hildesheim, Germany; Fraunhofer Institute for Applied Information Technology FIT, Germany; Department of Informatics, University of Hamburg, Germany; CS Dept., Norwegian Open AI Lab, NTNU Trondheim, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811977/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5986706310182516146&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "Goethe University;Robert Bosch GmbH;Fraunhofer Institute for Applied Information Technology FIT;University of Hamburg;Norwegian University of Science and Technology",
        "aff_unique_dep": "CS Dept.;;;Department of Informatics;Department of Computer Science",
        "aff_unique_url": "https://www.uni-frankfurt.de;https://www.bosch.com;https://www.fit.fraunhofer.de/;https://www.uni-hamburg.de;https://www.ntnu.edu",
        "aff_unique_abbr": "Goethe U;Bosch;FIT;;NTNU",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Frankfurt am Main;;Trondheim",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Germany;Norway"
    },
    {
        "id": "9812383",
        "title": "HDMapNet: An Online HD Map Construction and Evaluation Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Constructing HD semantic maps is a central component of autonomous driving. However, traditional pipelines require a vast amount of human efforts and resources in annotating and maintaining the semantics in the map, which limits its scalability. In this paper, we introduce the problem of HD semantic map learning, which dynamically constructs the local semantics based on onboard sensor observations. Meanwhile, we introduce a semantic map learning method, dubbed HDMapNet. HDMapNet encodes image features from surrounding cameras and/or point clouds from LiDAR, and predicts vectorized map elements in the bird's-eye view. We benchmark HDMapNet on nuScenes dataset and show that in all settings, it performs better than baseline methods. Of note, our camera-LiDAR fusion-based HDMapNet outperforms existing methods by more than 50 % in all metrics. In addition, we develop semantic-level and instance-level metrics to evaluate the map learning performance. Finally, we showcase our method is capable of predicting a locally consistent map. By introducing the method and metrics, we invite the community to study this novel map learning problem.",
        "primary_area": "",
        "author": "Qi Li;Yue Wang;Yilun Wang;Hang Zhao;Qi Li;Yue Wang;Yilun Wang;Hang Zhao",
        "authorids": "/37089732000;/37088218882;/37089450684;/37086232492;/37089732000;/37088218882;/37089450684;/37086232492",
        "aff": "Tsinghua University, Beijing, China; Massachusetts Institute of Technology, MA, USA; Li Auto, Beijing, China; Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812383/",
        "gs_citation": 360,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17030190634754001020&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Tsinghua University;Massachusetts Institute of Technology;Li Auto",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://web.mit.edu;",
        "aff_unique_abbr": "THU;MIT;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Beijing;MA;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9811756",
        "title": "HGC-Net: Deep Anthropomorphic Hand Grasping in Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping in cluttered environments is one of the most fundamental skills in robotic manipulation. Most of the current works focus on estimating grasp poses for parallel-jaw or suction-cup end effectors. However, the study for dexterous anthropomorphic hand grasping in clutter remains a great challenge. In this paper, we propose HGC-Net, a single-shot network that learns to predict dense hand grasp configurations in clutter from single-view point cloud input. Our end-to-end neural network can predict hand grasp proposals efficiently and effectively. To enhance generalization, we built a large-scale synthetic grasping dataset with 179 household objects, 5K cluttered scenes and over 10M hand annotations. Experiments in simulation show that our model can predict dense and robust hand grasps and clear over 78% of unseen objects in clutter without any post-processing and outperform baseline methods by a large margin. Experiments on the real robot platform also demonstrate that the model trained on synthetic data performs well in natural environments. Code is available at https://github.com/yimingli1998/hgc_net.",
        "primary_area": "",
        "author": "Yiming Li;Wei Wei;Daheng Li;Peng Wang;Wanyi Li;Jun Zhong;Yiming Li;Wei Wei;Daheng Li;Peng Wang;Wanyi Li;Jun Zhong",
        "authorids": "/37090022116;/37088998436;/37088918733;/37538869400;/38469175800;/37089001468;/37090022116;/37088998436;/37088918733;/37538869400;/38469175800;/37089001468",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science and Innovation, Chinese Academy of Sciences, Hong Kong, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811756/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13496209249669313258&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;2",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Hong Kong Institute of Science and Innovation, Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": "School of Artificial Intelligence;Centre for Artificial Intelligence and Robotics;Institute of Automation",
        "aff_unique_url": "http://www.ucas.ac.cn;;http://www.ia.cas.cn",
        "aff_unique_abbr": "UCAS;;CAS",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Beijing;Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812024",
        "title": "HMD-former: a Transformer-based Human Mesh Deformer with Inter-layer Semantic Consistency",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a transformer-based network, Human Mesh Deformer (HMD-former), to tackle the problem of 3D human mesh reconstruction from a single RGB image. HMD-former applies a pre-trained CNN to extract image grid features and a transformer decoder to gradually warp the template 3D mesh to the deformed mesh. On each decoder layer, the fine-grained local information of grid features is well utilized using cross-attention by softly and content-dependently transforming the grid features to vertex embeddings. Auxiliary losses and proposed bi-directional mapping layers inherently ensure semantic consistency throughout the whole decoder, which free the network from learning unnecessary embedding transformation between layers. This further induces each layer of the decoder to focus on refining vertex embeddings and makes the whole network work in a progressively refining manner. Experiments on different public datasets Human3.6M and 3DPW show better reconstruction accuracy and faster inference speed than previous state-of-the-art methods, demonstrating the effectiveness and generalizability of HMD-former. Code is publicly available at https://github.com/siyuzou/HMD-former.",
        "primary_area": "",
        "author": "Siyu Zou;Sheng Liu;Chaonan Li;Lu Yao;Shengyong Chen;Siyu Zou;Sheng Liu;Chaonan Li;Lu Yao;Shengyong Chen",
        "authorids": "/37089450389;/37599356700;/37089449020;/37089448191;/37290961700;/37089450389;/37599356700;/37089449020;/37089448191;/37290961700",
        "aff": "Zhejiang University of Technology, HangZhou, China; Zhejiang University of Technology, HangZhou, China; Zhejiang University of Technology, HangZhou, China; Zhejiang University of Technology, HangZhou, China; Tianjin University of Technology, Tianjin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812024/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15565332233503600767&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Zhejiang University of Technology;Tianjin University of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.zjut.edu.cn;http://www.tjut.edu.cn",
        "aff_unique_abbr": ";TUT",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "HangZhou;Tianjin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812400",
        "title": "HR-Planner: A Hierarchical Highway Tactical Planner based on Residual Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactical planning is crucial for safe and efficient driving on the highway. However, the problem is complicated by the uncertain intention of surrounding vehicles, as well as observation noise caused by measurement noise and perception errors. Rule-based tactical planning methods are ineffective in handling dynamic scenarios with uncertainty, and susceptible to observation noise. To tackle this problem, we propose a hierarchical tactical planning framework based on residual reinforcement learning. Besides, a new reinforcement learning from demonstrations scheme that views rule-based methods as soft guidance is developed to combine prior knowledge with data-driven methods. Based on the framework and the training scheme, rule-based methods not only can be improved in highway scenarios with uncertainty and observation noise, but also will guide the training procedure for increased sampling efficiency. Additionally, to boost in-depth and consistent exploration in a vehicle system with inertia, we employ noisy networks to explore the optimal policy. The proposed method is validated in a stochastic and uncertain simulation environment, and the results reveal that our method outperforms both rule-based methods and pure data-driven methods in terms of safety and driving efficiency under noisy observations and uncertainty.",
        "primary_area": "",
        "author": "Haoran Wu;Yueyuan Li;Hanyang Zhuang;Chunxiang Wang;Ming Yang;Haoran Wu;Yueyuan Li;Hanyang Zhuang;Chunxiang Wang;Ming Yang",
        "authorids": "/37089450669;/37089189786;/37089184462;/37578423000;/37576820400;/37089450669;/37089189786;/37089184462;/37578423000;/37576820400",
        "aff": "Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai, China; Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai, China; University of Michigan-Shanghai Jiao Tong University Joint Institute, Shanghai Jiao Tong University, Shanghai, China; Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai, China; Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812400/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18346152366326922399&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Shanghai Engineering Research Center of Intelligent Control and Management;Shanghai Jiao Tong University",
        "aff_unique_dep": ";University of Michigan-Shanghai Jiao Tong University Joint Institute",
        "aff_unique_url": ";https://www.sjtu.edu.cn",
        "aff_unique_abbr": ";SJTU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812254",
        "title": "HYPER: Learned Hybrid Trajectory Prediction via Factored Inference and Adaptive Sampling",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling multi-modal high-level intent is important for ensuring diversity in trajectory prediction. Existing approaches explore the discrete nature of human intent before predicting continuous trajectories, to improve accuracy and support explainability. However, these approaches often assume the intent to remain fixed over the prediction horizon, which is problematic in practice, especially over longer horizons. To overcome this limitation, we introduce HYPER, a general and expressive hybrid prediction framework that models evolving human intent. By modeling traffic agents as a hybrid discrete-continuous system, our approach is capable of predicting discrete intent changes over time. We learn the probabilistic hybrid model via a maximum likelihood estimation problem and leverage neural proposal distributions to sample adaptively from the exponentially growing discrete space. The overall approach affords a better trade-off between accuracy and coverage. We train and validate our model on the Argoverse dataset, and demonstrate its effectiveness through comprehensive ablation studies and comparisons with state-of-the-art models.",
        "primary_area": "",
        "author": "Xin Huang;Guy Rosman;Igor Gilitschenski;Ashkan Jasour;Stephen G. McGill;John J. Leonard;Brian C. Williams;Xin Huang;Guy Rosman;Igor Gilitschenski;Ashkan Jasour;Stephen G. McGill;John J. Leonard;Brian C. Williams",
        "authorids": "/37086595235;/37393688300;/38469566100;/37078643400;/37089259672;/37329387400;/37274902300;/37086595235;/37393688300;/38469566100;/37078643400;/37089259672;/37329387400;/37274902300",
        "aff": "Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812254/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8772363815235375536&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;0;1;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Toyota Research Institute",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;",
        "aff_unique_url": "https://web.mit.edu;https://www.tri.global",
        "aff_unique_abbr": "MIT;TRI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812302",
        "title": "HandoverSim: A Simulation Framework and Benchmark for Human-to-Robot Object Handovers",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a new simulation benchmark \u201cHan-doverSim\u201d for human-to-robot object handovers. To simulate the giver's motion, we leverage a recent motion capture dataset of hand grasping of objects. We create training and evaluation environments for the receiver with standardized protocols and metrics. We analyze the performance of a set of baselines and show a correlation with a real-world evaluation.11Code is open sourced at https://handover-sim.github.io.",
        "primary_area": "",
        "author": "Yu-Wei Chao;Chris Paxton;Yu Xiang;Wei Yang;Balakumar Sundaralingam;Tao Chen;Adithyavairavan Murali;Maya Cakmak;Dieter Fox;Yu-Wei Chao;Chris Paxton;Yu Xiang;Wei Yang;Balakumar Sundaralingam;Tao Chen;Adithyavairavan Murali;Maya Cakmak;Dieter Fox",
        "authorids": "/37088503888;/37085403975;/37087234731;/37069403600;/37086455625;/37089000331;/37085349840;/37409159800;/37284329000;/37088503888;/37085403975;/37087234731;/37069403600;/37086455625;/37089000331;/37085349840;/37409159800;/37284329000",
        "aff": "NVIDIA; NVIDIA; UT Dallas.; NVIDIA; NVIDIA; MIT CSAIL.; NVIDIA; University of Washington; University of Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812302/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=121696480911948150&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;0;0;2;0;3;3",
        "aff_unique_norm": "NVIDIA;University of Texas at Dallas;Massachusetts Institute of Technology;University of Washington",
        "aff_unique_dep": "NVIDIA Corporation;;Computer Science and Artificial Intelligence Laboratory;",
        "aff_unique_url": "https://www.nvidia.com;https://www.utdallas.edu;https://www.csail.mit.edu;https://www.washington.edu",
        "aff_unique_abbr": "NVIDIA;UT Dallas;MIT CSAIL;UW",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Dallas;Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811737",
        "title": "HiTPR: Hierarchical Transformer for Place Recognition in Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition or loop closure detection is one of the core components in a full SLAM system. In this paper, aiming at strengthening the relevancy of local neighboring points and the contextual dependency among global points simultaneously, we investigate the exploitation of transformer-based network for feature extraction, and propose a Hierarchical Transformer for Place Recognition (HiTPR). The HiTPR consists of four major parts: point cell generation, short-range transformer (SRT), long-range transformer (LRT) and global descriptor aggregation. Specifically, the point cloud is initially divided into a sequence of small cells by down-sampling and nearest neighbors searching. In the SRT, we extract the local feature for each point cell. While in the LRT, we build the global dependency among all of the point cells in the whole point cloud. Experiments on several standard benchmarks demonstrate the superiority of the HiTPR in terms of average recall rate, achieving 93.71 % at top 1 % and 86.63 % at top 1 on the Oxford RobotCar dataset for example.",
        "primary_area": "",
        "author": "Zhixing Hou;Yan Yan;Chengzhong Xu;Hui Kong;Zhixing Hou;Yan Yan;Chengzhong Xu;Hui Kong",
        "authorids": "/37086166211;/38547789800;/37278305300;/37061510500;/37086166211;/38547789800;/37278305300;/37061510500",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Department of Computer Science, University of Macau, Macau, China; Faculty of Science and Technology, University of Macau, Macau, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811737/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=279776720112721003&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Nanjing University of Science and Technology;University of Macau",
        "aff_unique_dep": "School of Computer Science and Engineering;Department of Computer Science",
        "aff_unique_url": "http://www.nust.edu.cn;https://www.um.edu.mo",
        "aff_unique_abbr": "NUST;UM",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Nanjing;Macau",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811572",
        "title": "Hierarchical Policy Learning for Mechanical Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Retrieving objects from clutters is a complex task, which requires multiple interactions with the environment until the target object can be extracted. These interactions involve executing action primitives like grasping or pushing as well as setting priorities for the objects to manipulate and the actions to execute. Mechanical Search (MS) [1] is a framework for object retrieval, which uses a heuristic algorithm for pushing and rule-based algorithms for high-level planning. While rule-based policies profit from human intuition in how they work, they usually perform sub-optimally in many cases. Deep reinforcement learning (RL) has shown great performance in complex tasks such as taking decisions through evaluating pixels, which makes it suitable for training policies in the context of object-retrieval. In this work, we first formulate the MS problem in a principled formulation as a hierarchical POMDP. Based on this formulation, we propose a hierarchical policy learning approach for the MS problem. For demonstration, we present two main parameterized sub-policies: a push policy and an action selection policy. When integrated into the hierarchical POMDP's policy, our proposed sub-policies increase the success rate of retrieving the target object from less than 32% to nearly 80%, while reducing the computation time for push actions from multiple seconds to less than 10 milliseconds.",
        "primary_area": "",
        "author": "Oussama Zenkri;Ngo Anh Vien;Gerhard Neumann;Oussama Zenkri;Ngo Anh Vien;Gerhard Neumann",
        "authorids": "/37089450518;/37838848600;/38542033100;/37089450518;/37838848600;/38542033100",
        "aff": "Karlsruhe Institute of Technology (KIT); Bosch Center for Artificial Intelligence (BCAI); Karlsruhe Institute of Technology (KIT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811572/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6535340810595426582&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Bosch Center for Artificial Intelligence",
        "aff_unique_dep": ";Artificial Intelligence",
        "aff_unique_url": "https://www.kit.edu;https://www.bosch-ai.com",
        "aff_unique_abbr": "KIT;BCAI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812179",
        "title": "Hierarchical Representations and Explicit Memory: Learning Effective Navigation Policies on 3D Scene Graphs using Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Representations are crucial for a robot to learn effective navigation policies. Recent work has shown that mid-level perceptual abstractions, such as depth estimates or 2D semantic segmentation, lead to more effective policies when provided as observations in place of raw sensor data (e.g., RGB images). However, such policies must still learn latent three-dimensional scene properties from mid-level abstractions. In contrast, high-level, hierarchical representations such as 3D scene graphs explicitly provide a scene's geometry, topology, and semantics, making them compelling representations for navigation. In this work, we present a reinforcement learning framework that leverages high-level hierarchical representations to learn navigation policies. Towards this goal, we propose a graph neural network architecture and show how to embed a 3D scene graph into an agent-centric feature space, which enables the robot to learn policies that map 3D scene graphs to a platform-agnostic control space (e.g., go straight, turn left). For each node in the scene graph, our method uses features that capture occupancy and semantic content, while explicitly retaining memory of the robot trajectory. We demonstrate the effectiveness of our method against commonly used visuomotor policies in a challenging multi-object search task. These experiments and supporting ablation studies show that our method leads to more effective object search behaviors, exhibits improved long-term memory, and successfully leverages hierarchical information to guide its navigation objectives.",
        "primary_area": "",
        "author": "Zachary Ravichandran;Lisa Peng;Nathan Hughes;J. Daniel Griffith;Luca Carlone;Zachary Ravichandran;Lisa Peng;Nathan Hughes;J. Daniel Griffith;Luca Carlone",
        "authorids": "/37089448650;/37089448129;/37089198205;/38242115500;/37545784100;/37089448650;/37089448129;/37089198205;/38242115500;/37545784100",
        "aff": "Lincoln Laboratory, Massachusetts Institute of Technology, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, USA; Lincoln Laboratory, Massachusetts Institute of Technology, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812179/",
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16230884250832014104&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Lincoln Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811695",
        "title": "High Definition, Inexpensive, Underwater Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a complete framework for Underwater SLAM utilizing a single inexpensive sensor. Over the recent years, imaging technology of action cameras is producing stunning results even under the challenging conditions of the underwater domain. The GoPro 9 camera provides high definition video in synchronization with an Inertial Measurement Unit (IMU) data stream encoded in a single mp4 file. The visual inertial SLAM framework is augmented to adjust the map after each loop closure. Data collected at an artificial wreck of the coast of South Carolina and in caverns and caves in Florida demonstrate the robustness of the proposed approach in a variety of conditions.",
        "primary_area": "",
        "author": "Bharat Joshi;Marios Xanthidis;Sharmin Rahman;Ioannis Rekleitis;Bharat Joshi;Marios Xanthidis;Sharmin Rahman;Ioannis Rekleitis",
        "authorids": "/37087324582;/37085810183;/37085989996;/37281356300;/37087324582;/37085810183;/37085989996;/37281356300",
        "aff": "Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA; Computer Science and Engineering Department, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811695/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5659778075533691587&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of South Carolina",
        "aff_unique_dep": "Computer Science and Engineering Department",
        "aff_unique_url": "https://www.sc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Columbia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812353",
        "title": "HoloOcean: An Underwater Robotics Simulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the difficulty and expense of underwater field trials, a high fidelity underwater simulator is a necessity for testing and developing algorithms. To fill this need, we present HoloOcean, an open source underwater simulator, built upon Unreal Engine 4 (UE4). HoloOcean comes equipped with multi-agent support, various sensor implementations of common underwater sensors, and simulated communications support. We also implement a novel sonar sensor model that leverages an octree representation of the environment for efficient and realistic sonar imagery generation. Due to being built upon UE4, new environments are straightforward to add, enabling easy extensions to be built. Finally, HoloOcean is controlled via a simple python interface, allowing simple installation via pip, and requiring few lines of code to execute simulations.",
        "primary_area": "",
        "author": "Easton Potokar;Spencer Ashford;Michael Kaess;Joshua G. Mangelson;Easton Potokar;Spencer Ashford;Michael Kaess;Joshua G. Mangelson",
        "authorids": "/37088598849;/37089449356;/37324200400;/37086109836;/37088598849;/37089449356;/37324200400;/37086109836",
        "aff": "Brigham Young University; Brigham Young University; Carnegie Mellon University.; Brigham Young University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812353/",
        "gs_citation": 91,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13204896592434333568&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Brigham Young University;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.byu.edu;https://www.cmu.edu",
        "aff_unique_abbr": "BYU;CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811930",
        "title": "HoloSeg: An Efficient Holographic Segmentation Network for Real-time Scene Parsing",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time semantic segmentation is a crucial but challenging dense prediction task for scene parsing. However, the existing CNN-based methods commonly bias the model in favor of speed-boosting compromising spatial resolution due to business requirements and hardware constrains, which impedes the high-accuracy segmentation result. To address the dilemma, we provide a novel Holographic Segmentation Network (HoloSeg), which presents a strong ability of comprehensive information preservation and extraction, and achieves a better trade-off between speed and accuracy. We first design a Lossless Sample Pair (LSP) without any stride for early spatial preservation and later resolution recovery while modeling long-range context dependence. Then, we propose Distributed Pyramid Learning (DPL) to efficiently extract multiscale features and saves a lot of computation. Finally, we propose Resolution Fusion and Restoration (RFR) to fuse multi-level semantic representations across stages and generate output without decoder. Without bells and whistles, HoloSeg achieves state-of-the-art performance on the Cityscapes benchmark which reports 76.24% mIoU at 231 FPS. Code is available online: https://github.com/LiShuTJ/HoloSeg.",
        "primary_area": "",
        "author": "Shu Li;Qingqing Yan;Chengju Liu;Ming Liu;Qijun Chen;Shu Li;Qingqing Yan;Chengju Liu;Ming Liu;Qijun Chen",
        "authorids": "/37086349133;/37089298351;/37677379800;/37085398677;/37276133600;/37086349133;/37089298351;/37677379800;/37085398677;/37276133600",
        "aff": "Robotics and Artificial Intelligence Lab (RAIL), Tongji University, Shanghai, China; Robotics and Artificial Intelligence Lab (RAIL), Tongji University, Shanghai, China; Robotics and Artificial Intelligence Lab (RAIL), Tongji University, Shanghai, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong; Robotics and Artificial Intelligence Lab (RAIL), Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811930/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16024393536493592440&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Tongji University;Hong Kong University of Science and Technology",
        "aff_unique_dep": "Robotics and Artificial Intelligence Lab (RAIL);Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.ust.hk",
        "aff_unique_abbr": "Tongji;HKUST",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Shanghai;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811676",
        "title": "How to Build a Curb Dataset with LiDAR Data for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Curbs are one of the essential elements of urban and highway traffic environments. Robust curb detection provides road structure information for motion planning in an autonomous driving system. Commonly, video cameras and 3D LiDARs are mounted on autonomous vehicles for curb detection. However, camera-based methods suffer from challenging illumination conditions. During the long period of time before wide application of Deep Neural Network (DNN) with point clouds, LiDAR-based curb detection methods are based on hand-crafted features, which suffer from poor detection in some complex scenes. Recently, DNN-based dynamic object detection using LiDAR data has become prevalent, while few works pay attention to curb detection with a DNN approach due to lack of labeled data. A dataset with curb annotations or an efficient curb labeling approach, hence, is of high demand. In this paper, we present how to build a curb dataset with LiDAR data for autonomous driving highly automatically. Firstly, a Semantic High Definition map (SHD map) in a global coordinate frame is generated by applying both SLAM and semantic segmentation on consecutive LiDAR frames. Next, a Road HD map (RHD map) is generated from the SHD map by removing its dynamic noise caused by road users e.g. cars. After that, a Curb Instance map (CI map) can be obtained from the filtered RHD map by a series of curb point extraction and growing. Finally, the CI map can be projected back to single frames for direct, highly automatic curb labeling. In order to validate our proposed labeling method, on top of an open public LiDAR semantic dataset SemanticKITTI [1], an additional curb dataset is built. We run both semantic segmentation and instance segmentation methods on this built dataset. Experimental results show that the curb annotations have good consistency and accuracy. We released this dataset and it is publicly available at https://download.mindspore.cn.",
        "primary_area": "",
        "author": "Dongfeng Bai;Tongtong Cao;Jingming Guo;Bingbing Liu;Dongfeng Bai;Tongtong Cao;Jingming Guo;Bingbing Liu",
        "authorids": "/37089450513;/37089447467;/37089449302;/38572992400;/37089450513;/37089447467;/37089449302;/38572992400",
        "aff": "Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811676/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1089355040744343114&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Noah's Ark Lab",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811883",
        "title": "Human Navigational Intent Inference with Probabilistic and Optimal Approaches",
        "track": "main",
        "status": "Poster",
        "abstract": "Although human navigational intent inference has been studied in the literature, none have adequately considered both the dynamics that describe human motion and internal human parameters that may affect human navigational behaviour. In this paper, we propose a general probabilistic framework to infer the probability distribution over future navigational states of a human. Our framework incorporates an extended Dubins car dynamics to model human movement, which captures differences in human navigational behaviour depending on their position, heading, and movement speed. We assume a noisily rational model of human behaviour that incorporates a) human navigational intent that may change over time, b) how optimal a person's actions are given the navigational intent, and c) how far ahead in time a person considers when choosing navigational actions. These parameters are recursively and continuously updated in a Bayesian fashion. To make the Bayesian update and inference tractable, we exploit properties of the time-to-reach value function from optimal control and the extended Dubins car dynamics to construct a utility function on which the human policy is based, and employ particle representations of probability distributions where necessary. We demonstrate the effectiveness of our method by comparing our results with a recent approach using synthetic data and validate it on real world data.",
        "primary_area": "",
        "author": "Pedram Agand;Mahdi Taherahmadi;Angelica Lim;Mo Chen;Pedram Agand;Mahdi Taherahmadi;Angelica Lim;Mo Chen",
        "authorids": "/37085744445;/37089449647;/37086880157;/37085494765;/37085744445;/37089449647;/37086880157;/37085494765",
        "aff": "Simon Fraser University, Burnaby, Canada; Simon Fraser University, Burnaby, Canada; Simon Fraser University, Burnaby, Canada; Simon Fraser University, Burnaby, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811883/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10907915605144024493&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Burnaby",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812111",
        "title": "Human-Following and -guiding in Crowded Environments using Semantic Deep-Reinforcement-Learning for Mobile Service Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Assistance robots have gained widespread attention in various industries such as logistics and human assistance. The tasks of guiding or following a human in a crowded environment such as airports or train stations to carry weight or goods is still an open problem. In these use cases, the robot is not only required to intelligently interact with humans, but also to navigate safely among crowds. Thus, especially highly dynamic environments pose a grand challenge due to the volatile behavior patterns and unpredictable movements of humans. In this paper, we propose a Deep-Reinforcement-Learning-based agent for human-guiding and -following tasks in crowded environments. Therefore, we incorporate semantic information to provide the agent with high-level information like the social states of humans, safety models, and class types. We evaluate our proposed approach against a benchmark approach without semantic information and demonstrated enhanced navigational safety and robustness. Moreover, we demonstrate that the agent could learn to adapt its behavior to humans, which improves the human-robot interaction significantly.",
        "primary_area": "",
        "author": "Linh K\u00e4stner;Bassel Fatloun;Zhengcheng Shen;Daniel Gawrisch;Jens Lambrecht;Linh K\u00e4stner;Bassel Fatloun;Zhengcheng Shen;Daniel Gawrisch;Jens Lambrecht",
        "authorids": "/37087466037;/37089449450;/37088811455;/37089448691;/37342634600;/37087466037;/37089449450;/37088811455;/37089448691;/37342634600",
        "aff": "Faculty of Electrical Engineering, and Computer Science, Chair Industry Grade Networks and Clouds, Berlin Institute of Technology, Berlin, Germany; Faculty of Electrical Engineering, and Computer Science, Chair Industry Grade Networks and Clouds, Berlin Institute of Technology, Berlin, Germany; Faculty of Electrical Engineering, and Computer Science, Chair Industry Grade Networks and Clouds, Berlin Institute of Technology, Berlin, Germany; Faculty of Electrical Engineering, and Computer Science, Chair Industry Grade Networks and Clouds, Berlin Institute of Technology, Berlin, Germany; Faculty of Electrical Engineering, and Computer Science, Chair Industry Grade Networks and Clouds, Berlin Institute of Technology, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812111/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15308945060985131449&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Berlin Institute of Technology",
        "aff_unique_dep": "Faculty of Electrical Engineering, and Computer Science",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811893",
        "title": "Human-Guided Motion Planning in Partially Observable Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning is a core problem in robotics, with a range of existing methods aimed to address its diverse set of challenges. However, most existing methods rely on complete knowledge of the robot environment; an assumption that seldom holds true due to inherent limitations of robot perception. To enable tractable motion planning for high-DOF robots under partial observability, we introduce BLIND, an algorithm that leverages human guidance. BLIND utilizes inverse reinforcement learning to derive motion-level guidance from human critiques. The algorithm overcomes the computational challenge of reward learning for high-DOF robots by projecting the robot's continuous configuration space to a motion-planner-guided discrete task model. The learned reward is in turn used as guidance to generate robot motion using a novel motion planner. We demonstrate BLIND using the Fetch robot and perform two simulation experiments with partial observability. Our experiments demonstrate that, despite the challenge of partial observability and high dimensionality, BLIND is capable of generating safe robot motion and outperforms baselines on metrics of teaching efficiency, success rate, and path quality.",
        "primary_area": "",
        "author": "Carlos Quintero-Pe\u00f1a;Constantinos Chamzas;Zhanyi Sun;Vaibhav Unhelkar;Lydia E. Kavraki;Carlos Quintero-Pe\u00f1a;Constantinos Chamzas;Zhanyi Sun;Vaibhav Unhelkar;Lydia E. Kavraki",
        "authorids": "/37088997672;/37086933748;/37089448634;/37085482072;/37279015600;/37088997672;/37086933748;/37089448634;/37085482072;/37279015600",
        "aff": "Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811893/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8364926674232826935&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812379",
        "title": "Human-Robot Shared Control for Surgical Robot Based on Context-Aware Sim-to-Real Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot shared control, which integrates the advantages of both humans and robots, is an effective approach to facilitate efficient surgical operation. Learning from demonstration (LfD) techniques can be used to automate some of the surgical sub tasks for the construction of the shared control mechanism. However, a sufficient amount of data is required for the robot to learn the manoeuvres. Using a surgical simulator to collect data is a less resource-demanding approach. With sim-to-real adaptation, the manoeuvres learned from a simulator can be transferred to a physical robot. To this end, we propose a sim-to-real adaptation method to construct a human-robot shared control framework for robotic surgery. In this paper, a desired trajectory is generated from a simulator using LfD method, while dynamic motion primitives (DMP) is used to transfer the desired trajectory from the simulator to the physical robotic platform. Moreover, a role adaptation mechanism is developed such that the robot can adjust its role according to the surgical operation contexts predicted by a neural network model. The effectiveness of the proposed framework is validated on the da Vinci Research Kit (dVRK). Results of the user studies indicated that with the adaptive human-robot shared control framework, the path length of the remote controller, the total clutching number and the task completion time can be reduced significantly. The proposed method outperformed the traditional manual control via teleoperation.",
        "primary_area": "",
        "author": "Dandan Zhang;Zicong Wu;Junhong Chen;Ruiqi Zhu;Adnan Munawar;Bo Xiao;Yuan Guan;Hang Su;Wuzhou Hong;Yao Guo;Gregory S. Fischer;Benny Lo;Guang-Zhong Yang;Dandan Zhang;Zicong Wu;Junhong Chen;Ruiqi Zhu;Adnan Munawar;Bo Xiao;Yuan Guan;Hang Su;Wuzhou Hong;Yao Guo;Gregory S. Fischer;Benny Lo;Guang-Zhong Yang",
        "authorids": "/37086595836;/37088406835;/37087325379;/37088690572;/37086207599;/37085360685;/37089340344;/37089450920;/37086343957;/37086919325;/37398771000;/38183567000;/37276270800;/37086595836;/37088406835;/37087325379;/37088690572;/37086207599;/37085360685;/37089340344;/37089450920;/37086343957;/37086919325;/37398771000;/38183567000;/37276270800",
        "aff": "Bristol Robotics Lab, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom; Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom; Worcester Polytechnic Institute, USA; Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom; Bristol Robotics Lab, United Kingdom; Department of Electronics, Polytechnic University of Milan, Italy; Institute of Medical Robotics, Shanghai Jiao Tong University, China; Institute of Medical Robotics, Shanghai Jiao Tong University, China; Worcester Polytechnic Institute, USA; Department of Engineering Mathematics, University of Bristol, United Kingdom; Institute of Medical Robotics, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812379/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14924482966175227863&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;1;1;1;2;1;0;3;4;4;2;5;4",
        "aff_unique_norm": "Bristol Robotics Lab;Imperial College London;Worcester Polytechnic Institute;Polytechnic University of Milan;Shanghai Jiao Tong University;University of Bristol",
        "aff_unique_dep": ";Hamlyn Centre for Robotic Surgery;;Department of Electronics;Institute of Medical Robotics;Department of Engineering Mathematics",
        "aff_unique_url": ";https://www.imperial.ac.uk;https://www.wpi.edu;https://www.polimi.it;https://www.sjtu.edu.cn;https://www.bristol.ac.uk",
        "aff_unique_abbr": ";Imperial College;WPI;Politecnico di Milano;SJTU;UoB",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;0;0;0;1;0;0;2;3;3;1;0;3",
        "aff_country_unique": "United Kingdom;United States;Italy;China"
    },
    {
        "id": "9811878",
        "title": "Humanoid Arm Motion Planning for Improved Disturbance Recovery Using Model Hierarchy Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans noticeably swing their arms for balancing and locomotion. Although the underlying biomechanical mechanisms have been studied, it is unclear how robots can fully take advantage of these appendages. Most controllers that exploit arms for balance and locomotion rely on feedback and cannot anticipate incoming disturbances and future states. Model predictive controllers readily address these drawbacks but are computationally expensive. Here, we leverage recent work on model hierarchy predictive control (MHPC). We develop an MHPC formulation that plans arm motions in reaction to expected or unexpected disturbances. We tested multiple model compositions using simulated balance experiments with the MIT Humanoid undergoing various disturbances. We found that an MHPC formulation that plans over a full-body kino-dynamic model for a 0.3 s horizon followed by a single rigid body model for 0.5 s horizon runs at 40 Hz and increases the set of disturbances that the robot can withstand. Arms allow the robot to dissipate momentum quickly and move the center of mass independently from the lower body. This kinematic advantage helps generate ground wrenches while avoiding kinematic singularities and keeping the center of mass and center pressure within the support polygon. We note similar advantages when allowing the MHPC to anticipate incoming disturbances.",
        "primary_area": "",
        "author": "Charles Khazoom;Sangbae Kim;Charles Khazoom;Sangbae Kim",
        "authorids": "/37086876458;/37537397200;/37086876458;/37537397200",
        "aff": "Department of Mechanical Engineering Department, Massachusetts Institute of Technology, Cambridge, MA, United States; Department of Mechanical Engineering Department, Massachusetts Institute of Technology, Cambridge, MA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811878/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1614100070446478072&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811782",
        "title": "Hybrid Event Shaping to Stabilize Periodic Hybrid Orbits",
        "track": "main",
        "status": "Poster",
        "abstract": "Many controllers for legged robotic systems leverage open- or closed-loop control at discrete hybrid events to enhance stability. These controllers appear in several well studied phenomena such as the Raibert stepping controller, paddle juggling, and swing leg retraction. This work introduces hybrid event shaping (HES): a generalized method for analyzing and designing stable hybrid event controllers. HES utilizes the saltation matrix, which gives a closed-form equation for the effect that hybrid events have on stability. We also introduce shape parameters, which are higher order terms that can be tuned completely independently from the system dynamics to promote stability. Optimization methods are used to produce values of these parameters that optimize a stability measure. Hybrid event shaping captures previously developed control methods while also producing new optimally stable trajectories without the need for continuous-domain feedback.",
        "primary_area": "",
        "author": "James Zhu;Nathan J. Kong;George Council;Aaron M. Johnson;James Zhu;Nathan J. Kong;George Council;Aaron M. Johnson",
        "authorids": "/37089449436;/37089281130;/37085373075;/37589025300;/37089449436;/37089281130;/37085373075;/37589025300",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811782/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14852762988649986693&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811540",
        "title": "Hybrid Imitative Planning with Geometric and Predictive Costs in Off-road Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Geometric methods for solving open-world off-road navigation tasks, by learning occupancy and metric maps, provide good generalization but can be brittle in outdoor environments that violate their assumptions (e.g., tall grass). Learning-based methods can directly learn collision-free behavior from raw observations, but are difficult to integrate with standard geometry-based pipelines. This creates an unfortunate conflict \u2013 either use learning and lose out on well-understood geometric navigational components, or do not use it, in favor of extensively hand-tuned geometry-based cost maps. In this work, we reject this dichotomy by designing the learning and non-learning-based components in a way such that they can be effectively combined in a self-supervised manner. Both components contribute to a planning criterion: the learned component contributes predicted traversability as rewards, while the geometric component contributes obstacle cost information. We instantiate and comparatively evaluate our system in both in-distribution and out-of-distribution environments, showing that this approach inherits complementary gains from the learned and geometric components and significantly outperforms either of them.",
        "primary_area": "",
        "author": "Nitish Dashora;Daniel Shin;Dhruv Shah;Henry Leopold;David Fan;Ali Agha-Mohammadi;Nicholas Rhinehart;Sergey Levine;Nitish Dashora;Daniel Shin;Dhruv Shah;Henry Leopold;David Fan;Ali Agha-Mohammadi;Nicholas Rhinehart;Sergey Levine",
        "authorids": "/37089447866;/37089450035;/37089000677;/37088954738;/37086010932;/38274170800;/37085401789;/37085481973;/37089447866;/37089450035;/37089000677;/37088954738;/37086010932;/38274170800;/37085401789;/37085481973",
        "aff": "UC Berkeley; UC Berkeley; UC Berkeley; University of Waterloo; Georgia Institute of Technology; NASA Jet Propulsion Laboratory; UC Berkeley; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811540/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4450479598113806560&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;2;3;0;0",
        "aff_unique_norm": "University of California, Berkeley;University of Waterloo;Georgia Institute of Technology;NASA Jet Propulsion Laboratory",
        "aff_unique_dep": ";;;Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.berkeley.edu;https://uwaterloo.ca;https://www.gatech.edu;https://www.jpl.nasa.gov",
        "aff_unique_abbr": "UC Berkeley;UW;Georgia Tech;JPL",
        "aff_campus_unique_index": "0;0;0;2;0;0",
        "aff_campus_unique": "Berkeley;;Pasadena",
        "aff_country_unique_index": "0;0;0;1;0;0;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9811961",
        "title": "Hybrid Physical Metric For 6-DoF Grasp Pose Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "6-DoF grasp pose detection of multi-grasp and multi-object is a challenge task in the field of intelligent robot. To imitate human reasoning ability for grasping objects, data driven methods are widely studied. With the introduction of large-scale datasets, we discover that a single physical metric usually generates several discrete levels of grasp confidence scores, which cannot finely distinguish millions of grasp poses and leads to inaccurate prediction results. In this paper, we propose a hybrid physical metric to solve this evaluation insufficiency. First, we define a novel metric is based on the force-closure metric, supplemented by the measurement of the object flatness, gravity and collision. Second, we leverage this hybrid physical metric to generate elaborate confidence scores. Third, to learn the new confidence scores effectively, we design a multi-resolution network called Flatness Gravity Collision GraspNet (FGC-GraspNet). FGC-GraspNet proposes a multi-resolution features learning architecture for multiple tasks and introduces a new joint loss function that enhances the average precision of the grasp detection. The network evaluation and adequate real robot experiments demonstrate the effectiveness of our hybrid physical metric and FGC-GraspNet. Our method achieves 90.5% success rate in real-world cluttered scenes. Our code is available at https://github.com/luyh20IFGC-GraspNet.",
        "primary_area": "",
        "author": "Yuhao Lu;Beixing Deng;Zhenyu Wang;Peiyuan Zhi;Yali Li;Shengjin Wang;Yuhao Lu;Beixing Deng;Zhenyu Wang;Peiyuan Zhi;Yali Li;Shengjin Wang",
        "authorids": "/37089450226;/37299720300;/37089014913;/37089446804;/37598980300;/37280458700;/37089450226;/37299720300;/37089014913;/37089446804;/37598980300;/37280458700",
        "aff": "Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811961/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9272993447795162840&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812145",
        "title": "Hydraulic Servo Booster for Serially Configured Modular Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a proposal of new hydraulic circuit, designated as a modular hydraulic servo booster (MHSB), aimed at the realization of modular hydraulic robots. The modular robots, however, have important shortcomings compared to non-modular robots, such as separate power sources and power imbalance between axes when applied to serially configured robots. To mitigate those difficulties, we take advantage of pressure boost and flow summing by multiple servo pumps and switching valves, which are connected through the hydraulic rails shared between the circuits. Coordinated control of the pump and valve greatly improves energy efficiency over conventional servo valve systems. After presenting realization of the circuit and possible operating modes, the control method for each mode is explained. The experimentally obtained results for position control of a two-link serial manipulator validate the proposed method, especially by the shared boost mode, where small pumps work together to have high torque and speed of the proximal joint.",
        "primary_area": "",
        "author": "SangHo Hyon;Tomoro Kai;SangHo Hyon;Tomoro Kai",
        "authorids": "/37278958900;/37089448581;/37278958900;/37089448581",
        "aff": "Department of Robotics, Humanoid Systems Laboratory, Ritsumeikan University, Kusatsu, Shiga, Japan; Department of Robotics, Humanoid Systems Laboratory, Ritsumeikan University, Kusatsu, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812145/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16170762262902437771&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811983",
        "title": "Hydraulically Actuated Soft Tubular Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "There is an increasing interest in soft robotic grippers as they exhibit an ability to grip objects of differing shapes, sizes, textures, and even deformable materials, all of which present a difficult challenge to traditional rigid grippers. An ideal soft gripper would exhibit universal gripping with high gripping force and consists of low-cost materials with simple fabrication processes. This paper investigates the development of a strong and scalable hydraulic soft tubular gripper (HSTG) using facile fabrication method and low-cost materials. The HSTG which consists of a single long hydraulically actuated artificial muscle, soft 3D printed element, and commercial weaving yarn can expand and contract its orifice to grasp objects using a miniature hydraulic syringe. Grasping experiments show that the new HSTG can successfully grasp convex, nonconvex, and flat objects as well as the ones with cavity. The soft gripper uniquely exhibits high normal contact force at minimal pressure and energy use due to the nature of its working principle. A 26 g HSTG can produce at least 40 N of gripping force, can hold at least 88 N in external gripping mode (~346 times of its weight), 0.34 N in internal mode, and 1.74 N in suction gripping mode. The design and mechanical properties of its components can be fine-tuned to produce tailored performance for different grasping tasks.",
        "primary_area": "",
        "author": "James Davies;Phuoc Thien Phan;Diana Huang;Trung Thien Hoang;Harrison Low;Mai Thanh Thai;Chi Cong Nguyen;Emanuele Nicotra;Nigel H. Lovell;Thanh Nho Do;James Davies;Phuoc Thien Phan;Diana Huang;Trung Thien Hoang;Harrison Low;Mai Thanh Thai;Chi Cong Nguyen;Emanuele Nicotra;Nigel H. Lovell;Thanh Nho Do",
        "authorids": "/37089446972;/37086208825;/37089448592;/37088498761;/37088845641;/37088497860;/37089447104;/37089449558;/37300634000;/37085436676;/37089446972;/37086208825;/37089448592;/37088498761;/37088845641;/37088497860;/37089447104;/37089449558;/37300634000;/37085436676",
        "aff": "Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Universita Di Roma, Italy; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia; Faculty of Engineering, Graduate School of Biomedical Engineering, UNSW Sydney, Kensington Campus, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811983/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13614307007686805041&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0;0",
        "aff_unique_norm": "UNSW Sydney;University of Rome",
        "aff_unique_dep": "Graduate School of Biomedical Engineering;",
        "aff_unique_url": "https://www.unsw.edu.au;https://www.uniroma1.it",
        "aff_unique_abbr": "UNSW;UniRoma1",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Kensington;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;1;0;0",
        "aff_country_unique": "Australia;Italy"
    },
    {
        "id": "9812372",
        "title": "I Know What You Draw: Learning Grasp Detection Conditioned on a Few Freehand Sketches",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we are interested in the problem of generating target grasps by understanding freehand sketches. The sketch is useful for the persons who cannot formulate language and the cases where a textual description is not available on the fly. However, very few works are aware of the usability of this novel interactive way between humans and robots. To this end, we propose a method to generate a potential grasp configuration relevant to the sketch -depicted objects. Due to the inherent ambiguity of sketches with abstract details, we take the advantage of the graph by incorporating the structure of the sketch to enhance the representation ability. This graph-represented sketch is further validated to improve the generalization of the network, capable of learning the sketch-queried grasp detection by using a small collection (around 100 samples) of hand-drawn sketches. Additionally, our model is trained and tested in an end-to-end manner which is easy to be implemented in real-world applications. Experiments on the multi-object VMRD and GraspNet-1Billion datasets demonstrate the good generalization of the proposed method. The physical robot experiments confirm the utility of our method in object-cluttered scenes.",
        "primary_area": "",
        "author": "Haitao Lin;Chilam Cheang;Yanwei Fu;Xiangyang Xue;Haitao Lin;Chilam Cheang;Yanwei Fu;Xiangyang Xue",
        "authorids": "/37088455645;/37089448081;/37086206496;/37272718600;/37088455645;/37089448081;/37086206496;/37272718600",
        "aff": "Fudan University.; Fudan University.; Fudan University.; Fudan University.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812372/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=963321115727049830&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Fudan University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.fudan.edu.cn",
        "aff_unique_abbr": "Fudan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812041",
        "title": "I Know You Can't See Me: Dynamic Occlusion-Aware Safety Validation of Strategic Planners for Autonomous Vehicles Using Hypergames",
        "track": "main",
        "status": "Poster",
        "abstract": "A particular challenge for both autonomous and human driving is dealing with risk associated with dynamic occlusion, i.e., occlusion caused by other vehicles in traffic. Based on the theory of hypergames, we develop a novel multi-agent dynamic occlusion risk (DOR) measure for assessing situational risk in dynamic occlusion scenarios. Furthermore, we present a white-box, scenario-based, accelerated safety validation framework for assessing safety of strategic planners in AV. Based on evaluation over a large naturalistic database, our proposed validation method achieves a 4000% speedup compared to direct validation on naturalistic data, a more diverse coverage, and ability to generalize beyond the dataset and generate commonly observed dynamic occlusion crashes in traffic in an automated manner.",
        "primary_area": "",
        "author": "Maximilian Kahn;Atrisha Sarkar;Krzysztof Czarnecki;Maximilian Kahn;Atrisha Sarkar;Krzysztof Czarnecki",
        "authorids": "/37089449695;/37085763412;/37303741900;/37089449695;/37085763412;/37303741900",
        "aff": "University of Waterloo, Waterloo, ON; University of Waterloo, Waterloo, ON; University of Waterloo, Waterloo, ON",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812041/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2111115843882221741&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Waterloo",
        "aff_unique_dep": "",
        "aff_unique_url": "https://uwaterloo.ca",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Waterloo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9811777",
        "title": "IPC-GraspSim: Reducing the Sim2Real Gap for Parallel-Jaw Grasping with the Incremental Potential Contact Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurately simulating whether an object will be lifted securely or dropped during grasping is a longstanding Sim2Real challenge. Soft compliant jaw tips are almost universally used with parallel-jaw robot grippers due to their ability to increase contact area and friction between the jaws and the object to be manipulated. However, interactions between the compliant surfaces and rigid objects are notoriously difficult to model. We introduce IPC-GraspSim, a novel grasp simulator that extends Incremental Potential Contact (IPC) - a highly accurate collision + deformation model developed in 2020 for computer graphics. IPC-GraspSim models both the dynamics and the deformation of compliant jaw tips to reduce Sim2Real gap for robot grasping. We evaluate IPC-GraspSim using a set of 2,000 physical grasps across 16 adversarial objects where analytic models perform poorly. In comparison to both analytic quasistatic contact models (soft point contact, REACH, 6DFC) and dynamic grasp simulators (Isaac Gym with FleX), results suggest IPC-GraspSim can predict robustness with higher precision and recall (F1 = 0.85). IPC-GraspSim increases F1 score by 0.03 to 0.20 over analytic baselines and 0.09 over Isaac Gym, at a cost of 8000x and 1.5x more compute time, respectively. All data, code, videos, and supplementary material are available at https://sites.google.com/berkeley.edu/ipcgraspsim.",
        "primary_area": "",
        "author": "Chung Min Kim;Michael Danielczuk;Isabella Huang;Ken Goldberg;Chung Min Kim;Michael Danielczuk;Isabella Huang;Ken Goldberg",
        "authorids": "/37089449093;/37086541913;/37086538069;/37273026700;/37089449093;/37086541913;/37086538069;/37273026700",
        "aff": "The AUTOLab at University of California, Berkeley; The AUTOLab at University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley, USA; The AUTOLab at University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811777/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13803066916651821529&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "The AUTOLab",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811699",
        "title": "IPS300+: a Challenging multi-modal data sets for Intersection Perception System",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to high complexity and occlusion, insufficient perception in the crowded urban intersection can be a serious safety risk for both human drivers and autonomous algorithms, whereas CVIS (Cooperative Vehicle Infrastructure System) is a proposed solution for full-participants perception under this scenario. However, the research on roadside multi-modal perception is still in its infancy, and there is no open-source data sets for such scene. Accordingly, this paper fills the gap. Through an IPS (Intersection Perception System) installed at the diagonal of the intersection, this paper proposes a high-quality multi-modal data sets for the intersection perception task. The center of the experimental intersection covers an area of 3000m2, and the extended distance reaches 300m, which is typical for CVIS. The first batch of open-source data includes 14198 frames, and each frame has an average of 319.84 labels, which is 9.6 times larger than the most crowded data sets (H3D data sets in 2019) by now. Our data sets is available at: http://www.openmpd.com/column/IPS300.",
        "primary_area": "",
        "author": "Huanan Wang;Xinyu Zhang;Zhiwei Li;Jun Li;Kun Wang;Zhu Lei;Ren Haibing;Huanan Wang;Xinyu Zhang;Zhiwei Li;Jun Li;Kun Wang;Zhu Lei;Ren Haibing",
        "authorids": "/37089449857;/37085619542;/37088966086;/37088999341;/37089448782;/37089450532;/37089447553;/37089449857;/37085619542;/37088966086;/37088999341;/37089448782;/37089450532;/37089447553",
        "aff": "State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility in Tsinghua University; State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility in Tsinghua University; State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility in Tsinghua University; State Key Laboratory of Automotive Safety and Energy, School of Vehicle and Mobility in Tsinghua University; Daimer Greater China Ltd.; Mogo Auto Intelligence and Telemetics Information Technology Co. Ltd.; Meituan Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811699/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13489341693484272879&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;3",
        "aff_unique_norm": "Tsinghua University;Daimler Greater China Ltd.;Mogo Auto Intelligence and Telemetics Information Technology Co. Ltd.;Meituan Inc.",
        "aff_unique_dep": "School of Vehicle and Mobility;;;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.daimler.com;;https://www.meituan.com",
        "aff_unique_abbr": "Tsinghua;Daimler GC;;Meituan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811588",
        "title": "Immersive Virtual Walking System Using an Avatar Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "The ongoing COVID-19 pandemic has enforced governments across the world to impose social restrictions on the movement of people and confined them to their homes to avoid the spread of the disease. This not only forbids them from leaving their homes but also greatly reduces their physical activities. This situation has brought attention to virtual technologies such as virtual tours or telepresence robots. While these technologies allow people to remotely participate in activities, it does not address the problem of reduction in physical activities due to the pandemic. In this paper, we propose a telepresence robotic system driven by the user's gait to provide an immersive virtual walking experience in remote locations. To this end, we developed a control interface consisting of an automated treadmill that adjusts its speed to the user's pace automatically. This interface is used to control an avatar robot that sends a 360-degree live image back to the user for visual feedback. We conducted an evaluation experiment to compare the experience using the proposed system in two different conditions to that of regular walking. The results indicated that the proposed system gives an immersive and realistic virtual walking experience while demanding physical effort from the user.",
        "primary_area": "",
        "author": "Kengkij Promsutipong;Jose V. Salazar Luces;Ankit A. Ravankar;Seyed Amir Tafrishi;Yasuhisa Hirata;Kengkij Promsutipong;Jose V. Salazar Luces;Ankit A. Ravankar;Seyed Amir Tafrishi;Yasuhisa Hirata",
        "authorids": "/37088235277;/37088234483;/38236067100;/37086457214;/37274134900;/37088235277;/37088234483;/38236067100;/37086457214;/37274134900",
        "aff": "Department of Robotics, Tohoku University, Sendai, JAPAN; Department of Robotics, Tohoku University, Sendai, JAPAN; Department of Robotics, Tohoku University, Sendai, JAPAN; Department of Robotics, Tohoku University, Sendai, JAPAN; Department of Robotics, Tohoku University, Sendai, JAPAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811588/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16371069870347972690&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811681",
        "title": "Impact Planning and Pre-configuration based on Hierarchical Quadratic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "Impacts and other non-smooth behaviors are usually unwanted in robotic applications. However, several industrial tasks such as deburring, removing excess material, and assembling/fitting, involve impacts between objects, which can benefit from robotic automation due to the risks posed to human health. Towards this objective, in this paper, we propose a method for optimal impact planning and pre-configuration for torque-controlled robots. We thus employ a well-known impulsive contact model to plan the impact force and create a hierarchical quadratic programming based controller capable of minimizing the robot's peak torques by reconfiguring its joints optimally, before the impact occurs. The results obtained from multiple experiments during an industrial deburring task are discussed. Using a 7-DoF manipulator, we show consistent results, both in terms of accuracy of the impact force tracking with respect to the desired forces, and in terms of peak torques reduction and uniform torques distribution.",
        "primary_area": "",
        "author": "Francesco Tassi;Soheil Gholami;Simone Giudice;Arash Ajoudani;Francesco Tassi;Soheil Gholami;Simone Giudice;Arash Ajoudani",
        "authorids": "/37086861229;/37085622074;/37089448702;/37945239900;/37086861229;/37085622074;/37089448702;/37945239900",
        "aff": "Dept. of Electronics, Information and Bioengineering, NearLab, Politecnico di Milano, Milan, Italy; Dept. of Electronics, Information and Bioengineering, NearLab, Politecnico di Milano, Milan, Italy; Human-Robot Interfaces and physical Interaction (HRI2) lab, Istituto Italiano di Tecnologia, Genoa, Italy; Human-Robot Interfaces and physical Interaction (HRI2) lab, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811681/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8544843958171987707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Politecnico di Milano;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Dept. of Electronics, Information and Bioengineering;Human-Robot Interfaces and physical Interaction (HRI2) lab",
        "aff_unique_url": "https://www.polimi.it;https://www.iit.it",
        "aff_unique_abbr": "Politecnico di Milano;IIT",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Milan;Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9811647",
        "title": "Implicit Differential Dynamic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "Over the past decade, the Differential Dynamic Programming (DDP) method has gained in maturity and popularity within the robotics community. Several recent contributions have led to the integration of constraints within the original DDP formulation, hence enlarging its domain of application while making it a strong and easy-to-implement competitor against alternative methods of the state of the art such as collocation or multiple-shooting approaches. Yet, and similarly to its competitors, DDP remains unable to cope with high-dimensional dynamics within a receding horizon fashion, such as in the case of online generation of athletic motion on humanoid robots. In this paper, we propose to make a step towards this objective by reformulating classical DDP as an implicit optimal control problem, allowing the use of more advanced integration schemes such as implicit or variational integrators. To that end, we introduce a primal-dual proximal Lagrangian approach capable of handling dynamical and path constraints in a unified manner, while taking advantage of the time sparsity inherent to optimal control problems. We show that this reformulation enables us to relax the dynamics along the optimization process by solving it inexactly: far from the optimality conditions, the dynamics are only partially fulfilled, but continuously enforced as the solver gets closer to the local optimal solution. This inexactness enables our approach to robustly handle large time steps (100 ms or more), unlike other DDP solvers of the state of the art, as experimentally validated through different robotic scenarii.",
        "primary_area": "",
        "author": "Wilson Jallet;Nicolas Mansard;Justin Carpentier;Wilson Jallet;Nicolas Mansard;Justin Carpentier",
        "authorids": "/37089448726;/37542913400;/37085506841;/37089448726;/37542913400;/37085506841",
        "aff": "Departement d'informatique, l'ENS, Paris, France; LAAS-CNRS, Toulouse, France; Departement d'informatique, l'ENS, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811647/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13076617914924814472&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Ecole Normale Superieure;LAAS-CNRS",
        "aff_unique_dep": "Departement d'informatique;",
        "aff_unique_url": "https://www.ens.fr;https://www.laas.fr",
        "aff_unique_abbr": "ENS;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Paris;Toulouse",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812165",
        "title": "Implicit Kinematic Policies: Unifying Joint and Cartesian Action Spaces in End-to-End Robot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Action representation is an important yet often overlooked aspect in end-to-end robot learning with deep networks. Choosing one action space over another (e.g. target joint positions, or Cartesian end-effector poses) can result in surprisingly stark performance differences between various downstream tasks - and as a result, considerable research has been devoted to finding the right action space for a given application. However, in this work, we instead investigate how our models can discover and learn for themselves which action space to use. Leveraging recent work on implicit behavioral cloning, which takes both observations and actions as input, we demonstrate that it is possible to present the same action in multiple different spaces to the same policy - allowing it to learn inductive patterns from each space. Specifically, we study the benefits of combining Cartesian and joint action spaces in the context of learning manipulation skills. To this end, we present Implicit Kinematic Policies (IKP), which incorporates the kinematic chain as a differentiable module within the deep network. Quantitative experiments across several simulated continuous control tasks-from scooping piles of small objects, to lifting boxes with elbows, to precise block insertion with miscalibrated robots-suggest IKP not only learns complex prehensile and non-prehensile manipulation from pixels better than baseline alternatives, but also can learn to compensate for small joint encoder offset errors. Finally, we also run qualitative experiments on a real UR5e to demonstrate the feasibility of our algorithm on a physical robotic system with real data. See https://tinyurl.com/4wz3nf86 for code and supplementary material.",
        "primary_area": "",
        "author": "Aditya Ganapathi;Pete Florence;Jake Varley;Kaylee Burns;Ken Goldberg;Andy Zeng;Aditya Ganapathi;Pete Florence;Jake Varley;Kaylee Burns;Ken Goldberg;Andy Zeng",
        "authorids": "/37088688406;/37085786926;/37085632898;/37089447650;/37273026700;/37086217185;/37088688406;/37085786926;/37085632898;/37089447650;/37273026700;/37086217185",
        "aff": "UC Berkeley; Robotics, Google; Robotics, Google; Stanford University; UC Berkeley; Robotics, Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812165/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5936154475788907768&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;0;1",
        "aff_unique_norm": "University of California, Berkeley;Google;Stanford University",
        "aff_unique_dep": ";Robotics;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.google.com;https://www.stanford.edu",
        "aff_unique_abbr": "UC Berkeley;Google;Stanford",
        "aff_campus_unique_index": "0;1;1;2;0;1",
        "aff_campus_unique": "Berkeley;Mountain View;Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811992",
        "title": "Implicit LiDAR Network: LiDAR Super-Resolution via Interpolation Weight Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Super-resolution of LiDAR range images is crucial to improving many downstream tasks such as object detection, recognition, and tracking. While deep learning has made a remarkable advances in super-resolution techniques, typical convolutional architectures limit upscaling factors to specific output resolutions in training. Recent work has shown that a continuous representation of an image and learning its implicit function enable almost limitless upscaling. However, the detailed approach, predicting values (depths) for neighbor pixels in the input and then linearly interpolating them, does not best fit the LiDAR range images since it does not fill the unmeasured details but creates a new image with regression in a high-dimensional space. In addition, the linear interpolation blurs sharp edges providing important boundary information of objects in 3-D points. To handle these problems, we propose a novel network, Implicit LiDAR Network (ILN), which learns not the values per pixels but weights in the interpolation so that the super-resolution can be done by blending the input pixel depths but with non-linear weights. Also, the weights can be considered as attentions from the query to the neighbor pixels, and thus an attention module in the recent Transformer architecture can be leveraged. Our experiments with a novel large-scale synthetic dataset demonstrate that the proposed network reconstructs more accurately than the state-of-the-art methods, achieving much faster convergence in training.",
        "primary_area": "",
        "author": "Youngsun Kwon;Minhyuk Sung;Sung\u2013Eui Yoon;Youngsun Kwon;Minhyuk Sung;Sung\u2013Eui Yoon",
        "authorids": "/37085769014;/37089014344;/37066068100;/37085769014;/37089014344;/37066068100",
        "aff": "School of Computing, Korea Advanced Institute of Science and Technol-ogy, Daejeon, South Korea; School of Computing, Korea Advanced Institute of Science and Technol-ogy, Daejeon, South Korea; School of Computing, Korea Advanced Institute of Science and Technol-ogy, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811992/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4602490419013740854&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812234",
        "title": "Important Object Identification with Semi-Supervised Learning for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate identification of important objects in the scene is a prerequisite for safe and high-quality decision making and motion planning of intelligent agents (e.g., autonomous vehicles) that navigate in complex and dynamic environments. Most existing approaches attempt to employ attention mechanisms to learn importance weights associated with each object indirectly via various tasks (e.g., trajectory prediction), which do not enforce direct supervision on the importance estimation. In contrast, we tackle this task in an explicit way and formulate it as a binary classification (\u201cimportant\u201d or \u201cunimportant\u201d) problem. We propose a novel approach for important object identification in egocentric driving scenarios with relational reasoning on the objects in the scene. Besides, since human annotations are limited and expensive to obtain, we present a semi-supervised learning pipeline to enable the model to learn from unlimited unlabeled data. Moreover, we propose to leverage the auxiliary tasks of ego vehicle behavior prediction to further improve the accuracy of importance estimation. The proposed approach is evaluated on a public egocentric driving dataset (H3D) collected in complex traffic scenarios. A detailed ablative study is conducted to demonstrate the effectiveness of each model component and the training strategy. Our approach also outperforms rule-based baselines by a large margin.",
        "primary_area": "",
        "author": "Jiachen Li;Haiming Gang;Hengbo Ma;Masayoshi Tomizuka;Chiho Choi;Jiachen Li;Haiming Gang;Hengbo Ma;Masayoshi Tomizuka;Chiho Choi",
        "authorids": "/37086309095;/37086936889;/37086547315;/37281933000;/37086937192;/37086309095;/37086936889;/37086547315;/37281933000;/37086937192",
        "aff": "Department of Aeronautics & Astronautics, Stanford University, CA, USA; Honda Research Institute, San Jose, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Honda Research Institute, San Jose, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812234/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9199057753831077745&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;1",
        "aff_unique_norm": "Stanford University;Honda Research Institute;University of California, Berkeley",
        "aff_unique_dep": "Department of Aeronautics & Astronautics;;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu;https://honda-ri.com;https://www.berkeley.edu",
        "aff_unique_abbr": "Stanford;HRI;UC Berkeley",
        "aff_campus_unique_index": "0;1;2;2;1",
        "aff_campus_unique": "Stanford;San Jose;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812192",
        "title": "Improved Kalman-Particle Kernel Filter on Lie Groups Applied to Angles-Only UAV Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Kalman-Particle Kernel Filter (KPKF) is a sub-class of Particle Filter (PF) that uses Gaussian kernels as particles, which enables a local Kalman update for each measurement in addition to the usual weight update. Besides, recent research about filtering on Lie groups brought powerful theoretical results, and showed the superiority of this approach. Hence, this paper extends the Euclidean KPKF to a new formulation on Lie groups and introduces substantial improvements based on Lie groups Kalman filters theory and Laplace Particle Filters on Lie groups (LG-LPF) for improved resampling. The proposed algorithm is tested on an angles-only UAV navigation scenario with challenging initial errors. It shows superior robustness and accuracy compared to Lie group Extended Kalman Filter (LG-EKF), with near-to optimal performance, even with a limited amount of particles.",
        "primary_area": "",
        "author": "Cl\u00e9ment Chahbazian;Karim Dahia;Nicolas Merlinge;B\u00e9nedicte Winter-Bonnet;K\u00e9vin Honore;Christian Musso;Cl\u00e9ment Chahbazian;Karim Dahia;Nicolas Merlinge;B\u00e9nedicte Winter-Bonnet;K\u00e9vin Honore;Christian Musso",
        "authorids": "/37088688916;/37085747099;/37086327173;/37089176032;/37089449929;/37328439900;/37088688916;/37085747099;/37086327173;/37089176032;/37089449929;/37328439900",
        "aff": "Information and Signals department, The French aerospace laboratory, ONERA, Palaiseau, France; Information and Signals department, The French aerospace laboratory, ONERA, Palaiseau, France; Information and Signals department, The French aerospace laboratory, ONERA, Palaiseau, France; Dpt. of Guidance Control and Navigation, MBDA France, Le Plessis Robinson, France; Dpt. of Guidance Control and Navigation, MBDA France, Le Plessis Robinson, France; Information and Signals department, The French aerospace laboratory, ONERA, Palaiseau, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812192/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17667935768559756994&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "ONERA;MBDA France",
        "aff_unique_dep": "Information and Signals department;Department of Guidance Control and Navigation",
        "aff_unique_url": "https://www.onera.fr;https://www.mbda-systems.com",
        "aff_unique_abbr": "ONERA;MBDA",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Palaiseau;Le Plessis Robinson",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812206",
        "title": "Improved Soft Duplicate Detection in Search-Based Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Search-based techniques have shown great success in motion planning problems such as robotic navigation by discretizing the state space and precomputing motion primitives. However in domains with complex dynamic constraints, constructing motion primitives in a discretized state space is non-trivial. This requires operating in continuous space which can be challenging for search-based planners as they can get stuck in local minima regions. Previous work [1] on planning in continuous spaces introduced soft duplicate detection which requires search to compute the duplicity of a state with respect to previously seen states to avoid exploring states that are likely to be duplicates, especially in local minima regions. They propose a simple metric utilizing the Euclidean distance between states, and proximity to obstacles to compute the duplicity. In this paper, we improve upon this metric by introducing a kinodynamically informed metric, subtree overlap, between two states as the similarity between their successors that can be reached within a fixed time horizon using kinodynamic motion primitives. This captures the intuition that, due to robot dynamics, duplicate states can be far in Euclidean distance and result in very similar successor states, while non-duplicate states can be close and result in widely different successors. Our approach computes the new metric offline for a given robot dynamics, and stores the subtree overlap value for all possible relative state configurations. During search, the planner uses these precomputed values to speed up duplicity computation, and achieves fast planning times in continuous spaces in addition to completeness and sub-optimality guarantees. Empirically, we show that our improved metric for soft duplicity detection in search-based planning outperforms previous approaches in terms of planning time, by a factor of 1.5 to 2\u00d7 on 3D and 5D planning domains with highly constrained dynamics.",
        "primary_area": "",
        "author": "Nader Maray;Anirudh Vemula;Maxim Likhachev;Nader Maray;Anirudh Vemula;Maxim Likhachev",
        "authorids": "/37089447575;/37085400555;/37309318800;/37089447575;/37085400555;/37309318800",
        "aff": "Department of Computer Science, Texas State University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812206/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4540746693572090938&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Texas State University;Carnegie Mellon University",
        "aff_unique_dep": "Department of Computer Science;Robotics Institute",
        "aff_unique_url": "https://www.txstate.edu;https://www.cmu.edu",
        "aff_unique_abbr": "TXST;CMU",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811989",
        "title": "Improved State Propagation through AI-based Pre-processing and Down-sampling of High-Speed Inertial Data",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel approach to improve 6 degree-of-freedom state propagation for unmanned aerial vehicles in a classical filter through pre-processing of high-speed inertial data with AI algorithms. We evaluate both an LSTM-based approach as well as a Transformer encoder architecture. Both algorithms take as input short sequences of fixed length N of high-rate inertial data provided by an inertial measurement unit (IMU) and are trained to predict in turn one pre-processed IMU sample that minimizes the state propagation error of a classical filter across M sequences. This setup allows us to provide sufficient temporal history to the networks for good performance while maintaining a high propagation rate of pre-processed IMU samples important for later deployment on real-world systems. In addition, our network architectures are formulated to directly accept input data at variable rates thus minimizing necessary data preprocessing. The results indicate that the LSTM based architecture outperforms the Transformer encoder architecture and significantly improves the propagation error even for long IMU propagation times.",
        "primary_area": "",
        "author": "Jan Steinbrener;Christian Brommer;Thomas Jantos;Alessandro Fornasier;Stephan Weiss;Jan Steinbrener;Christian Brommer;Thomas Jantos;Alessandro Fornasier;Stephan Weiss",
        "authorids": "/37087049144;/37086574162;/37089447758;/37088685957;/37535323400;/37087049144;/37086574162;/37089447758;/37088685957;/37535323400",
        "aff": "Control of Networked Systems group, Universit\u00e4t Klagenfurt, Klagenfurt, Austria; Control of Networked Systems group, Universit\u00e4t Klagenfurt, Klagenfurt, Austria; Control of Networked Systems group, Universit\u00e4t Klagenfurt, Klagenfurt, Austria; Control of Networked Systems group, Universit\u00e4t Klagenfurt, Klagenfurt, Austria; Control of Networked Systems group, Universit\u00e4t Klagenfurt, Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811989/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13064149803618682869&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Universit\u00e4t Klagenfurt",
        "aff_unique_dep": "Control of Networked Systems group",
        "aff_unique_url": "https://www.aau.at",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Klagenfurt",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9812236",
        "title": "Improved Task Planning through Failure Anticipation in Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-Robot Collaboration (HRC) has become a major trend in robotics in recent years with the idea of combining the strengths from both humans and robots. In order to share the work to be done, many task planning approaches have been implemented. However, they don't fully satisfy the required adaptability in human-robot collaborative tasks, with most approaches not considering neither the state of the human partner nor the possibility of adapting the collaborative plan during execution or even anticipating failures. In this paper, we present a planning system for human-robot collaborative plans that takes into account the agents' states and deals with unforeseen human behaviour, by replanning in anticipation when the human state changes to prevent action failure. The human state is defined in terms of capacity, knowledge and motivation. The system has been implemented in a standardised environment using the Planning Domain Definition Language (PDDL) and the modular ROSPlan framework, and we have validated the approach in multiple simulation settings. Our results show that using the human model fosters an appropriate task allocation while allowing failure anticipation, replanning in time to prevent it.",
        "primary_area": "",
        "author": "Silvia Izquierdo-Badiola;Gerard Canal;Carlos Rizzo;Guillem Aleny\u00e0;Silvia Izquierdo-Badiola;Gerard Canal;Carlos Rizzo;Guillem Aleny\u00e0",
        "authorids": "/37089449061;/37085687945;/37085409384;/37546459500;/37089449061;/37085687945;/37085409384;/37546459500",
        "aff": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; Department of Informatics, King's College London, United Kingdom; Eurecat, Centre Tecnol\u00f2gic de Catalunya, Robotics and Automation Unit, Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812236/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5623922464778077411&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial;King's College London;Eurecat",
        "aff_unique_dep": ";Department of Informatics;Robotics and Automation Unit",
        "aff_unique_url": "http://www.iri.upc.edu/;https://www.kcl.ac.uk;https://www.eurecat.org",
        "aff_unique_abbr": "IRI;KCL;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Barcelona;London",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Spain;United Kingdom"
    },
    {
        "id": "9812200",
        "title": "Improving Haptic Exploration of Object Shape by Discovering Symmetries",
        "track": "main",
        "status": "Poster",
        "abstract": "The shapes of most real-world objects are symmetric with respect to at least one plane of symmetry. This information is unconsciously used by humans when they attempt to estimate the shape of an object in presence of uncertainty or missing evidence, for example if the object is partially occluded or if they are exploring the object by touch (i.e. haptic exploration). In robotics, this concept has been used for the visual estimation of object shape. However, no attempt has been made so far to incorporate this idea into haptic-based estimation. This work presents a method for the haptic exploration of object shape that includes the assumption that a symmetry could exist. The approach combines a tailored version of Gaussian Processes and a novel exploratory procedure that is able to detect the position and orientation of any plane of symmetry. Our results show that, if one or more symmetries exist, the object shape can be estimated faster and more accurately. Interestingly, in the case that no symmetry is present, the exploration process is only slightly slower, and the final accuracy of the shape estimation is not compromised.",
        "primary_area": "",
        "author": "Aramis Augusto Bonzini;Lucia Seminara;Lorenzo Jamone;Aramis Augusto Bonzini;Lucia Seminara;Lorenzo Jamone",
        "authorids": "/37088943164;/37669318100;/37295474600;/37088943164;/37669318100;/37295474600",
        "aff": "ARQ (Advanced Robotics at Queen Mary), School of Electronic Engineering and Computer Science, Queen Mary University of London, London, UK; Department of Naval, Electrical, Electronic, and Telecommunications Engineering (DITEN), University of Genoa, Genova, Italy; ARQ (Advanced Robotics at Queen Mary), School of Electronic Engineering and Computer Science, Queen Mary University of London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812200/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14451970442917213067&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Queen Mary University of London;University of Genoa",
        "aff_unique_dep": "School of Electronic Engineering and Computer Science;Department of Naval, Electrical, Electronic, and Telecommunications Engineering (DITEN)",
        "aff_unique_url": "https://www.qmul.ac.uk;https://www.unige.it",
        "aff_unique_abbr": "QMUL;UniGe",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "London;Genova",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;Italy"
    },
    {
        "id": "9812181",
        "title": "Improving Safety in Deep Reinforcement Learning using Unsupervised Action Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the key challenges to deep reinforcement learning (deep RL) is to ensure safety at both training and testing phases. In this work, we propose a novel technique of unsupervised action planning to improve the safety of on-policy reinforcement learning algorithms, such as trust region policy optimization (TRPO) or proximal policy optimization (PPO). We design our safety-aware reinforcement learning by storing all the history of \u201crecovery\u201d actions that rescue the agent from dangerous situations into a separate \u201csafety\u201d buffer and finding the best recovery action when the agent encounters similar states. Because this functionality requires the algorithm to query similar states, we implement the proposed safety mechanism using an unsupervised learning algorithm, k-means clustering. We evaluate the proposed algorithm on six robotic control tasks that cover navigation and manipulation. Our results show that the proposed safe RL algorithm can achieve higher rewards compared with multiple baselines in both discrete and continuous control problems. The supplemental video can be found at: https://youtu.be/AFTeWSohILo.",
        "primary_area": "",
        "author": "Hao-Lun Hsu;Qiuhua Huang;Sehoon Ha;Hao-Lun Hsu;Qiuhua Huang;Sehoon Ha",
        "authorids": "/37089446684;/37085809265;/37086314268;/37089446684;/37085809265;/37086314268",
        "aff": "Georgia Institute of Technology, Atlanta, GA, USA; Pacific Northwest National Laboratory, Richland, WA, USA; Robotics at Google, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812181/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8721211341051086847&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Georgia Institute of Technology;Pacific Northwest National Laboratory;Google",
        "aff_unique_dep": ";;Robotics",
        "aff_unique_url": "https://www.gatech.edu;https://www.pnnl.gov;https://www.google.com",
        "aff_unique_abbr": "Georgia Tech;PNNL;Google",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Atlanta;Richland;Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812284",
        "title": "Improving Standing Balance Performance through the Assistance of a Mobile Collaborative Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design and development of a robotic system to give physical assistance to the elderly or people with neurological disorders such as Ataxia or Parkin-son's. In particular, we propose using a mobile collaborative robot with an interaction-assistive whole-body interface to help people unable to maintain balance. The robotic system consists of an Omni-directional mobile base, a high-payload robotic arm, and an admittance-type interface acting as a support handle while measuring human-sourced interaction forces. The postural balance of the human body is estimated through the projection of the body Center of Mass (CoM) to the support polygon (SP) representing the quasi-static Center of Pressure (CoP). In response to the interaction forces and the tracking of the human posture, the robot can create assistive forces to restore balance in case of its loss. Otherwise, during normal stance or walking, it will follow the user with minimum/no opposing forces through the generation of coupled arm and base movements. As the balance-restoring strategy, we propose two strategies and evaluate them in a laboratory setting on healthy human participants. Quantitative and qualitative results of a 12-subjects experiment are then illustrated and discussed, comparing the performances of the two strategies and the overall system.",
        "primary_area": "",
        "author": "Francisco J. Ruiz-Ruiz;Alberto Giammarino;Marta Lorenzini;Juan M. Gandarias;Jes\u00fas H. G\u00f3mez-De-Gabriel;Arash Ajoudani;Francisco J. Ruiz-Ruiz;Alberto Giammarino;Marta Lorenzini;Juan M. Gandarias;Jes\u00fas H. G\u00f3mez-De-Gabriel;Arash Ajoudani",
        "authorids": "/37088820138;/37089440546;/37086249968;/37086294706;/38273879300;/37945239900;/37088820138;/37089440546;/37086249968;/37086294706;/38273879300;/37945239900",
        "aff": "Robotics and Mechatronics Group, University of M\u00e1laga, M\u00e1laga, Spain; HRI2 Lab, Istituto Italiano di Tecnologia, Genoa, Italy; HRI2 Lab, Istituto Italiano di Tecnologia, Genoa, Italy; HRI2 Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Robotics and Mechatronics Group, University of M\u00e1laga, M\u00e1laga, Spain; HRI2 Lab, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812284/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12554863782538726821&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;1",
        "aff_unique_norm": "University of M\u00e1laga;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Robotics and Mechatronics Group;HRI2 Lab",
        "aff_unique_url": "https://www.uma.es;https://www.iit.it",
        "aff_unique_abbr": "UMA;",
        "aff_campus_unique_index": "0;1;1;1;0;1",
        "aff_campus_unique": "M\u00e1laga;Genoa",
        "aff_country_unique_index": "0;1;1;1;0;1",
        "aff_country_unique": "Spain;Italy"
    },
    {
        "id": "9811700",
        "title": "Improving the Feasibility of DS-based Collision Avoidance Using Non-Linear Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a novel strategy for reactive collision-free feasible motion planning for robotic manipulators operating inside an environment populated by moving obstacles. The proposed strategy embeds the Dynamical System (DS) based obstacle avoidance algorithm into a constrained non-linear optimization problem following the Model Predictive Control (MPC) approach. The solution of the problem allows the robot to avoid undesired collision with moving obstacles ensuring at the same time that its motion is feasible and does not overcome the designed constraints on velocity and acceleration. Simulations demonstrate that the introduction of the MPC prediction horizon helps the optimization solver in finding the solution leading to obstacle avoidance in situations where a non predictive implementation of the DS-based method would fail. Finally, the proposed strategy has been validated in an experimental work-cell using a Franka-Emika Panda robot.",
        "primary_area": "",
        "author": "Saverio Farsoni;Alessio Sozzi;Marco Minelli;Cristian Secchi;Marcello Bonf\u00e9;Saverio Farsoni;Alessio Sozzi;Marco Minelli;Cristian Secchi;Marcello Bonf\u00e9",
        "authorids": "/37085440514;/37087322421;/37086036138;/37300905500;/37300903100;/37085440514;/37087322421;/37086036138;/37300905500;/37300903100",
        "aff": "Department of Engineering, University of Ferrara, Italy; Department of Engineering, University of Ferrara, Italy; Department of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy; Department of Sciences and Methods of Engineering, University of Modena and Reggio, Emilia, Italy; Department of Engineering, University of Ferrara, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811700/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=640714117833005362&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of Ferrara;University of Modena and Reggio Emilia",
        "aff_unique_dep": "Department of Engineering;Department of Sciences and Methods of Engineering",
        "aff_unique_url": "https://www.unife.it;https://www.unimore.it",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9811991",
        "title": "Incorporating Rich Social Interactions Into MDPs",
        "track": "main",
        "status": "Poster",
        "abstract": "Much of what we do as humans is engage socially with other agents, a skill that robots must also eventually possess. We demonstrate that a rich theory of social interactions originating from microsociology can be formalized by extending a nested MDP where agents reason about arbitrary functions of each other's rewards. This extended Social MDP allows us to encode the five basic interactions that underlie microsociology: cooperation, conflict, coercion, competition, and exchange. The result is a robotic agent capable of executing social interactions in new environments with no interaction-specific training; like humans it can engage socially in novel ways even without a single example of that social interaction. Moreover, the estimations of these Social MDPs align closely with the judge-ments of humans when considering which social interaction is taking place in an environment. This method both sheds light on the nature of social interactions, by providing concrete mathematical definitions, and brings rich social interactions into a mathematical framework that has proven to be natural for robotics.",
        "primary_area": "",
        "author": "Ravi Tejwani;Yen-Ling Kuo;Tianmin Shu;Bennett Stankovits;Dan Gutfreund;Joshua B. Tenenbaum;Boris Katz;Andrei Barbu;Ravi Tejwani;Yen-Ling Kuo;Tianmin Shu;Bennett Stankovits;Dan Gutfreund;Joshua B. Tenenbaum;Boris Katz;Andrei Barbu",
        "authorids": "/37597460400;/37086579906;/37085659891;/37089447234;/38312427400;/37622583000;/37086574046;/37086580332;/37597460400;/37086579906;/37085659891;/37089447234;/38312427400;/37622583000;/37086574046;/37086580332",
        "aff": "CSAIL & CBMM, MIT; CSAIL & CBMM, MIT; BCS & CBMM, MIT; CSAIL & CBMM, MIT; MIT-IBM Watson AI Lab; BCS & CBMM, MIT; CSAIL & CBMM, MIT; CSAIL & CBMM, MIT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811991/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8507652678464581869&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory & Center for Brains, Minds, and Machines",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812078",
        "title": "Incremental Abstraction in Distributed Probabilistic SLAM Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Scene graphs represent the key components of a scene in a compact and semantically rich way, but are difficult to build during incremental SLAM operation because of the challenges of robustly identifying abstract scene elements and optimising continually changing, complex graphs. We present a distributed, graph-based SLAM framework for incrementally building scene graphs based on two novel components. First, we propose an incremental abstraction framework in which a neural network proposes abstract scene elements that are incorporated into the factor graph of a feature-based monocular SLAM system. Scene elements are confirmed or rejected through optimisation and incrementally replace the points yielding a more dense, semantic and compact representation. Second, enabled by our novel routing procedure, we use Gaussian Belief Propagation (GBP) for distributed inference on a graph processor. The time per iteration of GBP is structure-agnostic and we demonstrate the speed advantages over direct methods for inference of heterogeneous factor graphs. We run our system on real indoor datasets using planar abstractions and recover the major planes with significant compression.",
        "primary_area": "",
        "author": "Joseph Ortiz;Talfan Evans;Edgar Sucar;Andrew J. Davison;Joseph Ortiz;Talfan Evans;Edgar Sucar;Andrew J. Davison",
        "authorids": "/37088456059;/37089447363;/37086453728;/37293837200;/37088456059;/37089447363;/37086453728;/37293837200",
        "aff": "Robot Vision Laboratory, Imperial College London, United Kingdom; Robot Vision Laboratory, Imperial College London, United Kingdom; Robot Vision Laboratory, Imperial College London, United Kingdom; Robot Vision Laboratory, Imperial College London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812078/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3995435316209788446&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Robot Vision Laboratory",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811856",
        "title": "Incremental Few-Shot Object Detection for Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Incremental few-shot learning is highly expected for practical robotics applications. On one hand, robot is desired to learn new tasks quickly and flexibly using only few annotated training samples; on the other hand, such new additional tasks should be learned in a continuous and incremental manner without forgetting the previous learned knowledge dramatically. In this work, we propose a novel Class-Incremental Few- Shot Object Detection (CI-FSOD) framework that enables deep object detection network to perform effective continual learning from just few-shot samples without re-accessing the previous training data. We achieve this by equipping the widely-used Faster-RCNN detector with three elegant components. Firstly, to best preserve performance on the pre-trained base classes, we propose a novel Dual-Embedding-Space (DES) architecture which decouples the representation learning of base and novel categories into different spaces. Secondly, to mitigate the catastrophic forgetting on the accumulated novel classes, we propose a Sequential Model Fusion (SMF) method, which is able to achieve long-term memory without additional storage cost. Thirdly, to promote inter-task class separation in feature space, we propose a novel regularization technique that extends the classification boundary further away from the previous classes to avoid misclassification. Overall, our framework is simple yet effective and outperforms the previous SOTA with a significant margin of 2.4 points in AP performance.",
        "primary_area": "",
        "author": "Yiting Li;Haiyue Zhu;Sichao Tian;Fan Feng;Jun Ma;Chek Sing Teo;Cheng Xiang;Prahlad Vadakkepat;Tong Heng Lee;Yiting Li;Haiyue Zhu;Sichao Tian;Fan Feng;Jun Ma;Chek Sing Teo;Cheng Xiang;Prahlad Vadakkepat;Tong Heng Lee",
        "authorids": "/37088689764;/37085409877;/37089015011;/37087234597;/37085728817;/37288627000;/37282223900;/37274712000;/37277268600;/37088689764;/37085409877;/37089015011;/37087234597;/37085728817;/37288627000;/37282223900;/37274712000;/37277268600",
        "aff": "National University of Singapore, Singapore; Adaptive Robotics and Mechatronics Group, Singapore Institute of Manufacturing Technology, Agency for Science, Technology and Research, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Adaptive Robotics and Mechatronics Group, Singapore Institute of Manufacturing Technology, Agency for Science, Technology and Research, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811856/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7960985671827801430&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;0;2;1;0;0;0",
        "aff_unique_norm": "National University of Singapore;Singapore Institute of Manufacturing Technology;Hong Kong University of Science and Technology",
        "aff_unique_dep": ";Adaptive Robotics and Mechatronics Group;Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.simtech.a-star.edu.sg;https://www.ust.hk",
        "aff_unique_abbr": "NUS;SIMTech;HKUST",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;1;0;0;0;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9812108",
        "title": "Incremental Learning for Enhanced Personalization of Autocomplete Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Remote controlling robots without any automated help is difficult due to various limitations. Autocomplete mitigates this difficulty by automatically detecting and completing the intended motions on robots from the input of the user. Such an approach can improve the system performance and reduce the load on the operator. Usually, recognizing intended motions is achieved using pre-trained Deep Learning (DL) models. In this paper, we introduce personalization to the autocomplete teleoperation framework when new operators take over by customizing the autocomplete DL model using incremental learning. Also, we tackle the problem of concept drift that arises in real-life applications; the data distribution of already learned classes may change in unforeseen ways as new observations of these classes come sequentially over time. We create and update an exemplar set using new observations of the classes online so that the model can be trained to adapt to the new observations. Several scenarios have been evaluated to balance the speed of learning with the accuracy of the model, and results demonstrate the effectiveness of the proposed models and their advantage in adapting to the specific operator versus our previous framework: personalization using transfer learning with full feedback.",
        "primary_area": "",
        "author": "Mohammad Haj Hussein;Batool Ibrahim;Imad H. Elhajj;Daniel Asmar;Mohammad Haj Hussein;Batool Ibrahim;Imad H. Elhajj;Daniel Asmar",
        "authorids": "/37089021407;/37088913912;/37281934400;/37424435700;/37089021407;/37088913912;/37281934400;/37424435700",
        "aff": "Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon; Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon; Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon; Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812108/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13678183130282656246&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "American University of Beirut",
        "aff_unique_dep": "Vision and Robotics Lab",
        "aff_unique_url": "https://www.aub.edu.lb",
        "aff_unique_abbr": "AUB",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beirut",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Lebanon"
    },
    {
        "id": "9812449",
        "title": "Indoor Localization for Quadrotors using Invisible Projected Tags",
        "track": "main",
        "status": "Poster",
        "abstract": "Augmented reality (AR) technology has been in-troduced into the robotics field to narrow the visual gap between indoor and outdoor environments. However, without signals from satellite navigation systems, flight experiments in these indoor AR scenarios need other accurate localization approaches. This work proposes a real-time centimeter-level indoor localization method based on psycho-visually invisible projected tags (IPT), requiring a projector as the sender and quadrotors with high-speed cameras as the receiver. The method includes a modulation process for the sender, as well as demodulation and pose estimation steps for the receiver, where screen-camera communication technology is applied to hide fiducial tags using human vision property. Experiments have demonstrated that IPT can achieve accuracy within ten centimeters and a speed of about ten FPS. Compared with other localization methods for AR robotics platforms, IPT is affordable by using only a projector and high-speed cameras as hardware consumption and convenient by omitting a coordinate alignment step. To the authors' best knowledge, this is the first time screen-camera communication is utilized for AR robot localization.",
        "primary_area": "",
        "author": "Jinjie Li;Liang Han;Zhang Ren;Jinjie Li;Liang Han;Zhang Ren",
        "authorids": "/37089448036;/37085691940;/37418980100;/37089448036;/37085691940;/37418980100",
        "aff": "School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Sino-French Engineer School, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812449/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18046775504469604908&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "School of Automation Science and Electrical Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812375",
        "title": "Informative Planning for Worst-Case Error Minimisation in Sparse Gaussian Process Regression",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a planning framework for min-imising the deterministic worst-case error in sparse Gaus-sian process (GP) regression. We first derive a univer-sal worst-case error bound for sparse GP regression with bounded noise using interpolation theory on reproducing kernel Hilbert spaces (RKHSs). By exploiting the conditional inde-pendence (CI) assumption central to sparse GP regression, we show that the worst-case error minimisation can be achieved by solving a posterior entropy minimisation problem. In turn, the posterior entropy minimisation problem is solved using a Gaussian belief space planning algorithm. We corroborate the proposed worst-case error bound in a simple 1D example, and test the planning framework in simulation for a 2D vehicle in a complex flow field. Our results demonstrate that the proposed posterior entropy minimisation approach is effective in minimising deterministic error, and outperforms the conventional measurement entropy maximisation formulation when the inducing points are fixed.",
        "primary_area": "",
        "author": "Jennifer Wakulicz;Ki Myung Brian Lee;Chanyeol Yoo;Teresa Vidal-Calleja;Robert Fitch;Jennifer Wakulicz;Ki Myung Brian Lee;Chanyeol Yoo;Teresa Vidal-Calleja;Robert Fitch",
        "authorids": "/37088996209;/37088506983;/37086933786;/37085384801;/38466367800;/37088996209;/37088506983;/37086933786;/37085384801;/38466367800",
        "aff": "University of Tech-nology Sydney, Ultimo, NSW, Australia; University of Tech-nology Sydney, Ultimo, NSW, Australia; University of Tech-nology Sydney, Ultimo, NSW, Australia; University of Tech-nology Sydney, Ultimo, NSW, Australia; University of Tech-nology Sydney, Ultimo, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812375/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7890192888032770251&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Ultimo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9812267",
        "title": "Informative Planning in the Presence of Outliers",
        "track": "main",
        "status": "Poster",
        "abstract": "Informative planning seeks a sequence of actions that guide the robot to collect the most informative data to build a large-scale environmental model or learn a dynamical system. Existing work in informative planning mainly focuses on proposing new planners and applying them to various robotic applications such as environmental monitoring, autonomous exploration, and system identification. The informative planners optimize an objective given by a probabilistic model, e.g., Gaussian process regression (GPR). In practice, the ubiquitous sensing outliers can easily affect the model, resulting in a misleading objective. A straightforward solution is to filter out the outliers in the sensing data stream using an off-the-shelf outlier detector. However, informative samples are also scarce by definition so they might be falsely filtered out. In this paper, we propose a method to enable the robot to re-visit the locations where outliers were sampled besides optimizing the informative planning objective. The robot can collect more samples in the vicinity of outliers and update the outlier detector to reduce the number of false alarms. We achieve this by designing a new objective for the Pareto Monte Carlo tree search (MCTS). We demonstrate that the proposed framework performs better than applying an outlier detector naively.",
        "primary_area": "",
        "author": "Weizhe Chen;Lantao Liu;Weizhe Chen;Lantao Liu",
        "authorids": "/37087246657;/37085785167;/37087246657;/37085785167",
        "aff": "Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812267/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15948211388823592532&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indiana University",
        "aff_unique_dep": "Luddy School of Informatics, Computing, and Engineering",
        "aff_unique_url": "https://www.indiana.edu",
        "aff_unique_abbr": "IU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bloomington",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812389",
        "title": "Infrastructure-Enabled Autonomy: An Attention Mechanism for Occlusion Handling",
        "track": "main",
        "status": "Poster",
        "abstract": "Although there has been tremendous progress in autonomous driving, navigating environments and predicting the behavior of other drivers in the presence of occlusions remains challenging. Cities have started investing in infrastructure sensors that could provide information about occluded spaces. We propose a framework that integrates infrastructure-to-vehicle communication in autonomous vehicle decision making, improving operational safety and mobility in challenging environments. By framing the problem as a partially observable Markov decision process in which querying an infrastructure sensor is a data-gathering action, we reduce the computational complexity associated with sensor processing while maintaining equivalent performance compared to an omniscient actor and demonstrate the value of infrastructure communication through a series of experiments.",
        "primary_area": "",
        "author": "Victoria Magdalena Dax;Mykel J. Kochenderfer;Ransalu Senanayake;Umair Ibrahim;Victoria Magdalena Dax;Mykel J. Kochenderfer;Ransalu Senanayake;Umair Ibrahim",
        "authorids": "/37089446777;/37596929200;/38490726500;/37089449769;/37089446777;/37596929200;/38490726500;/37089449769",
        "aff": "Stanford Intelligent Systems Laboratory, Stanford University; Stanford Intelligent Systems Laboratory, Stanford University; Stanford Intelligent Systems Laboratory, Stanford University; Ford Motor Company",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812389/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14711750958833462139&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Stanford University;Ford Motor Company",
        "aff_unique_dep": "Intelligent Systems Laboratory;",
        "aff_unique_url": "https://www.stanford.edu;https://www.ford.com",
        "aff_unique_abbr": "Stanford;Ford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811798",
        "title": "InsertionNet 2.0: Minimal Contact Multi-Step Insertion Using Multimodal Multiview Sensory Input",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of devising the means for a robot to rapidly and safely learn insertion skills with just a few human interventions and without hand-crafted rewards or demonstrations. Our InsertionNet version 2.0 provides an improved technique to robustly cope with a wide range of use-cases featuring different shapes, colors, initial poses, etc. In particular, we present a regression-based method based on multimodal input from stereo perception and force, augmented with contrastive learning for the efficient learning of valuable features. In addition, we introduce a one-shot learning technique for insertion, which relies on a relation network scheme to better exploit the collected data and to support multi-step insertion tasks. Our method improves on the results obtained with the original InsertionNet, achieving an almost perfect score (above 97.5% on 200 trials) in 16 real-life insertion tasks while minimizing the execution time and contact during insertion. We further demonstrate our method's ability to tackle a real-life 3-step insertion task and perfectly solve an unseen insertion task without learning.",
        "primary_area": "",
        "author": "Oren Spector;Vladimir Tchuiev;Dotan Di Castro;Oren Spector;Vladimir Tchuiev;Dotan Di Castro",
        "authorids": "/37088872507;/37086447716;/37062208100;/37088872507;/37086447716;/37062208100",
        "aff": "Bosch Center for Artificial Inteligence, Haifa, Israel; Bosch Center for Artificial Inteligence, Haifa, Israel; Bosch Center for Artificial Inteligence, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811798/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3554703006208880541&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence",
        "aff_unique_dep": "Artificial Intelligence",
        "aff_unique_url": "https://www.bosch-ai.com",
        "aff_unique_abbr": "BCAI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9811366",
        "title": "Inside LineRanger: Mechanism Design to Optimize Operation and Performances of Powerline Inspection Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Even if UAVs undoubtedly had a profound effect on the visual inspection capabilities of transmission lines, rolling robots, especially for bundled configurations, will still play an extensive role in the maintenance of these strategic assets. As such, LineRanger is among the most efficient and capable wheeled platform, that can travel at an average speed of 8 km/h. In this paper, LineRanger mechanical design insights are shared, unfolding how strictly mechanical solutions deals with ease of obstacle crossing, ease of installation procedure without requiring any linemen to access the high voltage environment area, and ease of deployment of dedicated, custom-made sensors onto the line component of interest. This novel robotic platform is now being deployed onto Hydro-Quebec power grid network, performing high value applications.",
        "primary_area": "",
        "author": "Pierre-Luc Richard;Fran\u00e7ois Morin;Marco Lepage;Philippe Hamelin;Ghislain Lambert;Alex Sartor;Camille H\u00e9bert;Nicolas Pouliot;Pierre-Luc Richard;Fran\u00e7ois Morin;Marco Lepage;Philippe Hamelin;Ghislain Lambert;Alex Sartor;Camille H\u00e9bert;Nicolas Pouliot",
        "authorids": "/37590423100;/38343678400;/38564940400;/37605037100;/37601415800;/37086934271;/37088504524;/37299751800;/37590423100;/38343678400;/38564940400;/37605037100;/37601415800;/37086934271;/37088504524;/37299751800",
        "aff": "Hydro-Qu\u00e9bec's research institute (IREQ), Varennes, CANADA; Hydro-Qu\u00e9bec's research institute (IREQ), Varennes, CANADA; Hydro-Qu\u00e9bec's research institute (IREQ), Varennes, CANADA; Hydro-Qu\u00e9bec's research institute (IREQ), Varennes, CANADA; Hydro-Qu\u00e9bec's research institute (IREQ), Varennes, CANADA; Hydro-Qu\u00e9bec's research institute (IREQ), Varennes, CANADA; Hydro-Qu\u00e9bec's research institute (IREQ), Varennes, CANADA; Hydro-Qu\u00e9bec's research institute (IREQ), Varennes, CANADA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811366/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5562145140483930845&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Hydro-Qu\u00e9bec",
        "aff_unique_dep": "research institute (IREQ)",
        "aff_unique_url": "https://www.hydroquebec.com/",
        "aff_unique_abbr": "HQ",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Varennes",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9811741",
        "title": "Instinctive Real-time sEMG-based Control of Prosthetic Hand with Reduced Data Acquisition and Embedded Deep Learning Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Achieving instinctive multi-grasp control of prosthetic hands typically still requires a large number of sensors, such as electromyography (EMG) electrodes mounted on a residual limb, that can be costly and time consuming to position, with their signals difficult to classify. Deep-learning-based EMG classifiers however have shown promising results over traditional methods, yet due to high computational requirements, limited work has been done with in-prosthetic training. By targeting specific muscles non-invasively, separating grasping action into hold and release states, and implementing data augmentation, we show in this paper that accurate results for embedded, instinctive, multi-grasp control can be achieved with only 2 low-cost sensors, a simple neural network, and minimal amount of training data. The presented controller, which is based on only 2 surface EMG (sEMG) channels, is implemented in an enhanced version of the OLYMPIC prosthetic hand. Results demonstrate that the controller is capable of identifying all 7 specified grasps and gestures with 93% accuracy, and is successful in achieving several real-life tasks in a real world setting.",
        "primary_area": "",
        "author": "Zeyu Yang;Angus B. Clark;Digby Chappell;Nicolas Rojas;Zeyu Yang;Angus B. Clark;Digby Chappell;Nicolas Rojas",
        "authorids": "/37089318125;/37086808936;/37088691283;/37990657400;/37089318125;/37086808936;/37088691283;/37990657400",
        "aff": "REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811741/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=577124386335968768&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dyson School of Design Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812338",
        "title": "Insulator Aiming Using Multi-Feature Fusion-Based Visual Servo Control for Washing Drone",
        "track": "main",
        "status": "Poster",
        "abstract": "Insulator visual aiming is difficult for washing drone due to the complex washing environment, strong dis-turbance, lack of debugging environment, and other factors. Conventional visual servo control methods often fail to consider these complex factors adequately and fall short in reliable insulator visual aiming. To address these problems, we propose a novel multi-feature fusion-based drone visual servo control method for accurate insulator visual aiming. A multi-feature fusion neural network (MFFNet) is proposed to map the dif-ferent input modalities into an embedding space spanned by the learned deep features. Suitable control commands are generated by the simple combination of learned deep features. These deep features represent the intrinsic structural properties of the insulator and the motion pattern of the drones. Particularly, our method is trained purely in simulation and transferred to a real drone directly. Moreover, accurate visual aiming is guaranteed even in strong disturbance environments. Simulation and experimental results verify the high accurate insulator aiming, anti-disturbance, and sim-to-real transfer capabilities of the proposed method. Video: https://youtu.be/Ptlajzvp46A.",
        "primary_area": "",
        "author": "Jian Di;Shaofeng Chen;Xinghu Wang;Hepeng Zhang;Haibo Ji;Jian Di;Shaofeng Chen;Xinghu Wang;Hepeng Zhang;Haibo Ji",
        "authorids": "/37089178519;/37086605637;/37077730100;/37089449362;/37398694500;/37089178519;/37086605637;/37077730100;/37089449362;/37398694500",
        "aff": "Department of Automation, University of Science and Technology of China; Department of Automation, University of Science and Technology of China; Department of Automation, University of Science and Technology of China; Department of Automation, University of Science and Technology of China; Department of Automation, University of Science and Technology of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812338/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9173396445035704325&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811815",
        "title": "Integrated Learning of Robot Motion and Sentences: Real-Time Prediction of Grasping Motion and Attention based on Language Instructions",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a motion generation model that can achieve robust behavior against environmental changes based on language instructions at a low cost. Conventional robots that communicate with humans use a restricted environment and language to build up a mapping between language and motion, and thus need to prepare a huge training set in order to achieve versatility. Our method trains pairs of language, visual, and motor information of the robot, and generates motions in real-time based on the \u201cattention\u201d of the language instructions. Specifically, the robot generates motions while focusing on the indicated objects by the human when multiple objects are in the field of view. In addition, since position recognition and motion generation of the indicated object are performed in real-time, robust motion generation is possible in response to changes in the object position and lighting conditions. We clarified that features related to the object name and its location are self-organized in the latent (PB: Parametric Bias) space by end-to-end learning of robot motion and sentences. These observations may indicate the importance of integrated learning of robot motion and sentences since such feature representations cannot be obtained by learning motions alone.",
        "primary_area": "",
        "author": "Hiroshi Ito;Hideyuki Ichiwara;Kenjiro Yamamoto;Hiroki Mori;Tetsuya Ogata;Hiroshi Ito;Hideyuki Ichiwara;Kenjiro Yamamoto;Hiroki Mori;Tetsuya Ogata",
        "authorids": "/37088235935;/37089449817;/38127848300;/37086432927;/37273829100;/37088235935;/37089449817;/38127848300;/37086432927;/37273829100",
        "aff": "Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Center for Technology Innovation - Controls and Robotics, Research & Development Group, Hitachi, Ltd., Ibaraki, Japan; Center for Technology Innovation - Controls and Robotics, Research & Development Group, Hitachi, Ltd., Ibaraki, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811815/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1508048015628093810&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Waseda University;Hitachi, Ltd.",
        "aff_unique_dep": "Department of Intermedia Art and Science;Center for Technology Innovation - Controls and Robotics, Research & Development Group",
        "aff_unique_url": "https://www.waseda.jp/top;https://www.hitachi.com",
        "aff_unique_abbr": "Waseda;Hitachi",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Tokyo;Ibaraki",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811861",
        "title": "Integrating Deep Reinforcement and Supervised Learning to Expedite Indoor Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "The challenge of mapping indoor environments is addressed. Typical heuristic algorithms for solving the motion planning problem are frontier-based methods, that are especially effective when the environment is completely unknown. However, in cases where prior statistical data on the environment's architectonic features is available, such algorithms can be far from optimal. Furthermore, their calculation time may increase substantially as more areas are exposed. In this paper we propose two means by which to overcome these shortcomings. One is the use of deep reinforcement learning to train the motion planner. The second is the inclusion of a pre-trained generative deep neural network, acting as a map predictor. Each one helps to improve the decision making through use of the learned structural statistics of the environment, and both, being realized as neural networks, ensure a constant calculation time. We show that combining the two methods can shorten the duration of the mapping process by up to 4 times, compared to frontier-based motion planning.",
        "primary_area": "",
        "author": "Elchanan Zwecher;Eran Iceland;Sean R. Levy;Shmuel Y. Hayoun;Oren Gal;Ariel Barel;Elchanan Zwecher;Eran Iceland;Sean R. Levy;Shmuel Y. Hayoun;Oren Gal;Ariel Barel",
        "authorids": "/37660806400;/38286945200;/37089448381;/37085685331;/37577144200;/37089449460;/37660806400;/38286945200;/37089448381;/37085685331;/37577144200;/37089449460",
        "aff": "Computer Science Department, Hebrew University of Jerusalem, Jerusalem, Israel; Computer Science Department, Hebrew University of Jerusalem, Jerusalem, Israel; Faculty of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, Israel; Faculty of Aerospace Engineering, Technion - Israel Institute of Technology, Haifa, Israel; Geo-information Department, Technion - Israel Institute of Technology, Haifa, Israel; Ariel Barel is an academic visitor at the Computer Science Department, Technion - Israel Institute of Technology, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811861/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7948962664012430836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;1",
        "aff_unique_norm": "Hebrew University of Jerusalem;Technion - Israel Institute of Technology",
        "aff_unique_dep": "Computer Science Department;Faculty of Aerospace Engineering",
        "aff_unique_url": "http://www.huji.ac.il;https://www.technion.ac.il",
        "aff_unique_abbr": "HUJI;Technion",
        "aff_campus_unique_index": "0;0;1;1;1;1",
        "aff_campus_unique": "Jerusalem;Haifa",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9811641",
        "title": "Integrating Point and Line Features for Visual-Inertial Initialization",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and robust initialization is crucial in visual-inertial system, which significantly affects the localization accuracy. Most of the existing feature-based initialization methods rely on point features to estimate initial parameters. However, the performance of these methods often decreases in real scene, as point features are unstable and may be discontinuously observed especially in low textured environments. By contrast, line features, providing richer geometrical information than points, are also very common in man-made buildings. Thereby, in this paper, we propose a novel visual-inertial initialization method integrating both point and line features. Specifically, a closed-form method of line features is presented for initialization, which is combined with point-based method to build an integrated linear system. Parameters including initial velocity, gravity, point depth and line's endpoints depth can be jointly solved out. Furthermore, to refine these parameters, a global optimization method is proposed, which consists of two novel nonlinear least squares problems for respective points and lines. Both gravity magnitude and gyroscope bias are considered in refinement. Extensive experimental results on both simulated and public datasets show that integrating point and line features in initialization stage can achieve higher accuracy and better robustness compared with pure point-based methods.",
        "primary_area": "",
        "author": "Hong Liu;Junyin Qiu;Weibo Huang;Hong Liu;Junyin Qiu;Weibo Huang",
        "authorids": "/37279504000;/37089448588;/37086454085;/37279504000;/37089448588;/37086454085",
        "aff": "Key Laboratory of Machine Perception, Peking University, Shenzhen Graduate School; Key Laboratory of Machine Perception, Peking University, Shenzhen Graduate School; Key Laboratory of Machine Perception, Peking University, Shenzhen Graduate School",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811641/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16931094024541577469&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Peking University",
        "aff_unique_dep": "Key Laboratory of Machine Perception",
        "aff_unique_url": "http://www.pku.edu.cn",
        "aff_unique_abbr": "PKU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen Graduate School",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811813",
        "title": "Interactive Human-in-the-loop Coordination of Manipulation Skills Learned from Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from demonstration (LfD) provides a fast, intuitive and efficient framework to program robot skills, which has gained growing interest both in research and industrial applications. Most complex manipulation tasks are long-term and involve a set of skill primitives. Thus it is crucial to have a reliable coordination scheme that selects the correct sequence of skill primitive and the correct parameters for each skill, under various scenarios. Instead of relying on a precise simulator, this work proposes a human-in-the-loop coordination framework for LfD skills that: builds parameterized skill models from kinesthetic demonstrations; constructs a geometric task network (GTN) on-the-fly from human instructions; learns a hierarchical control policy incrementally during execution. This framework can reduce significantly the manual design efforts, while improving the adaptability to new scenes. We show on a 7-DoF robotic manipulator that the proposed approach can teach complex industrial tasks such as bin sorting and assembly in less than 30 minutes.",
        "primary_area": "",
        "author": "Meng Guo;Mathias B\u00fcrger;Meng Guo;Mathias B\u00fcrger",
        "authorids": "/38237113400;/37528853600;/38237113400;/37528853600",
        "aff": "College of Engineering, Peking University, China; Bosch Center for Artificial Intelligence (BCAI), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811813/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4490157144363344450&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Peking University;Bosch Center for Artificial Intelligence",
        "aff_unique_dep": "College of Engineering;Artificial Intelligence",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.bosch-ai.com",
        "aff_unique_abbr": "Peking U;BCAI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "9812360",
        "title": "Interactive Robotic Grasping with Attribute-Guided Disambiguation",
        "track": "main",
        "status": "Poster",
        "abstract": "Interactive robotic grasping using natural language is one of the most fundamental tasks in human-robot interaction. However, language can be a source of ambiguity, particularly when there are ambiguous visual or linguistic contents. This paper investigates the use of object attributes in disambiguation and develops an interactive grasping system capable of effectively resolving ambiguities via dialogues. Our approach first predicts target scores and attribute scores through vision-and-language grounding. To handle ambiguous objects and commands, we propose an attribute-guided formulation of the partially observable Markov decision process (Attr-POMDP) for disambiguation. The Attr-POMDP utilizes target and attribute scores as the observation model to calculate the expected return of an attribute-based (e.g., \u201cwhat is the color of the target, red or green?\u201d) or a pointing-based (e.g., \u201cdo you mean this one?\u201d) question. Our disambiguation module runs in real time on a real robot, and the interactive grasping system achieves a 91.43 % selection accuracy in the real-robot experiments, outperforming several baselines by large margins. Supplementary material is available at https://sites.google.com/umn.eduJattr-disam.",
        "primary_area": "",
        "author": "Yang Yang;Xibai Lou;Changhyun Choi;Yang Yang;Xibai Lou;Changhyun Choi",
        "authorids": "/37088070512;/37088504165;/37085811337;/37088070512;/37088504165;/37085811337",
        "aff": "University of Minnesota, Minneapolis, USA; University of Minnesota, Minneapolis, USA; University of Minnesota, Minneapolis, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812360/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13953886019874334636&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.minnesota.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812132",
        "title": "Interleaving Monte Carlo Tree Search and Self-Supervised Learning for Object Retrieval in Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, working with the task of object retrieval in clutter, we have developed a robot learning framework in which Monte Carlo Tree Search (MCTS) is first applied to enable a Deep Neural Network (DNN) to learn the intricate interactions between a robot arm and a complex scene containing many objects, allowing the DNN to partially clone the behavior of MCTS. In turn, the trained DNN is integrated into MCTS to help guide its search effort. We call this approach learning-guided Monte Carlo tree search for Object REtrieval (MORE), which delivers significant computational efficiency gains and added solution optimality. MORE is a self-supervised robotics framework/pipeline capable of working in the real world that successfully embodies the System 2 \u2192 System 1 learning philosophy proposed by Kahneman, where learned knowledge, used properly, can help greatly speed up a time-consuming decision process over time. Videos and supplementary material can be found at https://github.com/arc-l/more.",
        "primary_area": "",
        "author": "Baichuan Huang;Teng Guo;Abdeslam Boularias;Jingjin Yu;Baichuan Huang;Teng Guo;Abdeslam Boularias;Jingjin Yu",
        "authorids": "/37088981654;/37088998158;/37542596800;/37536570700;/37088981654;/37088998158;/37542596800;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812132/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1419878514166323130&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812425",
        "title": "Interval-based Visual-Inertial LiDAR SLAM with Anchoring Poses",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel interval-based visual-inertial LiDAR SLAM (i-VIL SLAM) method that solely assumes sensor errors to be bounded and propagates the error from the input sources to the estimated map and trajectory using interval analysis. The method allows us to restrict the solution set of the robot poses and the position of the landmarks to the set that is consistent with the measurements. If the error limits are not violated, it is guaranteed that the estimated set contains the true solution. The accumulation of the uncertainty is stabilized by anchoring poses derived from GNSS/INS data. Furthermore, for the first time we compare confidence ellipses determined by a classical SLAM graph optimization approach with the interval estimates of the robot poses provided by our method. In this work, we experimentally show that the marginal co-variances computed by the classical SLAM graph optimization are too overconfident and underestimate the uncertainty of the poses. While the 99.9 %-ellipsoids derived from the marginal covariances of the poses only enclose less than 64 % of the ground truth in the worst case, our method provides interval bounds for the pose parameters that enclose the ground truth for more than 96 % of all frames.",
        "primary_area": "",
        "author": "Aaronkumar Ehambram;Raphael Voges;Claus Brenner;Bernardo Wagner;Aaronkumar Ehambram;Raphael Voges;Claus Brenner;Bernardo Wagner",
        "authorids": "/37088584902;/37086577673;/38070386300;/37276784800;/37088584902;/37086577673;/38070386300;/37276784800",
        "aff": "Real Time Systems Group (RTS), Institute for Systems Engineering, Leibniz University Hannover, Hannover, Germany; Real Time Systems Group (RTS), Institute for Systems Engineering, Leibniz University Hannover, Hannover, Germany; Institute of Cartography and Geoinformat-ics (IKG), Leibniz Unversit\u00e4t Hannover, Hannover, Germany; Real Time Systems Group (RTS), Institute for Systems Engineering, Leibniz University Hannover, Hannover, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812425/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18408932283866083942&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Leibniz University Hannover;Leibniz Universit\u00e4t Hannover",
        "aff_unique_dep": "Institute for Systems Engineering;Institute of Cartography and Geoinformatics (IKG)",
        "aff_unique_url": "https://www.leibniz.uni-hannover.de;https://www.leibniz-uni-hannover.de",
        "aff_unique_abbr": ";LUH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hannover",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812213",
        "title": "Intrinsically Motivated Self-supervised Learning in Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In vision-based reinforcement learning (RL) tasks, it is prevalent to assign auxiliary tasks with a surrogate self-supervised loss so as to obtain more semantic representations and improve sample efficiency. However, abundant information in self-supervised auxiliary tasks has been disregarded, since the representation learning part and the decision-making part are separated. To sufficiently utilize information in auxiliary tasks, we present a simple yet effective idea to employ self-supervised loss as an intrinsic reward, called Intrinsically Motivated Self-Supervised learning in Reinforcement learning (IM-SSR). We formally show that the self-supervised loss can be decomposed as exploration for novel states and robustness improvement from nuisance elimination. IM-SSR can be effortlessly plugged into any reinforcement learning with self-supervised auxiliary objectives with nearly no additional cost. Combined with IM-SSR, the previous underlying algorithms achieve salient improvements on both sample efficiency and generalization in various vision-based robotics tasks from the DeepMind Control Suite, especially when the reward signal is sparse.",
        "primary_area": "",
        "author": "Yue Zhao;Chenzhuang Du;Hang Zhao;Tiejun Li;Yue Zhao;Chenzhuang Du;Hang Zhao;Tiejun Li",
        "authorids": "/37089451016;/37089449346;/37086232492;/37088356666;/37089451016;/37089449346;/37086232492;/37088356666",
        "aff": "Peking University, Haidian, Beijing, China; Tsinghua University, Haidian, Beijing, China; Tsinghua University, Haidian, Beijing, China; Peking University, Haidian, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812213/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6671056740130061089&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Peking University;Tsinghua University",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Peking U;THU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Haidian",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811843",
        "title": "Introducing RH5 Manus: A Powerful Humanoid Upper Body Design for Dynamic Movements",
        "track": "main",
        "status": "Poster",
        "abstract": "It is well established that a stiff structure along with an optimal mass distribution are key features to perform dynamic movements, and parallel designs provide these characteristics to a robot. This work presents the new upper-body design of the humanoid robot RH5 named RH5 Manus with series-parallel hybrid design. The new design choices allow us to perform dynamic motions including tasks that involve a payload of 4 kg in each hand and fast boxing motions. The parallel kinematics combined with an overall serial chain of the robot provides us with high force production along with a larger range of motion and low peripheral inertia. The robot is equipped with backdrivable actuators with current sensing, force-torque sensors, stereo camera, laser scanners, high-resolution encoders etc that provide interaction with operators and environment. We generate several diverse dynamic motions using trajectory optimization, and successfully execute them on the robot with accurate trajectory and velocity tracking, while respecting joint rotation, velocity, and torque limits.",
        "primary_area": "",
        "author": "Melya Boukheddimi;Shivesh Kumar;Heiner Peters;Dennis Mronga;Rohan Budhiraja;Frank Kirchner;Melya Boukheddimi;Shivesh Kumar;Heiner Peters;Dennis Mronga;Rohan Budhiraja;Frank Kirchner",
        "authorids": "/37087244433;/37085850436;/37085587031;/37592491000;/37086291965;/37283559600;/37087244433;/37085850436;/37085587031;/37592491000;/37086291965;/37283559600",
        "aff": "Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Robotics Innovation Center, DFKI GmbH, Bremen, Germany; D\u00e9partement d'informatique, ENS, Paris, France; AG Robotik University of Bremen, Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811843/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8156300208709671933&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "DFKI GmbH;\u00c9cole Normale Sup\u00e9rieure;University of Bremen",
        "aff_unique_dep": "Robotics Innovation Center;D\u00e9partement d'informatique;AG Robotik",
        "aff_unique_url": "https://www.dfki.de;https://www.ens.fr;https://www.uni-bremen.de",
        "aff_unique_abbr": "DFKI;ENS;",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Bremen;Paris",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Germany;France"
    },
    {
        "id": "9811900",
        "title": "Intrusion Distance and Reaction Time Estimation for Safe and Efficient Industrial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Circular economy and agile manufacturing require a safe and efficient industrial robot system working in close human proximity. Although, close proximity local sensing enables safe collaboration with small cobots. However, they cannot ensure safety at high velocities with a heavy-duty industrial robot. Stereo-camera and 3D LiDAR-based touch-less global sensing methods exist, but they do not address the safety standards. This work proposes a novel method for estimating the safety parameters in speed and separation monitoring mode for 3D vision sensors. Accurate estimation of these parameters ensures compact sensing zones. Thus, enabling efficient human-robot collaboration for permanent operator presence. The method requires less effort in setup. The developed software with a graphical user interface enables workers from wide technical expertise to perform safety measurements at a precision of \u00b115ms in reaction time estimation. The experiments are repeatable and capture the statistical data for low error in estimation. The estimated parameters for two exemplary 3D sensors enable a human to work in close proximity of 20 cm while enabling safety from a collision.",
        "primary_area": "",
        "author": "Aquib Rashid;Ibrahim Al Naser;Shuxiao Hou;Mohamad Bdiwi;Matthias Putz;Steffen Ihlenfeldt;Aquib Rashid;Ibrahim Al Naser;Shuxiao Hou;Mohamad Bdiwi;Matthias Putz;Steffen Ihlenfeldt",
        "authorids": "/37085809825;/37085782662;/37088908637;/37946592100;/38467170500;/37088523444;/37085809825;/37085782662;/37088908637;/37946592100;/38467170500;/37088523444",
        "aff": "Fraunhofer IWU and is the main; Fraunhofer IWU and is the main; Fraunhofer IWU and is the main; Fraunhofer IWU and is the main; Fraunhofer IWU and is the main; Fraunhofer IWU and is the main",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811900/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2652303648592467811&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Fraunhofer IWU",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iwu.fraunhofer.de/",
        "aff_unique_abbr": "IWU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812431",
        "title": "Is it Worth to Reason about Uncertainty in Occupancy Grid Maps during Path Planning?",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates the usefulness of reasoning about the uncertain presence of obstacles during path planning, which typically stems from the usage of probabilistic occupancy grid maps for representing the environment when mapping via a noisy sensor like a stereo camera. The traditional planning paradigm prescribes using a hard threshold on the occupancy probability to declare that a cell is an obstacle, and to plan a single path accordingly while treating unknown space as free. We compare this approach against a new uncertainty-aware planner, which plans two different path hypotheses and then merges their initial trajectory segments into a single one ending in a \u201cnext-best view\u201d pose. After this informative view is taken, the planner commits to one of the hypotheses, or to a completely new one if a collision is imminent. Simulations were conducted comparing the proposed and traditional planner. Results show the existence of planning scenarios -like when the environment contains a dead-end, or when the goal is placed close to an obstacle- in which reasoning about uncertainty can significantly decrease the robot's traveled distance and increase the chances of reaching the goal. The new planner was also validated on a real Clearpath Jackal robot equipped with a ZED 2 stereo camera.",
        "primary_area": "",
        "author": "Jacopo Banfi;Lindsey Woo;Mark Campbell;Jacopo Banfi;Lindsey Woo;Mark Campbell",
        "authorids": "/37085491416;/37089447679;/37272971700;/37085491416;/37089447679;/37272971700",
        "aff": "CSAIL, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812431/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4669424878138974976&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Cornell University",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Sibley School of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.cornell.edu",
        "aff_unique_abbr": "MIT;Cornell",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Cambridge;Ithaca",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812116",
        "title": "Iterative Mesh Modification Planning: A new Method for Automatic Disassembly Planning of Complex Industrial Components",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic disassembly planning for complex industrial products like vehicles checks the expandability of components already at early stages of design. For a fast computation of collision-free disassembly paths, sampling-based rigid body motion planning is used in the literature. However, in real-world scenarios there are circumstances that prevent the finding of plausible collision-free disassembly paths with these conventional motion planners. The most difficult problem is that many components have deformable fastening elements that are modeled in a relaxed state and often as a part of the rigid object. The fastening elements cause unavoidable collisions of the component with its environment along the actual disassembly path. In this paper, we present Iterative Mesh Modification Planning (IMMP). Given the information about fastening elements in advance, our method applies a controlled iterative process of geometric deformations and planning attempts to the component to be disassembled. With this process, we are able to disassemble the component from its installed position with a conventional rigid body motion planner taking fastening elements and also overpressure into account. We demonstrate the effectiveness of our method on real-world planning scenarios from the automotive industry.",
        "primary_area": "",
        "author": "Robert Hegewald;Nicola Wolpert;Elmar Sch\u00f6mer;Robert Hegewald;Nicola Wolpert;Elmar Sch\u00f6mer",
        "authorids": "/37088998118;/37085352554;/37331462600;/37088998118;/37085352554;/37331462600",
        "aff": "Digital Factory Body in White & Validation, Mercedes-Benz AG, Germany; Department: Geomatics, Computer Science and Mathematics, Stuttgart University of Applied Science, Germany; Department: Physics, Mathematics and Computer Science, Johannes Gutenberg - University Mainz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812116/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3311926696348560303&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Mercedes-Benz AG;Stuttgart University of Applied Science;Johannes Gutenberg University Mainz",
        "aff_unique_dep": "Digital Factory Body in White & Validation;Department of Geomatics, Computer Science and Mathematics;Department of Physics, Mathematics and Computer Science",
        "aff_unique_url": "https://www.mercedes-benz.com;https://www.hft-stuttgart.de;https://www.jgu.de",
        "aff_unique_abbr": "MBAG;;JGU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mainz",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811975",
        "title": "JST: Joint Self-training for Unsupervised Domain Adaptation on 2D&3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "2D&3D object detection always suffers from a dramatic performance drop when transferring the model trained in the source domain to the target domain due to various domain shifts. In this paper, we propose a Joint Self-Training (JST) framework to improve 2D image and 3D point cloud detectors with aligned outputs simultaneously during the transferring. The proposed framework contains three novelties to overcome object biases and unstable self-training processes: 1) an anchor scaling scheme is developed to efficiently eliminate the object size biases without any modification on point clouds; 2) a 2D&3D bounding box alignment method is proposed to generate high-quality pseudo labels for the self-training process; 3) a model smoothing based training strategy is developed to reduce the training oscillation properly. Experiment results show that the proposed approach improves the performance of 2D and 3D detectors in the target domain simultaneously; especially the superior accuracy of 3D detection can be achieved on benchmark datasets over the state-of-the-art methods.",
        "primary_area": "",
        "author": "Guangyao Ding;Meiying Zhang;E Li;Qi Hao;Guangyao Ding;Meiying Zhang;E Li;Qi Hao",
        "authorids": "/37089448988;/37089447788;/37088753335;/37403530000;/37089448988;/37089447788;/37088753335;/37403530000",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Research Institute of-Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811975/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4812423217356342207&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812155",
        "title": "Jerk Constrained Velocity Planning for an Autonomous Vehicle: Linear Programming Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Velocity Planning for self-driving vehicles in a complex environment is one of the most challenging tasks. It must satisfy the following three requirements: safety with regards to collisions; respect of the maximum velocity limits defined by the traffic rules; comfort of the passengers. In order to achieve these goals, the jerk and dynamic objects should be considered, however, it makes the problem as complex as a non-convex optimization problem. In this paper, we propose a linear programming (LP) based velocity planning method with jerk limit and obstacle avoidance constraints for an autonomous driving system. To confirm the efficiency of the proposed method, a comparison is made with several optimization-based approaches, and we show that our method can generate a velocity profile which satisfies the aforementioned requirements more efficiently than the compared methods. In addition, we tested our algorithm on a real vehicle at a test field to validate the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Yutaka Shimizu;Takamasa Horibe;Fumiya Watanabe;Shinpei Kato;Yutaka Shimizu;Takamasa Horibe;Fumiya Watanabe;Shinpei Kato",
        "authorids": "/37089197396;/37089610751;/37089610395;/37537228700;/37089197396;/37089610751;/37089610395;/37537228700",
        "aff": "Tier IV, Inc., Tokyo, Japan; Tier IV, Inc., Tokyo, Japan; Tier IV, Inc., Tokyo, Japan; Tier IV, Inc., Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812155/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1251003436251652340&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "TIER IV, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tier-iv.com",
        "aff_unique_abbr": "Tier IV",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812261",
        "title": "Joint Communication and Motion Planning for Cobots",
        "track": "main",
        "status": "Poster",
        "abstract": "The increasing deployment of robots in co-working scenarios with humans has revealed complex safety and efficiency challenges in the computation of the robot behavior. Movement among humans is one of the most fundamental \u2014and yet critical\u2014problems in this frontier. While several approaches have addressed this problem from a purely navigational point of view, the absence of a unified paradigm for communicating with humans limits their ability to prevent deadlocks and compute feasible solutions. This paper presents a joint communication and motion planning framework that selects from an arbitrary input set of robot's communication signals while computing robot motion plans. It models a human co-worker's imperfect perception of these communications using a noisy sensor model and facilitates the specification of a variety of social/workplace compliance priorities with a flexible cost function. Theoretical results and simulator-based empirical evaluations show that our approach efficiently computes motion plans and communication strategies that reduce conflicts between agents and resolve potential deadlocks.",
        "primary_area": "",
        "author": "Mehdi Dadvar;Keyvan Majd;Elena Oikonomou;Georgios Fainekos;Siddharth Srivastava;Mehdi Dadvar;Keyvan Majd;Elena Oikonomou;Georgios Fainekos;Siddharth Srivastava",
        "authorids": "/37089449463;/37086487572;/37089450757;/38529834400;/37086427654;/37089449463;/37086487572;/37089450757;/38529834400;/37086427654",
        "aff": "School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ, USA; School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ, USA; School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ, USA; School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ, USA; School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812261/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7872573480098789820&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of Computing and Augmented Intelligence",
        "aff_unique_url": "https://asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811636",
        "title": "Joint State and Input Estimation of Agent Based on Recursive Kalman Filter Given Prior Knowledge",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern autonomous systems are purposed for many challenging scenarios, where agents will face unexpected events and complicated tasks. The presence of disturbance noise with control command and unknown inputs can negatively impact robot performance. Previous research of joint input and state estimation separately studied the continuous and discrete cases without any prior information. This paper combines the continuous and discrete input cases into a unified theory based on the Expectation-Maximum (EM) algorithm. By introducing prior knowledge of events as the constraint, inequality optimization problems are formulated to determine a gain matrix or dynamic weights to realize an optimal input estimation with lower variance and more accurate decision-making. Finally, statistical results from experiments show that our algorithm owns 81% improvement of the variance than KF and 47% improvement than RKF in continuous space; a remarkable improvement of right decision-making probability of our input estimator in discrete space, identification ability is also analyzed by experiments.",
        "primary_area": "",
        "author": "Zida Wu;Zhaoliang Zheng;Ankur Mehta;Zida Wu;Zhaoliang Zheng;Ankur Mehta",
        "authorids": "/37089449125;/37089449533;/37086302574;/37089449125;/37089449533;/37086302574",
        "aff": "Department of Electrical and Computer Engineering, University of California Los Angeles, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of California Los Angeles, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of California Los Angeles, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811636/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6318801279810751824&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812337",
        "title": "KEMP: Keyframe-Based Hierarchical End-to-End Deep Model for Long- Term Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting future trajectories of road agents is a critical task for autonomous driving. Recent goal-based trajectory prediction methods, such as DenseTNT and PECNet [1], [2], have shown good performance on prediction tasks on public datasets. However, they usually require complicated goal-selection algorithms and optimization. In this work, we propose KEMP, a hierarchical end-to-end deep learning framework for trajectory prediction. At the core of our framework is keyframe-based trajectory prediction, where keyframes are representative states that trace out the general direction of the trajectory. KEMP first predicts keyframes conditioned on the road con-text, and then fills in intermediate states conditioned on the keyframes and the road context. Under our general framework, goal-conditioned methods are special cases in which the number of keyframes equal to one. Unlike goal-conditioned methods, our keyframe predictor is learned automatically and does not require hand-crafted goal-selection algorithms. We evaluate our model on public benchmarks and our model ranked 1st on Waymo Open Motion Dataset Leaderboard (as of September 1, 2021).",
        "primary_area": "",
        "author": "Qiujing Lu;Weiqiao Han;Jeffrey Ling;Minfa Wang;Haoyu Chen;Balakrishnan Varadarajan;Paul Covington;Qiujing Lu;Weiqiao Han;Jeffrey Ling;Minfa Wang;Haoyu Chen;Balakrishnan Varadarajan;Paul Covington",
        "authorids": "/37087995172;/37089612796;/37089447633;/37089449631;/37089449639;/37089448894;/37089450261;/37087995172;/37089612796;/37089447633;/37089449631;/37089449639;/37089448894;/37089450261",
        "aff": "UCLA; MIT; Waymo; Waymo; Waymo; Waymo; Waymo",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812337/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14045595693387075523&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;2;2;2;2",
        "aff_unique_norm": "University of California, Los Angeles;Massachusetts Institute of Technology;Waymo",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ucla.edu;https://web.mit.edu;https://www.waymo.com",
        "aff_unique_abbr": "UCLA;MIT;Waymo",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811803",
        "title": "KHAOS: a Kinematic Human Aware Optimization-based System for Reactive Planning of Flying-Coworker",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of drones in human-populated areas is increasing day by day. Such robots flying in close proximity to humans and potentially interacting with them, as in object handover or delivery, need to carefully plan their navigation considering the presence of humans. We propose a humanaware 3D reactive planner based on stochastic optimization for drone navigation. Besides considering the kinematics constraints of the drone, we propose two criteria to produce socially acceptable trajectories. The first, called discomfort, considers the unease caused to the humans spatially close to fast-moving drones. The second, called visibility, promotes the drone's visibility for humans. We demonstrate the planner's performance and adaptability in various simulated experiments.",
        "primary_area": "",
        "author": "J\u00e9r\u00f4me Truc;Phani-Teja Singamaneni;Daniel Sidobre;Serena Ivaldi;Rachid Alami;J\u00e9r\u00f4me Truc;Phani-Teja Singamaneni;Daniel Sidobre;Serena Ivaldi;Rachid Alami",
        "authorids": "/37089449004;/37089448169;/37378284900;/38534379600;/37278643600;/37089449004;/37089448169;/37378284900;/38534379600;/37278643600",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, UPS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, UPS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, UPS, Toulouse, France; Inria, Universit\u00e9 de Lorraine, CNRS; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, UPS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811803/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15504252278410918445&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "LAAS-CNRS;INRIA",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.laas.fr/;https://www.inria.fr",
        "aff_unique_abbr": "LAAS-CNRS;Inria",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toulouse;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9811720",
        "title": "Keypoint-Based Category-Level Object Pose Tracking from an RGB Sequence with Uncertainty Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a single-stage, category-level 6-DoF pose estimation algorithm that simultaneously detects and tracks instances of objects within a known category. Our method takes as input the previous and current frame from a monocular RGB video, as well as predictions from the previous frame, to predict the bounding cuboid and 6- DoF pose (up to scale). Internally, a deep network predicts distributions over object keypoints (vertices of the bounding cuboid) in image coordinates, after which a novel probabilistic filtering process integrates across estimates before computing the final pose using PnP. Our framework allows the system to take previous uncertainties into consideration when predicting the current frame, resulting in predictions that are more accurate and stable than single frame methods. Extensive experiments show that our method outperforms existing approaches on the challenging Objectron benchmark of annotated object videos. We also demonstrate the usability of our work in an augmented reality setting.",
        "primary_area": "",
        "author": "Yunzhi Lin;Jonathan Tremblay;Stephen Tyree;Patricio A. Vela;Stan Birchfield;Yunzhi Lin;Jonathan Tremblay;Stephen Tyree;Patricio A. Vela;Stan Birchfield",
        "authorids": "/37088506366;/37086455314;/37074894100;/37329553400;/37371627300;/37088506366;/37086455314;/37074894100;/37329553400;/37371627300",
        "aff": "NVIDIA:; NVIDIA:; NVIDIA:; Georgia Institute of Technology; NVIDIA:",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811720/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5580278149904980492&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "NVIDIA;Georgia Institute of Technology",
        "aff_unique_dep": "NVIDIA Corporation;",
        "aff_unique_url": "https://www.nvidia.com;https://www.gatech.edu",
        "aff_unique_abbr": "NVIDIA;Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812430",
        "title": "Kinematic Structure Estimation of Arbitrary Articulated Rigid Objects for Event Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel method that estimates the Kinematic Structure (KS) of arbitrary articulated rigid objects from event-based data. Event cameras are emerging sensors that asynchronously report brightness changes with a time resolution of microseconds, making them suitable candidates for motion-related perception. By assuming that an articulated rigid object is composed of body parts whose shape can be approximately described by a Gaussian distribution, we jointly segment the different parts by combining an adapted Bayesian inference approach and incremental event-based motion estimation. The respective KS is then generated based on the segmented parts and their respective biharmonic distance, which is estimated by building an affinity matrix of points sampled from the estimated Gaussian distributions. The method outperforms frame-based methods in sequences obtained by simulating events from video sequences and achieves a solid performance on new high-speed motions sequences, which frame-based KS estimation methods can not handle.",
        "primary_area": "",
        "author": "Urbano Miguel Nunes;Yiannis Demiris;Urbano Miguel Nunes;Yiannis Demiris",
        "authorids": "/37088220099;/37296338900;/37088220099;/37296338900",
        "aff": "Department of Electrical and Electronic Engineering, Personal Robotics Lab, Imperial College London; Department of Electrical and Electronic Engineering, Personal Robotics Lab, Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812430/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5047712052461702531&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811915",
        "title": "Kinematic Transfer Learning of Sampling Distributions for Manipulator Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent research has shown that guiding sampling-based planners with sampling distributions, learned from previous experiences via density estimation, can significantly decrease computation times for motion planning. We propose an algorithm that can estimate the density from the experiences of a robot with different kinematic structure, on the same task. The method allows to generalize collected data from one source manipulator to similarly designed target manipulators, significantly reducing the computation time for new queries for the target manipulator. We evaluate the algorithm in two experiments, including a constrained manipulation task with five different collaborative robots, and show that transferring information can significantly decrease planning time.",
        "primary_area": "",
        "author": "Peter Lehner;M\u00e1ximo A. Roa;Alin Albu-Sch\u00e4ffer;Peter Lehner;M\u00e1ximo A. Roa;Alin Albu-Sch\u00e4ffer",
        "authorids": "/37085411568;/37628512100;/38270361100;/37085411568;/37628512100;/38270361100",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR) at Oberpfaffenhofen, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR) at Oberpfaffenhofen, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR) at Oberpfaffenhofen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811915/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11882893824836039480&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "German Aerospace Center (DLR)",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Oberpfaffenhofen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812021",
        "title": "Kinematics Learning of Massive Heterogeneous Serial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Kinematics and instantaneous kinematics are fundamental in many robotic tasks, such as positioning and collision avoidance. Existing learning methods mainly concern a single robot, and small-scale networks are sufficient for considerable approximation accuracy. A question is: Can we learn a kinematics model that can generalize to various robots rather than a single robot? This paper studies the kinematics learning of massive heterogeneous serial robots and the transfer of these general models to reality. We generate a dataset by randomizing dimensions, configurations, and link lengths and employ a network based on the generative pre-trained transformer to learn general kinematics mappings. We directly transfer our models for accuracy and use distillation-based transfer for computational efficiency. The results validate that our method can accurately approximate the kinematics of thousands of robot models and demonstrates generality in transfer.",
        "primary_area": "",
        "author": "Dengpeng Xing;Wannian Xia;Bo Xu;Dengpeng Xing;Wannian Xia;Bo Xu",
        "authorids": "/37085584166;/37089447957;/37086386002;/37085584166;/37089447957;/37086386002",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812021/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5519347381456282617&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences",
        "aff_unique_dep": "School of Artificial Intelligence",
        "aff_unique_url": "http://www.ucas.ac.cn",
        "aff_unique_abbr": "UCAS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812352",
        "title": "KinoJGM: A framework for efficient and accurate quadrotor trajectory generation and tracking in dynamic environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmapped areas and aerodynamic disturbances render autonomous navigation with quadrotors extremely challenging. To fly safely and efficiently, trajectory planners and trackers must be able to navigate unknown environments with unpredictable aerodynamic effects in real-time. When encountering aerodynamic effects such as strong winds, most current approaches to quadrotor trajectory planning and tracking will not attempt to deviate from a determined plan, even if it is risky, in the hope that any aerodynamic disturbances can be resisted by a robust controller. This paper presents a novel systematic trajectory planning and tracking framework for autonomous quadrotors. We propose a Kinodynamic Jump Space Search (Kino-JSS) to generate a safe and efficient route in unknown environments with aerodynamic disturbances. A real-time Gaussian Process is employed to model the errors caused by aerodynamic disturbances, which we then integrate with a Model Predictive Controller to achieve efficient and accurate trajectory optimization and tracking. We demonstrate our system to improve the efficiency of trajectory generation in unknown environments by up to 75% in the cases tested, compared with recent state-of-the-art. We also show that our system improves the accuracy of tracking in selected environments with unpredictable aerodynamic effects. Our implementation is available in an open source package11https://github.com/Alex-yanranwang/Imperial-KinoJGM.",
        "primary_area": "",
        "author": "Yanran Wang;James O'Keeffe;Qiuchen Qian;David Boyle;Yanran Wang;James O'Keeffe;Qiuchen Qian;David Boyle",
        "authorids": "/37089451018;/37086284423;/37088845963;/37078092800;/37089451018;/37086284423;/37088845963;/37078092800",
        "aff": "Dyson School of Design Engineering, Imperial College, London, United Kingdom; Dyson School of Design Engineering, Imperial College, London, United Kingdom; Dyson School of Design Engineering, Imperial College, London, United Kingdom; Dyson School of Design Engineering, Imperial College, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812352/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dyson School of Design Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811896",
        "title": "KoopNet: Joint Learning of Koopman Bilinear Models and Function Dictionaries with Application to Quadrotor Trajectory Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Nonlinear dynamical effects are crucial to the operation of many agile robotic systems. Koopman-based model learning methods can capture these nonlinear dynamical system effects in higher dimensional lifted bilinear models that are amenable to optimal control. However, standard methods that lift the system state using a fixed function dictionary before model learning result in high dimensional models that are intractable for real time control. This paper presents a novel method that jointly learns a function dictionary and lifted bilinear model purely from data by incorporating the Koopman model in a neural network architecture. Nonlinear MPC design utilizing the learned model can be performed readily. We experimentally realized this method on a multirotor drone for agile trajectory tracking at low altitudes where the aerodynamic ground effect influences the system's behavior. Experimental results demonstrate that the learning-based controller achieves similar performance as a nonlinear MPC based on a nominal dynamics model in medium altitude. However, our learning-based system can reliably track trajectories in near-ground flight regimes while the nominal controller crashes due to unmodeled dynamical effects that are captured by our method.",
        "primary_area": "",
        "author": "Carl Folkestad;Skylar X. Wei;Joel W. Burdick;Carl Folkestad;Skylar X. Wei;Joel W. Burdick",
        "authorids": "/37088482867;/37089446656;/37265975700;/37088482867;/37089446656;/37265975700",
        "aff": "Division of Engineering and Applied Sciences, California Institute of Technology, Pasadena, CA, USA; Division of Engineering and Applied Sciences, California Institute of Technology, Pasadena, CA, USA; Division of Engineering and Applied Sciences, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811896/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6994232857970400242&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Division of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811946",
        "title": "L1Adaptive Augmentation for Geometric Tracking Control of Quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces an LL1adaptive control aug-mentation for geometric tracking control of quadrotors. In the proposed design, the LL 1 augmentation handles nonlinear (time-and state-dependent) uncertainties in the quadrotor dynamics without assuming or enforcing parametric structures, while the baseline geometric controller achieves stabilization of the known nonlinear model of the system dynamics. The LL1augmentation applies to both the rotational and the translational dynamics. Experimental results demonstrate that the augmented geomet-ric controller shows consistent and (on average five times) smaller trajectory tracking errors compared with the geometric controller alone when tested for different trajectories and under various types of uncertainties/disturbances.",
        "primary_area": "",
        "author": "Zhuohuan Wu;Sheng Cheng;Kasey A. Ackerman;Aditya Gahlawat;Arun Lakshmanan;Pan Zhao;Naira Hovakimyan;Zhuohuan Wu;Sheng Cheng;Kasey A. Ackerman;Aditya Gahlawat;Arun Lakshmanan;Pan Zhao;Naira Hovakimyan",
        "authorids": "/37089449105;/37089446688;/37085541358;/38232718300;/37088334097;/37085531074;/37299175600;/37089449105;/37089446688;/37085541358;/38232718300;/37088334097;/37085531074;/37299175600",
        "aff": "Mechanical Science and Engineering, University of Illinois Urbana-Champaign, USA; Mechanical Science and Engineering, University of Illinois Urbana-Champaign, USA; Mechanical Science and Engineering, University of Illinois Urbana-Champaign, USA; Mechanical Science and Engineering, University of Illinois Urbana-Champaign, USA; Mechanical Science and Engineering, University of Illinois Urbana-Champaign, USA; Mechanical Science and Engineering, University of Illinois Urbana-Champaign, USA; Mechanical Science and Engineering, University of Illinois Urbana-Champaign, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811946/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18035678177263247447&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Mechanical Science and Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812305",
        "title": "LADC: Learning-Based Anti-Disturbance Control for Washing Drone",
        "track": "main",
        "status": "Poster",
        "abstract": "Disturbance mainly caused by recoil force in-evitably makes washing drone seriously deviate from the desired position, thereby reducing the cleaning efficiency. It is neces-sary to develop an effective anti-disturbance control method. Although some progresses have been made, the position error thereof is still large, rendering existing methods inapplicable in washing drone. In this paper, we propose a learning-based anti-disturbance control (LADC) method to significantly reduce the position error by combining robust nonlinear control and partial differential equation network (PDENet). Taking data noise into account, we use differential spectral normalization in the training of the PDENet. A distinguishing feature of our method is to directly learn PDENet parameters from flight logs without installing extra sensors. Experimental results indicate that the proposed method outperforms classical PD method and extended state observer (ESO) based control method with 70 % and 50 % reduced position error, respectively, and can be further applied in variable scenarios. Video: https: / / youtu.be/gNfLFAXalkI",
        "primary_area": "",
        "author": "Jian Di;Shaofeng Chen;Han Yan;Xinghu Wang;Hepeng Zhang;Haibo Ji;Tao Jin;Jian Di;Shaofeng Chen;Han Yan;Xinghu Wang;Hepeng Zhang;Haibo Ji;Tao Jin",
        "authorids": "/37089178519;/37086605637;/37085548829;/37077730100;/37089449362;/37398694500;/37089446799;/37089178519;/37086605637;/37085548829;/37077730100;/37089449362;/37398694500;/37089446799",
        "aff": "University of Science and Technology of China; University of Science and Technology of China; Beijing Institute of Control Engineering and Beijing SunWise Space Technology Ltd.; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China; University of Science and Technology of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812305/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5943228610814549825&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China;Beijing Institute of Control Engineering",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.ustc.edu.cn;",
        "aff_unique_abbr": "USTC;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812062",
        "title": "LB-L2L-Calib: Accurate and Robust Extrinsic Calibration for Multiple 3D LiDARs with Long Baseline and Large Viewpoint Difference",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-LiDAR system is an important part of V2X (Vehicle to Everything) to enhance the perception information for unmanned vehicles. To fuse the information from multiple 3D LiDARs, accurate extrinsic calibration between the LiDARs is essential. However, the existing multi-LiDAR calibration methods mainly focus on short baseline scenarios, where multiple LiDARs are closely mounted on a single platform (e.g., an unmanned vehicle). Besides, most methods typically use a planar target for calibration. Some of the methods require the motion of the multi-LiDAR system. The above conditions severely limit the application of these methods to V2X, where LiDARs are non-movable, the baseline and viewpoint difference between the LiDARs can be very large. In order to meet these challenges, we propose an accurate and robust extrinsic calibration method for long baseline multi-LiDAR systems, named LB-L2L-Calib (Large Baseline LiDAR to LiDAR extrinsic Calibration). (1) We use a sphere as the calibration target for multiple LiDARs with large viewpoint difference, leveraging the viewpoint-invariance of the sphere. (2) A improved sphere detection and sphere center estimation strategy is introduced to detect and extract the sphere center from a cluttered point cloud in large-scale outdoor scenario. (3) A extrinsic parameter regression scheme is introduced. Both simulation and real experiments demonstrate that LB-L2L-Calib is highly accurate and robust. Quantitative results show that the rotation and translation error is less than 0.01m and 0.01\u00b0 (in simulation, Gauss noise 0.03m, the distance and viewpoint difference between two LiDARs is more than 30m and 90\u00b0).",
        "primary_area": "",
        "author": "Jun Zhang;Qiyang Lyu;Guohao Peng;Zhenyu Wu;Qiao Yan;Danwei Wang;Jun Zhang;Qiyang Lyu;Guohao Peng;Zhenyu Wu;Qiao Yan;Danwei Wang",
        "authorids": "/37086009222;/37089446613;/37087049757;/37088406849;/37089447365;/37279547600;/37086009222;/37089446613;/37087049757;/37088406849;/37089447365;/37279547600",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812062/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10108809553116831641&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9812138",
        "title": "LEGS: Learning Efficient Grasp Sets for Exploratory Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "While deep learning has enabled significant progress in designing general purpose robot grasping systems, there remain objects which still pose challenges for these systems. Recent work on Exploratory Grasping has formalized the problem of systematically exploring grasps on these adversarial objects and explored a multi-armed bandit model for identifying high-quality grasps on each object stable pose. However, these systems are still limited to exploring a small number or grasps on each object. We present Learned Efficient Grasp Sets (LEGS), an algorithm that efficiently explores thousands of possible grasps by maintaining small active sets of promising grasps and determining when it can stop exploring the object with high confidence. Experiments suggest that LEGS can identify a high-quality grasp more efficiently than prior algorithms which do not use active sets. In simulation experiments, we measure the gap between the success probability of the best grasp identified by LEGS, baselines, and the most-robust grasp (verified ground truth). After 3000 exploration steps, LEGS outperforms baseline algorithms on 10/14 and 25/39 objects on the Dex-Net Adversarial and EGAD! datasets respectively. We then evaluate LEGS in physical experiments; trials on 3 challenging objects suggest that LEGS converges to high-performing grasps significantly faster than baselines. See https://sites.google.com/view/LEGS-exp-grasping for supplemental material and videos.",
        "primary_area": "",
        "author": "Letian Fu;Michael Danielczuk;Ashwin Balakrishna;Daniel S. Brown;Jeffrey Ichnowski;Eugen Solowjow;Ken Goldberg;Letian Fu;Michael Danielczuk;Ashwin Balakrishna;Daniel S. Brown;Jeffrey Ichnowski;Eugen Solowjow;Ken Goldberg",
        "authorids": "/37089449079;/37086541913;/37085692655;/38478370100;/38541287200;/37947855300;/37273026700;/37089449079;/37086541913;/37085692655;/38478370100;/38541287200;/37947855300;/37273026700",
        "aff": "The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; Siemens Research Lab; The AUTOLab, UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812138/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16517448105959612636&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;Siemens AG",
        "aff_unique_dep": "The AUTOLab;Research Lab",
        "aff_unique_url": "https://www.berkeley.edu;https://www.siemens.com",
        "aff_unique_abbr": "UC Berkeley;Siemens",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0;1;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "9811605",
        "title": "LLOL: Low-Latency Odometry for Spinning Lidars",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a low-latency odometry system designed for spinning lidars. Many existing lidar odometry methods wait for an entire sweep from the lidar before processing the data. This introduces a large delay between the first laser firing and its pose estimate. To reduce this latency, we treat the spinning lidar as a streaming sensor and process packets as they arrive. This effectively distributes expensive operations across time, resulting in a very fast and lightweight system with a much higher throughput and lower latency. Our open source implementation is available at https://github.com/versatran01/llol.",
        "primary_area": "",
        "author": "Chao Qu;Shreyas S. Shivakumar;Wenxin Liu;Camillo J. Taylor;Chao Qu;Shreyas S. Shivakumar;Wenxin Liu;Camillo J. Taylor",
        "authorids": "/37085780604;/37086151076;/37086453631;/37277248500;/37085780604;/37086151076;/37086453631;/37277248500",
        "aff": "GRASP Laboratory, School of Engineering and Applied Sciences, University of Pennsylvania; GRASP Laboratory, School of Engineering and Applied Sciences, University of Pennsylvania; GRASP Laboratory, School of Engineering and Applied Sciences, University of Pennsylvania; GRASP Laboratory, School of Engineering and Applied Sciences, University of Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811605/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8885140003895507185&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811916",
        "title": "LT-mapper: A Modular Framework for LiDAR-based Lifelong Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Long-term 3D map management is a fundamental capability required by a robot to reliably navigate in the non-stationary real-world. This paper develops open-source, modular, and readily available LiDAR-based lifelong mapping for urban sites. This is achieved by dividing the problem into successive subproblems: multi-session SLAM (MSS), high/low dynamic change detection, and positive/negative change management. The proposed method leverages MSS and minimizes potential trajectory error; thus, a manual or good initial alignment is not required for change detection. Our change management scheme preserves efficacy in both memory and computation costs, providing automatic object segregation from a large-scale point cloud map. We verify the framework's reliability and applicability even under permanent year-level variation, through extensive real-world experiments with multiple temporal gaps (from day to year).",
        "primary_area": "",
        "author": "Giseop Kim;Ayoung Kim;Giseop Kim;Ayoung Kim",
        "authorids": "/37086578593;/37403315600;/37086578593;/37403315600",
        "aff": "Autonomous Driving Group, NAVER LABS, Seongnam-si, Gyeonggi-do, S. Korea; Department of Mechanical Engineering, SNU, Seoul, S. Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811916/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14293455049107626328&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "NAVER LABS;Seoul National University",
        "aff_unique_dep": "Autonomous Driving Group;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.naverlabs.com;https://www.snu.ac.kr",
        "aff_unique_abbr": "NAVER LABS;SNU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Seongnam-si;Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811855",
        "title": "LTSR: Long-term Semantic Relocalization based on HD Map for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Highly accurate and robust relocalization or localization initialization ability is of great importance for autonomous vehicles (AVs). Traditional GNSS-based methods are not reliable enough in occlusion and multipath conditions. In this paper we propose a novel long-term semantic relocalization algorithm based on HD map and semantic features which are compact in representation. Semantic features appear widely on urban roads, and are robust to illumination, weather, view-point and appearance changes. Repeated structures, missed and false detections make data association (DA) highly ambiguous. To this end, a robust semantic feature matching method based on a new local semantic descriptor which encodes the spatial and normal relationship between semantic features is performed. Further, we introduce an accurate, efficient, yet simple outlier removal method which works by assessing the local and global geometric consistencies and temporal consistency of semantic matching pairs. The experimental results on our urban dataset demonstrate that our approach performs better in accuracy and robustness compared with the current state-of-the-art methods.",
        "primary_area": "",
        "author": "Huayou Wang;Changliang Xue;Yu Tang;Wanlong Li;Feng Wen;Hongbo Zhang;Huayou Wang;Changliang Xue;Yu Tang;Wanlong Li;Feng Wen;Hongbo Zhang",
        "authorids": "/37089001409;/37089001737;/37089448198;/37088687641;/37088690190;/37859161500;/37089001409;/37089001737;/37089448198;/37088687641;/37088690190;/37859161500",
        "aff": "Noah's Ark Lab, Huawei Technologies, Beijing, China; Noah's Ark Lab, Huawei Technologies, Beijing, China; Noah's Ark Lab, Huawei Technologies, Beijing, China; Noah's Ark Lab, Huawei Technologies, Beijing, China; Noah's Ark Lab, Huawei Technologies, Beijing, China; Noah's Ark Lab, Huawei Technologies, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811855/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6634114202711830702&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Noah's Ark Lab",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811879",
        "title": "Large-angle and High-speed Trajectory Tracking Control of a Quadrotor UAV based on Reachability",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper solves the tracking control problem for a quadrotor system under the tasks of large-angle rotation and high-speed trajectory tracking. A quadrotor dynamic model is presented taking both disturbances and drag force into account. A reachability control strategy is developed for a quadrotor to track the planned attitude and position. Outdoor experiments of a circle trajectory tracking at different flight speeds validate the robustness of the proposed method. A task of flip is demonstrated to verify the effectiveness of the proposed controller under a large tilt angle.",
        "primary_area": "",
        "author": "Zhou Liu;Lilong Cai;Zhou Liu;Lilong Cai",
        "authorids": "/37089937754;/37288206200;/37089937754;/37288206200",
        "aff": "Department of Mechanical and Aerospace En-gineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Mechanical and Aerospace Engineering, The Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811879/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7842171728769543044&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812427",
        "title": "Large-scale Network Traffic Prediction With LSTM and Temporal Convolutional Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time and precise prediction for traffic of networks is critically important for allocating the optimal computing/network resources based on users' business requirements, analyzing the network performance, and realizing intelligent congestion control and high-accuracy anomaly detection. The dramatic growth of users' applications significantly increases the volume, uncertainty, and complexity of workload, thereby making it highly challenging to precisely predict future net-work traffic. Temporal Convolutional Networks (TCNs) and Long Short-Term Memory (LSTM) can be effectively used to analyze and predict time series. This work designs an improved prediction approach for the prediction of network traffic, which combines a Savitzky-Golay filter, TCN, and LSTM, called ST-LSTM for short. It first removes the noise of data with the filter of Savitzky-Golay. It then investigates temporal characteristics of data by using TCN. At last, it investigates the long-term dependency in the time series by using LSTM. Experimental results on a real-life website dataset show the prediction accuracy of ST-LSTM is higher than autoregressive integrated moving average, support vector regression, eXtreme Gradient Boosting, backpropagation, TCN, and LSTM, in terms of several commonly used performance indicators.",
        "primary_area": "",
        "author": "Jing Bi;Haitao Yuan;Kangyuan Xu;Haisen Ma;MengChu Zhou;Jing Bi;Haitao Yuan;Kangyuan Xu;Haisen Ma;MengChu Zhou",
        "authorids": "/37530385000;/37592390300;/37089449152;/37089449678;/37273591600;/37530385000;/37592390300;/37089449152;/37089449678;/37273591600",
        "aff": "Faculty of Information Technology, Beijing University of Technology, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Faculty of Information Technology, Beijing University of Technology, Beijing, China; Department of Electrical and Computer Engineering, New Jersey Institute of Technology, Newark, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812427/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11732391638151312454&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "Beijing University of Technology;Beihang University;New Jersey Institute of Technology",
        "aff_unique_dep": "Faculty of Information Technology;School of Automation Science and Electrical Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.bit.edu.cn;http://www.buaa.edu.cn;https://www.njit.edu",
        "aff_unique_abbr": "BIT;BUAA;NJIT",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Beijing;Newark",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9811650",
        "title": "Latent Imagination Facilitates Zero-Shot Transfer in Autonomous Racing",
        "track": "main",
        "status": "Poster",
        "abstract": "World models learn behaviors in a latent imagination space to enhance the sample-efficiency of deep reinforcement learning (RL) algorithms. While learning world models for high-dimensional observations (e.g., pixel inputs) has become practicable on standard RL benchmarks and some games, their effectiveness in real-world robotics applications has not been explored. In this paper, we investigate how such agents generalize to real-world autonomous vehicle control tasks, where advanced model-free deep RL algorithms fail. In particular, we set up a series of time-lap tasks for an F1TENTH racing robot, equipped with a high-dimensional LiDAR sensor, on a set of test tracks with a gradual increase in their complexity. In this continuous-control setting, we show that model-based agents capable of learning in imagination substantially outperform model-free agents with respect to performance, sample efficiency, successful task completion, and generalization. Moreover, we show that the generalization ability of model-based agents strongly depends on the choice of their observation model. We provide extensive empirical evidence for the effectiveness of world models provided with long enough memory horizons in sim2real tasks.",
        "primary_area": "",
        "author": "Axel Brunnbauer;Luigi Berducci;Andreas Brandst\u00e1tter;Mathias Lechner;Ramin Hasani;Daniela Rus;Radu Grosu;Axel Brunnbauer;Luigi Berducci;Andreas Brandst\u00e1tter;Mathias Lechner;Ramin Hasani;Daniela Rus;Radu Grosu",
        "authorids": "/37089446813;/37089449792;/37089534584;/37086937501;/37085814419;/37279652300;/37442339800;/37089446813;/37089449792;/37089534584;/37086937501;/37085814419;/37279652300;/37442339800",
        "aff": "CPS, Technische Universit\u00e1t Wien (TU Wien), Austria; CPS, Technische Universit\u00e1t Wien (TU Wien), Austria; CPS, Technische Universit\u00e1t Wien (TU Wien), Austria; Institute of Science and Technology Austria (IST Austria); CSAIL, Massachusetts Institute of Technology (MIT), MA, USA; CSAIL, Massachusetts Institute of Technology (MIT), MA, USA; CPS, Technische Universit\u00e1t Wien (TU Wien), Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811650/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2201524533036053495&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;2;2;0",
        "aff_unique_norm": "Technische Universit\u00e1t Wien;Institute of Science and Technology Austria;Massachusetts Institute of Technology",
        "aff_unique_dep": "CPS;;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.tuwien.ac.at;https://www.ist.ac.at;https://www.csail.mit.edu",
        "aff_unique_abbr": "TU Wien;IST Austria;MIT",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0;1;1;0",
        "aff_country_unique": "Austria;United States"
    },
    {
        "id": "9811685",
        "title": "Learn to Grasp with Less Supervision: A Data-Efficient Maximum Likelihood Grasp Sampling Loss",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic grasping for a diverse set of objects is essential in many robot manipulation tasks. One promising approach is to learn deep grasping models from large training datasets of object images and grasp labels. However, empirical grasping datasets are typically sparsely labeled (i.e., a small number of successful grasp labels**Labels refer to marking the image to indicate a successful robotic grasp. in each image). The data sparsity issue can lead to insufficient supervision and false-negative labels, and thus results in poor learning results. This paper proposes a Maximum Likelihood Grasp Sampling Loss (MLGSL) to tackle the data sparsity issue. The proposed method supposes that successful grasps are stochastically sampled from the predicted grasp distribution and maximizes the observing likelihood. MLGSL is utilized for training a fully convolutional network that generates thousands of grasps simultaneously. Training results suggest that models based on MLGSL can learn to grasp with datasets composing of 2 labels per image. Compared to previous works, which require training datasets of 16 labels per image, MLGSL is 8\u00d7 more data-efficient. Meanwhile, physical robot experiments demonstrate an equivalent performance at a 90.7% grasp success rate on household objects. Codes and videos are available at [1].",
        "primary_area": "",
        "author": "Xinghao Zhu;Yefan Zhou;Yongxiang Fan;Lingfeng Sun;Jianyu Chen;Masayoshi Tomizuka;Xinghao Zhu;Yefan Zhou;Yongxiang Fan;Lingfeng Sun;Jianyu Chen;Masayoshi Tomizuka",
        "authorids": "/37087322158;/37089229312;/37085827034;/37087105341;/37086004703;/37281933000;/37087322158;/37089229312;/37085827034;/37087105341;/37086004703;/37281933000",
        "aff": "Mechanical Systems Control Lab, UC Berkeley, CA, USA; Mechanical Systems Control Lab, UC Berkeley, CA, USA; FANUC Advanced Research Lab, FANUC America Corporation, CA, USA; Mechanical Systems Control Lab, UC Berkeley, CA, USA; Mechanical Systems Control Lab, UC Berkeley, CA, USA; Mechanical Systems Control Lab, UC Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811685/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9524981943481737446&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "University of California, Berkeley;FANUC America Corporation",
        "aff_unique_dep": "Mechanical Systems Control Lab;FANUC Advanced Research Lab",
        "aff_unique_url": "https://www.berkeley.edu;https://www.fanucamerica.com",
        "aff_unique_abbr": "UC Berkeley;FANUC",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Berkeley;CA",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811367",
        "title": "Learning 6-DoF Object Poses to Grasp Category-Level Objects by Language Instructions",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the task of any objects grasping from the known categories by free-form language instructions. This task demands the technique in computer vision, natural language processing, and robotics. We bring these disciplines together on this open challenge, which is essential to human-robot interaction. Critically, the key challenge lies in inferring the category of objects from linguistic instructions and accurately estimating the 6-DoF information of unseen objects from the known classes. In contrast, previous works focus on inferring the pose of object candidates at the instance level. This significantly limits its applications in real-world scenarios. In this paper, we propose a language-guided 6-DoF category-level object localization model to achieve robotic grasping by comprehending human intention. To this end, we propose a novel two-stage method. Particularly, the first stage grounds the target in the RGB image through language description of names, attributes, and spatial relations of objects. The second stage extracts and segments point clouds from the cropped depth image and estimates the full 6-DoF object pose at category-level. Under such a manner, our approach can locate the specific object by following human instructions, and estimate the full 6-DoF pose of a category-known but unseen instance which is not utilized for training the model. Extensive experimental results show that our method is competitive with the state-of-the-art language-conditioned grasp method. Importantly, we deploy our approach on a physical robot to validate the usability of our framework in real-world applications. Please refer to the supplementary for the demo videos of our robot experiments.",
        "primary_area": "",
        "author": "Chilam Cheang;Haitao Lin;Yanwei Fu;Xiangyang Xue;Chilam Cheang;Haitao Lin;Yanwei Fu;Xiangyang Xue",
        "authorids": "/37089448081;/37088455645;/37086206496;/37272718600;/37089448081;/37088455645;/37086206496;/37272718600",
        "aff": "Fudan University; Fudan University; School of Data Science, Fudan University; Fudan University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811367/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5305713069129522712&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Fudan University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.fudan.edu.cn",
        "aff_unique_abbr": "Fudan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811541",
        "title": "Learning Controller Gains on Bipedal Walking Robots via User Preferences",
        "track": "main",
        "status": "Poster",
        "abstract": "Experimental demonstration of complex robotic behaviors relies heavily on finding the correct controller gains. This painstaking process is often completed by a domain expert, requiring deep knowledge of the relationship between parameter values and the resulting behavior of the system. Even when such knowledge is possessed, it can take significant effort to navigate the nonintuitive landscape of possible parameter combinations. In this work, we explore the extent to which preference-based learning can be used to optimize controller gains online by repeatedly querying the user for their preferences. This general methodology is applied to two variants of control Lyapunov function based nonlinear controllers framed as quadratic programs, which provide theoretical guarantees but are challenging to realize in practice. These controllers are successfully demonstrated both on the planar underactuated biped, AMBER, and on the 3D underactuated biped, Cassie. We experimentally evaluate the performance of the learned controllers and show that the proposed method is repeatably able to learn gains that yield stable and robust locomotion.",
        "primary_area": "",
        "author": "Noel Csomay-Shanklin;Maegan Tucker;Min Dai;Jenna Reher;Aaron D. Ames;Noel Csomay-Shanklin;Maegan Tucker;Min Dai;Jenna Reher;Aaron D. Ames",
        "authorids": "/37086862522;/37087122493;/37089450183;/37085715578;/37300877900;/37086862522;/37087122493;/37089450183;/37085715578;/37300877900",
        "aff": "Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811541/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12781716393640282541&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Computing and Mathematical Sciences",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812011",
        "title": "Learning Crowd-Aware Robot Navigation from Challenging Environments via Distributed Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a deep reinforcement learning (DRL) sframework for safe and efficient navigation in crowded environments. Here, the robot learns cooperative behavior using a new reward function that penalizes robot actions interfering with the pedestrian's movement. Also, we propose a simulated pedestrian policy reflecting data from actual pedestrian movements. Furthermore, we introduce a collision detection that considers the pedestrian's personal space to generate affinity robot behavior. To efficiently explore this simulation environment, we propose distributed learning using Ape-X [1]. We deployed the robot in a real environment and verified its crowd-aware navigation performance compared with an actual human in terms of path length, travel time, and the number of abrupt avoidances.",
        "primary_area": "",
        "author": "Sango Matsuzaki;Yuji Hasegawa;Sango Matsuzaki;Yuji Hasegawa",
        "authorids": "/37089001443;/37088997609;/37089001443;/37088997609",
        "aff": "Honda R&D Co., LTD.; Honda R&D Co., LTD.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812011/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3217775979085374796&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Honda R&D Co., Ltd.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.honda.com/",
        "aff_unique_abbr": "Honda R&D",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811624",
        "title": "Learning Design and Construction with Varying-Sized Materials via Prioritized Memory Resets",
        "track": "main",
        "status": "Poster",
        "abstract": "Can a robot autonomously learn to design and construct a bridge from varying-sized blocks without a blueprint? It is a challenging task with long horizon and sparse reward - the robot has to figure out physically stable design schemes and feasible actions to manipulate and transport blocks. Due to diverse block sizes, the state space and action trajectories are vast to explore. In this paper, we propose a hierarchical approach for this problem. It consists of a reinforcement-learning designer to propose high-level building instructions and a motion-planning-based action generator to manipulate blocks at the low level. For high-level learning, we develop a novel technique, prioritized memory resetting (PMR) to improve exploration. PMR adaptively resets the state to those most critical configurations from a replay buffer so that the robot can resume training on partial architectures instead of from scratch. Furthermore, we augment PMR with auxiliary training objectives and fine-tune the designer with the locomotion generator. Our experiments in simulation and on a real deployed robotic system demonstrate that it is able to effectively construct bridges with blocks of varying sizes at a high success rate. Demos can be found at https://sites.google.com/view/bridge-pmr.",
        "primary_area": "",
        "author": "Yunfei Li;Tao Kong;Lei Li;Yi Wu;Yunfei Li;Tao Kong;Lei Li;Yi Wu",
        "authorids": "/37089195348;/37085802024;/37088997323;/37089194863;/37089195348;/37085802024;/37088997323;/37089194863",
        "aff": "Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China; ByteDance AI Lab, Beijing, China; University of California, Santa Barbara; Shanghai Qi Zhi Institute, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811624/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10328999826251541726&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Tsinghua University;ByteDance;University of California, Santa Barbara;Shanghai Qi Zhi Institute",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences;AI Lab;;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.bytedance.com;https://www.ucsb.edu;",
        "aff_unique_abbr": "Tsinghua;;UCSB;",
        "aff_campus_unique_index": "0;0;1;2",
        "aff_campus_unique": "Beijing;Santa Barbara;Shanghai",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9811640",
        "title": "Learning Efficient and Robust Multi-Modal Quadruped Locomotion: A Hierarchical Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Four-legged animals are able to change their gaits adaptively for lower energy consumption. However, designing a robust controller for their robot counterparts with multi-modal locomotion remains challenging. In this paper, we present a hierarchical control framework that decomposes this challenge into two kinds of problems: high-level decision-making for gait selection and robust low-level control in complex application environments. For gait transitions, we use reinforcement learning (RL) to design a gait policy that selects the optimal gaits in different environments. After the gait is decided, model predictive control (MPC) is applied to implement the desired gait. To improve the robustness of the locomotion, a model adaptation policy is developed to optimize the input parameters of our MPC controller adaptively. The control framework is first trained and tested in simulation, and then it is applied directly to a quadruped robot in real without any fine-tuning. We show that our control framework is more energy efficient by choosing different gaits and is more robust by adjusting model parameters compared to baseline controllers.",
        "primary_area": "",
        "author": "Shaohang Xu;Lijun Zhu;Chin Pang Ho;Shaohang Xu;Lijun Zhu;Chin Pang Ho",
        "authorids": "/37089450582;/37535028800;/37089448658;/37089450582;/37535028800;/37089448658",
        "aff": "School of Data Science, City University of Hong Kong, HKSAR; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China; School of Data Science, City University of Hong Kong, HKSAR",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811640/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2049700435942737856&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "City University of Hong Kong;Huazhong University of Science and Technology",
        "aff_unique_dep": "School of Data Science;School of Artificial Intelligence and Automation",
        "aff_unique_url": "https://www.cityu.edu.hk;http://www.hust.edu.cn",
        "aff_unique_abbr": "CityU;HUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812285",
        "title": "Learning Emergent Discrete Message Communication for Cooperative Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Communication is an important factor that en-ables agents to work cooperatively in multi-agent reinforcement learning (MARL) contexts. Prior work used continuous message communication whose high representational capacity comes at the expense of interpretability. Allowing agents to learn their own discrete emergent message communication protocols can increase the interpretability for human designers and other agents. This paper proposes a method to generate discrete messages analogous to human languages. Discrete message communication is achieved by a broadcast-and-listen mecha-nism based on self-attention. We show that discrete message communication has performance comparable to continuous message communication but with a much smaller vocabulary size. Discrete message communication protocols can potentially be used for human-agent interaction.",
        "primary_area": "",
        "author": "Sheng Li;Yutai Zhou;Ross Allen;Mykel J. Kochenderfer;Sheng Li;Yutai Zhou;Ross Allen;Mykel J. Kochenderfer",
        "authorids": "/37088593519;/37088589136;/37088470952;/37596929200;/37088593519;/37088589136;/37088470952;/37596929200",
        "aff": "Department of Aeronautics and Astronautics, Stanford University; Lincoln Laboratory, Massachusetts Institute of Technology; Lincoln Laboratory, Massachusetts Institute of Technology; Department of Aeronautics and Astronautics, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812285/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8607672688627921245&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Stanford University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;Lincoln Laboratory",
        "aff_unique_url": "https://www.stanford.edu;https://web.mit.edu",
        "aff_unique_abbr": "Stanford;MIT",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Stanford;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811587",
        "title": "Learning Friction Model for Magnet-Actuated Tethered Capsule Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "The potential diagnostic applications of magnet-actuated capsules have been greatly increased in recent years. For most of these potential applications, accurate position control of the capsule have been highly demanding. However, the friction between the robot and the environment as well as the drag force from the tether play a significant role during the motion control of the capsule. Moreover, these forces especially the friction force are typically hard to model beforehand. In this paper, we first designed a magnet-actuated tethered capsule robot, where the driving magnet is mounted on the end of a robotic arm. Then, we proposed a learning-based approach to model the friction force between the capsule and the environment, with the goal of increasing the control accuracy of the whole system. Finally, several real robot experiments are demonstrated to showcase the effectiveness of our proposed approach.",
        "primary_area": "",
        "author": "Yi Wang;Yuyang Tu;Yuchen He;Xutian Deng;Ziwei Lei;Jianwei Zhang;Miao Li;Yi Wang;Yuyang Tu;Yuchen He;Xutian Deng;Ziwei Lei;Jianwei Zhang;Miao Li",
        "authorids": "/37089229164;/37089449114;/37089224930;/37089227663;/37089224299;/37281460600;/37086045835;/37089229164;/37089449114;/37089224930;/37089227663;/37089224299;/37281460600;/37086045835",
        "aff": "School of Power and Mechanical Engineering, Wuhan University, Hubei, China; Department of Informatics, University of Hamburg, Germany; School of Mechanical Engineering and Automation, Wuhan Textile University, Hubei; School of Power and Mechanical Engineering, Wuhan University, Hubei, China; School of Power and Mechanical Engineering, Wuhan University, Hubei, China; Department of Informatics, University of Hamburg, Germany; School of Power and Mechanical Engineering, Wuhan University, Hubei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811587/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11409179709639514957&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;0;1;0",
        "aff_unique_norm": "Wuhan University;University of Hamburg;Wuhan Textile University",
        "aff_unique_dep": "School of Power and Mechanical Engineering;Department of Informatics;School of Mechanical Engineering and Automation",
        "aff_unique_url": "http://www.whu.edu.cn;https://www.uni-hamburg.de;http://www.wtu.edu.cn",
        "aff_unique_abbr": "WHU;;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Wuhan;",
        "aff_country_unique_index": "0;1;0;0;0;1;0",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "9811973",
        "title": "Learning Insertion Primitives with Discrete-Continuous Hybrid Action Space for Robotic Assembly Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a discrete-continuous action space to learn insertion primitives for robotic assembly tasks. Primitives are sequences of elementary actions with certain exit conditions, such as \u201cpushing down the peg until contact\u201d. Since the primitive is an abstraction of robot control commands and encodes human prior knowledge, it reduces the exploration difficulty and yields better learning efficiency. In this paper, we learn robot assembly skills via primitives. Specifically, we formulate insertion primitives as parameterized actions: hybrid actions consisting of discrete primitive types and continuous primitive parameters. Compared with the previous work using a set of discretized parameters for each primitive, the agent in our method can freely choose primitive parameters from a continuous space, which is more flexible and efficient. To learn these insertion primitives, we propose Twin-Smoothed Multi-pass Deep Q-Network (TS-MP-DQN), an advanced version of MP-DQN with twin Q-network to reduce the Q-value over-estimation. Extensive experiments are conducted in the simulation and real world for validation. From experiment results, our approach achieves higher success rates than three baselines: MP-DQN with parameterized actions, primitives with discrete parameters, and continuous velocity control. Furthermore, learned primitives are robust to sim-to-real transfer and can generalize to challenging assembly tasks such as tight round peg-hole and complex shaped electric connectors with promising success rates. Experiment videos are available at https://msc.berkeley.edu/research/insertion-primitives.html.",
        "primary_area": "",
        "author": "Xiang Zhang;Shiyu Jin;Changhao Wang;Xinghao Zhu;Masayoshi Tomizuka;Xiang Zhang;Shiyu Jin;Changhao Wang;Xinghao Zhu;Masayoshi Tomizuka",
        "authorids": "/37089612990;/37087321850;/37086426211;/37087322158;/37281933000;/37089612990;/37087321850;/37086426211;/37087322158;/37281933000",
        "aff": "Department of Mechanical Engineering, UC Berkeley, CA, USA; Department of Mechanical Engineering, UC Berkeley, CA, USA; Department of Mechanical Engineering, UC Berkeley, CA, USA; Department of Mechanical Engineering, UC Berkeley, CA, USA; Department of Mechanical Engineering, UC Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811973/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5339644531957485891&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812407",
        "title": "Learning Interactive Driving Policies via Data-driven Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Data-driven simulators promise high data-efficiency for driving policy learning. When used for modelling interactions, this data-efficiency becomes a bottleneck: small underlying datasets often lack interesting and challenging edge cases for learning interactive driving. We address this challenge by proposing a data-driven simulation engine\u2020 that uses inpainted ado vehicles for learning robust driving policies. Thus, our approach can be used to learn policies that involve multi-agent interactions and allows for training via state-of-the-art policy learning methods. We evaluate the approach for learning standard interaction scenarios in driving. In extensive experiments, our work demonstrates that the resulting policies can be directly transferred to a full-scale autonomous vehicle without making use of any traditional sim-to-real transfer techniques such as domain randomization.",
        "primary_area": "",
        "author": "Tsun-Hsuan Wang;Alexander Amini;Wilko Schwarting;Igor Gilitschenski;Sertac Karaman;Daniela Rus;Tsun-Hsuan Wang;Alexander Amini;Wilko Schwarting;Igor Gilitschenski;Sertac Karaman;Daniela Rus",
        "authorids": "/37089287640;/37086454594;/37085590089;/38469566100;/37304113000;/37279652300;/37089287640;/37086454594;/37085590089;/38469566100;/37304113000;/37279652300",
        "aff": "Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology (MIT).; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology (MIT).; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology (MIT).; Department of Computer Science, University of Toronto and Toyota Research Institute (TRI).; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology (MIT).; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology (MIT).",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812407/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8599085438884968849&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Toronto",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;Department of Computer Science",
        "aff_unique_url": "https://web.mit.edu;https://www.utoronto.ca",
        "aff_unique_abbr": "MIT;U of T",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Cambridge;Toronto",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9812230",
        "title": "Learning Latent Actions without Human Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "We can make it easier for disabled users to control assistive robots by mapping the user's low-dimensional joystick inputs to high-dimensional, complex actions. Prior works learn these mappings from human demonstrations: a non-disabled human either teleoperates or kinesthetically guides the robot arm through a variety of motions, and the robot learns to reproduce the demonstrated behaviors. But this framework is often impractical \u2014 disabled users will not always have access to external demonstrations! Here we instead learn diverse teleoperation mappings without either human demonstrations or pre-defined tasks. Under our unsupervised approach the robot first optimizes for object state entropy: i.e., the robot autonomously learns to push, pull, open, close, or otherwise change the state of nearby objects. We then embed these diverse, object-oriented behaviors into a latent space for real-time control: now pressing the joystick causes the robot to perform dexterous motions like pushing or opening. We experimentally show that \u2014 with a best-case human operator \u2014 our unsupervised approach actually outperforms the teleoperation mappings learned from human demonstrations, particularly if those demonstrations are noisy or imperfect. But our user study results were less clear-cut: although our approach enabled participants to complete tasks more quickly and with fewer changes of direction, users were confused when the unsupervised robot learned unexpected behaviors. See videos of the user study here: https://youtu.be/BkqHQjsUKDg",
        "primary_area": "",
        "author": "Shaunak A. Mehta;Sagar Parekh;Dylan P. Losey;Shaunak A. Mehta;Sagar Parekh;Dylan P. Losey",
        "authorids": "/37089447282;/37089612937;/37085812055;/37089447282;/37089612937;/37085812055",
        "aff": "Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA; Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA; Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812230/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4813723302047702201&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811597",
        "title": "Learning Latent Graph Dynamics for Visual Manipulation of Deformable Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulating deformable objects, such as ropes and clothing, is a long-standing challenge in robotics, because of their large degrees of freedom, complex non-linear dynamics, and self-occlusion in visual perception. The key difficulty is a suitable representation, rich enough to capture the object shape, dynamics for manipulation and yet simple enough to be estimated reliably from visual observations. This work aims to learn latent Graph dynamics for DefOrmable Object Manipulation (G-DOOM). G-DOOM approximates a deformable object as a sparse set of interacting keypoints, which are extracted automatically from images via unsupervised learning. It learns a graph neural network that captures abstractly the geometry and the interaction dynamics of the keypoints. To handle object self-occlusion, G-DOOM uses a recurrent neural network to track the keypoints over time and condition their interactions on the history. We then train the resulting recurrent graph dynamics model through contrastive learning in a high-fidelity simulator. For manipulation planning, G-DOOM reasons explicitly about the learned dynamics model through model-predictive control applied at each keypoint. Preliminary experiments of G-DOOM on a set of challenging rope and cloth manipulation tasks indicate strong performance, compared with state-of-the-art methods. Although trained in a simulator, G-DOOM transfers directly to a real robot for both rope and cloth manipulation 11Demo video available online at https://youtu.be/oCfbNMx2sQI.",
        "primary_area": "",
        "author": "Xiao Ma;David Hsu;Wee Sun Lee;Xiao Ma;David Hsu;Wee Sun Lee",
        "authorids": "/37086010748;/37421581500;/37366213700;/37086010748;/37421581500;/37366213700",
        "aff": "School of Computing, National University of Singapore; School of Computing, National University of Singapore; School of Computing, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811597/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10707245632945605036&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9811687",
        "title": "Learning Local Event-based Descriptor for Patch-based Stereo Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Stereo matching is an indispensable function that enables machine vision system to obtain depth information of its environment. However, most of existing algorithms rely on conventional camera, which follows the frame-based scheme and has several shortcomings: low dynamic range, low temporal resolution and high power consumption. To address these issues, we propose two novel patch-based stereo matching methods that exploit the output from a pair of neuromorphic vision sensors. Compared to frame-based camera, neuromorphic vision sensor has independent pixels that generates events at the time intensity changes occur. Based on this unique output, we first construct event representations and present a novel encoding method, which integrates with attention mechanism to encode rich spatial-temporal information of event streams. Then, we design efficient and accuracy networks and propose corresponding loss to train them, which are used to extract event-based descriptors from representations. Finally, the disparity maps are calculated based on local features and refined by two simple smoothing methods. Extensive experiments on the Multi Vehicle Stereo Event Camera Dataset demonstrate the effectiveness of our methods.",
        "primary_area": "",
        "author": "Peigen Liu;Guang Chen;Zhijun Li;Huajin Tang;Alois Knoll;Peigen Liu;Guang Chen;Zhijun Li;Huajin Tang;Alois Knoll",
        "authorids": "/37088396059;/38251904000;/37309823400;/37274558400;/37276234100;/37088396059;/38251904000;/37309823400;/37274558400;/37276234100",
        "aff": "Department of Automotive Engineering, Tongji University, Shanghai, China; Department of Automotive Engineering, Tongji University, Shanghai, China; Department of Automation, University of Science and Technology, Hefei, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Chair of Robotics, Artificial Intelligence and Real-time Systems, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811687/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16722070641776759645&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;3",
        "aff_unique_norm": "Tongji University;University of Science and Technology of China;Zhejiang University;Technical University of Munich",
        "aff_unique_dep": "Department of Automotive Engineering;Department of Automation;College of Computer Science and Technology;Chair of Robotics, Artificial Intelligence and Real-time Systems",
        "aff_unique_url": "https://www.tongji.edu.cn;http://www.ustc.edu.cn;http://www.zju.edu.cn;https://www.tum.de",
        "aff_unique_abbr": "Tongji;USTC;ZJU;TUM",
        "aff_campus_unique_index": "0;0;1;2;3",
        "aff_campus_unique": "Shanghai;Hefei;Hangzhou;Munich",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "9812077",
        "title": "Learning Model Predictive Control for Quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial robots can enhance their safe and agile navigation in complex and cluttered environments by efficiently exploiting the information collected during a given task. In this paper, we address the learning model predictive control problem for quadrotors. We design a learning receding-horizon nonlinear control strategy directly formulated on the system nonlinear manifold configuration space SO(3)\u00d7R3. The proposed approach exploits past successful task iterations to improve the system performance over time while respecting system dynamics and actuator constraints. We further relax its computational complexity making it compatible with real-time quadrotor control requirements. We show the effectiveness of the proposed approach in learning a minimum time control task, respecting dynamics, actuators, and environment constraints. Several experiments in simulation and real-world set-up validate the proposed approach.",
        "primary_area": "",
        "author": "Guanrui Li;Alex Tunchez;Giuseppe Loianno;Guanrui Li;Alex Tunchez;Giuseppe Loianno",
        "authorids": "/37086455447;/37089001498;/37085496544;/37086455447;/37089001498;/37085496544",
        "aff": "New York University, Tandon School of Engineering, Brooklyn, NY, USA; New York University, Tandon School of Engineering, Brooklyn, NY, USA; New York University, Tandon School of Engineering, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812077/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4779812374076606449&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "Tandon School of Engineering",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brooklyn",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811697",
        "title": "Learning Multi-Task Transferable Rewards via Variational Inverse Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Many robotic tasks are composed of a lot of temporally correlated sub-tasks in a highly complex environment. It is important to discover situational intentions and proper actions by deliberating on temporal abstractions to solve problems effectively. To understand the intention separated from changing task dynamics, we extend an empowerment-based regularization technique to situations with multiple tasks based on the framework of a generative adversarial network. Under the multitask environments with unknown dynamics, we focus on learning a reward and policy from the unlabeled expert examples. In this study, we define situational empowerment as the maximum of mutual information representing how an action conditioned on both a certain state and sub-task affects the future. Our proposed method derives the variational lower bound of the situational mutual information to optimize it. We simultaneously learn the transferable multi-task reward function and policy by adding an induced term to the objective function. By doing so, the multi-task reward function helps to learn a robust policy for environmental change. We validate the advantages of our approach on multi-task learning and multi-task transfer learning. We demonstrate our proposed method has the robustness of both randomness and changing task dynamics. Finally, we prove that our method has significantly better performance and data efficiency than existing imitation learning methods on various benchmarks.",
        "primary_area": "",
        "author": "Se-Wook Yoo;Seung-Woo Seo;Se-Wook Yoo;Seung-Woo Seo",
        "authorids": "/37089355796;/37271925900;/37089355796;/37271925900",
        "aff": "Department of Electrical and Computer Engineering, Seoul National University, Republic of Korea; Department of Electrical and Computer Engineering, Seoul National University, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811697/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7896204482912708680&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812251",
        "title": "Learning Multi-step Robotic Manipulation Policies from Visual Observation of Scene and Q-value Predictions of Previous Action",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we focus on multi-step manipulation tasks that involve long-horizon planning and considers progress reversal. Such tasks interlace high-level reasoning that consists of the expected states that can be attained to achieve an overall task and low-level reasoning that decides what actions will yield these states. We propose a sample efficient Previous Action Conditioned Robotic Manipulation Network (PAC-RoManNet) to learn the action-value functions and predict manipulation action candidates from visual observation of the scene and action-value predictions of the previous action. We define a Task Progress based Gaussian (TPG) reward function that computes the reward based on actions that lead to successful motion primitives and progress towards the overall task goal. To balance the ratio of exploration/exploitation, we introduce a Loss Adjusted Exploration (LAE) policy that determines actions from the action candidates according to the Boltzmann distribution of loss estimates. We demonstrate the effectiveness of our approach by training PAC-RoManNet to learn several challenging multi-step robotic manipulation tasks in both simulation and real-world. Experimental results show that our method outperforms the existing methods and achieves state-of-the-art performance in terms of success rate and action efficiency. The ablation studies show that TPG and LAE are especially beneficial for tasks like multiple block stacking. Additional experiments on Ravens-10 benchmark tasks suggest good generalizability of the proposed PAC-RoManNet.",
        "primary_area": "",
        "author": "Sulabh Kumra;Shirin Joshi;Ferat Sahin;Sulabh Kumra;Shirin Joshi;Ferat Sahin",
        "authorids": "/38666961800;/37088525671;/37396486100;/38666961800;/37088525671;/37396486100",
        "aff": "OSARO Inc, San Francisco, CA, USA; Siemens Corporation, Corporate Technology, Berkeley, CA; Rochester Institute of Technology, Rochester, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812251/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16914886182774066554&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Osaro Inc;Siemens Corporation;Rochester Institute of Technology",
        "aff_unique_dep": ";Corporate Technology;",
        "aff_unique_url": "https://www.osaro.com;https://www.siemens.com;https://www.rit.edu",
        "aff_unique_abbr": "OSARO;Siemens;RIT",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "San Francisco;Berkeley;Rochester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811601",
        "title": "Learning Object Relations with Graph Neural Networks for Target-Driven Grasping in Dense Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots in the real world frequently come across identical objects in dense clutter. When evaluating grasp poses in these scenarios, a target-driven grasping system requires knowledge of spatial relations between scene objects (e.g., proximity, adjacency, and occlusions). To efficiently complete this task, we propose a target-driven grasping system that simultaneously considers object relations and predicts 6-DoF grasp poses. A densely cluttered scene is first formulated as a grasp graph with nodes representing object geometries in the grasp coordinate frame and edges indicating spatial relations between the objects. We design a Grasp Graph Neural Network (G2N2) that evaluates the grasp graph and finds the most feasible 6-DoF grasp pose for a target object. Additionally, we develop a shape completion-assisted grasp pose sampling method that improves sample quality and consequently grasping efficiency. We compare our method against several baselines in both simulated and real settings. In real-world experiments with novel objects, our approach achieves a 77.78% grasping accuracy in densely cluttered scenarios, surpassing the best-performing baseline by more than 15%. Supplementary material is available at https://sites.google.com/umn.edu/graph-grasping.",
        "primary_area": "",
        "author": "Xibai Lou;Yang Yang;Changhyun Choi;Xibai Lou;Yang Yang;Changhyun Choi",
        "authorids": "/37088504165;/37088070512;/37085811337;/37088504165;/37088070512;/37085811337",
        "aff": "Department of Electrical and Computer Engineering, Univ. of Minnesota, Minneapolis, USA; Department of Computer Science and Engineering, Univ. of Minnesota, Minneapolis, USA; Department of Electrical and Computer Engineering, Univ. of Minnesota, Minneapolis, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811601/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17061606460900115843&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811950",
        "title": "Learning Observation-Based Certifiable Safe Policy for Decentralized Multi-Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety is of great importance in multi-robot navigation problems. In this paper, we propose a control barrier function (CBF) based optimizer that ensures robot safety with both high probability and flexibility, using only sensor measurement. The optimizer takes action commands from the policy network as initial values and provides refinement to drive the potentially dangerous ones back into safe regions. With the help of a deep world model that predicts the evolution of surrounding dynamics and the consequences of different actions, the CBF module can guide the optimization within a reasonable time horizon. We also present a novel joint training framework that improves the cooperation between the Reinforcement Learning (RL) based policy and the CBF-based optimizer by utilizing reward feedback from the CBF module. We observe that our policy can achieve a higher success rate while maintaining the safety of multiple robots in significantly fewer episodes. Experiments are conducted in multiple scenarios both in simulation and the real world, the results demonstrate the effectiveness of our method in maintaining the safety of multiple robots. Code is available at https://github.com/YuxiangCui/MARL-OCBF.",
        "primary_area": "",
        "author": "Yuxiang Cui;Longzhong Lin;Xiaolong Huang;Dongkun Zhang;Yunkai Wang;Wei Jing;Junbo Chen;Rong Xiong;Yue Wang;Yuxiang Cui;Longzhong Lin;Xiaolong Huang;Dongkun Zhang;Yunkai Wang;Wei Jing;Junbo Chen;Rong Xiong;Yue Wang",
        "authorids": "/37088954385;/37089346617;/37088953173;/37087886680;/37088600631;/37085809046;/37089196396;/37271511300;/37072299700;/37088954385;/37089346617;/37088953173;/37087886680;/37088600631;/37085809046;/37089196396;/37271511300;/37072299700",
        "aff": "State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Department of Autonomous, Driving Lab, Alibaba DAMO Academy, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Department of Autonomous, Driving Lab, Alibaba DAMO Academy, Hangzhou, China; Department of Autonomous, Driving Lab, Alibaba DAMO Academy, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811950/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8867824483390446801&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;1;0;1;1;0;0",
        "aff_unique_norm": "Zhejiang University;Alibaba DAMO Academy",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control;Department of Autonomous, Driving Lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://damo.alibaba.com",
        "aff_unique_abbr": "ZJU;Alibaba DAMO",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812402",
        "title": "Learning Periodic Tasks from Human Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop a method for learning periodic tasks from visual demonstrations. The core idea is to leverage periodicity in the policy structure to model periodic aspects of the tasks. We use active learning to optimize parameters of rhythmic dynamic movement primitives (rDMPs) and propose an objective to maximize the similarity between the motion of objects manipulated by the robot and the desired motion in human video demonstrations. We consider tasks with deformable objects and granular matter whose states are challenging to represent and track: wiping surfaces with a cloth, winding cables, and stirring granular matter with a spoon. Our method does not require tracking markers or manual annotations. The initial training data consists of 10-minute videos of random unpaired interactions with objects by the robot and human. We use these for unsupervised learning of a keypoint model to get task-agnostic visual correspondences. Then, we use Bayesian optimization to optimize rDMPs from a single human video demonstration within few robot trials. We present simulation and hardware experiments to validate our approach.",
        "primary_area": "",
        "author": "Jingyun Yang;Junwu Zhang;Connor Settle;Akshara Rai;Rika Antonova;Jeannette Bohg;Jingyun Yang;Junwu Zhang;Connor Settle;Akshara Rai;Rika Antonova;Jeannette Bohg",
        "authorids": "/37089353827;/37089449214;/37089448899;/37085480350;/37085991913;/37591153900;/37089353827;/37089449214;/37089448899;/37085480350;/37085991913;/37591153900",
        "aff": "Machine Learning Department, Carnegie Mellon University; Department of Mechanical Engineering, Stanford University; Department of Computer Science, Stanford University; Meta AI.; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812402/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1840850935271300016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;1;1",
        "aff_unique_norm": "Carnegie Mellon University;Stanford University;Meta",
        "aff_unique_dep": "Machine Learning Department;Department of Mechanical Engineering;Meta AI",
        "aff_unique_url": "https://www.cmu.edu;https://www.stanford.edu;https://meta.com",
        "aff_unique_abbr": "CMU;Stanford;Meta AI",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812093",
        "title": "Learning Purely Tactile In-Hand Manipulation with a Torque-Controlled Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "We show that a purely tactile dextrous in-hand manipulation task with continuous regrasping, requiring permanent force closure, can be learned from scratch and executed robustly on a torque-controlled humanoid robotic hand. The task is rotating a cube without dropping it, but in contrast to OpenAI's seminal cube manipulation task [1], the palm faces downwards and no cameras but only the hand's position and torque sensing are used. Although the task seems simple, it combines for the first time all the challenges in execution as well as learning that are important for using in-hand manipulation in real-world applications. We efficiently train in a precisely modeled and identified rigid body simulation with off-policy deep reinforcement learning, significantly sped up by a domain adapted curriculum, leading to a moderate 600 CPU hours of training time. The resulting policy is robustly transferred to the real humanoid DLR Hand-II, e.g., reaching more than 46 full 2\\pi2\\pi rotations of the cube in a single run and allowing for disturbances like different cube sizes, hand orientation, or pulling a finger.",
        "primary_area": "",
        "author": "Leon Sievers;Johannes Pitz;Berthold B\u00e4uml;Leon Sievers;Johannes Pitz;Berthold B\u00e4uml",
        "authorids": "/37089450909;/37089449984;/37295469600;/37089450909;/37089449984;/37295469600",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR) and the Deggendorf Institute of Technology, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR) and the Deggendorf Institute of Technology, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR) and the Deggendorf Institute of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812093/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5163244195322331747&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "German Aerospace Center (DLR)",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812370",
        "title": "Learning Scalable Policies over Graphs for Multi-Robot Task Allocation using Capsule Attention Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel graph reinforcement learning (RL) architecture to solve multi-robot task allocation (MRTA) problems that involve tasks with deadlines and workload, and robot constraints such as work capacity. While drawing motivation from recent graph learning methods that learn to solve combinatorial optimization (CO) problems such as multi-Traveling Salesman and Vehicle Routing Problems using RL, this paper seeks to provide better performance (compared to non-learning methods) and important scalability (compared to existing learning architectures) for the stated class of MRTA problems. The proposed neural architecture, called Capsule Attention-based Mechanism or CapAM acts as the policy network, and includes three main components: 1) an encoder: a Capsule Network based node embedding model to represent each task as a learnable feature vector; 2) a decoder: an attention-based model to facilitate a sequential output; and 3) context: that encodes the states of the mission and the robots. To train the CapAM model, the policy-gradient method based on REINFORCE is used. When evaluated over unseen scenar-ios, CapAM demonstrates better task completion performance and > 10 times faster decision-making compared to standard non-learning based online MRTA methods. CapAM's advantage in generalizability, and scalability to test problems of size larger than those used in training, are also successfully demonstrated in comparison to a popular approach for learning to solve CO problems, namely the purely attention mechanism.",
        "primary_area": "",
        "author": "Steve Paul;Payam Ghassemi;Souma Chowdhury;Steve Paul;Payam Ghassemi;Souma Chowdhury",
        "authorids": "/37086118266;/37085518637;/37086117851;/37086118266;/37085518637;/37086117851",
        "aff": "department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA; department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA; department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812370/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8955666324899230859&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University at Buffalo",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.buffalo.edu",
        "aff_unique_abbr": "UB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Buffalo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811703",
        "title": "Learning Sensorimotor Primitives of Sequential Manipulation Tasks from Visual Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "This work aims to learn how to perform complex robot manipulation tasks that are composed of several, consecutively executed low-level sub-tasks, given as input a few visual demonstrations of the tasks performed by a person. The sub-tasks consist of moving the robot's end-effector until it reaches a sub-goal region in the task space, performing an action, and triggering the next sub-task when a pre-condition is met. Most prior work in this domain has been concerned with learning only low-level tasks, such as hitting a ball or reaching an object and grasping it. This paper describes a new neural network-based framework for learning simultaneously low-level policies as well as high-level policies, such as deciding which object to pick next or where to place it relative to other objects in the scene. A key feature of the proposed approach is that the policies are learned directly from raw videos of task demonstrations, without any manual annotation or post-processing of the data. Empirical results on object manipulation tasks with a robotic arm show that the proposed network can efficiently learn from real visual demonstrations to perform the tasks, and outperforms popular imitation learning algorithms.",
        "primary_area": "",
        "author": "Junchi Liang;Bowen Wen;Kostas Bekris;Abdeslam Boularias;Junchi Liang;Bowen Wen;Kostas Bekris;Abdeslam Boularias",
        "authorids": "/37088689223;/37088488448;/37282424700;/37542596800;/37088689223;/37088488448;/37282424700;/37542596800",
        "aff": "Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811703/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10131504665693053783&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812297",
        "title": "Learning Spatiotemporal Occupancy Grid Maps for Lifelong Navigation in Dynamic Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel method for generating, predicting, and using Spatiotemporal Occupancy Grid Maps (SOGM), which embed future information of dynamic scenes. Our au-tomated generation process creates groundtruth SOGMs from previous navigation data. We build on prior work to annotate lidar points based on their dynamic properties, which are then projected on time-stamped 2D grids: SOGMs. We design a 3D-2D feedforward architecture, trained to predict the future time steps of SOGMs, given 3D lidar frames as input. Our pipeline is entirely self-supervised, thus enabling lifelong learning for robots. The network is composed of a 3D back-end that extracts rich features and enables the semantic segmentation of the lidar frames, and a 2D front-end that predicts the future information embedded in the SOGMs within planning. We also design a navigation pipeline that uses these predicted SOGMs. We provide both quantitative and qualitative insights into the predictions and validate our choices of network design with a comparison to the state of the art and ablation studies.",
        "primary_area": "",
        "author": "Hugues Thomas;Matthieu Gallet de Saint Aurin;Jian Zhang;Timothy D. Barfoot;Hugues Thomas;Matthieu Gallet de Saint Aurin;Jian Zhang;Timothy D. Barfoot",
        "authorids": "/37088643515;/37089447238;/37086568802;/37283734000;/37088643515;/37089447238;/37086568802;/37283734000",
        "aff": "University of Toronto Institute for Aerospace Studies (UTIAS), Canada; ETH, Z\u00fcrich, Switzerland; Apple Inc.; University of Toronto Institute for Aerospace Studies (UTIAS), Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812297/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16958692500142686972&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Toronto Institute for Aerospace Studies;ETH Zurich;Apple",
        "aff_unique_dep": "Institute for Aerospace Studies;;Apple Inc.",
        "aff_unique_url": "https://utias.utoronto.ca;https://www.ethz.ch;https://www.apple.com",
        "aff_unique_abbr": "UTIAS;ETH;Apple",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Z\u00fcrich",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "Canada;Switzerland;United States"
    },
    {
        "id": "9811944",
        "title": "Learning Stable Dynamical Systems for Visual Servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents the dual benefit of integrating imitation learning techniques, based on the dynamical systems formalism, with the visual servoing paradigm. On the one hand, dynamical systems allow to program additional skills without explicitly coding them in the visual servoing law, but leveraging few demonstrations of the full desired behavior. On the other, visual servoing allows to consider exteroception into the dynam-ical system architecture and be able to adapt to unexpected environment changes. The beneficial combination of the two concepts is proven by applying three existing dynamical systems methods to the visual servoing case. Simulations validate and compare the methods; experiments with a robot manipulator show the validity of the approach in a real-world scenario.",
        "primary_area": "",
        "author": "Antonio Paolillo;Matteo Saveriano;Antonio Paolillo;Matteo Saveriano",
        "authorids": "/37077525100;/38542234400;/37077525100;/38542234400",
        "aff": "Dalle Molle Institute for Artificial Intelligence (IDSIA), USI-SUPSI, Lugano, Switzerland; Department of Industrial Engineering (DII), University of Trento, Trento, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811944/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10979069943617478513&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Dalle Molle Institute for Artificial Intelligence;University of Trento",
        "aff_unique_dep": "Institute for Artificial Intelligence;Department of Industrial Engineering",
        "aff_unique_url": "https://www.idsia.ch/;https://www.unitn.it",
        "aff_unique_abbr": "IDSIA;UniTN",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Lugano;Trento",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Switzerland;Italy"
    },
    {
        "id": "9812215",
        "title": "Learning Visual Shape Control of Novel 3D Deformable Objects from Partial-View Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "If robots could reliably manipulate the shape of 3D deformable objects, they could find applications in fields ranging from home care to warehouse fulfillment to surgical assistance. Analytic models of elastic, 3D deformable objects require numerous parameters to describe the potentially infinite degrees of freedom present in determining the object's shape. Previous attempts at performing 3D shape control rely on hand-crafted features to represent the object shape and require training of object-specific control models. We overcome these issues through the use of our novel DeformerNet neural network architecture, which operates on a partial-view point cloud of the object being manipulated and a point cloud of the goal shape to learn a low-dimensional representation of the object shape. This shape embedding enables the robot to learn to define a visual servo controller that provides Cartesian pose changes to the robot end-effector causing the object to deform towards its target shape. Crucially, we demonstrate both in simulation and on a physical robot that DeformerNet reliably generalizes to object shapes and material stiffness not seen during training and outperforms comparison methods for both the generic shape control and the surgical task of retraction.",
        "primary_area": "",
        "author": "Bao Thach;Brian Y. Cho;Alan Kuntz;Tucker Hermans;Bao Thach;Brian Y. Cho;Alan Kuntz;Tucker Hermans",
        "authorids": "/37089449513;/37088505344;/37085508764;/38230909600;/37089449513;/37088505344;/37085508764;/38230909600",
        "aff": "Robotics Center and School of Computing, University of Utah, Salt Lake City, UT, USA; Robotics Center and School of Computing, University of Utah, Salt Lake City, UT, USA; Robotics Center and School of Computing, University of Utah, Salt Lake City, UT, USA; NVIDIA Corporation, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812215/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17059229650864066858&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Utah;NVIDIA",
        "aff_unique_dep": "Robotics Center and School of Computing;NVIDIA Corporation",
        "aff_unique_url": "https://www.utah.edu;https://www.nvidia.com",
        "aff_unique_abbr": "U of U;NVIDIA",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Salt Lake City;Seattle",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811891",
        "title": "Learning from Imperfect Demonstrations via Adversarial Confidence Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing learning from demonstration algorithms usually assume access to expert demonstrations. However, this assumption is limiting in many real-world applications since the collected demonstrations may be suboptimal or even consist of failure cases. We therefore study the problem of learning from imperfect demonstrations by learning a confidence predictor. Specifically, we rely on demonstrations along with their confidence values from a different correspondent environment (source environment) to learn a confidence predictor for the environment we aim to learn a policy in (target environment-where we only have unlabeled demonstrations). We learn a common latent space through adversarial distribution matching of multi-length partial trajectories to enable the transfer of confidence across source and target environments. The learned confidence reweights the demonstrations to enable learning more from informative demonstrations and discarding the irrelevant ones. Our experiments in three simulated environments and a real robot reaching task demonstrate that our approach learns a policy with the highest expected return. We show the videos of our experiments on our website.",
        "primary_area": "",
        "author": "Zhangjie Cao;Zihan Wang;Dorsa Sadigh;Zhangjie Cao;Zihan Wang;Dorsa Sadigh",
        "authorids": "/37089504094;/37089447875;/38234464200;/37089504094;/37089447875;/38234464200",
        "aff": "Computer Science, Stanford University, CA, USA; Computer Science, Stanford University, CA, USA; Computer Science, Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811891/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=83699142780006253&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811592",
        "title": "Learning to Detect Slip with Barometric Tactile Sensors and a Temporal Convolutional Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to perceive object slip via tactile feedback enables humans to accomplish complex manipulation tasks including maintaining a stable grasp. Despite the utility of tactile information for many applications, tactile sensors have yet to be widely deployed in industrial robotics settings; part of the challenge lies in identifying slip and other events from the tactile data stream. In this paper, we present a learning-based method to detect slip using barometric tactile sensors. These sensors have many desirable properties including high durability and reliability, and are built from inexpensive, off-the-shelf components. We train a temporal convolution neural network to detect slip, achieving high detection accuracies while displaying robustness to the speed and direction of the slip motion. Further, we test our detector on two manipulation tasks involving a variety of common objects and demonstrate successful generalization to real-world scenarios not seen during training. We argue that barometric tactile sensing technology, combined with data-driven learning, is suitable for many manipulation tasks such as slip compensation.",
        "primary_area": "",
        "author": "Abhinav Grover;Philippe Nadeau;Christopher Grebe;Jonathan Kelly;Abhinav Grover;Philippe Nadeau;Christopher Grebe;Jonathan Kelly",
        "authorids": "/37088541458;/37088507489;/37089002066;/37085364182;/37088541458;/37088507489;/37089002066;/37085364182",
        "aff": "Space & Terrestrial Autonomous Robotics Systems (STARS) Laboratory, University of Toronto Institute for Aerospace Studies, Toronto, Ontario, Canada; Space & Terrestrial Autonomous Robotics Systems (STARS) Laboratory, University of Toronto Institute for Aerospace Studies, Toronto, Ontario, Canada; Space & Terrestrial Autonomous Robotics Systems (STARS) Laboratory, University of Toronto Institute for Aerospace Studies, Toronto, Ontario, Canada; Space & Terrestrial Autonomous Robotics Systems (STARS) Laboratory, University of Toronto Institute for Aerospace Studies, Toronto, Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811592/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17448584003923078995&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Toronto Institute for Aerospace Studies",
        "aff_unique_dep": "Space & Terrestrial Autonomous Robotics Systems (STARS) Laboratory",
        "aff_unique_url": "https://www.ias.utoronto.ca",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812429",
        "title": "Learning to Fill the Seam by Vision: Sub-millimeter Peg-in-hole on Unseen Shapes in Real World",
        "track": "main",
        "status": "Poster",
        "abstract": "In the peg insertion task, human pays attention to the seam between the peg and the hole and tries to fill it continuously with visual feedback. By imitating the human's behavior, we design architectures with position and orientation estimators based on the seam representation for pose alignment, which proves to be general to the unseen peg geometries. By putting the estimators into the closed-loop control with reinforcement learning, we further achieve higher or comparable success rate, efficiency, and robustness compared with the baseline methods. The policy is trained totally in simulation without any manual intervention. To achieve sim-to-real, a learnable segmentation module with automatic data collecting and labeling can be easily trained to decouple the perception and the policy, which helps the model trained in simulation quickly adapting to the real world with negligible effort. Results are presented in simulation and on a physical robot. Code, videos, and supplemental material are available at https://github.com/xieliang555/SFN.git",
        "primary_area": "",
        "author": "Liang Xie;Hongxiang Yu;Yinghao Zhao;Haodong Zhang;Zhongxiang Zhou;Minhang Wang;Yue Wang;Rong Xiong;Liang Xie;Hongxiang Yu;Yinghao Zhao;Haodong Zhang;Zhongxiang Zhou;Minhang Wang;Yue Wang;Rong Xiong",
        "authorids": "/37087005862;/37086345520;/37089450994;/37089393786;/37088809302;/37088662584;/37072299700;/37271511300;/37087005862;/37086345520;/37089450994;/37089393786;/37088809302;/37088662584;/37072299700;/37271511300",
        "aff": "State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Application Innovate Lab, Huawei Incorporated Company, P.R. China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812429/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=209660816452497997&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Zhejiang University;Huawei",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control;Application Innovate Lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "ZJU;Huawei",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811968",
        "title": "Learning to Infer Kinematic Hierarchies for Novel Object Instances",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulating an articulated object requires perceiving its kinematic hierarchy: its parts, how each can move, and how those motions are coupled. Previous work has explored perception for kinematics, but none infers a complete kinematic hierarchy on never-before-seen object instances, without relying on a schema or template. We present a novel perception system that achieves this goal. Our system infers the moving parts of an object and the kinematic couplings that relate them. To infer parts, it uses a point cloud instance segmentation neural network and to infer kinematic hierarchies, it uses a graph neural network to predict the existence, direction, and type of edges (i.e. joints) that relate the inferred parts. We train these networks using simulated scans of synthetic 3D models. We evaluate our system on simulated scans of 3D objects, and we demonstrate a proof-of-concept use of our system to drive real-world robotic manipulation.",
        "primary_area": "",
        "author": "Hameed Abdul-Rashid;Miles Freeman;Ben Abbatematteo;George Konidaris;Daniel Ritchie;Hameed Abdul-Rashid;Miles Freeman;Ben Abbatematteo;George Konidaris;Daniel Ritchie",
        "authorids": "/37086823369;/37089449786;/37089197450;/38318614200;/37086579449;/37086823369;/37089449786;/37089197450;/38318614200;/37086579449",
        "aff": "University of Illinois at Urbana-Champaign; Brown University; Brown University; Brown University; Brown University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811968/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12325491101787242793&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Brown University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://illinois.edu;https://www.brown.edu",
        "aff_unique_abbr": "UIUC;Brown",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Urbana-Champaign;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812193",
        "title": "Learning to Listen and Move: An Implementation of Audio-Aware Mobile Robot Navigation in Complex Indoor Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Sound is an essential navigation cue that intelligent robots can leverage for localizing sound-emitting targets. This work introduces a framework for the audio-aware navigation task of mobile robots equipped with a microphone array in a complex indoor environment. The robot initialized at a random starting position has to accurately localize a distant sound source and plan an optimal path towards the sound-emitting target. Auto-encoders are used to extract implicit acoustic features that are robust against environmental noise and reverberation. The proposed framework is based on two key ideas - a sound inference module (SIM) that maps the perceived acoustic information to a given geometric map of the physical space, and a path planner that generates a path from the robot's current position to the estimated position of the sound source. Experimental results show that the SIM achieved a minimum and maximum localization error of 0.31 m and 0.70 m at a robot-source distance of 1 m and 6 m, respectively at different environmental configurations. Additionally, the proposed framework achieved a minimum and maximum reliability of 4.38 m^{-1}m^{-1} and 2.31 m^{-1}m^{-1} at a robot-source distance of 1 m and 6 m, respectively under the influence of background noise.",
        "primary_area": "",
        "author": "Pratyaksh P. Rao;Abhra Roy Chowdhury;Pratyaksh P. Rao;Abhra Roy Chowdhury",
        "authorids": "/37088699133;/37088568061;/37088699133;/37088568061",
        "aff": "Department of Electrical and Computer Engineering, New York University, New York, USA; Centre for Product Design and Manufacturing (CPDM), Indian Institute of Science (IISc), Bangalore, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812193/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3304950030452535822&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "New York University;Indian Institute of Science",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Centre for Product Design and Manufacturing",
        "aff_unique_url": "https://www.nyu.edu;https://www.iisc.ac.in",
        "aff_unique_abbr": "NYU;IISc",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "New York;Bangalore",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "9812393",
        "title": "Learning to Localize, Grasp, and Hand Over Unmodified Surgical Needles",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic Surgical Assistants (RSAs) are commonly used to perform minimally invasive surgeries by expert surgeons. However, long procedures filled with tedious and repetitive tasks such as suturing can lead to surgeon fatigue, motivating the automation of suturing. As visual tracking of a thin reflective needle is extremely challenging, prior work has modified the needle with nonreflective contrasting paint. As a step towards automation of a suturing subtask without modifying the needle, we propose HOUSTON: Handover of Unmodified, Surgical, Tool-Obstructed Needles, a problem and algorithm that uses a learned active sensing policy with a stereo camera to iteratively localize and align the needle into a visible and accessible pose for the other gripper. To compensate for robot positioning and needle perception errors, the algorithm then executes a high-precision grasping motion that uses multiple cameras. Physical experiments with the da Vinci Research Kit (dVRK) suggest a success rate of 96.7% on needles used in training, and 75 - 92.9% on needles unseen in training. On sequential handovers, HOUSTON successfully executes 32.4 handovers on average before failure. To our knowledge, this work is the first to study handover of unmodified surgical needles. See https: / /tinyurl. com/houston-surgery for additional materials including details about offline datasets and model architectures.",
        "primary_area": "",
        "author": "Albert Wilcox;Justin Kerr;Brijen Thananjeyan;Jeffrey Ichnowski;Minho Hwang;Samuel Paradis;Danyal Fer;Ken Goldberg;Albert Wilcox;Justin Kerr;Brijen Thananjeyan;Jeffrey Ichnowski;Minho Hwang;Samuel Paradis;Danyal Fer;Ken Goldberg",
        "authorids": "/37089279177;/37086803999;/37086105009;/38541287200;/37085406507;/37088451566;/37086541068;/37273026700;/37089279177;/37086803999;/37086105009;/38541287200;/37085406507;/37088451566;/37086541068;/37273026700",
        "aff": "The AUTOLab at UC Berkeley, Baton Rouge, USA; The AUTOLab at UC Berkeley, Baton Rouge, USA; The AUTOLab at UC Berkeley, Baton Rouge, USA; The AUTOLab at UC Berkeley, Baton Rouge, USA; The AUTOLab at UC Berkeley, Baton Rouge, USA; The AUTOLab at UC Berkeley, Baton Rouge, USA; The AUTOLab at UC Berkeley, Baton Rouge, USA; The AUTOLab at UC Berkeley, Baton Rouge, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812393/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9801338427461700052&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "AUTOLab",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811635",
        "title": "Learning to Navigate Intersections with Unsupervised Driver Trait Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigation through uncontrolled intersections is one of the key challenges for autonomous vehicles. Identifying the subtle differences in hidden traits of other drivers can bring significant benefits when navigating in such environments. We propose an unsupervised method for inferring driver traits such as driving styles from observed vehicle trajectories. We use a variational autoencoder with recurrent neural networks to learn a latent representation of traits without any ground truth trait labels. Then, we use this trait representation to learn a policy for an autonomous vehicle to navigate through a T-intersection with deep reinforcement learning. Our pipeline enables the autonomous vehicle to adjust its actions when dealing with drivers of different traits to ensure safety and efficiency. Our method demonstrates promising performance and outperforms state-of-the-art baselines in the T-intersection scenario.",
        "primary_area": "",
        "author": "Shuijing Liu;Peixin Chang;Haonan Chen;Neeloy Chakraborty;Katherine Driggs-Campbell;Shuijing Liu;Peixin Chang;Haonan Chen;Neeloy Chakraborty;Katherine Driggs-Campbell",
        "authorids": "/37088687174;/37088688639;/37088504797;/37088996927;/37085509519;/37088687174;/37088688639;/37088504797;/37088996927;/37085509519",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811635/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16312627960976885253&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812194",
        "title": "Learning to Navigate by Pushing",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we investigate a form of dynamic contact-rich locomotion in which a robot pushes off from obstacles in order to move through its environment. We present a reflex-based approach that switches between optimized hand-crafted reflex controllers and produces smooth and predictable motions. In contrast to previous work, our approach does not rely on periodic movements, complex models of robot and contact dynamics, or extensive hand tuning. We demonstrate the effectiveness of our approach and evaluate its performance compared to a standard model-free RL algorithm. We identify continuous clusters of similar behaviours, which allows us to successfully transfer different push-off motions directly from simulation to a physical robot without further retraining.",
        "primary_area": "",
        "author": "Cornelia Bauer;Dominik Bauer;Alisa Allaire;Christopher G. Atkeson;Nancy Pollard;Cornelia Bauer;Dominik Bauer;Alisa Allaire;Christopher G. Atkeson;Nancy Pollard",
        "authorids": "/37089372008;/37086606269;/37089450215;/37277593800;/37341211200;/37089372008;/37086606269;/37089450215;/37277593800;/37341211200",
        "aff": "Robotics Institute, Carnegie Mellon Univ, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon Univ, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon Univ, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon Univ, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon Univ, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812194/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11059803711123978978&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812369",
        "title": "Learning to Optimize in Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based Model Predictive Control (MPC) is a flexible control framework that can reason about non-smooth dynamics and cost functions. Recently, significant work has focused on the use of machine learning to improve the performance of MPC, often through learning or fine-tuning the dynamics or cost function. In contrast, we focus on learning to optimize more effectively. In other words, to improve the update rule within MPC. We show that this can be particularly useful in sampling-based MPC, where we often wish to minimize the number of samples for computational reasons. Unfortunately, the cost of computational efficiency is a reduction in performance; fewer samples results in noisier updates. We show that we can contend with this noise by learning how to update the control distribution more effectively and make better use of the few samples that we have. Our learned controllers are trained via imitation learning to mimic an expert which has access to substantially more samples. We test the efficacy of our approach on multiple simulated robotics tasks in sample-constrained regimes and demonstrate that our approach can outperform a MPC controller with the same number of samples.",
        "primary_area": "",
        "author": "Jacob Sacks;Byron Boots;Jacob Sacks;Byron Boots",
        "authorids": "/37086214836;/37085459219;/37086214836;/37085459219",
        "aff": "University of Washington, Seattle, WA, USA; University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812369/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2803075772632024953&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811736",
        "title": "Learning to Pick by Digging: Data-Driven Dig-Grasping for Bin Picking from Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a data-driven approach for effective bin picking from clutter. Recent bin picking solutions usually lead to a direct pinch grasp on a target object without addressing any other potential contact interaction in clutter. However, appropriate physical interaction can be essential to successful singulation and subsequent secure picking, the goal of bin picking. In this work, we contribute a framework that learns physically interactive actions for object picking end-to-end from a visual input in a self-supervised manner. The learned actions enable the robot to purposefully interact with a target object by performing a digging operation through the clutter. By leveraging a fully convolutional network (FCN), we predict picking success probabilities for a set of interactive action primitives that will in turn specify an optimal action to perform. The FCN is trained in a simulated environment through trial and error. Moreover, new datasets are collected using the latest network through iterative self-supervision. Extensive real-world bin picking experiments show the effectiveness and generalizability of the approach.",
        "primary_area": "",
        "author": "Chao Zhao;Zhekai Tong;Juan Rojas;Jungwon Seo;Chao Zhao;Zhekai Tong;Juan Rojas;Jungwon Seo",
        "authorids": "/37089447535;/37088506915;/38469295700;/38252779400;/37089447535;/37088506915;/38469295700;/38252779400",
        "aff": "Electronic and Computer Engineering Department, The Hong Kong University of Science and Technology; Electronic and Computer Engineering Department, The Hong Kong University of Science and Technology; Mechanical and Aerospace/Electronic and Computer Engineering Department, The Hong Kong University of Science and Tech-nology; Mechanical and Automation Engineering Department, Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811736/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1791384819126217943&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Chinese University of Hong Kong",
        "aff_unique_dep": "Electronic and Computer Engineering Department;Mechanical and Automation Engineering Department",
        "aff_unique_url": "https://www.ust.hk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "HKUST;CUHK",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812076",
        "title": "Learning to Retrieve Relevant Experiences for Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work has demonstrated that motion planners' performance can be significantly improved by retrieving past experiences from a database. Typically, the experience database is queried for past similar problems using a similarity function defined over the motion planning problems. However, to date, most works rely on simple hand-crafted similarity functions and fail to generalize outside their corresponding training dataset. To address this limitation, we propose (FIRE), a framework that extracts local representations of planning problems and learns a similarity function over them. To generate the training data we introduce a novel self-supervised method that identifies similar and dissimilar pairs of local primitives from past solution paths. With these pairs, a Siamese network is trained with the contrastive loss and the similarity function is realized in the network's latent space. We evaluate FIRE on an 8-DOF manipulator in five categories of motion planning problems with sensed environments. Our experiments show that FIRE retrieves relevant experiences which can informatively guide sampling-based planners even in problems outside its training distribution, outperforming other baselines.",
        "primary_area": "",
        "author": "Constantinos Chamzas;Aedan Cullen;Anshumali Shrivastava;Lydia E. Kavraki;Constantinos Chamzas;Aedan Cullen;Anshumali Shrivastava;Lydia E. Kavraki",
        "authorids": "/37086933748;/37089449013;/37085998758;/37279015600;/37086933748;/37089449013;/37085998758;/37279015600",
        "aff": "Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812076/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6224573688972016062&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811554",
        "title": "Learning to Rock-and-Walk: Dynamic, Non-Prehensile, and Underactuated Object Locomotion Through Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "When moving objects that are too bulky or heavy to be grasped or lifted, robotic manipulation can benefit from the object's interaction with the support surface and its natural dynamics under gravity. In this work, we show that such dynamic, underactuated manipulation capability can be acquired through reinforcement learning and deployed on real robot systems. First, we present a framework to learn a control policy for object transport in a dynamic simulation environment, featuring the object and the support surface. We then demonstrate successful object locomotion with the learned policy through a set of simulated and real-world experiments, performed with a robot arm and an aerial robot interacting with the object in a non-prehensile manner. While the object, which is in contact with the support surface, oscillates sideways passively under gravity, the robot uses the learned policy to move the object forward with a steady gait by regulating the mechanical energy and the posture of the object. Our experiment results show that the learned policy can transport the object through unmodeled effects of terrain and perturbation.",
        "primary_area": "",
        "author": "Abdullah Nazir;Xu Pu;Juan Rojas;Jungwon Seo;Abdullah Nazir;Xu Pu;Juan Rojas;Jungwon Seo",
        "authorids": "/37086938255;/37089446723;/38469295700;/38252779400;/37086938255;/37089446723;/38469295700;/38252779400",
        "aff": "The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong; The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong; The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811554/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Od8FM0UO8CcJ:scholar.google.com/&scioq=Learning+to+Rock-and-Walk:+Dynamic,+Non-Prehensile,+and+Underactuated+Object+Locomotion+Through+Reinforcement+Learning&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Chinese University of Hong Kong",
        "aff_unique_dep": ";Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.ust.hk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "HKUST;CUHK",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811662",
        "title": "Learning to Socially Navigate in Pedestrian-rich Environments with Interaction Capacity",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing navigation policies for autonomous robots tend to focus on collision avoidance while ignoring human-robot interactions in social life. For instance, robots can pass along the corridor safer and easier if pedestrians notice them. Sounds have been considered as an efficient way to attract the attention of pedestrians, which can alleviate the freezing robot problem. In this work, we present a new deep reinforcement learning (DRL) based social navigation approach for autonomous robots to move in pedestrian-rich environments with interaction capacity. Most existing DRL based methods intend to train a general policy that outputs both navigation actions, i.e., expected robot's linear and angular velocities, and interaction actions, i.e., the beep action, in the context of reinforcement learning. Different from these methods, we intend to train the policy via both supervised learning and reinforcement learning. In specific, we first train an interaction policy in the context of supervised learning, which provides a better understanding of the social situation, then we use this interaction policy to train the navigation policy via multiple reinforcement learning algorithms. We evaluate our approach in various simulation environments and compare it to other methods. The experimental results show that our approach outperforms others in terms of the success rate. We also deploy the trained policy on a real-world robot, which shows a nice performance in crowded environments.",
        "primary_area": "",
        "author": "Quecheng Qiu;Shunyi Yao;Jing Wang;Jun Ma;Guangda Chen;Jianmin Ji;Quecheng Qiu;Shunyi Yao;Jing Wang;Jun Ma;Guangda Chen;Jianmin Ji",
        "authorids": "/37089194199;/37088594684;/37089450572;/37088597940;/37086702150;/38100458700;/37089194199;/37088594684;/37089450572;/37088597940;/37086702150;/38100458700",
        "aff": "School of Data Science, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, USTC, Hefei, China; School of Data Science, University of Science and Technology of China, Hefei, China; School of Data Science, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, USTC, Hefei, China; School of Computer Science and Technology, USTC, Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811662/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5675805604082691675&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "School of Data Science",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hefei",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811997",
        "title": "Learning to Swarm with Knowledge-Based Neural Ordinary Differential Equations",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding decentralized dynamics from collective behaviors in swarms is crucial for informing robot controller designs in artificial swarms and multi-agent robotic systems. However, the complexity in agent-to-agent interactions and the decentralized nature of most swarms pose a significant challenge to the extraction of single-robot control laws from collective behaviors. In this work, we consider the important task of learning decentralized single-robot controllers based solely on the state observations of a swarm's trajectory. We present a general framework by adopting knowledge-based neural ordinary differential equations (KNODE) \u2500 a hybrid machine learning method capable of combining artificial neural networks with known agent dynamics. Our approach distinguishes itself from most prior works in that we do not require action data for learning. We apply our framework to two different flocking swarms in 2D and 3D respectively, and demonstrate efficient training by leveraging the graphical structure of the swarms' information network. We further show that the learnt single-robot controllers can not only mimic flocking behavior in the original swarm but also scale to swarms with more robots.",
        "primary_area": "",
        "author": "Tom Z. Jiahao;Lishuo Pan;M. Ani Hsieh;Tom Z. Jiahao;Lishuo Pan;M. Ani Hsieh",
        "authorids": "/37089281208;/37086450935;/38238444800;/37089281208;/37086450935;/38238444800",
        "aff": "GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811997/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17193077947203816986&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812092",
        "title": "Learning to Synthesize Volumetric Meshes from Vision-based Tactile Imprints",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based tactile sensors typically utilize a deformable elastomer and a camera mounted above to provide high-resolution image observations of contacts. Obtaining accurate volumetric meshes for the deformed elastomer can provide direct contact information and benefit robotic grasping and manipulation. This paper focuses on learning to synthesize the volumetric mesh of the elastomer based on the image imprints acquired from vision-based tactile sensors. Synthetic image-mesh pairs and real-world images are gathered from 3D finite element methods (FEM) and physical sensors, respectively. A graph neural network (GNN) is introduced to learn the image-to-mesh mappings with supervised learning. A self-supervised adaptation method and image augmentation techniques are proposed to transfer networks from simulation to reality, from primitive contacts to unseen contacts, and from one sensor to another. Using these learned and adapted networks, our proposed method can accurately reconstruct the deformation of the real-world tactile sensor elastomer in various domains, as indicated by the quantitative and qualitative results.",
        "primary_area": "",
        "author": "Xinghao Zhu;Siddarth Jain;Masayoshi Tomizuka;Jeroen Van Baar;Xinghao Zhu;Siddarth Jain;Masayoshi Tomizuka;Jeroen Van Baar",
        "authorids": "/37087322158;/37088688017;/37281933000;/37324479700;/37087322158;/37088688017;/37281933000;/37324479700",
        "aff": "Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mechanical Systems Control Lab, UC Berkeley, Berkeley, CA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812092/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13439166831454567247&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Mitsubishi Electric Research Laboratories;University of California, Berkeley",
        "aff_unique_dep": ";Mechanical Systems Control Lab",
        "aff_unique_url": "https://www.merl.com;https://www.berkeley.edu",
        "aff_unique_abbr": "MERL;UC Berkeley",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Cambridge;Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812184",
        "title": "Learning-Guided Exploration for Efficient Sampling-Based Motion Planning in High Dimensions",
        "track": "main",
        "status": "Poster",
        "abstract": "Optimal motion planning is a long-studied problem with a wide range of applications in robotics, from grasping to navigation. While sampling-based motion planning methods have made solving such problems significantly more feasible, these methods still often struggle in high-dimensional spaces wherein exploration is computationally costly. In this paper, we propose a new motion planning algorithm that reduces the computational burden of the exploration process. The proposed algorithm utilizes a guidance policy acquired offline through model-free reinforcement learning. The guidance policy is used to bias the exploration process in motion planning and to guide it toward promising regions of the state space. Moreover, we show that the gradients of the corresponding learned value function can be used to locally fine-tune the sampled states. We empirically demonstrate that the proposed approach can significantly reduce planning time and improve success rate and path quality.",
        "primary_area": "",
        "author": "Liam Schramm;Abdeslam Boularias;Liam Schramm;Abdeslam Boularias",
        "authorids": "/37088505139;/37542596800;/37088505139;/37542596800",
        "aff": "Computer Science Department, Rutgers University; Computer Science Department, Rutgers University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812184/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18168775920337828334&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812363",
        "title": "Learning-based Ellipse Detection for Robotic Grasps of Cylinders and Ellipsoids",
        "track": "main",
        "status": "Poster",
        "abstract": "In our daily life, there are many objects represented by cylindrical shapes and ellipsoids. The tops of these objects are formed by elliptic shape primitives. Thus, it is available for a robot to manipulate these objects by ellipse detection. In this work, we propose a novel approach to generating ground truth for training the model based on domain randomization. Using synthetic data generated in this manner, we build an end-to-end deep neural network with a detection backbone and then, combine multiple branches archived from the backbone for sharing the multiple-scale features; further, after employing active rotation filters, the features pass through the region proposal net to form the prediction branches of the box, orientation regression, and object classification; finally, these branches are fused to do ellipse detection, allowing robotic manipulations of cylinders and ellipsoids. To demonstrate the capabilities of the proposed detector, we show the comparison results with the state-of-the-art detector on synthetic and public datasets. The proposed model for ellipse detection and data generation pipeline based on domain randomization in a simulation are evaluated by a series of robotic manipulations implemented in real application scenarios. The results illustrate a high success rate on real-world grasp attempts despite having only been trained on a synthetic dataset. (A video of some robotic experiments is available on YouTube: https://youtu.be/Ueg1XSI2S98).",
        "primary_area": "",
        "author": "Huixu Dong;Jiadong Zhou;Chen Qiu;Prasad K. Dilip;I-Ming Chen;Huixu Dong;Jiadong Zhou;Chen Qiu;Prasad K. Dilip;I-Ming Chen",
        "authorids": "/37086340778;/37086942231;/37089110391;/37089450194;/37277668700;/37086340778;/37086942231;/37089110391;/37089450194;/37277668700",
        "aff": "Robotics Research Center of Nanyang Technological University, Singapore; Robotics Research Center of Nanyang Technological University, Singapore; Maider Medical Industry Equipment Co., Itd, China; Bio-AI Lab of Department of Computer Science at UiT The Arctic, University of Norway, Tromso, Norway; Robotics Research Center of Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812363/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7916842213293419866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Nanyang Technological University;Maider Medical Industry Equipment Co.;University of Tromso",
        "aff_unique_dep": "Robotics Research Center;;Department of Computer Science",
        "aff_unique_url": "https://www.ntu.edu.sg;;https://www.uit.no",
        "aff_unique_abbr": "NTU;;UiT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Tromso",
        "aff_country_unique_index": "0;0;1;2;0",
        "aff_country_unique": "Singapore;China;Norway"
    },
    {
        "id": "9812166",
        "title": "Legged Robots that Keep on Learning: Fine-Tuning Locomotion Policies in the Real World",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robots are physically capable of traversing a wide range of challenging environments, but designing controllers that are sufficiently robust to handle this diversity has been a long-standing challenge in robotics. Reinforcement learning presents an appealing approach for automating the controller design process and has been able to produce remarkably robust controllers when trained in a suitable range of environments. However, it is difficult to predict all likely conditions the robot will encounter during deployment and enumerate them at training-time. What if instead of training controllers that are robust enough to handle any eventuality, we enable the robot to continually learn in any setting it finds itself in? This kind of real-world reinforcement learning poses a number of challenges, including efficiency, safety, and autonomy. To address these challenges, we propose a practical robot reinforcement learning system for fine-tuning locomotion policies in the real world. We demonstrate that a modest amount of real-world training can substantially improve performance during deployment, and this enables a real A1 quadrupedal robot to autonomously fine-tune multiple locomotion skills in a range of environments, including an outdoor lawn and a variety of indoor terrains. (Videos and code11https://sites.google.com/berkele.edu/fine-tuning-locomotion)",
        "primary_area": "",
        "author": "Laura Smith;J. Chase Kew;Xue Bin Peng;Sehoon Ha;Jie Tan;Sergey Levine;Laura Smith;J. Chase Kew;Xue Bin Peng;Sehoon Ha;Jie Tan;Sergey Levine",
        "authorids": "/37089449288;/37088462457;/37089447976;/37086314268;/37086455820;/37085481973;/37089449288;/37088462457;/37089447976;/37086314268;/37086455820;/37085481973",
        "aff": "Berkeley AI Research, UC Berkeley; Google Research; Berkeley AI Research, UC Berkeley; Georgia Institute of Technology; Google Research; Google Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812166/",
        "gs_citation": 136,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9642552556913327340&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;1;1",
        "aff_unique_norm": "University of California, Berkeley;Google;Georgia Institute of Technology",
        "aff_unique_dep": "Berkeley AI Research;Google Research;",
        "aff_unique_url": "https://www.berkeley.edu;https://research.google;https://www.gatech.edu",
        "aff_unique_abbr": "UC Berkeley;Google Research;Georgia Tech",
        "aff_campus_unique_index": "0;1;0;1;1",
        "aff_campus_unique": "Berkeley;Mountain View;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812031",
        "title": "Let Them Have Bubbles! Filling Gaps in Toy-Like Behaviors for Child-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-mediated interventions are one promising and novel approach for encouraging motor exploration in young children, but knowledge about the effectiveness of toy-like features for child-robot interaction is limited. We were interested in understanding the characteristics of current toys to inform the design of interactive abilities for assistive robots. This work first provides a systematic review of toy characteristics in n=154n=154 Fisher-Price products and then analyzes the effectiveness of common and uncommon toy-like behaviors from our custom assistive robot. Toy review results showed that light and sound features were significantly more common than bubbles, wheels, and self-propulsion. Exploratory play sessions with our assistive robot showed that bubbles were significantly more successful at encouraging child motion than other robot behaviors. Further, all studied robot behaviors demonstrated the capability to encourage child motion. The products of this work can inform the efforts of human-robot interaction and child development experts who study child mobility interventions.",
        "primary_area": "",
        "author": "Ameer Helmi;Samantha Noregaard;Natasha Giulietti;Samuel W. Logan;Naomi T. Fitter;Ameer Helmi;Samantha Noregaard;Natasha Giulietti;Samuel W. Logan;Naomi T. Fitter",
        "authorids": "/37088687638;/37089447698;/37089449000;/37085364040;/37077925800;/37088687638;/37089447698;/37089449000;/37085364040;/37077925800",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, Oregon, USA; Social Mobility Lab, Oregon State University, Corvallis, Oregon, USA; Social Mobility Lab, Oregon State University, Corvallis, Oregon, USA; Social Mobility Lab, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, Oregon, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812031/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6459577719118336528&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812298",
        "title": "Let's Collaborate: Regret-based Reactive Synthesis for Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots gain capabilities to enter our humancentric world, they require formalism and algorithms that enable smart and efficient interactions. This is challenging, especially for robotic manipulators with complex tasks that may require collaboration with humans. Prior works approach this problem through reactive synthesis and generate strategies for the robot that guarantee task completion by assuming an adversarial human. While this assumption gives a sound solution, it leads to an \u201cunfriendly\u201d robot that is agnostic to the human intentions. We relax this assumption by formulating the problem using the notion of regret. We identify an appropriate definition for regret and develop regret-minimizing synthesis framework that enables the robot to seek cooperation when possible while preserving task completion guarantees. We illus-trate the efficacy of our framework via various case studies.",
        "primary_area": "",
        "author": "Karan Muvvala;Peter Amorese;Morteza Lahijanian;Karan Muvvala;Peter Amorese;Morteza Lahijanian",
        "authorids": "/37089448756;/37089446991;/37398443600;/37089448756;/37089446991;/37398443600",
        "aff": "department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA; department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812298/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4517816810107987023&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Aerospace Engineering Sciences",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811718",
        "title": "Leveraging Smooth Attention Prior for Multi-Agent Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent interactions are important to model for forecasting other agents' behaviors and trajectories. At a certain time, to forecast a reasonable future trajectory, each agent needs to pay attention to the interactions with only a small group of most relevant agents instead of unnecessarily paying attention to all the other agents. However, existing attention modeling works ignore that human attention in driving does not change rapidly, and may introduce fluctuating attention across time steps. In this paper, we formulate an attention model for multi-agent interactions based on a total variation temporal smoothness prior and propose a trajectory prediction architecture that leverages the knowledge of these attended interactions. We demonstrate how the total variation attention prior along with the new sequence prediction loss terms leads to smoother attention and more sample-efficient learning of multi-agent trajectory prediction, and show its advantages in terms of prediction accuracy by comparing it with the state-of-the-art approaches on both synthetic and naturalistic driving data. We demonstrate the performance of our algorithm for trajectory prediction on the INTERACTION dataset on our website11https://sites.google.com/view/smoothness-attention.",
        "primary_area": "",
        "author": "Zhangjie Cao;Erdem Biyik;Guy Rosman;Dorsa Sadigh;Zhangjie Cao;Erdem Biyik;Guy Rosman;Dorsa Sadigh",
        "authorids": "/37089504094;/37086082220;/37393688300;/38234464200;/37089504094;/37086082220;/37393688300;/38234464200",
        "aff": "Computer Science, Stanford University, CA, USA; Electrical Engineering, Stanford University, CA, USA; Toyota Research Institute, MA, USA; Computer Science, Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811718/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=730623327365646854&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Stanford University;Toyota Research Institute",
        "aff_unique_dep": "Computer Science;",
        "aff_unique_url": "https://www.stanford.edu;https://www.tri.global",
        "aff_unique_abbr": "Stanford;TRI",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Stanford;MA",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812186",
        "title": "Leveraging distributed contact force measurements for slip detection: a physics-based approach enabled by a data-driven tactile sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping objects whose physical properties are unknown is still a great challenge in robotics. Most solutions rely entirely on visual data to plan the best grasping strategy. However, to match human abilities and be able to reliably pick and hold unknown objects, the integration of an artificial sense of touch in robotic systems is pivotal. This paper describes a novel model-based slip detection pipeline that can predict possibly failing grasps in real-time and signal a necessary increase in grip force. As such, the slip detector does not rely on manually collected data, but exploits physics to generalize across different tasks. To evaluate the approach, a state-of-the-art vision-based tactile sensor that accurately estimates distributed forces was integrated into a grasping setup composed of a six degrees-of-freedom cobot and a two-finger gripper. Results show that the system can reliably predict slip while manipulating objects of different shapes, materials, and weights. The sensor can detect both translational and rotational slip in various scenarios, making it suitable to improve the stability of a grasp.",
        "primary_area": "",
        "author": "Pietro Griffa;Carmelo Sferrazza;Raffaello D'Andrea;Pietro Griffa;Carmelo Sferrazza;Raffaello D'Andrea",
        "authorids": "/37089450420;/37085991609;/38525077800;/37089450420;/37085991609;/38525077800",
        "aff": "Institute for Dynamic Systems and Control, ETH Zurich, Switerland; Institute for Dynamic Systems and Control, ETH Zurich, Switerland; Institute for Dynamic Systems and Control, ETH Zurich, Switerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812186/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16875612541291876510&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Institute for Dynamic Systems and Control",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9811693",
        "title": "Lifting 2D Object Locations to 3D by Discounting LiDAR Outliers across Objects and Views",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a system for automatic converting of 2D mask object predictions and raw LiDAR point clouds into full 3D bounding boxes of objects. Because the LiDAR point clouds are partial, directly fitting bounding boxes to the point clouds is meaningless. Instead, we suggest that obtaining good results requires sharing information between all objects in the dataset jointly, over multiple frames. We then make three improvements to the baseline. First, we address ambiguities in predicting the object rotations via direct optimization in this space while still backpropagating rotation prediction through the model. Second, we explicitly model outliers and task the network with learning their typical patterns, thus better discounting them. Third, we enforce temporal consistency when video data is available. With these contributions, our method significantly outperforms previous work despite the fact that those methods use significantly more complex pipelines, 3D models and additional human-annotated external sources of prior information.",
        "primary_area": "",
        "author": "Robert McCraith;Eldar Insafutdinov;Lukas Neumann;Andrea Vedaldi;Robert McCraith;Eldar Insafutdinov;Lukas Neumann;Andrea Vedaldi",
        "authorids": "/37089015953;/37086236050;/37076554300;/37398040100;/37089015953;/37086236050;/37076554300;/37398040100",
        "aff": "Dept. of Engineering Science, Visual Geometry Group, University of Oxford; Dept. of Engineering Science, Visual Geometry Group, University of Oxford; Faculty of Electrical Engineering, Czech Technical University, Prague; Dept. of Engineering Science, Visual Geometry Group, University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811693/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16676477564988543913&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Oxford;Czech Technical University",
        "aff_unique_dep": "Dept. of Engineering Science;Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.cvut.cz",
        "aff_unique_abbr": "Oxford;CTU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Oxford;Prague",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;Czech Republic"
    },
    {
        "id": "9812350",
        "title": "Liftoff of A Motor-Driven Flapping Wing Rotorcraft with Mechanically Decoupled Wings",
        "track": "main",
        "status": "Poster",
        "abstract": "Flapping Wing Rotorcraft (FWR) combines flapping and rotating wing motion in one element. Such a hybrid design integrates the high-efficiency characteristics of the rotating wing and the high-lift feature of the flapping wing under low Reynolds number, providing a broader range of simultaneous lift and power efficiency optimization. Nevertheless, the flight performance of the current FWRs is limited by their complex transmission mechanisms. Such mechanical constraints not only induce coupled wing kinematics but also render tedious assembly work and fabrication imperfections. In order to fundamentally address the constraints, we propose a motor-driven FWR with mechanically decoupled wings. The wing of the proposed DFWR is directly actuated by two bi-directional rotating motors instead of using the crank rocker (or alike) transmission. The proposed DFWR flaps within 25Hz to 35Hz, with about 12.4 grams of system weight and 185mm wingspan. With the direct-drive principle, the wing kinematics can be modulated properly by real-time motor control. In particular, we tuned the flapping frequency, stroke amplitude, and mid-stroke angle of the proposed direct-drive FWR to attain its best lift performance. As a result, it can generate about 16 grams of maximum total lift. In order to validate the proposed design, free flight tests have been conducted. The proposed FWR demonstrates stable liftoff.",
        "primary_area": "",
        "author": "Fangyuan Liu;Song Li;Ziyu Wang;Xin Dong;Daochun Li;Zhan Tu;Fangyuan Liu;Song Li;Ziyu Wang;Xin Dong;Daochun Li;Zhan Tu",
        "authorids": "/37089449347;/37090021178;/37089448102;/37089450269;/37086315653;/37086047175;/37089449347;/37090021178;/37089448102;/37089450269;/37086315653;/37086047175",
        "aff": "School of Aeronautic Science and Engineering, Beihang University, Beijing, China; School of Aeronautic Science and Engineering, Beihang University, Beijing, China; School of Aeronautic Science and Engineering, Beihang University, Beijing, China; School of Aeronautic Science and Engineering, Beihang University, Beijing, China; School of Aeronautic Science and Engineering, Beihang University, Beijing, China; Institute of Unmanned System, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812350/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4169297654734036213&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "School of Aeronautic Science and Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812220",
        "title": "Lightweight Monocular Depth Estimation through Guided Decoding",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a lightweight encoder-decoder architecture for monocular depth estimation, specifically designed for embedded platforms. Our main contribution is the Guided Upsampling Block (GUB) for building the decoder of our model. Motivated by the concept of guided image filtering, GUB relies on the image to guide the decoder on upsampling the feature representation and the depth map reconstruction, achieving high resolution results with fine-grained details. Based on multiple GUBs, our model outperforms the related methods on the NYU Depth V2 dataset in terms of accuracy while delivering up to 35.1 fps on the NVIDIA Jetson Nano and up to 144.5 fps on the NVIDIA Xavier NX. Similarly, on the KITTI dataset, inference is possible with up to 23.7 fps on the Jetson Nano and 102.9 fps on the Xavier NX. Our code and models are made publicly available14https://github.com/mic-rud/GuidedDecoding.",
        "primary_area": "",
        "author": "Michael Rudolph;Youssef Dawoud;Ronja G\u00fcldenring;Lazaros Nalpantidis;Vasileios Belagiannis;Michael Rudolph;Youssef Dawoud;Ronja G\u00fcldenring;Lazaros Nalpantidis;Vasileios Belagiannis",
        "authorids": "/37089448990;/37089447400;/37088687358;/37304022500;/37085391038;/37089448990;/37089447400;/37088687358;/37304022500;/37085391038",
        "aff": "Ulm University; Ulm University, Ulm, Germany; DTU \u2013 Technical University of Denmark, Kgs. Lyngby, Denmark; DTU \u2013 Technical University of Denmark, Kgs. Lyngby, Denmark; Ulm University, Ulm, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812220/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8024006666411797073&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Ulm University;Technical University of Denmark",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-ulm.de/;https://www.dtu.dk",
        "aff_unique_abbr": "U Ulm;DTU",
        "aff_campus_unique_index": "1;2;2;1",
        "aff_campus_unique": ";Ulm;Kgs. Lyngby",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "Germany;Denmark"
    },
    {
        "id": "9811753",
        "title": "LoGG3D-Net: Locally Guided Global Descriptor Learning for 3D Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Retrieval-based place recognition is an efficient and effective solution for re-localization within a pre-built map, or global data association for Simultaneous Localization and Mapping (SLAM). The accuracy of such an approach is heavily dependant on the quality of the extracted scene-level representation. While end-to-end solutions - which learn a global descriptor from input point clouds - have demonstrated promising results, such approaches are limited in their ability to enforce desirable properties at the local feature level. In this paper, we introduce a local consistency loss to guide the network towards learning local features which are consistent across revisits, hence leading to more repeatable global descriptors resulting in an overall improvement in 3D place recognition performance. We formulate our approach in an end-to-end trainable architecture called LoGG3D-Net. Experiments on two large-scale public benchmarks (KITTI and MulRan) show that our method achieves mean F1max scores of 0.939 and 0.968 on KITTI and MulRan respectively, achieving state-of-the-art performance while operating in near real-time. The open-source implementation is available at: https://github.com/csiro-robotics/LoGG3D-Net.",
        "primary_area": "",
        "author": "Kavisha Vidanapathirana;Milad Ramezani;Peyman Moghadam;Sridha Sridharan;Clinton Fookes;Kavisha Vidanapathirana;Milad Ramezani;Peyman Moghadam;Sridha Sridharan;Clinton Fookes",
        "authorids": "/37087049355;/37088504403;/37666497200;/37266096100;/37281919100;/37087049355;/37088504403;/37666497200;/37266096100;/37281919100",
        "aff": "SAIVT research programme in the School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Brisbane, Australia; Robotics and Autonomous Systems Group, DATA61, CSIRO, Brisbane, QLD, Australia; SAIVT research programme in the School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Brisbane, Australia; SAIVT research programme in the School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Brisbane, Australia; SAIVT research programme in the School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811753/",
        "gs_citation": 98,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5099032652782998961&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Queensland University of Technology;CSIRO",
        "aff_unique_dep": "School of Electrical Engineering and Robotics;Robotics and Autonomous Systems Group",
        "aff_unique_url": "https://www.qut.edu.au;https://www.csiro.au",
        "aff_unique_abbr": "QUT;CSIRO",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9812260",
        "title": "Load-sensitive Data Acquisition for a Tactile Sensor System of Multi-fingered Robotic Hands",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a data acquisition method to realize a distributed tactile sensor system that can provide wide-range, and high-sensitivity with a small data size for communication. Since the data size is proportional to the number of acquired data and the resolution of the data, we propose systems to increase the resolution of the sensor output values without increasing the amount of data and to reduce the sampling frequency without reducing the time resolution. The system to increase the data resolution is based on a mechanism to dynamically change the gain of an amplifier circuit for a tactile sensor depending on the input value in the local controller. The system to reduce the number of data acquisitions consists of an analog circuit to judge the amount of change in the tactile sensor output based on a threshold at the hardware level. We demonstrate that the system reduces the data size for communication on a sensor system in our robotic hand. The experimental results indicate that the tactile sensor systems could sense high-resolution data with a small data size for communication.",
        "primary_area": "",
        "author": "Ryusuke Ishizaki;Shun Ogiwara;Fumiya Hamatsu;Tomoyuki Sakurai;Hirofumi Shin;Takahide Yoshiike;Ryusuke Ishizaki;Shun Ogiwara;Fumiya Hamatsu;Tomoyuki Sakurai;Hirofumi Shin;Takahide Yoshiike",
        "authorids": "/37087324975;/37089303688;/37089447200;/37089450486;/37089735155;/37682554700;/37087324975;/37089303688;/37089447200;/37089450486;/37089735155;/37682554700",
        "aff": "Frontier Robotics Domain, Honda R&D Co.,Ltd, Saitama, Japan; Frontier Robotics Domain, Honda R&D Co.,Ltd, Saitama, Japan; Frontier Robotics Domain, Honda R&D Co.,Ltd, Saitama, Japan; Frontier Robotics Domain, Honda R&D Co.,Ltd, Saitama, Japan; Frontier Robotics Domain, Honda R&D Co.,Ltd, Saitama, Japan; Frontier Robotics Domain, Honda R&D Co.,Ltd, Saitama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812260/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14769183773842989772&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Honda R&D Co., Ltd.",
        "aff_unique_dep": "Frontier Robotics Domain",
        "aff_unique_url": "https://www.honda.com",
        "aff_unique_abbr": "Honda",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Saitama",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811793",
        "title": "Localization of a Smart Infrastructure Fisheye Camera in a Prior Map for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a technique for localization of a smart infrastructure node, consisting of a fisheye camera, in a prior map. These cameras can detect objects that are outside the line of sight of the autonomous vehicles (AV) and send that information to AVs using V2X technology. However, in order for this information to be of any use to the AV, the detected objects should be provided in the reference frame of the prior map that the AV uses for its own navigation. Therefore, it is important to know the accurate pose of the infrastructure camera with respect to the prior map. Here we propose to solve this localization problem in two steps, (i) we perform feature matching between perspective projection of fisheye image and bird's eye view (BEV) satellite imagery from the prior map to estimate an initial camera pose, (ii) we refine the initialization by maximizing the Mutual Information (MI) between intensity of pixel values of fisheye image and reflectivity of 3D LiDAR points in the map data. We validate our method on simulated data and also present results with real world data.",
        "primary_area": "",
        "author": "Subodh Mishra;Armin Parchami;Enrique Corona;Punarjay Chakravarty;Ankit Vora;Devarth Parikh;Gaurav Pandey;Subodh Mishra;Armin Parchami;Enrique Corona;Punarjay Chakravarty;Ankit Vora;Devarth Parikh;Gaurav Pandey",
        "authorids": "/37088635827;/37089448770;/37089448544;/37952596000;/37087325085;/37087323851;/37084693200;/37088635827;/37089448770;/37089448544;/37952596000;/37087325085;/37087323851;/37084693200",
        "aff": "Graduate student in the Department of Mechanical Engineering, Texas A&M University; All other authors with the Ford Autonomous Vehicles LLC, USA; All other authors with the Ford Autonomous Vehicles LLC, USA; All other authors with the Ford Autonomous Vehicles LLC, USA; All other authors with the Ford Autonomous Vehicles LLC, USA; All other authors with the Ford Autonomous Vehicles LLC, USA; All other authors with the Ford Autonomous Vehicles LLC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811793/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15432888532062107866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;1;1",
        "aff_unique_norm": "Texas A&M University;Ford Autonomous Vehicles LLC",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.tamu.edu;https://www.fordautonomousvehicles.com",
        "aff_unique_abbr": "TAMU;FAV",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812103",
        "title": "Locomotion as a Risk-mitigating Behavior in Uncertain Environments: A Rapid Planning and Few-shot Failure Adaptation Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "We want robots to complete assigned tasks even when unexpected task pressures arise, either from the robot or the environment. This paper presents a method of both learning sources of task failure in situ and rapidly planning new motions on-the-fly to accommodate them. This \u201crisk-adaptive\u201d approach to robot control uses a few encounters with a novel failure mode to generate a probabilistic failure model which we use to optimize a risk-mitigating motion plan. We demonstrate two toy problems, where risk-adaptive double-integrator agents are introduced to separate environments, each with their own tasks and modes of failure. The agents are not aware a priori of any risks the environments might present, but after one failure, the agents quickly adapt their motion plans and ensure task completion. We further conduct numerical experiments to characterize the algorithm's speed of adaptation with respect to environmental uncertainty. We see this framework as a natural extension for the myriad of robotic applications using model-based motion planners.",
        "primary_area": "",
        "author": "Jacob Hackett;Dylan Epstein-Gross;Monica Daley;Christian Hubicki;Jacob Hackett;Dylan Epstein-Gross;Monica Daley;Christian Hubicki",
        "authorids": "/37088686594;/37089449167;/37085394138;/37085380316;/37088686594;/37089449167;/37085394138;/37085380316",
        "aff": "Department of Mechanical Engineering, Florida State University, FAMU-FSU College of Engineering, Tallahassee, FL, USA; Department of Mechanical Engineering, Florida State University, FAMU-FSU College of Engineering, Tallahassee, FL, USA; Ecology & Evolutionary Biology Department, University of California Irvine, Irvine, CA, USA; Department of Mechanical Engineering, Florida State University, FAMU-FSU College of Engineering, Tallahassee, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812103/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6975537035615433163&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Florida State University;University of California, Irvine",
        "aff_unique_dep": "Department of Mechanical Engineering;Ecology & Evolutionary Biology Department",
        "aff_unique_url": "https://www.fsu.edu;https://www.uci.edu",
        "aff_unique_abbr": "FSU;UCI",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Tallahassee;Irvine",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812057",
        "title": "Long-Horizon Manipulation of Unknown Objects via Task and Motion Planning with Estimated Affordances",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a strategy for designing and building very general robot manipulation systems using a general-purpose task-and-motion planner with both engineered and learned modules that estimate properties and affordances of unknown objects. Such systems are closed-loop policies that map from RGB images, depth images, and robot joint encoder measurements to robot joint position commands. We show that this strategy leads to intelligent behaviors even without a priori knowledge regarding the set of objects, their geometries, and their affordances. We show how these modules can be flexibly composed with robot-centric primitives using the PDDLStream task and motion planning framework. Finally, we demonstrate that this strategy can enable a single policy to perform a wide variety of real-world multi-step manipulation tasks, generalizing over a broad class of objects, arrangements, and goals, without prior knowledge of the environment or re-training.",
        "primary_area": "",
        "author": "Aidan Curtis;Xiaolin Fang;Leslie Pack Kaelbling;Tom\u00e1s Lozano-P\u00e9rez;Caelan Reed Garrett;Aidan Curtis;Xiaolin Fang;Leslie Pack Kaelbling;Tom\u00e1s Lozano-P\u00e9rez;Caelan Reed Garrett",
        "authorids": "/37089450030;/37089448973;/37269373600;/38273814000;/37085688184;/37089450030;/37089448973;/37269373600;/38273814000;/37085688184",
        "aff": "CSAIL, MIT, USA; CSAIL, MIT, USA; CSAIL, MIT, USA; CSAIL, MIT, USA; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812057/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14429589916725082512&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;NVIDIA",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;NVIDIA Corporation",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.nvidia.com",
        "aff_unique_abbr": "MIT;NVIDIA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812125",
        "title": "Look and Listen: A Multi-Sensory Pouring Network and Dataset for Granular Media from Human Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans have the ability to pour various media, both liquid and granular, to desired ends in various containers. We do this by using multiple senses simultaneously in a constant feedback loop to complete a pouring task. Combining multiple sensing modalities, similar to humans, could aid in robotic pouring control outside of a structured or industrial setting. We present a multi-sensory pouring dataset consisting of human pouring demonstrations of various granular media, coupled with two multi-sensory networks that estimate pouring rate and pouring average height. For both pouring metrics, a combined input of audio and visual data provides a lower median error than either the audio network or visual network. The multi-sensory network achieves a median error of 6.4 mm for average height estimation and 0.06 N/s for pouring rate estimation.",
        "primary_area": "",
        "author": "Alexis Burns;Siyuan Xiang;Daewon Lee;Larry Jackel;Shuran Song;Volkan Isler;Alexis Burns;Siyuan Xiang;Daewon Lee;Larry Jackel;Shuran Song;Volkan Isler",
        "authorids": "/37089450943;/37089449685;/37599980600;/37089466321;/37089450550;/37298487800;/37089450943;/37089449685;/37599980600;/37089466321;/37089450550;/37298487800",
        "aff": "Samsung AI Center NY, New York; Samsung AI Center NY, New York; Samsung AI Center NY, New York; Samsung AI Center NY, New York; Samsung AI Center NY, New York; Samsung AI Center NY, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812125/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3807427366693169493&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "SAC NY",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811994",
        "title": "Looking for Trouble: Informative Planning for Safe Trajectories with Occlusions",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning a safe trajectory for an ego vehicle through an environment with occluded regions is a challenging task. Existing methods use some combination of metrics to evaluate a trajectory, either taking a worst case view or allowing for some probabilistic estimate, to eliminate or minimize the risk of collision respectively. Typically, these approaches assume occluded regions of the environment are unsafe and must be avoided, resulting in overly conservative trajectories-particularly when there are no hidden risks present. We propose a local trajectory planning algorithm which generates safe trajectories that maximize observations on un-certain regions. In particular, we seek to gain information on occluded areas that are most likely to pose a risk to the ego vehicle on its future path. Calculating the information gain is a computationally complex problem; our method approximates the maximum information gain and results in vehicle motion that remains safe but is less conservative than state-of-the-art approaches. We evaluate the performance of the proposed method within the CARLA simulator in different scenarios.",
        "primary_area": "",
        "author": "Barry Gilhuly;Armin Sadeghi;Peyman Yedmellat;Kasra Rezaee;Stephen L. Smith;Barry Gilhuly;Armin Sadeghi;Peyman Yedmellat;Kasra Rezaee;Stephen L. Smith",
        "authorids": "/37088333776;/37086070998;/37089448187;/38491501500;/37335139700;/37088333776;/37086070998;/37089448187;/38491501500;/37335139700",
        "aff": "Department of Electrical and Computer Engineering, University of Waterloo, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Canada; Noah's Arc Lab, Huawei Technologies, Canada; Noah's Arc Lab, Huawei Technologies, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811994/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11721911846922101215&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of Waterloo;Huawei",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Noah's Arc Lab",
        "aff_unique_url": "https://uwaterloo.ca;https://www.huawei.com",
        "aff_unique_abbr": "UW;Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812419",
        "title": "Loop Closure Detection and SLAM in Vineyards with Deep Semantic Cues",
        "track": "main",
        "status": "Poster",
        "abstract": "Automation of vineyards cultivation necessitates for mobile robots to retain accurate localization system. The paper introduces a stereo vision-based Graph-Simultaneous Localization and Mapping (Graph-SLAM) pipeline custom-tailored to the specificities of vineyard fields. Graph-SLAM is reinforced with a Loop Closure Detection (LCD) based on semantic segmentation of the vine trees. The Mask R-CNN network is applied to segment the trunk regions of images, on which unique visual features are extracted. These features are used to populate the bag of visual words (BoVW s) retained on the formulated graph. A nearest neighbor search is applied to each query trunk-image to associate each unique feature descriptor with the corresponding node in the graph using a voting procedure. We apply a probabilistic method to select the most suitable loop closing pair and, upon an LCD appearance, the 3D points of the trunks are employed to estimate the loop closure constraint to the graph. The traceable features on trunk segments drastically reduce the number of retained BoVWs, which in turn expedites significantly the loop closure and graph optimization, rendering our method suitable for large scale mapping in vineyards. The pipeline has been evaluated on several data sequences gathered from real vineyards, in different seasons, when the appearance of vine trees vary significantly, and exhibited robust mapping in long distances.",
        "primary_area": "",
        "author": "Alexios Papadimitriou;Ioannis Kleitsiotis;Ioannis Kostavelis;Ioannis Mariolis;Dimitrios Giakoumis;Spiriden Likothanassis;Dimitrios Tzovaras;Alexios Papadimitriou;Ioannis Kleitsiotis;Ioannis Kostavelis;Ioannis Mariolis;Dimitrios Giakoumis;Spiriden Likothanassis;Dimitrios Tzovaras",
        "authorids": "/37089449444;/37089194463;/38480784400;/37085791728;/37546562700;/37325941900;/37269764300;/37089449444;/37089194463;/38480784400;/37085791728;/37546562700;/37325941900;/37269764300",
        "aff": "Computer Engineering and Informatics, Large Scale Machine Learning and Cloud Data Engineering Lab, University of Patras, Greece; Computer Engineering and Informatics, Large Scale Machine Learning and Cloud Data Engineering Lab, University of Patras, Greece; Centre for Research and Technology-Hellas, Information Technologies Institute (CERTH / ITI); Centre for Research and Technology-Hellas, Information Technologies Institute (CERTH / ITI); Centre for Research and Technology-Hellas, Information Technologies Institute (CERTH / ITI); Computer Engineering and Informatics, Large Scale Machine Learning and Cloud Data Engineering Lab, University of Patras, Greece; Centre for Research and Technology-Hellas, Information Technologies Institute (CERTH / ITI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812419/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7509094533632485883&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;1;0;1",
        "aff_unique_norm": "University of Patras;Centre for Research and Technology-Hellas",
        "aff_unique_dep": "Computer Engineering and Informatics;Information Technologies Institute",
        "aff_unique_url": "https://www.upatras.gr;https://www.certh.gr",
        "aff_unique_abbr": ";CERTH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9811723",
        "title": "MOSAIX: a Swarm of Robot Tiles for Social Human-Swarm Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "MOSAIX is a new robot swarm platform built to be used in social settings. Consisting of up to 100 individual robot Tiles, MOSAIX is a social swarm system, aimed at helping humans in social tasks such as opinion-mixing and brainstorming. MOSAIX also has the potential to be used as a platform to study human-swarm interaction and swarm expressivity. MOSAIX is intended to be used outside laboratory settings and has already been used to collect 154 opinions about climate change in a local shopping mall, used by participants to create collaborative art and used as an educational tool for schoolchildren. We also discuss future applications, such as MOSAIX acting as smart post-it notes for ideation activities.",
        "primary_area": "",
        "author": "Merihan Alhafnawi;Edmund R. Hunt;Severin Lemaignan;Paul O'Dowd;Sabine Hauert;Merihan Alhafnawi;Edmund R. Hunt;Severin Lemaignan;Paul O'Dowd;Sabine Hauert",
        "authorids": "/37088762229;/37089448236;/38482927400;/38230680300;/37546505900;/37088762229;/37089448236;/38482927400;/38230680300;/37546505900",
        "aff": "Faculty of Engineering, University of Bristol, UK; Faculty of Engineering, University of Bristol, UK; Faculty of Environment and Technology, University of the West of England, Bristol, UK; Faculty of Engineering, University of Bristol, UK; Faculty of Engineering, University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811723/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17235053180201257930&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Bristol;University of the West of England",
        "aff_unique_dep": "Faculty of Engineering;Faculty of Environment and Technology",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.uwe.ac.uk",
        "aff_unique_abbr": "UoB;UWE",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Bristol",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811361",
        "title": "Magnetically Steerable Asymmetric Magnetized Soft Continuum Robot (AMSCR) for Minimally Invasive Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft continuum robots have been widely used as guide wires or catheters for minimally invasive surgery (MIS), and the miniaturization and dexterity are very important characteristics of soft continuum robots. As a representative actuation method for soft continuum robots, the steering using an external magnetic field has been actively studied. The magnetic actuation method is appropriate for the miniaturization of soft continuum robots but shows limitations in implementing high dexterity. To achieve miniaturization and high dexterity, this paper proposes a magnetically steerable asymmetric magnetized soft continuum robot (AMSCR). The proposed AMSCR includes an active steering part (ASP) of a thin PDMS cylinder in which NdFeB powder is uniformly dispersed and magnetized asymmetrically to the longitudinal direction. Therefore, compared to the conventional symmetric magnetized soft continuum robot (SMSCR), the proposed AMSCR has a larger steering range and high dexterity. Through various experiments, simulations, and phantom experiments using the proposed AMSCR, we analyzed its characteristics, verified its enhanced steering range, and demonstrated the applicability to the surgeries requiring high dexterity in the eye or cerebrovascular.",
        "primary_area": "",
        "author": "Joowon Park;Hyoryong Lee;Hyunchul Choi;Sunwoo Sohn;Hyeonwoo Kee;Joohack Lee;Gyungrae Cha;Sukho Park;Joowon Park;Hyoryong Lee;Hyunchul Choi;Sunwoo Sohn;Hyeonwoo Kee;Joohack Lee;Gyungrae Cha;Sukho Park",
        "authorids": "/37089447971;/37089447941;/37403216200;/37089446823;/37089448640;/37089447542;/37089447279;/38546366000;/37089447971;/37089447941;/37403216200;/37089446823;/37089448640;/37089447542;/37089447279;/38546366000",
        "aff": "Department of Robotics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Department of Robotics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Korea Institute of Medical Microrobotics, Gwangju, South Korea; Department of Robotics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Department of Robotics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea; Korea Institute of Medical Microrobotics, Gwangju, South Korea; Korea Institute of Medical Microrobotics, Gwangju, South Korea; Department of Robotics Engineering, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811361/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14644996533422832476&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;0;1;1;0",
        "aff_unique_norm": "Daegu Gyeongbuk Institute of Science and Technology;Korea Institute of Medical Microrobotics",
        "aff_unique_dep": "Department of Robotics Engineering;",
        "aff_unique_url": "https://www.dgist.ac.kr;",
        "aff_unique_abbr": "DGIST;",
        "aff_campus_unique_index": "0;0;1;0;0;1;1;0",
        "aff_campus_unique": "Daegu;Gwangju",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811713",
        "title": "Manipulation of unknown objects via contact configuration regulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an approach to robotic manipulation of unknown objects through regulation of the object's contact configuration: the location, geometry, and mode of all contacts between the object, robot, and environment. A contact configu-ration constrains the forces and motions that can be applied to the object; however, synthesizing these constraints generally requires knowledge of the object's pose and geometry. We develop an object-agnostic approach for estimation and control that circumvents this need. Our framework directly estimates a set of wrench and motion constraints which it uses to regulate the contact configuration. We use this to reactively manipulate unknown planar objects in the gravity plane. A video describing our work can be found on our project page: http://mcube.mit.edu/research/contactConfig.html.",
        "primary_area": "",
        "author": "Neel Doshi;Orion Taylor;Alberto Rodriguez;Neel Doshi;Orion Taylor;Alberto Rodriguez",
        "authorids": "/37085537968;/37088827845;/38194796600;/37085537968;/37088827845;/38194796600",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811713/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9531007269854741192&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811829",
        "title": "Map-based Visual-Inertial Localization: A Numerical Study",
        "track": "main",
        "status": "Poster",
        "abstract": "We revisit the problem of efficiently leveraging prior map information within a visual-inertial estimation framework. The use of traditional landmark-based maps with 2D-to-3D measurements along with the recently introduced keyframe-based maps with 2D-to-2D measurements are inves-tigated. The full joint estimation of the prior map is compared within a visual-inertial simulator to the Schmidt-Kalman filter (SKF) and measurement inflation methods in terms of their computational complexity, consistency, accuracy, and memory usage. This study shows that the SKF can enable efficient and consistent estimation for small workspace scenarios and the use of 2D-to-3D landmark maps have the highest levels of accuracy. Keyframe-based 2D-to-2D maps can reduce the required state size while still enabling accuracy gains. Finally, we show that measurement inflation methods, after tuning, can be accurate and efficient for large-scale environments if the guarantee of consistency is relaxed.",
        "primary_area": "",
        "author": "Patrick Geneva;Guoquan Huang;Patrick Geneva;Guoquan Huang",
        "authorids": "/37086125563;/37077670600;/37086125563;/37077670600",
        "aff": "Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811829/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1333172644150030143&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Robot Perception and Navigation Group",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812399",
        "title": "Mapping Unknown Environments With Instrumented Honey Bees",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent innovations in miniature sensors are driving a shift from robotic to bio-hybrid systems for exploration of unstructured environments. The ubiquity of honey bees in modern agriculture and ecology along with their superior agility, olfactory sense, and collective foraging skills make them a promising complement to traditional robots. This paper explores the potential of such systems based on a custom honey bee foraging simulator and models of state-of-the art miniature flight recorders which can measure solar heading at regular time intervals, as well as exploratory data collected from the sensor mounted on an autonomous quadrotor. The size and functionality of the sensor is heavily influenced by its memory footprint, therefore, we investigate the impact of sensor sampling time on map accuracy. Our results indicate that a sampling rate down to 5Hz can be used to sense obstacle locations in a 5-acre field with an accuracy corresponding to 70% of the obstacle radius, and within 4% of its true area. This technique shows promise for using instrumented honey bees to map and monitor unstructured environments which are difficult or costly for robots to robustly navigate, monitor, and map.",
        "primary_area": "",
        "author": "Haron Abdel-Raziq;Daniel Palmer;Alyosha Molnar;Kirstin Petersen;Haron Abdel-Raziq;Daniel Palmer;Alyosha Molnar;Kirstin Petersen",
        "authorids": "/37089341093;/37088852561;/37282515600;/37086043400;/37089341093;/37088852561;/37282515600;/37086043400",
        "aff": "Department of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA; Department of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA; Department of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA; Department of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812399/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15863428749175263265&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811602",
        "title": "Maximal Manipulation Framework using Quadratic Programming for a Teleoperated Robotic System with Articulated bodies",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a teleoperation framework to exploit the maximum manipulation capability during teleoperation. Here, exploiting maximum manipulation capacity means that the robot moves with its maximum control input while not violating the given constraints, and it is a nonlinear optimization problem with nonlinear constraints which is hard to be solved. The proposed framework relaxes the optimization problem into a simple QP problem and unifies the various constraints in the joint configuration space and Cartesian task space by utilizing control barrier function and control Lyapunov function techniques. The joint angle, velocity, acceleration limits are imposed on a teleoperated robot so that the robot does not generate any emergency stop during the teleoperation. Especially, the robot shows stable motion even near the kinematic singularity, so the operator can explore almost every reachable and admissible state of the robot via teleoperation.",
        "primary_area": "",
        "author": "Donghyeon Lee;Dongwoo Ko;Wan Kyun Chung;Keehoon Kim;Donghyeon Lee;Dongwoo Ko;Wan Kyun Chung;Keehoon Kim",
        "authorids": "/37677365900;/37086549660;/37280299100;/37066398600;/37677365900;/37086549660;/37280299100;/37066398600",
        "aff": "Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea; Department of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811602/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8912719624371090381&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Pohang University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.postech.ac.kr",
        "aff_unique_abbr": "POSTECH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pohang",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812228",
        "title": "Maximum Entropy Differential Dynamic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel maximum entropy formulation of the Differential Dynamic Programming algorithm and derive two variants using unimodal and multimodal value functions parameterizations. By combining the maximum entropy Bellman equations with a particular approximation of the cost function, we are able to obtain a new formulation of Differential Dynamic Programming which is able to escape from local minima via exploration with a multimodal policy. To demonstrate the efficacy of the proposed algorithm, we provide experimental results using four systems on tasks that are represented by cost functions with multiple local minima and compare them against vanilla Differential Dynamic Programming. Furthermore, we discuss connections with previous work on the linearly solvable stochastic control framework and its extensions in relation to compositionality. Link to Video.",
        "primary_area": "",
        "author": "Oswin So;Ziyi Wang;Evangelos A. Theodorou;Oswin So;Ziyi Wang;Evangelos A. Theodorou",
        "authorids": "/37089447383;/37086956594;/37546007800;/37089447383;/37086956594;/37546007800",
        "aff": "Autonomous Control and Decision Systems Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Autonomous Control and Decision Systems Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Autonomous Control and Decision Systems Laboratory, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812228/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14357797116919929747&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Autonomous Control and Decision Systems Laboratory",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811705",
        "title": "Maximum Likelihood Constraint Inference on Continuous State Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "When a robot observes another agent unexpectedly modifying their behavior, inferring the most likely cause is a valuable tool for maintaining safety and reacting appropriately. In this work, we present a novel method for inferring constraints that works on continuous, possibly sub-optimal demonstrations. We first learn a representation of the continuous-state maximum entropy trajectory distribution using deep reinforcement learning. We then use Monte Carlo sampling from this distribution to generate expected constraint violation probabilities and perform constraint inference. When the demonstrator's dynamics and objective function are known in advance, this process can be performed offline, allowing for real-time constraint inference at the moment demonstrations are observed. We evaluate our approach on two continuous dynamical systems: a 2-dimensional inverted pendulum model, and a 4-dimensional unicycle model that was successfully used for fast constraint inference on a 1/10 scale car remote-controlled by a human.",
        "primary_area": "",
        "author": "Kaylene C. Stocking;D. Livingston McPherson;Robert P. Matthew;Claire J. Tomlin;Kaylene C. Stocking;D. Livingston McPherson;Robert P. Matthew;Claire J. Tomlin",
        "authorids": "/37086915309;/37085370314;/37085613583;/37271692600;/37086915309;/37085370314;/37085613583;/37271692600",
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California Berkeley, Berkeley, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California Berkeley, Berkeley, CA, USA; Department of Physical Therapy and Rehabilitation Science, University of California, San Francisco, San Francisco, CA, USA; Department of Electrical Engineering and Computer Sciences, University of California Berkeley, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811705/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=875876134872910582&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;University of California, San Francisco",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences;Department of Physical Therapy and Rehabilitation Science",
        "aff_unique_url": "https://www.berkeley.edu;https://www.ucsf.edu",
        "aff_unique_abbr": "UC Berkeley;UCSF",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Berkeley;San Francisco",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811582",
        "title": "Mean Reflected Mass: A Physically Interpretable Metric for Safety Assessment and Posture Optimization in Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "In physical human-robot interaction (pHRI), safety is a key requirement. As collisions between humans and robots can generally not be avoided, it must be ensured that the human is not harmed. The robot reflected mass, the contact geometry, and the relative velocity between human and robot are the parameters that have the most significant influence on human injury severity during a collision. The reflected mass depends on the robot configuration and can be optimized especially in kinematically redundant robots. In this paper, we propose the Mean Reflected Mass (MRM) metric. The MRM is independent of the direction of contact/motion and enables assessing and optimizing the robot posture w.r.t. safety. In contrast to existing metrics, it is physically interpretable, meaning that it can be related to biomechanical injury data for realistic and model-independent safety analysis. For the Franka Emika Panda, we demonstrate in simulation that an optimization of the robot's MRM reduces the mean collision force. Finally, the relevance of the MRM for real pHRI applications is confirmed through a collision experiment.",
        "primary_area": "",
        "author": "Thomas Steinecker;Alexander Kurdas;Nico Mansfeld;Mazin Hamad;Robin Jeanne Kirschner;Saeed Abdolshah;Sami Haddadin;Thomas Steinecker;Alexander Kurdas;Nico Mansfeld;Mazin Hamad;Robin Jeanne Kirschner;Saeed Abdolshah;Sami Haddadin",
        "authorids": "/37089450621;/37088861524;/38541896600;/37086346281;/37088861072;/37086148547;/37542865300;/37089450621;/37088861524;/38541896600;/37086346281;/37088861072;/37086148547;/37542865300",
        "aff": "Institute for Autonomous Systems Technology, Universit\u00e4t der Bundeswehr M\u00fcnchen, Munich, Germany; Chair of Robotics and System Intelligence (RSI), Technical University of Munich (TUM), Munich Institute of Robotics and Machine Intelligence (MIRMI), Munich, Germany; Chair of Robotics and System Intelligence (RSI), Technical University of Munich (TUM), Munich Institute of Robotics and Machine Intelligence (MIRMI), Munich, Germany; Chair of Robotics and System Intelligence (RSI), Technical University of Munich (TUM), Munich Institute of Robotics and Machine Intelligence (MIRMI), Munich, Germany; Chair of Robotics and System Intelligence (RSI), Technical University of Munich (TUM), Munich Institute of Robotics and Machine Intelligence (MIRMI), Munich, Germany; Chair of Robotics and System Intelligence (RSI), Technical University of Munich (TUM), Munich Institute of Robotics and Machine Intelligence (MIRMI), Munich, Germany; Chair of Robotics and System Intelligence (RSI), Technical University of Munich (TUM), Munich Institute of Robotics and Machine Intelligence (MIRMI), Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811582/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6226048818959805375&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;1;1",
        "aff_unique_norm": "Universit\u00e4t der Bundeswehr M\u00fcnchen;Technical University of Munich",
        "aff_unique_dep": "Institute for Autonomous Systems Technology;Chair of Robotics and System Intelligence",
        "aff_unique_url": "https://www.unibw.de;https://www.tum.de",
        "aff_unique_abbr": ";TUM",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811622",
        "title": "Mechanical Search on Shelves using a Novel \u201cBluction\u201d Tool",
        "track": "main",
        "status": "Poster",
        "abstract": "Shelves are common in homes, warehouses, and commercial settings due to their storage efficiency. However, this efficiency comes at the cost of reduced visibility and accessibility. When looking from a side (lateral) view of a shelf, most objects will be fully occluded, resulting in a constrained lateral-access mechanical search problem. To address this problem, we introduce: (1) a novel bluction tool, which combines a thin pushing blade and a suction cup gripper, (2) a simulation pipeline and perception model that combine ray-casting with 2D Minkowski sums to efficiently generate target occupancy distributions, and (3) a novel search policy, which optimally reduces target object distribution support area using the bluction tool. Experimental data from 2000 simulated shelf trials and 18 trials with a physical Fetch robot suggest that a bluction tool can improve the average success rate by 26% in simulation and 67% in physical experiments over the highest-performing push-only policy.",
        "primary_area": "",
        "author": "Huang Huang;Michael Danielczuk;Chung Min Kim;Letian Fu;Zachary Tam;Jeffrey Ichnowski;Anelia Angelova;Brian Ichter;Ken Goldberg;Huang Huang;Michael Danielczuk;Chung Min Kim;Letian Fu;Zachary Tam;Jeffrey Ichnowski;Anelia Angelova;Brian Ichter;Ken Goldberg",
        "authorids": "/37088985585;/37086541913;/37089449093;/37089449079;/37088983619;/38541287200;/37295407600;/37086034185;/37273026700;/37088985585;/37086541913;/37089449093;/37089449079;/37088983619;/38541287200;/37295407600;/37086034185;/37273026700",
        "aff": "The AUTOLab, University of California, Berkeley; The AUTOLab, University of California, Berkeley; The AUTOLab, University of California, Berkeley; The AUTOLab, University of California, Berkeley; The AUTOLab, University of California, Berkeley; The AUTOLab, University of California, Berkeley; Google Research; Google Research; The AUTOLab, University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811622/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11039450200174260658&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;1;1;0",
        "aff_unique_norm": "University of California, Berkeley;Google",
        "aff_unique_dep": "The AUTOLab;Google Research",
        "aff_unique_url": "https://www.berkeley.edu;https://research.google",
        "aff_unique_abbr": "UC Berkeley;Google Research",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;1;0",
        "aff_campus_unique": "Berkeley;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811682",
        "title": "Memory-Efficient Gaussian Fitting for Depth Images in Real Time",
        "track": "main",
        "status": "Poster",
        "abstract": "Computing consumes a significant portion of energy in many robotics applications, especially the ones involving energy-constrained robots. In addition, memory access accounts for a significant portion of the computing energy. For mapping a 3D environment, prior approaches reduce the map size while incurring a large memory overhead used for storing sensor measurements and temporary variables during computation. In this work, we present a memory-efficient algorithm, named Single-Pass Gaussian Fitting (SPGF), that accurately constructs a compact Gaussian Mixture Model (GMM) which approximates measurements from a depthmap generated from a depth camera. By incrementally constructing the GMM one pixel at a time in a single pass through the depthmap, SPGF achieves higher throughput and orders-of-magnitude lower memory overhead than prior multipass approaches. By processing the depthmap row-by-row, SPGF exploits intrinsic properties of the camera to efficiently and accurately infer surface geometries, which leads to higher precision than prior approaches while maintaining the same compactness of the GMM. Using a low-power ARM Cortex-A57 CPU on the NVIDIA Jetson TX2 platform, SPGF operates at 32fps, requires 43KB of memory overhead, and consumes only 0.11J per frame (depthmap). Thus, SPGF enables real-time mapping of large 3D environments on energy-constrained robots.",
        "primary_area": "",
        "author": "Peter Zhi Xuan Li;Sertac Karaman;Vivienne Sze;Peter Zhi Xuan Li;Sertac Karaman;Vivienne Sze",
        "authorids": "/37089196151;/37304113000;/37394718900;/37089196151;/37304113000;/37394718900",
        "aff": "Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811682/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1933395305499033348&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812087",
        "title": "Memory-based gaze prediction in deep imitation learning for robot manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep imitation learning is a promising approach that does not require hard-coded control rules in autonomous robot manipulation. The current applications of deep imitation learning to robot manipulation have been limited to reactive control based on the states at the current time step. However, future robots will also be required to solve tasks utilizing their memory obtained by experience in complicated environments (e.g., when the robot is asked to find a previously used object on a shelf). In such a situation, simple deep imitation learning may fail because of distractions caused by complicated environments. We propose that gaze prediction from sequential visual input enables the robot to perform a manipulation task that requires memory. The proposed algorithm uses a Transformer-based self-attention architecture for the gaze estimation based on sequential data to implement memory. The proposed method was evaluated with a real robot multi-object manipulation task that requires memory of the previous states.",
        "primary_area": "",
        "author": "Heecheol Kim;Yoshiyuki Ohmura;Yasuo Kuniyoshi;Heecheol Kim;Yoshiyuki Ohmura;Yasuo Kuniyoshi",
        "authorids": "/37088419106;/37581602900;/37299294900;/37088419106;/37581602900;/37299294900",
        "aff": "Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812087/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6304149123137127928&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812439",
        "title": "Message Passing Framework for Vision Prediction Stability in Human Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "In Human Robot Interaction (HRI) scenarios, robot systems would benefit from an understanding of the user's state, actions and their effects on the environments to enable better interactions. While there are specialised vision algorithms for different perceptual channels, such as objects, scenes, human pose, and human actions, it is worth considering how their interaction can help improve each other's output. In computer vision, individual prediction modules for these perceptual channels frequently produce noisy outputs due to the limited datasets used for training and the compartmentalisation of the perceptual channels, often resulting in noisy or unstable prediction outcomes. To stabilise vision prediction results in HRI, this paper presents a novel message passing framework that uses the memory of individual modules to correct each other's outputs. The proposed framework is designed utilising common-sense rules of physics (such as the law of gravity) to reduce noise while introducing a pipeline that helps to effectively improve the output of each other's modules. The proposed framework aims to analyse primitive human activities such as grasping an object in a video captured from the perspective of a robot. Experimental results show that the proposed framework significantly reduces the output noise of individual modules compared to the case of running independently. This pipeline can be used to measure human reactions when interacting with a robot in various HRI scenarios.",
        "primary_area": "",
        "author": "Youngkyoon Jang;Yiannis Demiris;Youngkyoon Jang;Yiannis Demiris",
        "authorids": "/37536259200;/37296338900;/37536259200;/37296338900",
        "aff": "Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, Imperial College London, United Kingdom; Department of Electrical and Electronic Engineering, Personal Robotics Laboratory, Imperial College London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812439/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1702572616606334539&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811620",
        "title": "Meta-confidence estimation for stereo matching",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel framework to estimate the confidence of a disparity map taking into account, for the first time, the uncertainty affecting the confidence estimation process itself. Conversely to other tasks such as disparity estimation, the uncertainty of confidence directly hints that the confidence should be increased if initially low, but with high uncertainty, decreased otherwise. By modelling such a cue in the form of a second-level confidence, or meta-confidence, our solution allows for finding incorrect predictions inferred by confidence estimator and for learning a correction for them. Our strategy is suited for any state-of-the-art method known in literature, either implemented using random forest classifiers or deep neural networks. Especially, for deep neural networks-based models, we present a multi-headed confidence estimator followed by an uncertainty network, so as to predict mean confidence and meta-confidence within a single network without the cost of lower accuracy, a known limitation in literature for uncertainty estimation. Experimental results on a variety of stereo algorithms and confidence estimation models prove that the modeled meta-confidence is meaningful of the reliability of the estimated confidence and allows for refining it.",
        "primary_area": "",
        "author": "Seungryong Kim;Matteo Poggi;Sunok Kim;Kwanghoon Sohn;Stefano Mattoccia;Seungryong Kim;Matteo Poggi;Sunok Kim;Kwanghoon Sohn;Stefano Mattoccia",
        "authorids": "/37072295000;/37085848424;/37085712929;/37287181100;/37326275100;/37072295000;/37085848424;/37085712929;/37287181100;/37326275100",
        "aff": "Korea University; University of Bologna; Korea Aerospace University; Yonsei University; University of Bologna",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811620/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18195749108162268262&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;1",
        "aff_unique_norm": "Korea University;University of Bologna;Korea Aerospace University;Yonsei University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.korea.ac.kr;https://www.unibo.it;http://www.kau.ac.kr;https://www.yonsei.ac.kr",
        "aff_unique_abbr": "KU;Unibo;KAU;Yonsei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "South Korea;Italy"
    },
    {
        "id": "9811632",
        "title": "Meta-path Analysis on Spatio-Temporal Graphs for Pedestrian Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Spatio-temporal graphs (ST-graphs) have been used to model time series tasks such as traffic forecasting, human motion modeling, and action recognition. The high-level structure and corresponding features from ST-graphs have led to improved performance over traditional architectures. However, current methods tend to be limited by simple features, despite the rich information provided by the full graph structure, which leads to inefficiencies and suboptimal performance in downstream tasks. We propose the use of features derived from meta-paths, walks across different types of edges, in ST-graphs to improve the performance of Structural Recurrent Neural Network. In this paper, we present the Meta-path Enhanced Structural Recurrent Neural Network (MESRNN), a generic framework that can be applied to any spatio-temporal task in a simple and scalable manner. We employ MESRNN for pedestrian trajectory prediction, utilizing these meta-path based features to capture the relationships between the trajectories of pedestrians at different points in time and space. We compare our MESRNN against state-of-the-art ST-graph methods on standard datasets to show the performance boost provided by meta-path information. The proposed model consistently outperforms the baselines in trajectory prediction over long time horizons by over 32%, and produces more socially compliant trajectories in dense crowds. For more information please refer to the project website at https://sites.google.com/illinois.edu/mesrnn/home.",
        "primary_area": "",
        "author": "Aamir Hasan;Pranav Sriram;Katherine Driggs-Campbell;Aamir Hasan;Pranav Sriram;Katherine Driggs-Campbell",
        "authorids": "/37089922155;/37089450078;/37085509519;/37089922155;/37089450078;/37085509519",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Champaign, IL; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Champaign, IL; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Champaign, IL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811632/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10870812296750085502&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Champaign",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811887",
        "title": "Metareasoning for Safe Decision Making in Autonomous Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Although experts carefully specify the high-level decision-making models in autonomous systems, it is infeasible to guarantee safety across every scenario during operation. We therefore propose a safety metareasoning system that optimizes the severity of the system's safety concerns and the interference to the system's task: the system executes in parallel a task process that completes a specified task and safety processes that each address a specified safety concern with a conflict resolver for arbitration. This paper offers a formal definition of a safety metareasoning system, a recommendation algorithm for a safety process, an arbitration algorithm for a conflict resolver, an application of our approach to planetary rover exploration, and a demonstration that our approach is effective in simulation.",
        "primary_area": "",
        "author": "Justin Svegliato;Connor Basich;Sandhya Saisubramanian;Shlomo Zilberstein;Justin Svegliato;Connor Basich;Sandhya Saisubramanian;Shlomo Zilberstein",
        "authorids": "/37072711700;/37087105976;/37087104876;/37285091900;/37072711700;/37087105976;/37087104876;/37285091900",
        "aff": "University of California, Berkeley, CA, USA; University of Massachusetts, Amherst, MA, USA; Oregon State University, Corvallis, OR, USA; University of Massachusetts, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811887/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8752483178402002210&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "University of California, Berkeley;University of Massachusetts Amherst;Oregon State University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.umass.edu;https://oregonstate.edu",
        "aff_unique_abbr": "UC Berkeley;UMass Amherst;OSU",
        "aff_campus_unique_index": "0;1;2;1",
        "aff_campus_unique": "Berkeley;Amherst;Corvallis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812022",
        "title": "Microgripper Using Flexible Wire Hinge for Robotic Intraocular Snake",
        "track": "main",
        "status": "Poster",
        "abstract": "A substantially advance skill-set is a prerequisite in the domain of retinal surgery, given that the surgical instruments, constrained by small incisions made on the sclera, should be manipulated in a confined intraocular space. Therefore, robotic technologies with a snake-like architecture may be critical in retinal surgery to overcome this problem. These robots are expected to approach a target on the retina from a suitable direction when accessing its anterior portion for procedures such as vein cannulation or membrane peeling. Typical end-effectors or tools for retinal surgery include needles, light pipes, pipettes, and grippers. However, there are no retinal surgery robots or devices equipped with enough bending and grasping functionalities. We developed an Improved Integrated Robotic Intraocular Snake (I2RIS) in previous works. I2RIS has a user interface (a tactile switch or joystick unit) to provide maneuverability to the snake-like distal end. This study presents a new microgripper with its drive mechanism and an interface for retinal surgery; this microgripper is implemented into I2RIS. The proposed microgripper has a simple mechanism; it comprised only three parts, including a nitinol drive wire that functions as a flexible hinge. The microgripper diameter is 0.9 mm, and the length is 2.6 mm. A real-size prototype model was used to demonstrate the effectiveness of the proposed microgripper. In addition, a pick-and-place task using an eye model was performed by I2RIS with the proposed microgripper. It is trusted that the utility of this microgripper can extend beyond retinal surgery into other microsurgical applications.",
        "primary_area": "",
        "author": "Makoto Jinno;Iulian Iordachita;Makoto Jinno;Iulian Iordachita",
        "authorids": "/37088649257;/37330620500;/37088649257;/37330620500",
        "aff": "School of Science and Engineering, Mechanical Engineering Course, Kokushikan University, Tokyo, Japan; Whiting School of Engineering, Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812022/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6987383860290326124&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Kokushikan University;Johns Hopkins University",
        "aff_unique_dep": "Mechanical Engineering Course;Whiting School of Engineering, Laboratory for Computational Sensing and Robotics",
        "aff_unique_url": "https://www.kokushikan-u.ac.jp;https://www.jhu.edu",
        "aff_unique_abbr": "Kokushikan U;JHU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Tokyo;Baltimore",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "9812120",
        "title": "Mini Cheetah, the Falling Cat: A Case Study in Machine Learning and Trajectory Optimization for Robot Acrobatics",
        "track": "main",
        "status": "Poster",
        "abstract": "Seemingly in defiance of basic physics, cats consistently land on their feet after falling. In this paper, we design a controller that lands the Mini Cheetah quadruped robot on its feet as well. Specifically, we explore how trajectory optimization and machine learning can work together to enable highly dynamic bioinspired behaviors. We find that a reflex approach, in which a neural network learns entire state trajectories, outperforms a policy approach, in which a neural network learns a mapping from states to control inputs. We validate our proposed controller in both simulation and hardware experiments, and are able to land the robot on its feet from falls with initial pitch angles between \u221290 and 90 degrees.",
        "primary_area": "",
        "author": "Vince Kurtz;He Li;Patrick M. Wensing;Hai Lin;Vince Kurtz;He Li;Patrick M. Wensing;Hai Lin",
        "authorids": "/37086192874;/37088448396;/37946046300;/37291989100;/37086192874;/37088448396;/37946046300;/37291989100",
        "aff": "Department of Electrical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Electrical Engineering, University of Notre Dame, Notre Dame, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812120/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11368580859506380024&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Notre Dame",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812196",
        "title": "Mixed Control for Whole-Body Compliance of a Humanoid Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "The hierarchical quadratic programming (HQP) is commonly applied to consider strict hierarchies of multi-tasks and robot's physical inequality constraints during whole-body compliance. However, for the one-step HQP, the solution can oscillate when it is close to the boundary of constraints. It is because the abrupt hit of the bounds gives rise to unrealizable jerks and even infeasible solutions. This paper proposes the mixed control, which blends the single-axis model predictive control (MPC) and proportional derivative (PD) control for the whole-body compliance to overcome these deficiencies. The MPC predicts the distances between the bounds and the control target of the critical tasks, and it provides smooth and feasible solutions by prediction and optimization in advance. However, applying MPC will inevitably increase the computation time. Therefore, to achieve a 500 Hz servo rate, the PD controllers still regulate other tasks to save computation resources. Also, we use a more efficient null space projection (NSP) whole-body controller instead of the HQP and distribute the single-axis MPCs into four CPU cores for parallel computation. Finally, we validate the desired capabilities of the proposed strategy via simulations and the experiment on the humanoid robot Walker X.",
        "primary_area": "",
        "author": "Xiaozhu Ju;Jiajun Wang;Gang Han;Mingguo Zhao;Xiaozhu Ju;Jiajun Wang;Gang Han;Mingguo Zhao",
        "authorids": "/37089449748;/37089450674;/37089446921;/37336278300;/37089449748;/37089450674;/37089446921;/37336278300",
        "aff": "Beijing Research Institute of UBTECH Robotics, Beijing, China; Beijing Research Institute of UBTECH Robotics, Beijing, China; Beijing Research Institute of UBTECH Robotics, Beijing, China; Department of Automation, Tsinghua University and Beijing Innovation Center for Future Chips, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812196/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17912014460327008834&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "UBTECH Robotics;Tsinghua University",
        "aff_unique_dep": "Research Institute;Department of Automation",
        "aff_unique_url": "https://www.ubtech.com.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "UBTECH;Tsinghua",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812233",
        "title": "Mixed Reality as Communication Medium for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans engaged in collaborative activities are naturally able to convey their intentions to teammates through multi-modal communication, which is made up of explicit and implicit cues. Similarly, a more natural form of human-robot collaboration may be achieved by enabling robots to convey their intentions to human teammates via multiple communication channels. In this paper, we postulate that a better communication may take place should collaborative robots be able to anticipate their movements to human teammates in an intuitive way. In order to support such a claim, we propose a robot system's architecture through which robots can communicate planned motions to human teammates leveraging a Mixed Reality interface powered by modern head-mounted displays. Specifically, the robot's hologram, which is superimposed to the real robot in the human teammate's point of view, shows the robot's future movements, allowing the human to understand them in advance, and possibly react to them in an appropriate way. We conduct a preliminary user study to evaluate the effectiveness of the proposed anticipatory visualization during a complex collaborative task. The experimental results suggest that an improved and more natural collaboration can be achieved by employing this anticipatory communication mode.",
        "primary_area": "",
        "author": "Simone Macci\u00f2;Alessandro Carf\u00ec;Fulvio Mastrogiovanni;Simone Macci\u00f2;Alessandro Carf\u00ec;Fulvio Mastrogiovanni",
        "authorids": "/37089447573;/37086509662;/37546428500;/37089447573;/37086509662;/37546428500",
        "aff": "Department of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Genoa, Italy; Department of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Genoa, Italy; Department of Informatics, Bioengineering, Robotics, and Systems Engineering, University of Genoa, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812233/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1297729965688834378&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Genoa",
        "aff_unique_dep": "Department of Informatics, Bioengineering, Robotics, and Systems Engineering",
        "aff_unique_url": "https://www.unige.it",
        "aff_unique_abbr": "UniGe",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9812454",
        "title": "Model Identification and Control of a Low-cost Mobile Robot with Omnidirectional Wheels using Differentiable Physics",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new data-driven technique for pre-dicting the motion of a low-cost omnidirectional mobile robot under the influence of motor torques and friction forces. Our method utilizes a novel differentiable physics engine for analytically computing the gradient of the deviation between predicted motion trajectories and real-world trajectories. This allows to automatically learn and fine-tune the unknown friction coefficients on-the-fly, by minimizing a carefully designed loss function using gradient descent. Experiments show that the predicted trajectories are in excellent agreement with their real-world counterparts. Our proposed approach is computationally superior to existing black-box optimization methods, requiring very few real-world samples for accurate trajectory prediction compared to physics-agnostic techniques, such as neural net-works. Experiments also demonstrate that the proposed method allows the robot to quickly adapt to changes in the terrain. Our proposed approach combines the data-efficiency of classical analytical models that are derived from first principles, with the flexibility of data-driven methods, which makes it appropriate for low-cost mobile robots. Project website: https://go.rutgers.edu/mqxn2x6h",
        "primary_area": "",
        "author": "Edgar Granados;Abdeslam Boularias;Kostas Bekris;Mridul Aanjaneya;Edgar Granados;Abdeslam Boularias;Kostas Bekris;Mridul Aanjaneya",
        "authorids": "/37088505477;/37542596800;/37282424700;/37546899300;/37088505477;/37542596800;/37282424700;/37546899300",
        "aff": "Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812454/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5666279405336238902&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812109",
        "title": "Model Predictive Control for Fluid Human-to-Robot Handovers",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot handover is a fundamental yet challenging task in human-robot interaction and collaboration. Recently, remarkable progressions have been made in human-to-robot handovers of unknown objects by using learning-based grasp generators. However, how to responsively generate smooth motions to take an object from a human is still an open question. Specifically, planning motions that take human comfort into account is not a part of the human-robot handover process in most prior works. In this paper, we propose to generate smooth motions via an efficient model-predictive control (MPC) framework that integrates perception and complex domain-specific constraints into the optimization problem. We introduce a learning-based grasp reachability model to select candidate grasps which maximize the robot's manipulability, giving it more freedom to satisfy these constraints. Finally, we integrate a neural net force/torque classifier that detects contact events from noisy data. We conducted human-to-robot handover experiments on a diverse set of objects with several users (N=4N=4) and performed a systematic evaluation of each module. The study shows that the users preferred our MPC approach over the baseline system by a large margin.",
        "primary_area": "",
        "author": "Wei Yang;Balakumar Sundaralingam;Chris Paxton;Iretiayo Akinola;Yu-Wei Chao;Maya Cakmak;Dieter Fox;Wei Yang;Balakumar Sundaralingam;Chris Paxton;Iretiayo Akinola;Yu-Wei Chao;Maya Cakmak;Dieter Fox",
        "authorids": "/37069403600;/37086455625;/37085403975;/37086319261;/37088503888;/37409159800;/37284329000;/37069403600;/37086455625;/37085403975;/37086319261;/37088503888;/37409159800;/37284329000",
        "aff": "NVIDIA, USA; NVIDIA, USA; NVIDIA, USA; NVIDIA, USA; NVIDIA, USA; University of Washington, USA; University of Washington, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812109/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10738211311034561643&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;1",
        "aff_unique_norm": "NVIDIA;University of Washington",
        "aff_unique_dep": "NVIDIA;",
        "aff_unique_url": "https://www.nvidia.com;https://www.washington.edu",
        "aff_unique_abbr": "NV;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811590",
        "title": "Model Predictive Control with Gaussian Processes for Flexible Multi-Modal Physical Human Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Physical human-robot interaction can improve human ergonomics, task efficiency, and the flexibility of automation, but often requires application-specific methods to detect human state and determine robot response. At the same time, many potential human-robot interaction tasks involve discrete modes, such as phases of a task or multiple possible goals, where each mode has a distinct objective and human behavior. In this paper, we propose a novel method for multi-modal physical human-robot interaction that builds a Gaussian process model for human force in each mode of a collaborative task. These models are then used for Bayesian inference of the mode, and to determine robot reactions through model predictive control. This approach enables optimization of robot trajectory based on the belief of human intent, while considering robot impedance and human joint configuration, according to ergonomic- and/or task-related objectives. The proposed method reduces programming time and complexity, requiring only a low number of demonstrations (here, three per mode) and a mode-specific objective function to commission a flexible online human-robot collaboration task. We validate the method with experiments on an admittance-controlled robot, performing a collaborative assembly task with two modes where assistance is provided in full six degrees of freedom. It is shown that the developed algorithm robustly re-plans to changes in intent or robot initial position, achieving online control at 15 Hz.",
        "primary_area": "",
        "author": "Kevin Haninger;Christian Hegeler;Luka Peternel;Kevin Haninger;Christian Hegeler;Luka Peternel",
        "authorids": "/38468165500;/37089446669;/37077670700;/38468165500;/37089446669;/37077670700",
        "aff": "Department of Automation, Fraunhofer IPK, Berlin, Germany; Department of Automation, Fraunhofer IPK, Berlin, Germany; Cognitive Robotics Department, Delft Univerity of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811590/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6692962901516656102&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Fraunhofer IPK;Delft University of Technology",
        "aff_unique_dep": "Department of Automation;Cognitive Robotics Department",
        "aff_unique_url": "https://www.ipk.fraunhofer.de;https://www.tudelft.nl",
        "aff_unique_abbr": "Fraunhofer IPK;TU Delft",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Berlin;Delft",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;Netherlands"
    },
    {
        "id": "9811758",
        "title": "Model-based State Estimation of Two-Wheelers",
        "track": "main",
        "status": "Poster",
        "abstract": "Comprehensive and correct state estimation with meaningful uncertainties is the basis of object-based perception for automated mobile platforms. According to fatality statistics, the most endangered group of vulnerable road users are single-track two-wheelers (ST2W), consisting mainly of cyclists, motorcyclists, and scooter riders. Due to counter-steering, they need more time to adjust their driving state to a new situation compared to four-wheelers that can directly steer in the desired direction without loosing balance. Therefore, the roll angle gives valuable information about possible future actions, especially for short, safety-critical prediction horizons. In this work, we present a basic, robust state estimation approach that is tailored to ST2W. Due to the lack of publicly available ST2W datasets with dynamic driving maneuvers and a highly accurate state, we recorded, labeled and published three different ST2W tracks ourselves. According to our results, the roll angle can be estimated bias-free with a standard deviation of between 4.4\u25cbto 6.4\u25cb, outperforming the chosen baseline.",
        "primary_area": "",
        "author": "Florian Wirth;Julian Wadephul;Alexander Scheid;Carlos Fernandez-Lopez;Christoph Stiller;Florian Wirth;Julian Wadephul;Alexander Scheid;Carlos Fernandez-Lopez;Christoph Stiller",
        "authorids": "/37086453487;/37089449071;/37089447261;/37087273361;/37284652100;/37086453487;/37089449071;/37089447261;/37087273361;/37284652100",
        "aff": "Institute of Measurement and Control Systems, KIT, Karlsruhe, Germany; Institute of Measurement and Control Systems, KIT, Karlsruhe, Germany; Institute of Measurement and Control Systems, KIT, Karlsruhe, Germany; Institute of Measurement and Control Systems, KIT, Karlsruhe, Germany; Institute of Measurement and Control Systems, KIT, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811758/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1933826004532290059&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute of Measurement and Control Systems",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811792",
        "title": "Model-driven reinforcement learning and action dimension extension method for efficient asymmetric assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Complex assembly tasks remain huge challenge for robots because the traditional control methods rely on complicated contact state analysis. Reinforcement learning (RL) becomes one of the preferred embodiments to construct the control strategy of complex tasks. In this paper, the method of model-driven RL (MDRL) is employed to construct the control strategy. Then a completely innovative action dimension extension (ADE) mechanism is proposed to further accelerate the training process of RL. The simulation and experiment results demonstrate that the control strategy obtained through combining MDRL and ADE guarantees a more compliant assembly process. Besides, ADE method will enhance the data-efficiency of RL algorithms greatly (about 30%~40%) as well as increase the stable reward.",
        "primary_area": "",
        "author": "Yuhang Gai;Jiuming Guo;Dan Wu;Ken Chen;Yuhang Gai;Jiuming Guo;Dan Wu;Ken Chen",
        "authorids": "/37088371931;/37088578094;/37556619000;/37335409100;/37088371931;/37088578094;/37556619000;/37335409100",
        "aff": "Department of Mechanical Engineering, Tsinghua University, Beijing, China; Department of Mechanical Engineering, Tsinghua University, Beijing, China; Department of Mechanical Engineering, Tsinghua University, Beijing, China; Department of Mechanical Engineering, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811792/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4162693776478604840&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811609",
        "title": "Modeling of viscoelastic dielectric elastomer actuators based on the sparse identification method",
        "track": "main",
        "status": "Poster",
        "abstract": "Dielectric elastomer actuators (DEAs) have been widely employed to drive various soft robots, due to their quiet fast muscle-like behavior. It is significant but challenging to model and control these soft actuators, due to their viscoelastic property, irregular geometry, complex structure, etc. In this paper, we propose a data-driven sparse identification method to discover the hidden governing equations of DEAs. These equations can help us interpret the nonlinear properties of DEAs. Due to their low computational cost, we can further use these equations to explore classic model-based control methods for real-time accurate control of viscoelastic DEAs. The experiments show that the proposed method can model the viscoelastic behavior of the DEAs with reasonable accuracy. A feedforward controller is finally developed to validate the effectiveness of the proposed method. It is expected that this modeling method can pave the way for accurate control of soft actuators/robots with structural and material nonlinearities.",
        "primary_area": "",
        "author": "Jisen Li;Hao Wang;Jian Zhu;Jisen Li;Hao Wang;Jian Zhu",
        "authorids": "/37088836514;/37089450016;/37089777174;/37088836514;/37089450016;/37089777174",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811609/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3098360912588899804&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812286",
        "title": "Modeling the dynamics of soft robots by discs and threads",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a new tractable ordinary differential equation formulation for dynamic simulation of fabric- reinforced inflatable soft robots. The method performs a lumped-parameter discretization of the continuum robot into discrete discs (inertia), spring elements, and threads (representing the inextensible fabric reinforcement). Using the repetition in the structure of the Lagrangian formulation of the dynamic equations of motion, a method is developed that outputs machine- readable analytical expressions for the equations of motion. The method does not require symbolic computation of derivatives. The recursive nature allows us to scale the model to an arbitrary number NN discs, and can represent buckling, twisting, and pleating that is commonly seen in very soft robots. The expressions generated were validated against manually-derived equations of motion for the two-disc case using both Lagrangian and Newton-Euler means. A simulation environment which parses and evaluates the analytical expressions generated at run-time was used to numerically integrate and predict the response of a four-disc example robot. Trajectories observed varied smoothly and plausibly predicted the behavior envisioned in robots like these.",
        "primary_area": "",
        "author": "Joshua A. Schultz;Haley Sanders;Phuc Duc Hong Bui;Brett Layer;Marc Killpack;Joshua A. Schultz;Haley Sanders;Phuc Duc Hong Bui;Brett Layer;Marc Killpack",
        "authorids": "/37890321900;/37089448589;/37088472127;/37089450204;/37592226100;/37890321900;/37089448589;/37088472127;/37089450204;/37592226100",
        "aff": "Department of Mechanical Engineering, The University of Tulsa, Tulsa, OK; Department of Mechanical Engineering, Brigham Young University, Provo, UT; Department of Mechanical Engineering, The University of Tulsa, Tulsa, OK; Department of Mechanical Engineering, Brigham Young University, Provo, UT; Department of Mechanical Engineering, Brigham Young University, Provo, UT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812286/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8598669426386067531&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "University of Tulsa;Brigham Young University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.utulsa.edu;https://www.byu.edu",
        "aff_unique_abbr": "TU;BYU",
        "aff_campus_unique_index": "0;1;0;1;1",
        "aff_campus_unique": "Tulsa;Provo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812129",
        "title": "Modeling, Validation, and Design Investigation of a Passive Biped Walker with Knees and Biomimetic Feet",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies a passive biped walker with knees and biomimetic feet and its behavior, as a function of key parameters. The model includes a continuous dynamic representation of the knee joint's interaction with a viscoelastic kneecap, as well as a complete kinematic description of feet that are designed to mimic the human rollover shape. First, the analytical model is derived and studied numerically for its passive walking capabilities. Then, the model is verified through independent simulations in a different platform. Finally, to increase the efficiency of its passive gaits and to map out its walking capabilities, the model is investigated parametrically. The methods used as well as the results obtained can offer significant assistance in the field of designing passivity-based biomimetic walking robots and prosthetic devices.",
        "primary_area": "",
        "author": "Aikaterini Smyrli;Evangelos Papadopoulos;Aikaterini Smyrli;Evangelos Papadopoulos",
        "authorids": "/37086455674;/37273090500;/37086455674;/37273090500",
        "aff": "School of Mechanical Engineering, National Technical University of Athens; School of Mechanical Engineering, National Technical University of Athens",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812129/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15784578390050081588&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Technical University of Athens",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.ntua.gr",
        "aff_unique_abbr": "NTUA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9812444",
        "title": "Modelling and control of a variable-length flexible beam on inspection ground robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Stabilising an inverted pendulum on a cart is a well-known control problem. This paper proposes the mechan-ical and control design for solving the oscillation problem of a variable-length flexible beam mounted on a mobile robot. The system under consideration is the robot PovRob, used at the European Organization for Nuclear Research (CERN) for visual and remote inspection tasks of particle accelerators. The flexible beam mounted on the robot houses cameras and sensors. The innovative aspect of the approach concerns the use of actuated masses mounted at the end of the rod, which induces an impulsive moment due to their inertia and angular acceleration. The modelling of the flexible rod has been suitably simplified in a lumped-parameter system, with dynamic parameters related to the rod's flexibility. A linearisation of the dynamic model allows a linear-quadratic control to stabilise the system. Experimental results support the identification and the validation of the dynamic model, while simulation results evaluate the performances of the designed control law.",
        "primary_area": "",
        "author": "Giancarlo D'Ago;Marie Lefebvre;Luca Rosario Buonocore;Fabio Ruggiero;Mario Di Castro;Vincenzo Lippiello;Giancarlo D'Ago;Marie Lefebvre;Luca Rosario Buonocore;Fabio Ruggiero;Mario Di Castro;Vincenzo Lippiello",
        "authorids": "/37089447242;/37089448776;/37085383599;/37368775100;/38131112700;/37328749600;/37089447242;/37089448776;/37085383599;/37368775100;/38131112700;/37328749600",
        "aff": "European Organization for Nuclear Research, CERN, Geneva, Switzerland; \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; European Organization for Nuclear Research, CERN, Geneva, Switzerland; Department of Engineering and Information Technology, PRISMA Lab, University of Naples Federico II, Naples, Italy; European Organization for Nuclear Research, CERN, Geneva, Switzerland; Department of Engineering and Information Technology, PRISMA Lab, University of Naples Federico II, Naples, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812444/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=327992500085111510&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;2",
        "aff_unique_norm": "European Organization for Nuclear Research;EPFL;University of Naples Federico II",
        "aff_unique_dep": ";;Department of Engineering and Information Technology",
        "aff_unique_url": "https://home.cern;https://www.epfl.ch;https://www.unina.it",
        "aff_unique_abbr": "CERN;EPFL;UNINA",
        "aff_campus_unique_index": "0;1;0;2;0;2",
        "aff_campus_unique": "Geneva;Lausanne;Naples",
        "aff_country_unique_index": "0;0;0;1;0;1",
        "aff_country_unique": "Switzerland;Italy"
    },
    {
        "id": "9811819",
        "title": "Modular Adaptive Policy Selection for Multi- Task Imitation Learning through Task Division",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep imitation learning requires many expert demonstrations, which can be hard to obtain, especially when many tasks are involved. However, different tasks often share similarities, so learning them jointly can greatly benefit them and alleviate the need for many demonstrations. But, joint multi-task learning often suffers from negative transfer, sharing information that should be task-specific. In this work, we introduce a method to perform multi-task imitation while allowing for task-specific features. This is done by using proto-policies as modules to divide the tasks into simple sub-behaviours that can be shared. The proto-policies operate in parallel and are adaptively chosen by a selector mechanism that is jointly trained with the modules. Experiments on different sets of tasks show that our method improves upon the accuracy of single agents, task-conditioned and multi-headed multi-task agents, as well as state-of-the-art meta learning agents. We also demonstrate its ability to autonomously divide the tasks into both shared and task-specific sub-behaviours.",
        "primary_area": "",
        "author": "Dafni Antotsiou;Carlo Ciliberto;Tae\u2013Kyun Kim;Dafni Antotsiou;Carlo Ciliberto;Tae\u2013Kyun Kim",
        "authorids": "/37089000455;/38228801600;/37280613000;/37089000455;/38228801600;/37280613000",
        "aff": "Imperial College, London, UK; University College, London, UK; Ministry of Land, Infrastructure and Transport of Korea (22CTAP-C163793-02), and the National Research Council of Science and Technology, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811819/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13972290289128391712&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Imperial College London;University College London;Ministry of Land, Infrastructure and Transport of Korea",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.ucl.ac.uk;",
        "aff_unique_abbr": "ICL;UCL;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United Kingdom;South Korea"
    },
    {
        "id": "9812152",
        "title": "Modular End-Effector System for Autonomous Robotic Maintenance & Repair",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes the development of a modular end-effector system (MEES) for autonomous robotic maintenance and repair tasks. The design consists of the following major components: Robot Side Mating Socket Module (RSMS), End-Effector Side Mating Socket Module (EEMS), the Modular Camera System (MCS), and Tool Holder/Changer unit. Multiple prototypes for each component have been manufactured, tested, and evaluated resulting in the final concept. Existing robotic tool-changer systems on the market were evaluated and features were built into the Modular End-Effector System to overcome the current limitations of those systems. A notable advantage to the MEES is that it is a robot agnostic system and simply uses an ISO standard bolt mounting pattern to physically attached to the robot of choice along with an ethernet connection. No external cables are required that could restrain the workspace of the robot manipulator. Additionally, it is compatible with customized wrist-mounted sensors and end-effectors without any modification of the actual robot circuitry. The MEES is demonstrated working with three different end-effectors and two different robots.",
        "primary_area": "",
        "author": "Juncheng Li;Clark Teeple;Robert J. Wood;David J. Cappelleri;Juncheng Li;Clark Teeple;Robert J. Wood;David J. Cappelleri",
        "authorids": "/37089448401;/37086131116;/37326227400;/37568757700;/37089448401;/37086131116;/37326227400;/37568757700",
        "aff": "Multi-Scale Robotics & Automation Lab, School of Mechanical Engineering, Purdue University, West Lafayette, IN, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; Multi-Scale Robotics & Automation Lab, School of Mechanical Engineering, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812152/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11135422862486420280&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Purdue University;Harvard University",
        "aff_unique_dep": "School of Mechanical Engineering;John A. Paulson School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.purdue.edu;https://www.harvard.edu",
        "aff_unique_abbr": "Purdue;Harvard",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "West Lafayette;Boston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812091",
        "title": "Modular Robot Design Optimization with Generative Adversarial Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Modular robots are made up of a set of components which can be configured and reconfigured to form customized robots for a wide range of tasks. Fully utilizing the flexibility of modular robots is challenging, as it requires the identification of optimal modular designs for each given task, often with limited computation and time. Previous works in design automation achieve efficient run-times by utilizing machine learning to create a one-to-one mapping from task to design. However, the problem of robot design is often multimodal, where multiple distinct designs can be similarly or equally good for a task. Alternative design solutions may be needed in the field, for instance, if a module in the optimal design fails and no replacement is available. This paper presents a novel method based on generative adversarial networks (GANs) that learns a one-to-many mapping from task to a distribution of designs. We apply our method to construct locomoting modular robots for terrains with varying obstacle heights and infill. We compare our method against the state-of-the-art, and find that our algorithm results in better solution quality, diversity, and alternatives for when the optimal design fails.",
        "primary_area": "",
        "author": "Jiaheng Hu;Julian Whitman;Matthew Travers;Howie Choset;Jiaheng Hu;Julian Whitman;Matthew Travers;Howie Choset",
        "authorids": "/37089446932;/37086038296;/37545390200;/37281322200;/37089446932;/37086038296;/37545390200;/37281322200",
        "aff": "Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812091/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17138220460570830193&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812422",
        "title": "Monitoring the Mental State of Cooperativeness for Guiding an Elderly Person in Sit-to-Stand Assistance",
        "track": "main",
        "status": "Poster",
        "abstract": "In providing physical assistance to elderly people, ensuring cooperative behavior from the elderly persons is a critical requirement. In sit-to-stand assistance, for example, an older adult must lean forward, so that the body mass can shift towards the feet before a caregiver starts lifting the body. An experienced caregiver guides the older adult through verbal communications and physical interactions, so that the older adult may be cooperative throughout the process. This guidance is of paramount importance and is a major challenge in introducing a robotic aid to the eldercare environment. The wide-scope goal of the current work is to develop an in-telligent eldercare robot that can a) monitor the mental state of an older adult, and b) guide the older adult through an assisting procedure so that he/she can be cooperative in being assisted. The current work presents a basic modeling framework for describing a human's physical behaviors reflecting an internal mental state, and an algorithm for estimating the mental state through interactive observations. The sit-to-stand assistance problem is considered for the initial study. A simple Kalman Filter is constructed for estimating the level of cooperativeness in response to applied cues, with a thresholding scheme being used to make judgments on the cooperativeness state.",
        "primary_area": "",
        "author": "John Bell;H. Harry Asada;John Bell;H. Harry Asada",
        "authorids": "/37086862997;/37085790203;/37086862997;/37085790203",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812422/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:UEB4XSLJGG8J:scholar.google.com/&scioq=Monitoring+the+Mental+State+of+Cooperativeness+for+Guiding+an+Elderly+Person+in+Sit-to-Stand+Assistance&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811937",
        "title": "Monocular Depth Distribution Alignment with Low Computation",
        "track": "main",
        "status": "Poster",
        "abstract": "The performance of monocular depth estimation generally depends on the amount of parameters and computational cost. It leads to a large accuracy contrast between light-weight networks and heavy-weight networks, which limits their application in the real world. In this paper, we model the majority of accuracy contrast between them as the difference of depth distribution, which we call 'Distribution drift'. To this end, a distribution alignment network (DANet) is proposed. We firstly design a pyramid scene transformer (PST) module to capture inter-region interaction in multiple scales. By perceiving the difference of depth features between every two regions, DANet tends to predict a reasonable scene structure, which fits the shape of distribution to ground truth. Then, we propose a local-global optimization (LGO) scheme to realize the supervision of global range of scene depth. Thanks to the alignment of depth distribution shape and scene depth range, DANet sharply alleviates the distribution drift, and achieves a comparable performance with prior heavy-weight methods, but uses only 1% floating-point operations per second (FLOPs) of them. The experiments on two datasets, namely the widely used NYUDv2 dataset and the more challenging iBims-1 dataset, demonstrate the effectiveness of our method. The source code is available at https://github.com/YiLiM1/DANet.",
        "primary_area": "",
        "author": "Fei Sheng;Feng Xue;Yicong Chang;Wenteng Liang;Anlong Ming;Fei Sheng;Feng Xue;Yicong Chang;Wenteng Liang;Anlong Ming",
        "authorids": "/37089447118;/37086936532;/37089448944;/37089449662;/37293972600;/37089447118;/37086936532;/37089448944;/37089449662;/37293972600",
        "aff": "Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China; Beijing University of Posts and Telecommunications, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811937/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18263253443077006620&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Beijing University of Posts and Telecommunications",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.bupt.edu.cn/",
        "aff_unique_abbr": "BUPT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812421",
        "title": "Monte Carlo Tree Search Gait Planner for Non-Gaited Legged System Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, a non-gaited framework for legged system locomotion is presented. The approach decouples the gait sequence optimization by considering the problem as a decision-making process. The redefined contact sequence problem is solved by utilizing a Monte Carlo Tree Search (MCTS) algorithm that exploits optimization-based simulations to evaluate the best search direction. The proposed scheme has proven to have a good trade-off between exploration and exploitation of the search space compared to the state-of-the-art Mixed-Integer Quadratic Programming (MIQP). The model predictive control (MPC) utilizes the gait generated by the MCTS to optimize the ground reaction forces and future footholds position. The simulation results, performed on a quadruped robot, showed that the proposed framework could generate known periodic gait and adapt the contact sequence to the encountered conditions, including external forces and terrain with unknown and variable properties. When tested on robots with different layouts, the system has also shown its reliability.",
        "primary_area": "",
        "author": "Lorenzo Amatucci;Joon-Ha Kim;Jemin Hwangbo;Hae-Won Park;Lorenzo Amatucci;Joon-Ha Kim;Jemin Hwangbo;Hae-Won Park",
        "authorids": "/843794986782879;/37087322590;/37085428218;/37086265865;/843794986782879;/37087322590;/37085428218;/37086265865",
        "aff": "Dynamic Legged Systems Laboratory, Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812421/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17381875771696764534&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Dynamic Legged Systems Laboratory;Humanoid Robot Research Center",
        "aff_unique_url": "https://www.iit.it;https://www.kaist.ac.kr",
        "aff_unique_abbr": "IIT;KAIST",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Genova;Daejeon",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Italy;South Korea"
    },
    {
        "id": "9812231",
        "title": "Motion Primitives-based Navigation Planning using Deep Collision Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper contributes a method to design a novel navigation planner exploiting a learning-based collision prediction network. The neural network is tasked to predict the collision cost of each action sequence in a predefined motion primitives library in the robot's velocity-steering angle space, given only the current depth image and the estimated linear and angular velocities of the robot. Furthermore, we account for the uncertainty of the robot's partial state by utilizing the Unscented Transform and the uncertainty of the neural network model by using Monte Carlo dropout. The uncertainty-aware collision cost is then combined with the goal direction given by a global planner in order to determine the best action sequence to execute in a receding horizon manner. To demonstrate the method, we develop a resilient small flying robot integrating lightweight sensing and computing resources. A set of simulation and experimental studies, including a field deployment, in both cluttered and perceptually-challenging environments is conducted to evaluate the quality of the prediction network and the performance of the proposed planner.",
        "primary_area": "",
        "author": "Huan Nguyen;Sondre Holm Fyhn;Paolo De Petris;Kostas Alexis;Huan Nguyen;Sondre Holm Fyhn;Paolo De Petris;Kostas Alexis",
        "authorids": "/37088471319;/37089446668;/37088600627;/37546514600;/37088471319;/37089446668;/37088600627;/37546514600",
        "aff": "Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Autonomous Robots Lab, Norwegian University of Science and Technology (NTNU), Trondheim, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812231/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15059956128055894107&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Norwegian University of Science and Technology",
        "aff_unique_dep": "Autonomous Robots Lab",
        "aff_unique_url": "https://www.ntnu.edu",
        "aff_unique_abbr": "NTNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Trondheim",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Norway"
    },
    {
        "id": "9812288",
        "title": "MotionHint: Self-Supervised Monocular Visual Odometry with Motion Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel self-supervised algorithm named MotionHint for monocular visual odometry (VO) that takes motion constraints into account. A key aspect of our approach is to use an appropriate motion model that can help existing self-supervised monocular VO (SSM-VO) algorithms to overcome issues related to the local minima within their self-supervised loss functions. The motion model is expressed with a neural network named PPnet. It is trained to coarsely predict the next pose of the camera and the uncertainty of this prediction. Our self-supervised approach combines the original loss and the motion loss, which is the weighted difference between the prediction and the generated ego-motion. Taking two existing SSM-VO systems as our baseline, we evaluate our MotionHint algorithm on the standard KITTI benchmark. Experimental results show that our MotionHint algorithm can be easily applied to existing open-sourced state-of-the-art SSM-VO systems to greatly improve the performance by reducing the resulting ATE by up to 28.73%.",
        "primary_area": "",
        "author": "Cong Wang;Yu-Ping Wang;Dinesh Manocha;Cong Wang;Yu-Ping Wang;Dinesh Manocha",
        "authorids": "/37089197698;/37085396500;/37267825600;/37089197698;/37085396500;/37267825600",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Electrical, Computer Engineering at the University of Maryland, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812288/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12803168030445430272&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Tsinghua University;University of Maryland",
        "aff_unique_dep": "Department of Computer Science and Technology;Department of Computer Science and Electrical, Computer Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.umd.edu",
        "aff_unique_abbr": "THU;UMD",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Beijing;College Park",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9812037",
        "title": "Multi-Agent Dynamic Ergodic Search with Low-Information Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "The long-term goal of this work is to enable agents with low-information sensors to perform tasks usually restricted to ones with more sophisticated, high-information sensing capabilities. Our approach is to regulate the motion of these low-information agents to obtain \u201chigh-information\u201d results. As a first step, we consider a multi-agent system tasked with locating and tracking a moving target using only noisy binary sensors that measure the presence (or lack thereof) of a target in the sensor's field of view. To generate effective paths for these agents, we use ergodic trajectory optimization with a novel mutual information map that is fast to compute and can handle the discontinuous measurement models often associated with low-information sensing. We compare our approach with existing motion planning methods in multiple simulated experiments. Our experiments show that agents using our method outperform purely coverage-based approaches as well as naive ergodic approaches.",
        "primary_area": "",
        "author": "Howard Coffin;Ian Abraham;Guillaume Sartoretti;Tyler Dillstrom;Howie Choset;Howard Coffin;Ian Abraham;Guillaume Sartoretti;Tyler Dillstrom;Howie Choset",
        "authorids": "/37089446896;/37085549466;/37085791757;/37089448252;/37281322200;/37089446896;/37085549466;/37085791757;/37089448252;/37281322200",
        "aff": "Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Yale University, New Haven, CT, USA; Department of Mechanical Engineering, National University of Singapore, Singapore; Northrop Grumman Corporation at Falls Church, VA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812037/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11549958812539985656&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "Carnegie Mellon University;Yale University;National University of Singapore;Northrop Grumman Corporation",
        "aff_unique_dep": "Robotics Institute;Department of Mechanical Engineering;Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.cmu.edu;https://www.yale.edu;https://www.nus.edu.sg;https://www.northropgrumman.com",
        "aff_unique_abbr": "CMU;Yale;NUS;NGC",
        "aff_campus_unique_index": "0;1;3;0",
        "aff_campus_unique": "Pittsburgh;New Haven;;Falls Church",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;Singapore"
    },
    {
        "id": "9811643",
        "title": "Multi-Agent Path Finding with Prioritized Communication Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent pathfinding (MAPF) has been widely used to solve large-scale real-world problems, e.g., automation warehouses. The learning-based, fully decentralized framework has been introduced to alleviate real-time problems and simultaneously pursue optimal planning policy. However, existing methods might generate significantly more vertex conflicts (or collisions), which lead to a low success rate or more makespan. In this paper, we propose a PrIoritized COmmunication learning method (PICO), which incorporates the implicit planning priorities into the communication topology within the decentralized multi-agent reinforcement learning framework. Assembling with the classic coupled planners, the implicit priority learning module can be utilized to form the dynamic communication topology, which also builds an effective collision-avoiding mechanism. PICO performs significantly better in large-scale MAPF tasks in success rates and collision rates than state-of-the-art learning-based planners.",
        "primary_area": "",
        "author": "Wenhao Li;Hongjun Chen;Bo Jin;Wenzhe Tan;Hongyuan Zha;Xiangfeng Wang;Wenhao Li;Hongjun Chen;Bo Jin;Wenzhe Tan;Hongyuan Zha;Xiangfeng Wang",
        "authorids": "/37088455569;/37089449831;/37086218176;/37089449613;/37271683100;/37085342690;/37088455569;/37089449831;/37086218176;/37089449613;/37271683100;/37085342690",
        "aff": "School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Computer Science and Technology, East China Normal University, Shanghai, China; School of Computer Science and Technology, East China Normal University, Shanghai, China; Geekplus Technology Co., Ltd., Beijing, China; School of Data Science and AIRS, The Chinese University of Hong Kong, Shenzhen, China; Key Laboratory of Artificial Intelligence, Ministry of Education, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811643/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15176989466684778850&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;3",
        "aff_unique_norm": "East China Normal University;Geekplus Technology Co., Ltd.;Chinese University of Hong Kong;Key Laboratory of Artificial Intelligence",
        "aff_unique_dep": "School of Computer Science and Technology;;School of Data Science and AIRS;Ministry of Education",
        "aff_unique_url": "http://www.ecnu.edu.cn;;https://www.cuhk.edu.cn;",
        "aff_unique_abbr": "ECNU;;CUHK;",
        "aff_campus_unique_index": "0;0;0;2",
        "aff_campus_unique": "Shanghai;;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811774",
        "title": "Multi-Agent Variational Occlusion Inference Using People as Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles must reason about spatial occlusions in urban environments to ensure safety without being overly cautious. Prior work explored occlusion inference from observed social behaviors of road agents, hence treating people as sensors. Inferring occupancy from agent behaviors is an inherently multimodal problem; a driver may behave similarly for different occupancy patterns ahead of them (e.g., a driver may move at constant speed in traffic or on an open road). Past work, however, does not account for this multimodality, thus neglecting to model this source of aleatoric uncertainty in the relationship between driver behaviors and their environment. We propose an occlusion inference method that characterizes observed behaviors of human agents as sensor measurements, and fuses them with those from a standard sensor suite. To capture the aleatoric uncertainty, we train a conditional variational autoencoder with a discrete latent space to learn a multimodal mapping from observed driver trajectories to an occupancy grid representation of the view ahead of the driver. Our method handles multi-agent scenarios, combining measurements from multiple observed drivers using evidential theory to solve the sensor fusion problem. Our approach is validated on a cluttered, real-world intersection, outperforming baselines and demonstrating real-time capable performance. Our code is available at https://github.com/sisl/MultiAgentVariationalOcclusionInferenc",
        "primary_area": "",
        "author": "Masha Itkina;Ye-Ji Mun;Katherine Driggs-Campbell;Mykel J. Kochenderfer;Masha Itkina;Ye-Ji Mun;Katherine Driggs-Campbell;Mykel J. Kochenderfer",
        "authorids": "/37087102957;/37089449010;/37085509519;/37596929200;/37087102957;/37089449010;/37085509519;/37596929200",
        "aff": "Aeronautics and Astronautics Department, Stanford University, USA; Electrical and Computer Engineering Department, University of Illinois at Urbana-Champaign, USA; Electrical and Computer Engineering Department, University of Illinois at Urbana-Champaign, USA; Aeronautics and Astronautics Department, Stanford University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811774/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17174489702791728057&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Stanford University;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Aeronautics and Astronautics Department;Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.stanford.edu;https://illinois.edu",
        "aff_unique_abbr": "Stanford;UIUC",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Stanford;Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811580",
        "title": "Multi-Arm Payload Manipulation via Mixed Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-Robot Systems (MRS) present many advantages over single robots, e.g. improved stability and payload capacity. Being able to operate or teleoperate these systems is therefore of high interest in industries such as construction or logistics. However, controlling the collective motion of a MRS can place a significant cognitive burden on the operator. We present a Mixed Reality (MR) control interface, which allows an operator to specify payload target poses for a MRS in real-time, while effectively keeping the system away from unfavorable configurations. To this end, we solve the inverse kinematics problem for each arm individually and leverage redundant degrees of freedom to optimize for a secondary objective. Using the manipulability index as a secondary objective in particular, allows us to significantly improve the tracking and singularity avoidance capabilities of our MRS in comparison to the unoptimized scenario. This enables more secure and intuitive teleoperation. We simulate and test our approach on different setups and over different input trajectories, and analyse the convergence properties of our method. Finally, we show that the method also works well when deployed on to a dual-arm ABB YuMi robot.",
        "primary_area": "",
        "author": "Florian Kennel-Maushart;Roi Poranne;Stelian Coros;Florian Kennel-Maushart;Roi Poranne;Stelian Coros",
        "authorids": "/37088998456;/37085580542;/37077396200;/37088998456;/37085580542;/37077396200",
        "aff": "Department of Computer Science, ETH Zurich, Zurich, Switzerland; Department of Computer Science, University of Haifa, Haifa, Israel; Department of Computer Science, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811580/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2158523893664265375&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "ETH Zurich;University of Haifa",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch;https://www.haifa.ac.il",
        "aff_unique_abbr": "ETHZ;UoH",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Zurich;Haifa",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Switzerland;Israel"
    },
    {
        "id": "9812282",
        "title": "Multi-Class 3D Object Detection with Single-Class Supervision",
        "track": "main",
        "status": "Poster",
        "abstract": "While multi-class 3D detectors are needed in many robotics applications, training them with fully labeled datasets can be expensive in labeling cost. An alternative approach is to have targeted single-class labels on disjoint data samples. In this paper, we are interested in training a multi-class 3D object detection model, while using these single-class labeled data. We begin by detailing the unique stance of our \u201cSingle-Class Supervision\u201d (SCS) setting with respect to related concepts such as partial supervision and semi supervision. Then, based on the case study of training the multi-class version of Range Sparse Net (RSN), we adapt a spectrum of algorithms - from supervised learning to pseudo-labeling - to fully exploit the properties of our SCS setting, and perform extensive ablation studies to identify the most effective algorithm and practice. Empirical experiments on the Waymo Open Dataset show that proper training under SCS can approach or match full supervision training while saving labeling costs.",
        "primary_area": "",
        "author": "Mao Ye;Chenxi Liu;Maoqing Yao;Weiyue Wang;Zhaoqi Leng;Charles R. Qi;Dragomir Anguelov;Mao Ye;Chenxi Liu;Maoqing Yao;Weiyue Wang;Zhaoqi Leng;Charles R. Qi;Dragomir Anguelov",
        "authorids": "/37089447244;/37089895204;/37089446782;/37085517018;/37089447734;/37085643547;/37278026400;/37089447244;/37089895204;/37089446782;/37085517018;/37089447734;/37085643547;/37278026400",
        "aff": "The University of Texas at Austin; Waymo; Waymo; Waymo; Waymo; Waymo; Waymo",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812282/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2830203016363667123&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;1;1",
        "aff_unique_norm": "University of Texas at Austin;Waymo",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utexas.edu;https://www.waymo.com",
        "aff_unique_abbr": "UT Austin;Waymo",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812324",
        "title": "Multi-Dimensional Compliance of Soft Grippers Enables Gentle Interaction with Thin, Flexible Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we discuss the role of gripper compliance in successful grasping and manipulation of thin, flexible materials. We show, both conceptually and empirically, that each axis of compliance in a planar gripper provides unique benefits in this domain. Vertical compliance allows robust grasping of thin materials in the presence of large uncertainty in positioning. Lateral compliance increases opportunity to respond to unexpected snags by increasing the time window over which tensile forces are applied. Rotational compliance avoids damage to objects by decreasing the maximum tensile forces applied during snags. We explore these three benefits through empirical tests comparing a rigid gripper to a soft gripper, evaluating the level of vertical uncertainty each can handle for prehensile and non-prehensile manipulation, as well as the forces and displacements incurred during snags. The results show how a soft gripper's three-axis compliance provides a passive ability to prevent damage to delicate materials.",
        "primary_area": "",
        "author": "Clark B. Teeple;Justin Werfel;Robert J. Wood;Clark B. Teeple;Justin Werfel;Robert J. Wood",
        "authorids": "/37086131116;/37266345300;/37326227400;/37086131116;/37266345300;/37326227400",
        "aff": "School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812324/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17212665202616564615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811555",
        "title": "Multi-Dimensional Proprioception and Stiffness Tuning for Soft Robotic Joints",
        "track": "main",
        "status": "Poster",
        "abstract": "Proprioception and variable stiffness are two trending topics in soft robotics research. The former could endow soft robots with the ability to perceive the environment as well as their internal states without the need of dedicated sensors, while the latter could strengthen the otherwise excessive compliance, enabling soft robots for tasks which require a higher force. Both directions have been extensively reported in existing literature, achieving both concurrently was even more challenging. The major limiting factor was the limited stiffness due to the hyper elasticity of conventional soft robots, which increases the difficulties in capturing the continues deformation. In this work, we proposed an alternative approach to tackle these two challenges, a novel \u201ctune-down\u201d approach, combining proprioception with stiffness regulation and implemented over-constrained soft robotic joint designs to further strengthen this spirit. As a result, the soft robotic joint could achieve multi-directional proprioception, as well as variable stiffness tuning, concurrently, using merely an on-board sensor for basic pneumatic control. The concept, design, modeling, actuation/control, and experimental validation were presented in detail, demonstrating the efficacy and potential of the proposed approach.",
        "primary_area": "",
        "author": "Zhonggui Fang;Chaoyi Huang;Yaxi Wang;Jiahao Xu;Jiyong Tan;Bin Li;Zichen Wang;Yige Wu;Anlun Huang;Juan Yi;Sicong Liu;Zheng Wang;Zhonggui Fang;Chaoyi Huang;Yaxi Wang;Jiahao Xu;Jiyong Tan;Bin Li;Zichen Wang;Yige Wu;Anlun Huang;Juan Yi;Sicong Liu;Zheng Wang",
        "authorids": "/37088366157;/37089447764;/37086480704;/37089448406;/37088994577;/37089921494;/37089448341;/37089449040;/37089446876;/37086012478;/37086616485;/37085463419;/37088366157;/37089447764;/37086480704;/37089448406;/37088994577;/37089921494;/37089448341;/37089449040;/37089446876;/37086012478;/37086616485;/37085463419",
        "aff": "Department of Mechanical and Energy Engineering, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems, Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems, Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems, Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems, Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems, Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; SUSTECH-AISONO Joint Lab, Shenzhen, China; Department of Mechanical and Energy Engineering, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems, Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems, Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems, Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems, Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems, Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Shenzhen Key Laboratory of Biomimetic Robotics and Intelligent Systems, Guangdong Provincial Key Laboratory of Human Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811555/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4399838030458614162&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical and Energy Engineering",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812388",
        "title": "Multi-Object Grasping - Types and Taxonomy",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes 12 multi-object grasps (MOGs) types from a human and robot grasping data set. The grasp types are then analyzed and organized into a MOG taxonomy. This paper first presents three MOG data collection setups: a human finger tracking setup for multi-object grasping demonstrations, a real system with Barretthand, UR5e arm, and a MOG algorithm, a simulation system with the same settings as the real system. Then the paper describes a novel stochastic grasping routine designed based on a biased random walk to explore the robotic hand's configuration space for feasible MOGs. Based on obser-vations in both the human demonstrations and robotic MOG solutions, this paper proposes 12 MOG types in two groups: shape-based types and function-based types. The new MOG types are compared using six characteristics and then compiled into a taxonomy. This paper then introduces the observed MOG type combinations and shows examples of 16 different combinations.",
        "primary_area": "",
        "author": "Yu Sun;Eliza Amatova;Tianze Chen;Yu Sun;Eliza Amatova;Tianze Chen",
        "authorids": "/37291603500;/37089447892;/37087323523;/37291603500;/37089447892;/37087323523",
        "aff": "Robot Perception and Action Lab (RPAL) of Computer Science and Engineering Department, University of South Florida, Tampa, FL, USA; Robot Perception and Action Lab (RPAL) of Computer Science and Engineering Department, University of South Florida, Tampa, FL, USA; Robot Perception and Action Lab (RPAL) of Computer Science and Engineering Department, University of South Florida, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812388/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15134621190405707594&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of South Florida",
        "aff_unique_dep": "Computer Science and Engineering Department",
        "aff_unique_url": "https://www.usf.edu",
        "aff_unique_abbr": "USF",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tampa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812242",
        "title": "Multi-Operator Control of Connectivity-Preserving Robot Swarms Using Supervisory Control Theory",
        "track": "main",
        "status": "Poster",
        "abstract": "Involving human operators to support swarms of robots can be beneficial to address increasingly complex scenarios. However, the shared control between multiple operators remains a challenge, especially where communication between the operators is not available. This paper studies the problem of forming a dynamic chain of robots connecting two operators moving within an environment. The robot chain enables operators to share information and robots among themselves. Based on supervisory control theory, we propose a distributed solution which formally guarantees that the deployed robot controllers match the modeled specifications. We validate the controllers through simulations with groups of up to 40 mobile robots in an environment with obstacles, demonstrating the feasibility of the approach.",
        "primary_area": "",
        "author": "Genki Miyauchi;Yuri K. Lopes;Roderich Gro\u00df;Genki Miyauchi;Yuri K. Lopes;Roderich Gro\u00df",
        "authorids": "/37089447694;/37086210679;/37679099300;/37089447694;/37086210679;/37679099300",
        "aff": "Sheffield Robotics, The University of Sheffield, Sheffield, United Kingdom; Department of Computer Science, Santa Catarina State University, Joinville, Brazil; Sheffield Robotics, The University of Sheffield, Sheffield, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812242/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3031935636800522035&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Sheffield;Santa Catarina State University",
        "aff_unique_dep": "Sheffield Robotics;Department of Computer Science",
        "aff_unique_url": "https://www.sheffield.ac.uk;http://www.ufrgs.br",
        "aff_unique_abbr": "Sheffield;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Sheffield;Joinville",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United Kingdom;Brazil"
    },
    {
        "id": "9811673",
        "title": "Multi-Robot Persistent Environmental Monitoring Based on Constraint-Driven Execution of Learned Robot Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers a multi-robot team tasked with monitoring an environmental field of interest over long time horizons. The approach is based on a control-theoretic measure of the information collected by the robots, namely a norm of the constructability Gramian. This measure is leveraged in order to learn a distributed multi-robot control policy using the reinforcement learning paradigm. The learned policy is then combined with energy constraints using the constraint-driven control framework in order to achieve persistent environmental monitoring. The proposed approach is tested in a simulated multi-robot persistent environmental monitoring scenario where a team of robots with limited availability of energy is to be controlled in a coordinated fashion in order to estimate the concentration of a gas diffusing in the environment.",
        "primary_area": "",
        "author": "Gennaro Notomista;Claudio Pacchierotti;Paolo Robuffo Giordano;Gennaro Notomista;Claudio Pacchierotti;Paolo Robuffo Giordano",
        "authorids": "/37085607644;/38513576600;/37544316400;/37085607644;/38513576600;/37544316400",
        "aff": "CNRS, Univ Rennes, Inria, IRISA, Rennes, France; CNRS, Univ Rennes, Inria, IRISA, Rennes, France; CNRS, Univ Rennes, Inria, IRISA, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811673/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7449082531891386390&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812151",
        "title": "Multi-Target Encirclement with Collision Avoidance via Deep Reinforcement Learning using Relational Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel decentralized method based on deep reinforcement learning using robot-level and target-level relational graphs, to solve the problem of multi-target encirclement with collision avoidance (MECA). Specifically, the robot-level relational graphs, composed of three heterogeneous relational graphs between each robot and other robots, targets and obstacles, are modeled and learned through using graph attention networks (GATs) for extracting different spatial relational representations. Moreover, for each target within the observation of each robot, a target-level relational graph is built with GAT to construct spatial relations from the robot. Furthermore, the movement of each target is modeled by the target-level relational graph and learned through supervised learning for predicting the trajectory of the target. In addition, a knowledge-embedded compound reward function is defined to solve the multi-objective problem in MECA, and guide the policy learning for deriving the behavior of MECA. An actor-critic training algorithm based on the centralized training and decentralized execution framework is adopted to train the policy network. Simulation and real-world experiment results demonstrate the effectiveness and generalization of our method.",
        "primary_area": "",
        "author": "Tianle Zhang;Zhen Liu;Zhiqiang Pu;Jianqiang Yi;Tianle Zhang;Zhen Liu;Zhiqiang Pu;Jianqiang Yi",
        "authorids": "/37088518501;/37085471998;/37956875200;/37277001200;/37088518501;/37085471998;/37956875200;/37277001200",
        "aff": "Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812151/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6547897904743752514&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences",
        "aff_unique_dep": "Institute of Automation",
        "aff_unique_url": "http://www.ia.cas.cn",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812096",
        "title": "Multi-Task Learning with Sequence-Conditioned Transporter Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling robots to solve multiple manipulation tasks has a wide range of industrial applications. While learning-based approaches enjoy flexibility and generalizability, scaling these approaches to solve such compositional tasks remains a challenge. In this work, we aim to solve multi-task learning through the lens of sequence-conditioning and weighted sampling. First, we propose a new suite of benchmark specifically aimed at compositional tasks, MultiRavens, which allows defining custom task combinations through task modules that are inspired by industrial tasks and exemplify the difficulties in vision-based learning and planning methods. Second, we propose a vision-based end-to-end system architecture, Sequence-Conditioned Transporter Networks, which augments Goal-Conditioned Transporter Networks with sequence-conditioning and weighted sampling and can efficiently learn to solve multi-task long horizon problems. Our analysis suggests that not only the new framework significantly improves pick-and-place performance on novel 10 multi-task benchmark problems, but also the multi-task learning with weighted sampling can vastly improve learning and agent performances on individual tasks.",
        "primary_area": "",
        "author": "Michael H. Lim;Andy Zeng;Brian Ichter;Maryam Bandari;Erwin Coumans;Claire Tomlin;Stefan Schaal;Aleksandra Faust;Michael H. Lim;Andy Zeng;Brian Ichter;Maryam Bandari;Erwin Coumans;Claire Tomlin;Stefan Schaal;Aleksandra Faust",
        "authorids": "/37089279447;/37086217185;/37086034185;/37085436412;/37086455409;/37271692600;/37282144700;/37077144300;/37089279447;/37086217185;/37086034185;/37085436412;/37086455409;/37271692600;/37282144700;/37077144300",
        "aff": "Hybrid Systems Lab, The Unversity of California, Berkeley, USA; Google Research, USA; Google Research, USA; Intrinsic, USA; Google Research, USA; Hybrid Systems Lab, The Unversity of California, Berkeley, USA; Intrinsic, USA; Google Research, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812096/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15656909838188298848&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;2;1;0;2;1",
        "aff_unique_norm": "University of California, Berkeley;Google;Intrinsic",
        "aff_unique_dep": "Hybrid Systems Lab;Google Research;",
        "aff_unique_url": "https://www.berkeley.edu;https://research.google;",
        "aff_unique_abbr": "UC Berkeley;Google;",
        "aff_campus_unique_index": "0;1;1;1;0;1",
        "aff_campus_unique": "Berkeley;Mountain View;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812201",
        "title": "Multi-UAV Disaster Environment Coverage Planning with Limited-Endurance",
        "track": "main",
        "status": "Poster",
        "abstract": "Disaster areas involving floods and earthquakes are commonly large, with the rescue time being quite tight, suggesting multi-Unmanned Aerial Vehicles (UAV) exploration rather than employing a single UAV. For such scenarios, current UAV exploration is modeled as a Coverage Path Planning (CPP) problem to achieve full area coverage in the presence of obstacles. However, the UAV's endurance capability is limited, and the rescue time is constrained, prohibiting even multiple UAVs from completing disaster area coverage on time. Therefore, this paper defines a multi-Agent Endurance-limited CPP (MAEl-CPP) problem that is based on an a priori known heatmap of the disaster area, which affords to explore the most valuable areas under UAV limited energy constraints. Furthermore, we propose a path planning algorithm for the MAEl-CPP problem by ranking the possible disaster areas according to their importance through satellite or remote sensing aerial images and completing path planning according to this ranking. Experimental results demonstrate that the search efficiency of the proposed algorithm is 4.2 times that of the existing algorithm.",
        "primary_area": "",
        "author": "Hongyu Song;Jincheng Yu;Jiantao Qiu;Zhixiao Sun;Kuijun Lang;Qing Luo;Yuan Shen;Yu Wang;Hongyu Song;Jincheng Yu;Jiantao Qiu;Zhixiao Sun;Kuijun Lang;Qing Luo;Yuan Shen;Yu Wang",
        "authorids": "/37089448414;/37086203732;/37085859616;/37089448621;/37089448866;/37089446959;/37400482800;/37293645500;/37089448414;/37086203732;/37085859616;/37089448621;/37089448866;/37089446959;/37400482800;/37293645500",
        "aff": "Department of Electrical and Computer Engineering, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; EE department, Tsinghua University, Beijing, China; EE department, Tsinghua University, Beijing, China; Avic Shenyang Aircraft Design And Research Institute, Shenyang, China; Avic Shenyang Aircraft Design And Research Institute, Shenyang, China; Avic Shenyang Aircraft Design And Research Institute, Shenyang, China; EE department, Tsinghua University, Beijing, China; EE department, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812201/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15667343111208406440&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;2;2;2;1;1",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Tsinghua University;AVIC Shenyang Aircraft Design and Research Institute",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;EE department;",
        "aff_unique_url": "https://www.tum.de;https://www.tsinghua.edu.cn;",
        "aff_unique_abbr": "TUM;THU;AVIC SACRI",
        "aff_campus_unique_index": "0;1;1;2;2;2;1;1",
        "aff_campus_unique": "Munich;Beijing;Shenyang",
        "aff_country_unique_index": "0;1;1;1;1;1;1;1",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "9812060",
        "title": "Multi-modal Motion Prediction with Transformer-based Neural Network for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting the behaviors of other agents on the road is critical for autonomous driving to ensure safety and efficiency. However, the challenging part is how to represent the social interactions between agents and output different possible trajectories with interpretability. In this paper, we introduce a neural prediction framework based on the Transformer structure to model the relationship among the interacting agents and extract the attention of the target agent on the map waypoints. Specifically, we organize the interacting agents into a graph and utilize the multi-head attention Transformer encoder to extract the relations between them. To address the multi-modality of motion prediction, we propose a multi-modal attention Transformer encoder, which modifies the multi-head attention mechanism to multi-modal attention, and each predicted trajectory is conditioned on an independent attention mode. The proposed model is validated on the Argoverse motion forecasting dataset and shows state-of-the-art prediction accuracy while maintaining a small model size and a simple training process. We also demonstrate that the multi-modal attention module can automatically identify different modes of the target agent's attention on the map, which improves the interpretability of the model.",
        "primary_area": "",
        "author": "Zhiyu Huang;Xiaoyu Mo;Chen Lv;Zhiyu Huang;Xiaoyu Mo;Chen Lv",
        "authorids": "/37087239692;/37088557661;/37086095836;/37087239692;/37088557661;/37086095836",
        "aff": "School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812060/",
        "gs_citation": 151,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1722049673500185199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9812083",
        "title": "Multi-robot Cooperative Pursuit via Potential Field-Enhanced Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "It is of great challenge, though promising, to coordinate collective robots for hunting an evader in a decentralized manner purely in light of local observations. In this paper, this challenge is addressed by a novel hybrid cooperative pursuit algorithm that combines reinforcement learning with the artificial potential field method. In the proposed algorithm, decentralized deep reinforcement learning is employed to learn cooperative pursuit policies that are adaptive to dynamic environments. The artificial potential field method is integrated into the learning process as predefined rules to improve the data efficiency and generalization ability. It is shown by numerical simulations that the proposed hybrid design outperforms the pursuit policies either learned from vanilla reinforcement learning or designed by the potential field method. Furthermore, experiments are conducted by transferring the learned pursuit policies into real-world mobile robots. Experimental results demonstrate the feasibility and potential of the proposed algorithm in learning multiple cooperative pursuit strategies.",
        "primary_area": "",
        "author": "Zheng Zhang;Xiaohan Wang;Qingrui Zhang;Tianjiang Hu;Zheng Zhang;Xiaohan Wang;Qingrui Zhang;Tianjiang Hu",
        "authorids": "/37089449005;/37088884661;/37085341265;/37286680100;/37089449005;/37088884661;/37085341265;/37286680100",
        "aff": "Machine Intelligence and Collective Robotics (MICRO) Lab, Sun Yat-sen University, Guangzhou, China; Machine Intelligence and Collective Robotics (MICRO) Lab, Sun Yat-sen University, Guangzhou, China; Machine Intelligence and Collective Robotics (MICRO) Lab, Sun Yat-sen University, Guangzhou, China; Machine Intelligence and Collective Robotics (MICRO) Lab, Sun Yat-sen University, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812083/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6067434782435298375&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Sun Yat-sen University",
        "aff_unique_dep": "Machine Intelligence and Collective Robotics (MICRO) Lab",
        "aff_unique_url": "http://www.sysu.edu.cn",
        "aff_unique_abbr": "SYSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812339",
        "title": "Multi-view object pose distribution tracking for pre-grasp planning on mobile robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to track the 6D pose distribution of an object when a mobile manipulator robot is still approaching the object can enable the robot to pre-plan grasps that combine base and arm motion. However, tracking a 6D object pose distribution from a distance can be challenging due to the limited view of the robot camera. In this work, we present a framework that fuses observations from external stationary cameras with a moving robot camera and sequentially tracks it in time to enable 6D object pose distribution tracking from a distance. We model the object pose posterior as a multi-modal distribution which results in a better performance against uncertainties introduced by large camera-object distance, occlusions and object geometry. We evaluate the proposed framework on a simulated multi-view dataset using objects from the YCB data set. Results show that our framework enables accurate tracking even when the robot camera has poor visibility of the object.",
        "primary_area": "",
        "author": "Lakshadeep Naik;Thorbj\u00f8rn Mosekj\u00e6r Iversen;Aljaz Kramberger;Jakob Wilm;Norbert Kr\u00fcger;Lakshadeep Naik;Thorbj\u00f8rn Mosekj\u00e6r Iversen;Aljaz Kramberger;Jakob Wilm;Norbert Kr\u00fcger",
        "authorids": "/37086175049;/37086208129;/37085387168;/37075188100;/37546662200;/37086175049;/37086208129;/37085387168;/37075188100;/37546662200",
        "aff": "SDU Robotics, M\u00e6rsk Mc-Kinney M\u00f8ller Institute (MMMI), Faculty of Engineering, University of Southern Denmark, Odense M, Denmark; SDU Robotics, M\u00e6rsk Mc-Kinney M\u00f8ller Institute (MMMI), Faculty of Engineering, University of Southern Denmark, Odense M, Denmark; SDU Robotics, M\u00e6rsk Mc-Kinney M\u00f8ller Institute (MMMI), Faculty of Engineering, University of Southern Denmark, Odense M, Denmark; SDU Robotics, M\u00e6rsk Mc-Kinney M\u00f8ller Institute (MMMI), Faculty of Engineering, University of Southern Denmark, Odense M, Denmark; SDU Robotics, M\u00e6rsk Mc-Kinney M\u00f8ller Institute (MMMI), Faculty of Engineering, University of Southern Denmark, Odense M, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812339/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15113613584994446346&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Southern Denmark",
        "aff_unique_dep": "Faculty of Engineering",
        "aff_unique_url": "https://www.sdu.dk",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Odense",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9812107",
        "title": "MultiPath++: Efficient Information Fusion and Trajectory Aggregation for Behavior Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting the future behavior of road users is one of the most challenging and important problems in autonomous driving. Applying deep learning to this problem requires fusing heterogeneous world state in the form of rich perception signals and map information, and inferring highly multi-modal distributions over possible futures. In this paper, we present MultiPath++, a future prediction model that achieves state-of-the-art performance on popular benchmarks. MultiPath++ improves the MultiPath architecture [34] by revisiting many design choices. The first key design difference is a departure from dense image-based encoding of the input world state in favor of a sparse encoding of heterogeneous scene elements: MultiPath++ consumes compact and efficient polylines to describe road features, and raw agent state information directly (e.g., position, velocity, acceleration). We propose a context-aware fusion of these elements and develop a reusable multi-context gating fusion component. Second, we reconsider the choice of pre-defined static anchors, and develop a way to learn latent anchor embeddings end-to-end in the model. Lastly, we explore ensembling and output aggregation techniques\u2014common in other ML domains\u2014and find effective variants for our probabilistic multimodal output representation. We perform an extensive ablation on these design choices, and show that our proposed model achieves state-of-the-art performance on the Argoverse Motion Forecasting Competition [10] and the Waymo Open Dataset Motion Prediction Challenge [13].",
        "primary_area": "",
        "author": "Balakrishnan Varadarajan;Ahmed Hefny;Avikalp Srivastava;Khaled S. Refaat;Nigamaa Nayakanti;Andre Cornman;Kan Chen;Bertrand Douillard;Chi Pang Lam;Dragomir Anguelov;Benjamin Sapp;Balakrishnan Varadarajan;Ahmed Hefny;Avikalp Srivastava;Khaled S. Refaat;Nigamaa Nayakanti;Andre Cornman;Kan Chen;Bertrand Douillard;Chi Pang Lam;Dragomir Anguelov;Benjamin Sapp",
        "authorids": "/37089448894;/37086666025;/37089450820;/37540952100;/37089450300;/37089449783;/37085804626;/37296730300;/37089449297;/37278026400;/37089406608;/37089448894;/37086666025;/37089450820;/37540952100;/37089450300;/37089449783;/37085804626;/37296730300;/37089449297;/37278026400;/37089406608",
        "aff": "Waymo, Mountain View, California, USA; Waymo, Mountain View, California, USA; Waymo, Mountain View, California, USA; Waymo, Mountain View, California, USA; Waymo, Mountain View, California, USA; Waymo, Mountain View, California, USA; Waymo, Mountain View, California, USA; Waymo, Mountain View, California, USA; Waymo, Mountain View, California, USA; Waymo, Mountain View, California, USA; Waymo, Mountain View, California, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812107/",
        "gs_citation": 366,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6346335037641908603&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Waymo",
        "aff_unique_dep": "",
        "aff_unique_url": "https://waymo.com",
        "aff_unique_abbr": "Waymo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812435",
        "title": "Multimodal Hydrostatic Actuators for Wearable Robots: A Preliminary Assessment of Mass-Saving and Energy-Efficiency Opportunities",
        "track": "main",
        "status": "Poster",
        "abstract": "Wearable robots are limited by their actuators performances because they must bear the weight of their own power system and energy source. This paper explores the idea of leveraging hybrid modes to meet multiple operating points with a lightweight and efficient system by using hydraulic valves to dynamically reconfigure the connections of a hydrostatic actuator. The analyzed opportunities consist in 1) switching between a highly geared power source or a fast power source, 2) dynamically connecting an energy accumulator and 3) using a locking mechanism for holding. Based on a knee exoskeleton case study analysis, results show that switching between gearing ratio can lead to a lighter and more efficient actuator. Also, results show that using an accumulator to provide a preload continuous force has great mass-saving potential, but does not reduce mass significantly if used as a power booster for short transients. Finally, using a locking valve can slightly reduce battery mass if the work cycle includes frequent stops. The operating principles of the proposed multimodal schemes are demonstrated with a one-DOF prototype.",
        "primary_area": "",
        "author": "Jeff Denis;Alex Lecavalier;Jean-S\u00e9bastien Plante;Alexandre Girard;Jeff Denis;Alex Lecavalier;Jean-S\u00e9bastien Plante;Alexandre Girard",
        "authorids": "/37086933462;/37089449419;/37282435300;/37077071500;/37086933462;/37089449419;/37282435300;/37077071500",
        "aff": "Department of Mechanical Engineering, Universit\u00e9 de Sherbrooke, QC, Canada; Department of Mechanical Engineering, Universit\u00e9 de Sherbrooke, QC, Canada; Department of Mechanical Engineering, Universit\u00e9 de Sherbrooke, QC, Canada; Department of Mechanical Engineering, Universit\u00e9 de Sherbrooke, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812435/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2946148462102598045&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 de Sherbrooke",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.usherbrooke.ca",
        "aff_unique_abbr": "UdeS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Sherbrooke",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812447",
        "title": "Multiple Consistency Supervision based Semi-supervised OCT Segmentation using Very Limited Annotations",
        "track": "main",
        "status": "Poster",
        "abstract": "Optical Coherence Tomography (OCT) is a rapidly growing and promising imaging technique, enabling non-invasive high-resolution visualization of biological tissues. Segmentation of tissue structures from OCT scans is essen-tial for disease diagnosis but remains challenging for the blurry boundaries and large volumes. Deep learning-based OCT segmentation algorithms always require large numbers of annotations for satisfying performance, which is hard to meet since manually labeling is time-consuming and labor-intensive. Therefore, we propose a novel semi-supervised OCT segmentation framework utilizing very few labeled scans, i.e., 5 samples, and abundant unlabeled data. Specifically, our framework con-sists of one shared encoder and two different decoder branches. For the two branches, we design a strong augmentation-consistent supervision module and a scaling transformation-consistent supervision module respectively to improve their generalization ability. Besides, cross consistency supervision with feature perturbations between two branches is proposed to incorporate their advantages for further regularization. With such multiple consistency supervision, we aim to enrich the diversity of unsupervised information so as to make full use of labeled and unlabeled data. Experimental results on a public retinal OCT dataset demonstrate the effectiveness of our method, achieving an average dice score of 87.25% in the case of only 5 labeled samples used. It outperforms the supervised baseline by 3.46% and the best semi-supervised model by 1.42% in our experiments.",
        "primary_area": "",
        "author": "Ye Lu;Yutian Shen;Xiaohan Xing;Max Q.-H. Meng;Ye Lu;Yutian Shen;Xiaohan Xing;Max Q.-H. Meng",
        "authorids": "/37089345278;/37088955451;/37086496866;/37274117000;/37089345278;/37088955451;/37086496866;/37274117000",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812447/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10040973505665425388&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9812378",
        "title": "Multirobot control with double-integrator dynamics and control barrier functions for deformable object transport",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a formation control system for deforming and transporting simultaneously a de-formable object with a team of robots, modeled with double-integrator dynamics. The goal is to reach a target configuration, defined as a combination of shape, scale, orientation and position of the formation. We augment this controller with a set of control barrier functions (CBFs). The CBFs allow us to satisfy fundamental constraints for the success of the task: avoidance of agent-to-agent, agent-to-obstacle and object-to-obstacle collisions, and of excessive stretching. We test the performance of our proposal in different simulation scenarios.",
        "primary_area": "",
        "author": "Rafael Herguedas;Miguel Aranda;Gonzalo L\u00f3pez-Nicol\u00e1s;Carlos Sag\u00fc\u00e9s;Youcef Mezouar;Rafael Herguedas;Miguel Aranda;Gonzalo L\u00f3pez-Nicol\u00e1s;Carlos Sag\u00fc\u00e9s;Youcef Mezouar",
        "authorids": "/37087009639;/38575293000;/37546413100;/37089447304;/37299713100;/37087009639;/38575293000;/37546413100;/37089447304;/37299713100",
        "aff": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Spain; CNRS, Clermont Auvergne INP, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Spain; CNRS, Clermont Auvergne INP, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812378/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17056487156975783277&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "Universidad de Zaragoza;Universit\u00e9 Clermont Auvergne",
        "aff_unique_dep": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n;",
        "aff_unique_url": "https://www.unizar.es;https://www.uca.fr",
        "aff_unique_abbr": ";UCA",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Clermont-Ferrand",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "Spain;France"
    },
    {
        "id": "9811684",
        "title": "MyoSim: Fast and physiologically realistic MuJoCo models for musculoskeletal and exoskeletal studies",
        "track": "main",
        "status": "Poster",
        "abstract": "Owing to the restrictions of live experimentation, musculoskeletal simulation models play a key role in biological motor control studies and investigations. Successful results of which are then tried on live subjects to develop treatments as well as robot aided rehabilitation procedures for addressing neuromusculoskeletal anomalies ranging from limb loss, to tendinitis, from sarcopenia to brain and spinal injuries. Despite its significance, current musculoskeletal models are computationally expensive, and provide limited support for contact-rich interactions which are essential for studying motor behaviors in activities of daily living, during rehabilitation treatments, or in assistive robotic devices. To bridge this gap, this work proposes an automatic pipeline to generate physiologically accurate musculoskeletal, as well as hybrid musculoskeletal-exoskeletal models. Leveraging this pipeline we present MyoSim - a set of computationally efficient (over 2 orders of magnitude faster than state of the art) musculoskeletal models that support fully interactive contact rich simulation. We further extend MyoSim to support additional features that help simulate various real-life changes/diseases, such as muscle fatigue, and sarcopenia. To demonstrate the potential applications, several use cases, including interactive rehabilitation movements, tendon-reaffirmation, and the cosimulation with an exoskeleton, were developed and investigated for physiological correctness. Web-page: https://sites.google.com/view/myosuite",
        "primary_area": "",
        "author": "Huawei Wang;Vittorio Caggiano;Guillaume Durandau;Massimo Sartori;Vikash Kumar;Huawei Wang;Vittorio Caggiano;Guillaume Durandau;Massimo Sartori;Vikash Kumar",
        "authorids": "/37089449875;/37087033070;/37086207014;/37529058300;/37077886400;/37089449875;/37087033070;/37086207014;/37529058300;/37077886400",
        "aff": "Faculty of Biomechancial Engineering, Engineering Technology, University of Twente, The Netherlands; Facebook AI Research, USA; Faculty of Biomechancial Engineering, Engineering Technology, University of Twente, The Netherlands; Faculty of Biomechancial Engineering, Engineering Technology, University of Twente, The Netherlands; Facebook AI Research, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811684/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16125320285154745399&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "University of Twente;Meta",
        "aff_unique_dep": "Faculty of Biomechancial Engineering, Engineering Technology;Facebook AI Research",
        "aff_unique_url": "https://www.utwente.nl;https://research.facebook.com",
        "aff_unique_abbr": ";FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "Netherlands;United States"
    },
    {
        "id": "9812362",
        "title": "N-QGN: Navigation Map from a Monocular Camera using Quadtree Generating Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular depth estimation has been a popu-lar area of research for several years, especially since self-supervised networks have shown increasingly good results in bridging the gap with supervised and stereo methods. However, these approaches focus their interest on dense 3D reconstruction and sometimes on tiny details that are superfluous for autonomous navigation. In this paper, we propose to address this issue by estimating the navigation map under a quad tree representation. The objective is to create an adaptive depth map prediction that only extract details that are essential for the obstacle avoidance. Other 3D space which leaves large room for navigation will be provided with approximate distance. Experiment on KITTI dataset shows that our method can significantly reduce the number of output information without major loss of accuracy.",
        "primary_area": "",
        "author": "Daniel Braun;Olivier Morell;Pascal Vasseur;C\u00e9dric Demonceaux;Daniel Braun;Olivier Morell;Pascal Vasseur;C\u00e9dric Demonceaux",
        "authorids": "/37089449576;/37089450637;/37395435900;/37265984700;/37089449576;/37089450637;/37395435900;/37265984700",
        "aff": "Im ViA Laboratory, University of Bourgogne Franche-Comte, Le Creusot, France; Im ViA Laboratory, University of Bourgogne Franche-Comte, Le Creusot, France; Pascal Vasseur is with MIS Laboratory, University of Picardie Jules Verne, Amiens, France; Im ViA Laboratory, University of Bourgogne Franche-Comte, Le Creusot, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812362/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13416660261423028377&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Bourgogne Franche-Comte;University of Picardie Jules Verne",
        "aff_unique_dep": "ViA Laboratory;MIS Laboratory",
        "aff_unique_url": ";https://www.upjv.fr",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Le Creusot;Amiens",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812368",
        "title": "Narrowing the coordinate-frame gap in behavior prediction models: Distillation for efficient and accurate scene-centric motion forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Behavior prediction models have proliferated in recent years, especially in the popular real-world robotics application of autonomous driving, where representing the distribution over possible futures of moving agents is essential for safe and comfortable motion planning. In these models, the choice of coordinate frames to represent inputs and outputs has crucial trade offs which broadly fall into one of two categories. Agent-centric models transform inputs and perform inference in agent-centric coordinates. These models are intrinsically invari-ant to translation and rotation between scene elements, are best-performing on public leaderboards, but scale quadratically with the number of agents and scene elements. Scene-centric models use a fixed coordinate system to process all agents. This gives them the advantage of sharing representations among all agents, offering efficient amortized inference computation which scales linearly with the number of agents. However, these models have to learn invariance to translation and rotation between scene elements, and typically underperform agent-centric models. In this work, we develop knowledge distillation techniques between probabilistic motion forecasting models, and apply these techniques to close the gap in performance between agent-centric and scene-centric models. This improves scene-centric model performance by 13.2% on the public Argoverse benchmark, 7.8% on Waymo Open Dataset and up to 9.4% on a large In-House dataset. These improved scene-centric models rank highly in public leaderboards and are up to 15 times more efficient than their agent-centric teacher counterparts in busy scenes.",
        "primary_area": "",
        "author": "DiJia Andy Su;Bertrand Douillard;Rami Al-Rfou;Cheol Park;Benjamin Sapp;DiJia Andy Su;Bertrand Douillard;Rami Al-Rfou;Cheol Park;Benjamin Sapp",
        "authorids": "/37089448599;/37296730300;/37089448595;/37089449466;/37089406608;/37089448599;/37296730300;/37089448595;/37089449466;/37089406608",
        "aff": "Princeton University; Waymo LLC; Waymo LLC; Waymo LLC; Waymo LLC",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812368/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2309665783697973240&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Princeton University;Waymo",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.princeton.edu;https://www.waymo.com",
        "aff_unique_abbr": "Princeton;Waymo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812291",
        "title": "NeRF-Supervision: Learning Dense Object Descriptors from Neural Radiance Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "Thin, reflective objects such as forks and whisks are common in our daily lives, but they are particularly chal-lenging for robot perception because it is hard to reconstruct them using commodity RGB-D cameras or multi-view stereo techniques. While traditional pipelines struggle with objects like these, Neural Radiance Fields (NeRFs) have recently been shown to be remarkably effective for performing view synthesis on objects with thin structures or reflective materials. In this paper we explore the use of NeRF as a new source of supervision for robust robot vision systems. In particular, we demonstrate that a NeRF representation of a scene can be used to train dense object descriptors. We use an optimized NeRF to extract dense correspondences between multiple views of an object, and then use these correspondences as training data for learning a view-invariant representation of the object. NeRF's usage of a density field allows us to reformulate the correspondence problem with a novel distribution-of-depths formulation, as opposed to the conventional approach of using a depth map. Dense correspondence models supervised with our method significantly outperform off-the-shelf learned descriptors by 106% (PCK@3px metric, more than doubling performance) and outperform our baseline supervised with multi-view stereo by 29%. Furthermore, we demonstrate the learned dense descriptors enable robots to perform accurate 6-degree of freedom (6-DoF) pick and place of thin and reflective objects.",
        "primary_area": "",
        "author": "Lin Yen-Chen;Pete Florence;Jonathan T. Barron;Tsung-Yi Lin;Alberto Rodriguez;Phillip Isola;Lin Yen-Chen;Pete Florence;Jonathan T. Barron;Tsung-Yi Lin;Alberto Rodriguez;Phillip Isola",
        "authorids": "/37088505485;/37085786926;/37953015500;/37087233779;/38194796600;/37945396900;/37088505485;/37085786926;/37953015500;/37087233779;/38194796600;/37945396900",
        "aff": "MIT; Google; Google; Nvidia; MIT; MIT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812291/",
        "gs_citation": 154,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=237559368052531213&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Google;NVIDIA",
        "aff_unique_dep": ";Google;NVIDIA Corporation",
        "aff_unique_url": "https://web.mit.edu;https://www.google.com;https://www.nvidia.com",
        "aff_unique_abbr": "MIT;Google;NVIDIA",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812221",
        "title": "Nearest-Neighbor-based Collision Avoidance for Quadrotors via Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Collision avoidance algorithms are of central interest to many drone applications. In particular, decentralized approaches may be the key to enabling robust drone swarm solutions in cases where centralized communication becomes computationally prohibitive. In this work, we draw biological inspiration from flocks of starlings (Sturnus vulgaris) and apply the insight to end-to-end learned decentralized collision avoidance. More specifically, we propose a new, scalable observation model following a biomimetic nearest-neighbor information constraint that leads to fast learning and good collision avoidance behavior. By proposing a general reinforcement learning approach, we obtain an end-to-end learning-based approach to integrating collision avoidance with arbitrary tasks such as package collection and formation change. To validate the generality of this approach, we successfully apply our methodology through motion models of medium complexity, modeling momentum and nonetheless allowing direct application to real world quadrotors in conjunction with a standard PID controller. In contrast to prior works, we find that in our sufficiently rich motion model, nearest-neighbor information is indeed enough to learn effective collision avoidance behavior. Our learned policies are tested in simulation and subsequently transferred to real-world drones to validate their real-world applicability.",
        "primary_area": "",
        "author": "Ramzi Ourari;Kai Cui;Ahmed Elshamanhory;Heinz Koeppl;Ramzi Ourari;Kai Cui;Ahmed Elshamanhory;Heinz Koeppl",
        "authorids": "/37089448575;/37089280554;/37089447721;/37285057700;/37089448575;/37089280554;/37089447721;/37285057700",
        "aff": "Department of Electrical Engineering, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Department of Electrical Engineering, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Department of Electrical Engineering, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Department of Electrical Engineering, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812221/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6845664672791516387&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Darmstadt",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811964",
        "title": "Negative Stiffness Analysis and Regulation of In-Hand Manipulation with Underactuated Compliant Hands",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the generation mechanism and avoidance method of negative stiffness during in-Hand manipulation with underactuated compliant hands. Firstly, a planar hand with two three-jointed fingers manipulating a rectangular is set, and a quasi-static underactuated operation model is established. Secondly, based on this simulation model, we investigated the stiffness evolution during in-hand manipulation, and analyze the influence factors of system stiffness. Finally, a stiffness regulation method is developed to avoid negative stiffness during in-hand manipulation. The method is validated by simulation. The research results are beneficial to improve the performance of underactuated in-hand manipulation.",
        "primary_area": "",
        "author": "Wenrui Chen;Qiang Diao;Yaonan Wang;Xiaodong Zhou;Qiang Zhang;Cuo Yan;Zhiyong Li;Wenrui Chen;Qiang Diao;Yaonan Wang;Xiaodong Zhou;Qiang Zhang;Cuo Yan;Zhiyong Li",
        "authorids": "/37085521510;/37089446605;/37281429000;/37086145075;/37086960746;/37089449840;/37597763400;/37085521510;/37089446605;/37281429000;/37086145075;/37086960746;/37089449840;/37597763400",
        "aff": "School of Robotics, Hunan University, Changsha, China; School of Robotics, Hunan University, Changsha, China; School of Robotics, Hunan University, Changsha, China; Beijing Institute of Control Engineering, Beijing, China; Beijing Institute of Control Engineering, Beijing, China; School of Robotics, Hunan University, Changsha, China; School of Robotics, Hunan University, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811964/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:xr9hnqhD2VQJ:scholar.google.com/&scioq=Negative+Stiffness+Analysis+and+Regulation+of+In-Hand+Manipulation+with+Underactuated+Compliant+Hands&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;0;0",
        "aff_unique_norm": "Hunan University;Beijing Institute of Control Engineering",
        "aff_unique_dep": "School of Robotics;",
        "aff_unique_url": "http://www.hnu.edu.cn;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0;0;1;1;0;0",
        "aff_campus_unique": "Changsha;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812146",
        "title": "Neural Descriptor Fields: SE(3)-Equivariant Object Representations for Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Neural Descriptor Fields (NDFs), an object representation that encodes both points and relative poses between an object and a target (such as a robot gripper or a rack used for hanging) via category-level descriptors. We employ this representation for object manipulation, where given a task demonstration, we want to repeat the same task on a new object instance from the same category. We propose to achieve this objective by searching (via optimization) for the pose whose descriptor matches that observed in the demonstration. NDFs are conveniently trained in a self-supervised fashion via a 3D auto-encoding task that does not rely on expert-labeled keypoints. Further, NDFs are SE(3)-equivariant, guaranteeing performance that generalizes across all possible 3D object translations and rotations. We demonstrate learning of manipulation tasks from few (\u223c5-10) demonstrations both in simulation and on a real robot. Our performance generalizes across both object instances and 6-DoF object poses, and significantly outperforms a recent baseline that relies on 2D descriptors. Project website: https://yilundu.github.io/ndf/",
        "primary_area": "",
        "author": "Anthony Simeonov;Yilun Du;Andrea Tagliasacchi;Joshua B. Tenenbaum;Alberto Rodriguez;Pulkit Agrawal;Vincent Sitzmann;Anthony Simeonov;Yilun Du;Andrea Tagliasacchi;Joshua B. Tenenbaum;Alberto Rodriguez;Pulkit Agrawal;Vincent Sitzmann",
        "authorids": "/37086194255;/37089315638;/37546684700;/37622583000;/38194796600;/37085611190;/37086347632;/37086194255;/37089315638;/37546684700;/37622583000;/38194796600;/37085611190;/37086347632",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; University of Toronto; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812146/",
        "gs_citation": 184,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12888542250152654582&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Toronto",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.utoronto.ca",
        "aff_unique_abbr": "MIT;U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9812142",
        "title": "Neural Implicit Event Generator for Motion Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel framework of motion tracking from event data using implicit expression. Our framework uses pre-trained event generation MLP called the implicit event generator (IEG) and carries out motion tracking by updating its state (position and velocity) based on the difference between the observed event and generated event from the current state estimation. The difference is computed implicitly by the IEG. Unlike the conventional explicit approach, which requires dense computation to evaluate the difference, our implicit approach realizes the update of the efficient state directly from sparse event data. Our sparse algorithm is especially suitable for mobile robotics applications in which computational resources and battery life are limited. To verify the effectiveness of our method on real-world data, we applied it to the AR marker tracking application. We have confirmed that our framework works well in real-world environments in the presence of noise and background clutter.",
        "primary_area": "",
        "author": "Mana Masuda;Yusuke Sekikawa;Ryo Fujii;Hideo Saito;Mana Masuda;Yusuke Sekikawa;Ryo Fujii;Hideo Saito",
        "authorids": "/37089383547;/37086492685;/37087234680;/37273875600;/37089383547;/37086492685;/37087234680;/37273875600",
        "aff": "School of Science for Open and Environmental Systems, Keio University, Tokyo, Japan; Denso IT Laboratory, Tokyo, Japan; School of Science for Open and Environmental Systems, Keio University, Tokyo, Japan; School of Science for Open and Environmental Systems, Keio University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812142/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8345715891382872726&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Keio University;Denso IT Laboratory",
        "aff_unique_dep": "School of Science for Open and Environmental Systems;",
        "aff_unique_url": "https://www.keio.ac.jp;https://www.denso.com",
        "aff_unique_abbr": "Keio;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812245",
        "title": "Neural Style Transfer with Twin-Delayed DDPG for Shared Control of Robotic Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural Style Transfer (NST) refers to a class of algorithms able to manipulate an element, most often images, to adopt the appearance or style of another one. Each element is defined as a combination of Content and Style: the Content can be conceptually defined as the \u201cwhat\u201d and the Style as the \u201chow\u201d of said element. In this context, we propose a custom NST framework for transferring a set of styles to the motion of a robotic manipulator, e.g., the same robotic task can be carried out in an \u201cangry\u201d, \u201chappy\u201d, \u201ccalm\u201d, or \u201csad\u201d way. An autoencoder architecture extracts and defines the Content and the Style of the target robot motions. A Twin Delayed Deep Deterministic Policy Gradient (TD3) network generates the robot control policy using the loss defined by the autoencoder. The proposed Neural Policy Style Transfer TD3 (NPST33) alters the robot motion by introducing the trained style. Such an approach can be implemented either offline, for carrying out autonomous robot motions in dynamic environments, or online, for adapting at runtime the style of a teleoperated robot. The considered styles can be learned online from human demonstrations. We carried out an evaluation with human subjects enrolling 73 volunteers, asking them to recognize the style behind some representative robotic motions. Results show a good recognition rate, proving that it is possible to convey different styles to a robot using this approach.",
        "primary_area": "",
        "author": "Raul Fernandez-Fernandez;Marco Aggravi;Paolo Robuffo Giordano;Juan G. Victores;Claudio Pacchierotti;Raul Fernandez-Fernandez;Marco Aggravi;Paolo Robuffo Giordano;Juan G. Victores;Claudio Pacchierotti",
        "authorids": "/37086030936;/38251861800;/37544316400;/38234160200;/38513576600;/37086030936;/38251861800;/37544316400;/38234160200;/38513576600",
        "aff": "Department of Systems Engineering and Automation, Robotics Lab, Universidad Carlos III de Madrid (UC3M); CNRS, Univ Rennes, Inria, IRISA, Rennes, France; CNRS, Univ Rennes, Inria, IRISA, Rennes, France; Department of Systems Engineering and Automation, Robotics Lab, Universidad Carlos III de Madrid (UC3M); CNRS, Univ Rennes, Inria, IRISA, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812245/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3523087782447713357&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Universidad Carlos III de Madrid;CNRS",
        "aff_unique_dep": "Department of Systems Engineering and Automation;",
        "aff_unique_url": "https://www.uc3m.es;https://www.cnrs.fr",
        "aff_unique_abbr": "UC3M;CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "Spain;France"
    },
    {
        "id": "9812460",
        "title": "NeuroErgo: A Deep Neural Network Method to Improve Postural Optimization for Ergonomic Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robots can help industry workers to improve their ergonomics. They can propose a safe and ergonomic posture to the workers to reduce the risk of musculoskeletal disorders. Proposing an ergonomic stance needs postural evaluation and optimization. To optimize the workers' posture, we need to run the optimization on a cost function representing the ergonomic status. The tabular ergonomic assessment methods are the most common methods used by ergonomists, but they are linear stepwise functions that are not differentiable and not suitable for optimization purposes. We propose NeuroErgo, a deep neural network model that can approximate the tabular ergonomic assessment methods more precisely than existing methods. By solving the task constraints optimization problem for any task in industry and NeuroErgo as posture cost function, a safe and ergonomic posture can be derived and recommended to the workers while accomplishing their job.",
        "primary_area": "",
        "author": "Atieh Merikh Nejadasl;Omid Gheibi;Greet Van de Perre;Bram Vanderborght;Atieh Merikh Nejadasl;Omid Gheibi;Greet Van de Perre;Bram Vanderborght",
        "authorids": "/37087101827;/37088901810;/37085361891;/37295389300;/37087101827;/37088901810;/37085361891;/37295389300",
        "aff": "Flanders Make; Computer Science Department, KU Leuven, Belgium; Imec, Belgium; Imec, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812460/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5690384689412019100&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "Flanders Make;KU Leuven;IMEC",
        "aff_unique_dep": ";Computer Science Department;",
        "aff_unique_url": "https://www.flandersmake.be;https://www.kuleuven.be;https://www.imec-int.com",
        "aff_unique_abbr": "Flanders Make;KU Leuven;IMEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9811584",
        "title": "Next Steps: Learning a Disentangled Gait Representation for Versatile Quadruped Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadruped locomotion is rapidly maturing to a degree where robots now routinely traverse a variety of unstructured terrains. However, while gaits can be varied typically by selecting from a range of pre-computed styles, current planners are unable to vary key gait parameters continuously while the robot is in motion. The synthesis, on-the-fly, of gaits with unexpected operational characteristics or even the blending of dynamic manoeuvres lies beyond the capabilities of the current state-of-the-art. In this work we address this limitation by learning a latent space capturing the key stance phases of a particular gait, via a generative model trained on a single trot style. This encourages disentanglement such that application of a drive signal to a single dimension of the latent state induces holistic plans synthesising a continuous variety of trot styles. In fact properties of this drive signal map directly to gait parameters such as cadence, footstep height and full stance duration. The use of a generative model facilitates the detection and mitigation of disturbances to provide a versatile and robust planning framework. We evaluate our approach on a real ANYmal quadruped robot and demonstrate that our method achieves a continuous blend of dynamic trot styles whilst being robust and reactive to external perturbations.",
        "primary_area": "",
        "author": "Alexander L. Mitchell;Wolfgang Merkt;Mathieu Geisert;Siddhant Gangapurwala;Martin Engelcke;Oiwi Parker Jones;Ioannis Havoutis;Ingmar Posner;Alexander L. Mitchell;Wolfgang Merkt;Mathieu Geisert;Siddhant Gangapurwala;Martin Engelcke;Oiwi Parker Jones;Ioannis Havoutis;Ingmar Posner",
        "authorids": "/37088357300;/37086118415;/37085514664;/37088356748;/37086139639;/37088690104;/37542879900;/37601368300;/37088357300;/37086118415;/37085514664;/37088356748;/37086139639;/37088690104;/37542879900;/37601368300",
        "aff": "Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811584/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13501590164326181753&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811917",
        "title": "Next-Best-View Prediction for Active Stereo Cameras and Highly Reflective Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth acquisition with the active stereo camera is a challenging task for highly reflective objects. When setup permits, multi-view fusion can provide increased levels of depth completion. However, due to the slow acquisition speed of high-end active stereo cameras, collecting a large number of viewpoints for a single scene is generally not practical. In this work, we propose a next-best-view framework to strategically select camera viewpoints for completing depth data on reflective objects. In particular, we explicitly model the specular reflection of reflective surfaces based on the Phong reflection model and a photometric response function. Given the object CAD model and grayscale image, we employ an RGB-based pose estimator to obtain current pose predictions from the existing data, which is used to form predicted surface normal and depth hypotheses, and allows us to then assess the information gain from a subsequent frame for any candidate viewpoint. Using this formulation, we implement an active perception pipeline which is evaluated on a challenging real-world dataset. The evaluation results demonstrate that our active depth acquisition method outperforms two strong baselines for both depth completion and object pose estimation performance.",
        "primary_area": "",
        "author": "Jun Yang;Steven L. Waslander;Jun Yang;Steven L. Waslander",
        "authorids": "/37088838125;/37301169100;/37088838125;/37301169100",
        "aff": "University of Toronto Institute for Aerospace Studies and Robotics Institute; University of Toronto Institute for Aerospace Studies and Robotics Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811917/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17393431198182813866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Institute for Aerospace Studies and Robotics Institute",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9811363",
        "title": "Non-Gaussian Risk Bounded Trajectory Optimization for Stochastic Nonlinear Systems in Uncertain Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the risk bounded trajectory optimization problem of stochastic nonlinear robotic systems. More precisely, we consider the motion planning problem in which the robot has stochastic nonlinear dynamics and uncertain initial locations, and the environment contains multiple dynamic uncertain obstacles with arbitrary probabilistic distributions. The goal is to plan a sequence of control inputs for the robot to navigate to the target while bounding the probability of colliding with obstacles. Existing approaches to address risk bounded trajectory optimization problems are limited to particular classes of models and uncertainties such as Gaussian linear problems. In this paper, we deal with stochastic nonlinear models, nonlinear safety constraints, and arbitrary probabilistic uncertainties, the most general setting ever considered. To address the risk bounded trajectory optimization problem, we first formulate the problem as an optimization problem with stochastic dynamics equations and chance constraints. We then convert probabilistic constraints and stochastic dynamics constraints on random variables into a set of deterministic constraints on the moments of state probability distributions. Finally, we solve the resulting deterministic optimization prob-lem using nonlinear optimization solvers and get a sequence of control inputs. To our best knowledge, it is the first time that the motion planning problem to such a general extent is considered and solved. To illustrate the performance of the proposed method, we provide several robotics examples.",
        "primary_area": "",
        "author": "Weiqiao Han;Ashkan Jasour;Brian Williams;Weiqiao Han;Ashkan Jasour;Brian Williams",
        "authorids": "/37086298455;/37078643400;/37274902300;/37086298455;/37078643400;/37274902300",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811363/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8667733053230720152&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812043",
        "title": "Non-Penetration Iterative Closest Points for Single-View Multi-Object 6D Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel iterative closest points (ICP) variant, non-penetration iterative closest points (NPICP), which prevents interpenetration in 6DOF pose optimization and/or joint optimization of multiple object poses. This capability is particularly advantageous in cluttered scenarios, where there are many interactions between objects that constrain the space of valid poses. We use a semi-infinite programming approach to handle non-penetration constraints between complex, non-convex 3D geometries. NPICP is applied to a common use case for ICP as a post-processing method to improve the pose estimation accuracy of a rough guess. The results show that NPICP outperforms ICP, assists in outlier detection, and also outperforms the best result on the IC-BIN dataset in the Benchmark for 6D Object Pose Estimation.",
        "primary_area": "",
        "author": "Mengchao Zhang;Kris Hauser;Mengchao Zhang;Kris Hauser",
        "authorids": "/37089001334;/37543748800;/37089001334;/37543748800",
        "aff": "Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign; Department of Computer Science, University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812043/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=821864815341489752&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Mechanical Science and Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811920",
        "title": "Non-destructive Fruit Firmness Evaluation Using Vision-Based Tactile Information",
        "track": "main",
        "status": "Poster",
        "abstract": "During postharvest storage, fruit firmness usually decreases due to respiration and bruise, the former of which indicates the fruit ripeness while the latter negatively influence consumers' taste preference. This paper presents a portable and low-cost device using vision-based tactile information to evaluate fruit firmness in a non-destructive manner. The device consists of a camera, LED lights, and a soft sensing layer with small bumps to capture detailed tactile information of the fruit. Two working modes are designed and a CNN-LSTM architecture is developed to relate the tactile information to fruit overall firmness or detect local firmness distortion. According to the experimental results, an R2 up to 92.9% was achieved for the evaluation of the overall firmness of Cuixiang kiwifruit, and accuracy of 98.0% was obtained for the detection of local firmness distortion of Fuji apples. These results demonstrate the efficacy of the proposed solution to evaluate fruit firmness featuring high precision, and its non-destructive and potable nature is also anticipated to be favorable by the fresh fruit market.",
        "primary_area": "",
        "author": "Yaohui Chen;Jiahao Lin;Xuan Du;Bin Fang;Fuchun Sun;Shanjun Li;Yaohui Chen;Jiahao Lin;Xuan Du;Bin Fang;Fuchun Sun;Shanjun Li",
        "authorids": "/37089612283;/37089450314;/37089450560;/37089577630;/37279269000;/38066242000;/37089612283;/37089450314;/37089450560;/37089577630;/37279269000;/38066242000",
        "aff": "National R&D Center for Citrus Preservation, Wuhan, China; College of Engineering, Huazhong Agricultural University, Wuhan, Hubei, China; College of Engineering, Huazhong Agricultural University, Wuhan, Hubei, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; National R&D Center for Citrus Preservation, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811920/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16050995314402715877&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;2;0",
        "aff_unique_norm": "National R&D Center for Citrus Preservation;Huazhong Agricultural University;Tsinghua University",
        "aff_unique_dep": ";College of Engineering;Department of Computer Science and Technology",
        "aff_unique_url": ";http://www.hzau.edu.cn/;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": ";HZAU;THU",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Wuhan;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811942",
        "title": "Non-prehensile Planar Manipulation via Trajectory Optimization with Complementarity Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Contact adaptation is an essential capability when manipulating objects. Two key contact modes of non-prehensile manipulation are sticking and sliding. This paper presents a Trajectory Optimization (TO) method formulated as a Mathematical Program with Complementarity Constraints (MPCC), which is able to switch between these two modes. We show that this formulation can be applicable to both planning and Model Predictive Control (MPC) for planar manipulation tasks. We numerically compare: (i) our planner against a mixed integer alternative, showing that the MPCC planner converges faster, scales better with respect to the time horizon (TH), and can handle environments with obstacles; (ii) our controller against a state-of-the-art mixed integer approach, showing that the MPCC controller achieves improved tracking and more consistent computation times. Additionally, we experimentally validate both our planner and controller with the KUKA LWR robot on a range of planar manipulation tasks. See our accompanying video here: https://youtu.be/EkU6YHMhjto.",
        "primary_area": "",
        "author": "Jo\u00e3o Moura;Theodoros Stouraitis;Sethu Vijayakumar;Jo\u00e3o Moura;Theodoros Stouraitis;Sethu Vijayakumar",
        "authorids": "/37086411872;/37086314988;/37295595500;/37086411872;/37086314988;/37295595500",
        "aff": "The Alan Turing Institute, London, U.K.; School of Informatics, The University of Edinburgh, Edinburgh, U.K.; The Alan Turing Institute, London, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811942/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15150397122687893280&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Alan Turing Institute;University of Edinburgh",
        "aff_unique_dep": ";School of Informatics",
        "aff_unique_url": "https://www.turing.ac.uk;https://www.ed.ac.uk",
        "aff_unique_abbr": "ATI;Edinburgh",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "London;Edinburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812283",
        "title": "Nonlinear Model Identification and Observer Design for Thrust Estimation of Small-scale Turbojet Engines",
        "track": "main",
        "status": "Poster",
        "abstract": "Jet-powered vertical takeoff and landing (VTOL) drones require precise thrust estimation to ensure adequate stability margins and robust maneuvering. Small-scale turbojets have become good candidates for powering heavy aerial drones. However, due to limited instrumentation available in these turbojets, estimating the precise thrust using classical techniques is not straightforward. In this paper, we present a methodology to accurately estimate the online thrust for the small-scale turbojets used on the iRonCub - an aerial humanoid robot. We use a grey-box method to capture the turbojet system dynamics with a nonlinear state-space model based on the data acquired from a custom engine test bench. This model is then used to design an extended Kalman filter that estimates the turbojet thrust only from the angular speed measurements. We exploited the parameter estimation algorithm to ensure that the EKF gives smooth and accurate estimates even at engine failures. The designed EKF was validated on the test bench where the mean absolute error in estimated thrust was found to be within 2% of rated peak thrust.",
        "primary_area": "",
        "author": "Affaf Junaid Ahamad Momin;Gabriele Nava;Giuseppe L'Erario;Hosameldin Awadalla Omer Mohamed;Fabio Bergonti;Punith Reddy Vanteddu;Francesco Braghin;Daniele Pucci;Affaf Junaid Ahamad Momin;Gabriele Nava;Giuseppe L'Erario;Hosameldin Awadalla Omer Mohamed;Fabio Bergonti;Punith Reddy Vanteddu;Francesco Braghin;Daniele Pucci",
        "authorids": "/37089447110;/37086044221;/37087995791;/37087996277;/37086933580;/37089177578;/37564362300;/37706167200;/37089447110;/37086044221;/37087995791;/37087996277;/37086933580;/37089177578;/37564362300;/37706167200",
        "aff": "Department of Mechanical Engineering, Politecnico di Milano, Milan, Italy; Artificial and Mechanical Intelligence, Istituto Italiano di Tecnologia, Genova, Italy; School of Computer Science, Univ. of Manchester, Manchester, U.K.; Department of Mechanical Engineering, Politecnico di Milano, Milan, Italy; School of Computer Science, Univ. of Manchester, Manchester, U.K.; Artificial and Mechanical Intelligence, Istituto Italiano di Tecnologia, Genova, Italy; Department of Mechanical Engineering, Politecnico di Milano, Milan, Italy; School of Computer Science, Univ. of Manchester, Manchester, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812283/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12745871288201602244&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;0;2;1;0;2",
        "aff_unique_norm": "Politecnico di Milano;Istituto Italiano di Tecnologia;University of Manchester",
        "aff_unique_dep": "Department of Mechanical Engineering;Artificial and Mechanical Intelligence;School of Computer Science",
        "aff_unique_url": "https://www.polimi.it;https://www.iit.it;https://www.manchester.ac.uk",
        "aff_unique_abbr": "Politecnico di Milano;IIT;UoM",
        "aff_campus_unique_index": "0;1;2;0;2;1;0;2",
        "aff_campus_unique": "Milan;Genova;Manchester",
        "aff_country_unique_index": "0;0;1;0;1;0;0;1",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "9811810",
        "title": "Nonprehensile Object Transportation with a Legged Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper tackles the problem of nonprehensile object transportation through a legged manipulator. A whole-body control architecture is devised to prevent sliding of the object placed on the tray at the manipulator's end-effector and retain the legged robot balance during walking. The controller solves a quadratic optimization problem to realize the sought transportation task while maintaining the contact forces between the tray and the object and between the legs and the ground within their respective friction cones, also considering limits on the input torques. An extensive simulation campaign confirmed the feasibility of the approach and evaluated the control performance through a thorough statistical analysis conducted varying mass, friction, and the dimension of the transported object.",
        "primary_area": "",
        "author": "Viviana Morlando;Mario Selvaggio;Fabio Ruggiero;Viviana Morlando;Mario Selvaggio;Fabio Ruggiero",
        "authorids": "/37089449147;/37085859695;/37368775100;/37089449147;/37085859695;/37368775100",
        "aff": "Department of Electrical Engineering and Information Technology, PRISMA Lab, University of Naples Federico II, Naples, Italy; Department of Electrical Engineering and Information Technology, PRISMA Lab, University of Naples Federico II, Naples, Italy; Department of Electrical Engineering and Information Technology, PRISMA Lab, University of Naples Federico II, Naples, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811810/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15397823631147736532&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Naples Federico II",
        "aff_unique_dep": "Department of Electrical Engineering and Information Technology",
        "aff_unique_url": "https://www.unina.it",
        "aff_unique_abbr": "UNINA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Naples",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9811660",
        "title": "OPIRL: Sample Efficient Off-Policy Inverse Reinforcement Learning via Distribution Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Inverse Reinforcement Learning (IRL) is attractive in scenarios where reward engineering can be tedious. However, prior IRL algorithms use on-policy transitions, which require intensive sampling from the current policy for stable and optimal performance. This limits IRL applications in the real world, where environment interactions can become highly expensive. To tackle this problem, we present Off-Policy Inverse Reinforcement Learning (OPIRL), which (1) adopts off-policy data distribution instead of on-policy and enables significant reduction of the number of interactions with the environment, (2) learns a reward function that is transferable with high generalization capabilities on changing dynamics, and (3) leverages mode-covering behavior for faster convergence. We demonstrate that our method is considerably more sample efficient and generalizes to novel environments through the experiments. Our method achieves better or comparable results on policy performance baselines with significantly fewer interactions. Furthermore, we empirically show that the recovered reward function generalizes to different tasks where prior arts are prone to fail.",
        "primary_area": "",
        "author": "Hana Hoshino;Kei Ota;Asako Kanezaki;Rio Yokota;Hana Hoshino;Kei Ota;Asako Kanezaki;Rio Yokota",
        "authorids": "/37089447271;/37087323962;/37546453800;/38235438300;/37089447271;/37087323962;/37546453800;/38235438300",
        "aff": "Department of Computer Science, School of Computing, Tokyo Institute of Technology, Japan; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Department of Computer Science, School of Computing, Tokyo Institute of Technology, Japan; Global Scientific Information and Computing Center, Tokyo Institute of Technology, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811660/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=903136417382916060&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology;Mitsubishi Electric Corporation",
        "aff_unique_dep": "Department of Computer Science;Information Technology R&D Center",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.mitsubishielectric.com",
        "aff_unique_abbr": "Titech;MEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812038",
        "title": "OPV2V: An Open Benchmark Dataset and Fusion Pipeline for Perception with Vehicle-to-Vehicle Communication",
        "track": "main",
        "status": "Poster",
        "abstract": "Employing Vehicle-to-Vehicle communication to enhance perception performance in self-driving technology has attracted considerable attention recently; however, the absence of a suitable open dataset for benchmarking algorithms has made it difficult to develop and assess cooperative perception technologies. To this end, we present the first large-scale open simulated dataset for Vehicle-to-Vehicle perception. It contains over 70 interesting scenes, 11,464 frames, and 232,913 annotated 3D vehicle bounding boxes, collected from 8 towns in CARLA and a digital town of Culver City, Los Angeles. We then construct a comprehensive benchmark with a total of 16 implemented models to evaluate several information fusion strategies (i.e. early, late, and intermediate fusion) with state-of-the-art LiDAR detection algorithms. Moreover, we propose a new Attentive Intermediate Fusion pipeline to aggregate information from multiple connected vehicles. Our experiments show that the proposed pipeline can be easily integrated with existing 3D LiDAR detectors and achieve outstanding performance even with large compression rates. To encourage more researchers to investigate Vehicle-to-Vehicle perception, we will release the dataset, benchmark methods, and all related codes in https://mobility-lab.seas.ucla.edu/opv2v/.",
        "primary_area": "",
        "author": "Runsheng Xu;Hao Xiang;Xin Xia;Xu Han;Jinlong Li;Jiaqi Ma;Runsheng Xu;Hao Xiang;Xin Xia;Xu Han;Jinlong Li;Jiaqi Ma",
        "authorids": "/37089002744;/37089006777;/37086487632;/37089003544;/37089447894;/37085693088;/37089002744;/37089006777;/37086487632;/37089003544;/37089447894;/37085693088",
        "aff": "Mobility Lab., University of California, Los Angeles; Mobility Lab., University of California, Los Angeles; Mobility Lab., University of California, Los Angeles; Mobility Lab., University of California, Los Angeles; Cleveland Vision and AI Lab, Cleveland State University; Mobility Lab., University of California, Los Angeles",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812038/",
        "gs_citation": 487,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8655092024328155420&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of California, Los Angeles;Cleveland State University",
        "aff_unique_dep": "Mobility Lab.;Cleveland Vision and AI Lab",
        "aff_unique_url": "https://www.ucla.edu;https://www.csuohio.edu",
        "aff_unique_abbr": "UCLA;CSU",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Los Angeles;Cleveland",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812139",
        "title": "ORFD: A Dataset and Benchmark for Off-Road Freespace Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Freespace detection is an essential component of autonomous driving technology and plays an important role in trajectory planning. In the last decade, deep learning based freespace detection methods have been proved feasible. However, these efforts were focused on urban road environments and few deep learning based methods were specifically designed for off-road freespace detection due to the lack of off-road dataset and benchmark. In this paper, we present the ORFD dataset, which, to our knowledge, is the first off-road freespace detection dataset. The dataset was collected in different scenes (woodland, farmland, grassland and countryside), different weather conditions (sunny, rainy, foggy and snowy) and different light conditions (bright light, daylight, twilight, darkness), which totally contains 12,198 LiDAR point cloud and RGB image pairs with the traversable area, non-traversable area and unreachable area annotated in detail. We propose a novel network named OFF-Net, which unifies Transformer architecture to aggregate local and global information, to meet the requirement of large receptive fields for freespace detection task. We also propose the cross-attention to dynamically fuse LiDAR and RGB image information for accurate off-road freespace detection. Dataset and code are publicly available at https://github.com/chaytonmin/OFF-Net.",
        "primary_area": "",
        "author": "Chen Min;Weizhong Jiang;Dawei Zhao;Jiaolong Xu;Liang Xiao;Yiming Nie;Bin Dai;Chen Min;Weizhong Jiang;Dawei Zhao;Jiaolong Xu;Liang Xiao;Yiming Nie;Bin Dai",
        "authorids": "/37088811943;/37089448498;/37085406223;/37073877600;/37085349060;/37086934086;/37397374200;/37088811943;/37089448498;/37085406223;/37073877600;/37085349060;/37086934086;/37397374200",
        "aff": "Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812139/",
        "gs_citation": 78,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16648765619250960201&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "National Innovation Institute of Defense Technology",
        "aff_unique_dep": "Unmanned Systems Research Center",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811967",
        "title": "OSCAR: Data-Driven Operational Space Control for Adaptive and Robust Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning performant robot manipulation policies can be challenging due to high-dimensional continuous actions and complex physics-based dynamics. This can be alleviated through intelligent choice of action space. Operational Space Control (OSC) has been used as an effective task-space controller for manipulation. Nonetheless, its strength depends on the underlying modeling fidelity, and is prone to failure when there are modeling errors. In this work, we propose OSC for Adaptation and Robustness (OSCAR), a data-driven variant of OSC that compensates for modeling errors by inferring relevant dynamics parameters from online trajectories. OSCAR decomposes dynamics learning into task-agnostic and task-specific phases, decoupling the dynamics dependencies of the robot and the extrinsics due to its environment. This structure enables robust zero-shot performance under out-of-distribution and rapid adaptation to significant domain shifts through additional finetuning. We evaluate our method on a variety of simulated manipulation problems, and find substantial improvements over an array of controller baselines. For more results and information, please visit https://cremebrule.github.io/oscar-web/.",
        "primary_area": "",
        "author": "Josiah Wong;Viktor Makoviychuk;Anima Anandkumar;Yuke Zhu;Josiah Wong;Viktor Makoviychuk;Anima Anandkumar;Yuke Zhu",
        "authorids": "/37088968066;/37086938547;/37322138800;/37086080772;/37088968066;/37086938547;/37322138800;/37086080772",
        "aff": "NVIDIA; NVIDIA; California Institute of Technology; The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811967/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8227064728051727361&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "NVIDIA;California Institute of Technology;University of Texas at Austin",
        "aff_unique_dep": "NVIDIA Corporation;;",
        "aff_unique_url": "https://www.nvidia.com;https://www.caltech.edu;https://www.utexas.edu",
        "aff_unique_abbr": "NVIDIA;Caltech;UT Austin",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Pasadena;Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811816",
        "title": "Object Insertion Based Data Augmentation for Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural network used for the LiDAR semantic segmentation task needs the point-wise labeled point clouds for training, which is more expensive than bounding box annotations. Enhancing the diversity of training data through object insertion is an effective method to reduce labeling costs. The existing object insertion methods are mainly divided into two categories. First is \u201ccopy\u201d the clusters from a LiDAR frame and \u201cpaste\u201d it to other frames or positions. Second is inserting CAD models into the background then using LiDAR simulator to generate laser points of the inserted CAD models. \u201cCopy-paste\u201d method cannot generate realistic scanning lines and shadows, and the CAD models, especially the CAD models of flexible objects, are hard to obtain. We propose an object insertion based data augmentation method which can increase the performance of the semantic segmentation network remarkably. First, an object library is created by using the labeled LiDAR point clouds. Then, these objects are inserted into the LiDAR point clouds dynamically during the training. Finally, the realistic scanning lines and shadows are simulated according to the real LiDAR parameters. The experimental results show that the proposed augmentation method can increase the performance of different semantic segmentation frameworks remarkably.",
        "primary_area": "",
        "author": "Yuan Ren;Siyan Zhao;Liu Bingbing;Yuan Ren;Siyan Zhao;Liu Bingbing",
        "authorids": "/37088997700;/37089448435;/38257785200;/37088997700;/37089448435;/38257785200",
        "aff": "Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811816/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13470641459238335343&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Noah's Ark Lab",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812027",
        "title": "Object Memory Transformer for Object Goal Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a reinforcement learning method for object goal navigation (ObjNav) where an agent navigates in 3D indoor environments to reach a target object based on long-term observations of objects and scenes. To this end, we propose Object Memory Transformer (OMT) that consists of two key ideas: 1) Object-Scene Memory (OSM) that enables to store long-term scenes and object semantics, and 2) Transformer that attends to salient objects in the sequence of previously observed scenes and objects stored in OSM. This mechanism allows the agent to efficiently navigate in the indoor environment without prior knowledge about the environments, such as topological maps or 3D meshes. To the best of our knowledge, this is the first work that uses a long-term memory of object semantics in a goal-oriented navigation task. Experimental results conducted on the AI2-THOR dataset show that OMT outperforms previous approaches in navigating in unknown environments. In particular, we show that utilizing the long-term object semantics information improves the efficiency of navigation.",
        "primary_area": "",
        "author": "Rui Fukushima;Kei Ota;Asako Kanezaki;Yoko Sasaki;Yusuke Yoshiyasu;Rui Fukushima;Kei Ota;Asako Kanezaki;Yoko Sasaki;Yusuke Yoshiyasu",
        "authorids": "/37089447480;/37087323962;/37546453800;/37418160900;/37392153300;/37089447480;/37087323962;/37546453800;/37418160900;/37392153300",
        "aff": "National Institute of Advanced Industrial Science and Technology (AIST), Japan; Information Technology R&D Center, Mitsubishi Electric Corporation, Kanagawa, Japan; Tokyo Institute of Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology (AIST), Japan; National Institute of Advanced Industrial Science and Technology (AIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812027/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14313997464582958459&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology;Mitsubishi Electric Corporation;Tokyo Institute of Technology",
        "aff_unique_dep": ";Information Technology R&D Center;",
        "aff_unique_url": "https://www.aist.go.jp;https://www.mitsubishielectric.com;https://www.titech.ac.jp",
        "aff_unique_abbr": "AIST;MEC;Titech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812443",
        "title": "Object-based Visual-Inertial Navigation System on Matrix Lie Group",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel object-based visual-inertial navigation system fully embedded in a matrix Lie group and built upon the invariant Kalman filtering theory. Specifically, we focus on relative pose measurements of objects and derive an error equation at the associated tangent space. We prove that the observability property does not suffer from the filter inconsistency and nonlinear error terms are identically zero at the object initialization. A thorough Monte-Carlo simulation reveals that our approach yields consistent estimates and is very robust to a large initial state uncertainty. Further-more, we demonstrate a real-world application to the KITTI dataset with a deep neural network-based 3D object detector. Experimental results report that noises on pose measurements follow a Gaussian-like density matching our assumption. The proposed method improves the localization and object global mapping accuracy by probabilistically accounting for inertial readings and object pose uncertainties at multiple views.",
        "primary_area": "",
        "author": "Jae Hyung Jung;Chan Gook Park;Jae Hyung Jung;Chan Gook Park",
        "authorids": "/37086436394;/37614648200;/37086436394;/37614648200",
        "aff": "Department of Aerospace Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, Republic of Korea; Department of Aerospace Engineering, Automation and Systems Research Institute, Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812443/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8139887966646143023&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Aerospace Engineering, Automation and Systems Research Institute",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812026",
        "title": "Off Environment Evaluation Using Convex Risk Minimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Applying reinforcement learning (RL) methods on robots typically involves training a policy in simulation and deploying it on a robot in the real world. Because of the model mismatch between the real world and the simulator, RL agents deployed in this manner tend to perform suboptimally. To tackle this problem, researchers have developed robust policy learning algorithms that rely on synthetic noise disturbances. However, such methods do not guarantee performance in the target environment. We propose a convex risk minimization algorithm to estimate the model mismatch between the simulator and the target domain using trajectory data from both environments. We show that this estimator can be used along with the simulator to evaluate performance of an RL agents in the target domain, effectively bridging the gap between these two environments. We also show that the convergence rate of our estimator to be of the order of n^{-1/4}n^{-1/4}, where nn is the number of training samples. In simulation, we demonstrate how our method effectively approximates and evaluates performance on Gridworld, Cartpole, and Reacher environments on a range of policies. We also show that the our method is able to estimate performance of a 7 DOF robotic arm using the simulator and remotely collected data from the robot in the real world.",
        "primary_area": "",
        "author": "Pulkit Katdare;Shuijing Liu;Katherine Driggs Campbell;Pulkit Katdare;Shuijing Liu;Katherine Driggs Campbell",
        "authorids": "/37086333814;/37088687174;/37089450520;/37086333814;/37088687174;/37089450520",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Champaign, IL; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Champaign, IL; Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, Champaign, IL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812026/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10722218919974007465&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Champaign",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811963",
        "title": "Offline Learning of Counterfactual Predictions for Real-World Robotic Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider real-world reinforcement learning (RL) of robotic manipulation tasks that involve both visuomotor skills and contact-rich skills. We aim to train a policy that maps multimodal sensory observations (vision and force) to a manipulator's joint velocities under practical considerations. We propose to use offline samples to learn a set of general value functions (GVFs) that make counterfactual predictions from the visual inputs. We show that combining the offline learned counterfactual predictions with force feedbacks in online policy learning allows efficient reinforcement learning given only a terminal (success/failure) reward. We argue that the learned counterfactual predictions form a compact and informative representation that enables sample efficiency and provides auxiliary reward signals that guide online explorations towards contact-rich states. Various experiments in simulation and real-world settings were performed for evaluation. Recordings of the real-world robot training can be found via https://sites.google.com/view/realrl.",
        "primary_area": "",
        "author": "Jun Jin;Daniel Graves;Cameron Haigh;Jun Luo;Martin Jagersand;Jun Jin;Daniel Graves;Cameron Haigh;Jun Luo;Martin Jagersand",
        "authorids": "/37086574802;/37823099700;/37089446659;/37089002073;/37269568300;/37086574802;/37823099700;/37089446659;/37089002073;/37269568300",
        "aff": "Department of Computing Science, University of Alberta, Edmonton, AB., Canada; Noah's Ark Lab, Huawei Technologies Canada, Ltd., Edmonton, AB., Canada; Noah's Ark Lab, Huawei Technologies Canada, Ltd., Edmonton, AB., Canada; Noah's Ark Lab, Huawei Technologies Canada, Ltd., Edmonton, AB., Canada; Department of Computing Science, University of Alberta, Edmonton, AB., Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811963/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17644048502934711814&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of Alberta;Huawei",
        "aff_unique_dep": "Department of Computing Science;Noah's Ark Lab",
        "aff_unique_url": "https://www.ualberta.ca;https://www.huawei.com/ca-en/",
        "aff_unique_abbr": "UAlberta;Huawei",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Edmonton",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812312",
        "title": "Offline Meta-Reinforcement Learning for Industrial Insertion",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning (RL) can in principle let robots automatically adapt to new tasks, but current RL methods require a large number of trials to accomplish this. In this paper, we tackle rapid adaptation to new tasks through the framework of meta-learning, which utilizes past tasks to learn to adapt with a specific focus on industrial insertion tasks. Fast adaptation is crucial because prohibitively large number of on-robot trials will potentially damage hardware pieces. Additionally, effective adaptation is also feasible in that experience among different insertion applications can be largely leveraged by each other. In this setting, we address two specific challenges when applying meta-learning. First, conventional meta-RL algorithms require lengthy online meta-training. We show that this can be replaced with appropriately chosen offline data, resulting in an offline meta- RL method that only requires demonstrations and trials from each of the prior tasks, without the need to run costly meta-RL procedures online. Second, meta-RL methods can fail to generalize to new tasks that are too different from those seen at meta-training time, which poses a particular challenge in industrial applications, where high success rates are critical. We address this by combining contextual meta-learning with direct online finetuning: if the new task is similar to those seen in the prior data, then the contextual meta-learner adapts immediately, and if it is too different, it gradually adapts through finetuning. We show that our approach is able to quickly adapt to a variety of different insertion tasks, with a success rate of 100% using only a fraction of the samples needed for learning the tasks from scratch. Experiment videos and details are available at //sites.google.com/view/offline-metarl-insertion.https:",
        "primary_area": "",
        "author": "Tony Z. Zhao;Jianlan Luo;Oleg Sushkov;Rugile Pevceviciute;Nicolas Heess;Jon Scholz;Stefan Schaal;Sergey Levine;Tony Z. Zhao;Jianlan Luo;Oleg Sushkov;Rugile Pevceviciute;Nicolas Heess;Jon Scholz;Stefan Schaal;Sergey Levine",
        "authorids": "/37088998362;/37086453933;/37847036600;/37089446957;/38467156100;/37970047400;/37282144700;/37085481973;/37088998362;/37086453933;/37847036600;/37089446957;/38467156100;/37970047400;/37282144700;/37085481973",
        "aff": "Work done as an intern at X, The Moonshot Factory, Mountain View, CA, USA; Intrinsic Innovation LLC, Mountain View, CA, USA; Deepmind, London, UK; Deepmind, London, UK; Deepmind, London, UK; Deepmind, London, UK; Work done as an intern at X, The Moonshot Factory, Mountain View, CA, USA; Department of Electric Engineering and Computer Science, University of California, Berkeley, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812312/",
        "gs_citation": 104,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11553869650552000785&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;2;2;2;0;3",
        "aff_unique_norm": "X Development LLC (The Moonshot Factory);Intrinsic Innovation LLC;DeepMind;University of California, Berkeley",
        "aff_unique_dep": ";;;Department of Electric Engineering and Computer Science",
        "aff_unique_url": "https://xdevllc.com;;https://deepmind.com;https://www.berkeley.edu",
        "aff_unique_abbr": "X;;DeepMind;UC Berkeley",
        "aff_campus_unique_index": "0;0;1;1;1;1;0;2",
        "aff_campus_unique": "Mountain View;London;Berkeley",
        "aff_country_unique_index": "0;0;1;1;1;1;0;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9811372",
        "title": "Omni-Roach: A Legged Robot Capable of Traversing Multiple Types of Large Obstacles and Self-Righting",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots excel at avoiding obstacles but struggle to traverse complex 3-D terrain with cluttered large obstacles. By contrast, insects like cockroaches excel at doing so. Recent research in our lab elucidated how locomotor transitions emerge from locomotor-environment interaction for diverse locomotor challenges abstracted from complex 3-D terrain and the strategies to overcome them. Here we built on these fundamental insights to develop a cockroach-inspired legged robot, Omni-Roach, that integrated these strategies to achieve multi-modal locomotion and provide a robophysical model to study the tradeoff between multi-functionality and performance. The robot was based on the RHex design with six compliant legs and featured a rounded body with two wings that can open and a tail with pitch and yaw degrees of freedom. After two development and testing iterations, our robot was capable of overcoming all loco-motor challenges with a high performance and success rate. It traversed cluttered rigid pillars only 1.1\u00d7 robot body width apart, a 2.5\u00d7 hip height bump, a 0.75\u00d7 body length gap, densely cluttered flexible beams only 65% body width apart, and self-righted within 4 seconds. Systematic beam traversal experiments further revealed that a downward-pointing tail oscillating laterally helps roll the body into beam gaps and break frictional and interlocking contact to traverse. Our work highlights the usefulness of multi-functional appendages and exaptation for large obstacle traversal.",
        "primary_area": "",
        "author": "Jonathan Mi;Yaqing Wang;Chen Li;Jonathan Mi;Yaqing Wang;Chen Li",
        "authorids": "/37089161672;/37089451069;/37086208270;/37089161672;/37089451069;/37086208270",
        "aff": "Department of Electrical & Computer Engineering, University of California; research at JHU in an REU program; Dept. of Mechanical Engineering, Johns Hopkins University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811372/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6264759513740504016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of California;Johns Hopkins University",
        "aff_unique_dep": "Department of Electrical & Computer Engineering;",
        "aff_unique_url": "https://www.universityofcalifornia.edu;https://www.jhu.edu",
        "aff_unique_abbr": "UC;JHU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812198",
        "title": "On Wearable, Lightweight, Low-Cost Human Machine Interfaces for the Intuitive Collection of Robot Grasping and Manipulation Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot grasping and manipulation allow robots to interact with their environments and execute a plethora of complex tasks that require increased dexterity (e.g., open a door, push buttons, collect and transpose objects, etc.). Collecting data of such activities is of paramount importance as it allows roboticists to create new methods and models that will facilitate the execution of sophisticated tasks. In this paper, we propose new wearable, lightweight, low-cost human machine interfaces that improve the efficiency of the data collection process for both robotic grasping and manipulation by offering intuitive and simplified control of the employed robotic grippers and hands. In particular, two different types of interfaces are proposed: i) a handle-based forearm stabilized interface that uses a waist-linkage system to provide weight support for bulky and heavy robotic end-effectors and ii) a palm-mounted interface that can accommodate smaller and lightweight grippers and hands, offering more agility in the control and positioning of these devices. Both interfaces are equipped with appropriate sliders, joysticks, and buttons that facilitate the control of the multiple degrees of freedom of the employed end-effectors and appropriate cameras that allow for object detection, identification, and object pose estimation.",
        "primary_area": "",
        "author": "Che-Ming Chang;Jayden Chapman;Ke Wang;Patrick Jarvis;Minas Liarokapis;Che-Ming Chang;Jayden Chapman;Ke Wang;Patrick Jarvis;Minas Liarokapis",
        "authorids": "/37087236127;/37088482031;/37089448683;/37088456883;/38558084100;/37087236127;/37088482031;/37089448683;/37088456883;/38558084100",
        "aff": "Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; AI Data Innovations; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical and Mechatronics Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812198/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4916080479273835753&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Auckland;AI Data Innovations",
        "aff_unique_dep": "Department of Mechanical and Mechatronics Engineering;",
        "aff_unique_url": "https://www.auckland.ac.nz;",
        "aff_unique_abbr": "UoA;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "New Zealand;"
    },
    {
        "id": "9812073",
        "title": "On a New 10-Millimeter Surgical Robot Wrist",
        "track": "main",
        "status": "Poster",
        "abstract": "Presented is a new 10-mm diameter wrist designed for robotic surgery. Featuring greater dexterity than current designs, entirely new procedures may be possible. An innovative, parallel mechanism, it offers 180 degrees of singularity-free pitch/yaw motion. The wrist is also a new form of high angulation, constant velocity, universal joint and is capable of continuous 360 degrees of roll rotation at any angle to enable drilling, reaming, milling, filing, deburring, or inserting fasteners. Z-axis motion is incorporated into the wrist itself, a unique feature. In addition, a gripper, scissors, stapler or other open/close device may be added. A thru-hole allows for passing wires, fiber optics, or flexible tubes. Stainless steel rotary shafts drive the wrist and also enable force reflection useful for providing haptic feedback to the operator. Eliminating difficult to sterilize woven steel cables/pulleys and bearings, the wrist may be sterilized in an autoclave. A simple construction, the wrist lends itself to CNC machining and automated assembly.",
        "primary_area": "",
        "author": "Mark E. Rosheim;Mark E. Rosheim",
        "authorids": "/37351759700;/37351759700",
        "aff": "Ross-Hime Designs, Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812073/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4414235559518219536&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Ross-Hime Designs, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812371",
        "title": "On nondeterminism in combinatorial filters",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of combinatorial filter reduction arises from resource optimization in robots; it is one specific way in which automation can help to achieve minimalism, to build better robots. This paper contributes a new definition of filter minimization that is broader than its antecedents, allowing filters (input, output, or both) to be nondeterministic. This changes the problem considerably. Nondeterministic filters may re-use states to obtain more \u2018behavior\u2019 per vertex. We show that the gap in size can be significant (larger than polyno-mial), suggesting such cases will generally be more challenging than deterministic problems. Indeed, this is supported by the core complexity result established in this paper: producing nondeterministic minimizers is PSPACE-hard. The hardness separation for minimization existing between deterministic filter and automata, thus, fails to hold for the nondeterministic case.",
        "primary_area": "",
        "author": "Yulin Zhang;Dylan A. Shell;Yulin Zhang;Dylan A. Shell",
        "authorids": "/37089453389;/37269198900;/37089453389;/37269198900",
        "aff": "Dept. of Computer Science, The University of Texas, Austin, TX, USA; Dept. of Computer Science & Engineering, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812371/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2569034519613307778&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Texas at Austin;Texas A&M University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science & Engineering",
        "aff_unique_url": "https://www.utexas.edu;https://www.tamu.edu",
        "aff_unique_abbr": "UT Austin;TAMU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Austin;College Station",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811807",
        "title": "On the Convergence of Multi-robot Constrained Navigation: A Parametric Control Lyapunov Function Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the distributed multi-robot constrained navigation problem. While the multi-robot collision avoidance has been extensively studied in the literature with safety being the primary focus, the individual robot's destination convergence is not necessarily guaranteed. In particular, robots may get stuck in the local equilibria or periodic orbits of the multi-robot system, some of which are practically known as the deadlock and the livelock behaviors. Inspired by the combination of Control Lyapunov Function (CLF) and Control Barrier Function (CBF) for the nonlinear system's constrained stabilization, the authors present a guaranteed safe feedback control policy with improved convergence performance. The proposed Parametric CLF (PCLF) scheme adaptively determines the appropriate CLF parameterization within the in-stantaneous feasible action space. The algorithm also induces a conditional global asymptotic convergence guarantee for multi-robot system of single-integrator dynamics, and is empirically effective for nonlinear nonholonomic vehicle model. Empiri-cally, the proposed PCLF-CBF framework exhibits superior performance than state-of-the-art methods, including its de-generated counterpart of various CLF-CBF solutions.",
        "primary_area": "",
        "author": "Bowen Weng;Hua Chen;Wei Zhang;Bowen Weng;Hua Chen;Wei Zhang",
        "authorids": "/37086936098;/37086195529;/37089656248;/37086936098;/37086195529;/37089656248",
        "aff": "Electrical and Computer Engineering, Ohio State University, Columbus, OH, USA; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811807/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16483348239222770364&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Ohio State University;Southern University of Science and Technology",
        "aff_unique_dep": "Electrical and Computer Engineering;Department of Mechanical and Energy Engineering",
        "aff_unique_url": "https://www.osu.edu;https://www.sustech.edu.cn",
        "aff_unique_abbr": "OSU;SUSTech",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Columbus;",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9812212",
        "title": "On the Feasibility of Learning Finger-gaiting In-hand Manipulation with Intrinsic Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Finger-gaiting manipulation is an important skill to achieve large-angle in-hand re-orientation of objects. However, achieving these gaits with arbitrary orientations of the hand is challenging due to the unstable nature of the task. In this work, we use model-free reinforcement learning (RL) to learn finger-gaiting only via precision grasps and demonstrate finger-gaiting for rotation about an axis using only on-board proprioceptive and tactile feedback. To tackle the inherent instability of precision grasping, we propose the use of initial state distributions that enable effective exploration of the state space. Our method can learn finger gaiting with better sample complexity than the state-of-the-art. The policies we obtain are robust to noise and perturbations, and transfer to novel objects. Videos can be found at https://roamlab.github.io/learnfg/",
        "primary_area": "",
        "author": "Gagan Khandate;Maximilian Haas-Heger;Matei Ciocarlie;Gagan Khandate;Maximilian Haas-Heger;Matei Ciocarlie",
        "authorids": "/37088505962;/37086400751;/37297485500;/37088505962;/37086400751;/37297485500",
        "aff": "Department of Computer Science, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Columbia University, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812212/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14744869533963668917&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811847",
        "title": "On the Reliability of Inverse Optimal Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Inverse Optimal Control (IOC) is a popular method for human motion analysis. In the context of these methods it is necessary to pay attention to the reliability of the results. This paper proposes an approach based on the evaluation of Karush-Kuhn-Tucker conditions relying on a complete analysis with Singular Value Decomposition and provides a detailed analysis of reliability. With respect to a ground truth, our simulations illustrate how the proposed method analyzes the reliability of the resolution. After introducing a clear methodology, the properties of the matrices are studied with different noise levels and different experimental models and conditions. We show how to implement the method, step by step, by explaining the numerical difficulties encountered during the resolution and thus how to make the results of the IOC problem reliable.",
        "primary_area": "",
        "author": "Jessica Colombel;David Daney;Fran\u00e7ois Charpillet;Jessica Colombel;David Daney;Fran\u00e7ois Charpillet",
        "authorids": "/37089449428;/37273442100;/37284255200;/37089449428;/37273442100;/37284255200",
        "aff": "Jessica Colombel; David Daney; Fran\u00e7ois Charpillet",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811847/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15474588975369799757&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9811939",
        "title": "On the Role of Hyperdimensional Computing for Behavioral Prioritization in Reactive Robot Navigation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Hyperdimensional computing (HDC) is a brain-inspired computing paradigm that operates on pseudo-random hypervectors, an information-rich, hardware-efficient representation that is robust to noise and facilitates learning with limited training data. This work explores how robot navigation tasks can leverage the high-capacity hypervector representation to enable behavioral prioritization through a weighted encoding of heterogeneous sensor information. Experiments over 100 trials in each of the 100 randomly generated obstacle maps demonstrate that the proposed weighted sensor encoding scheme boosts the success rate of the navigation task by over 30% compared to an unweighted sensor encoding. A hybrid scheme using the HDC weighted scheme at the input of a deep feed-forward neural network achieves the highest success rate. The hybrid scheme furthermore is more robust when reducing the HDC dimension by 50%. However, the simple HDC implementation remains the most hardware efficient, making it desirable for resource-constrained systems.",
        "primary_area": "",
        "author": "Alisha Menon;Anirudh Natarajan;Laura I. Galindez Olascoaga;Youbin Kim;Braeden Benedict;Jan M. Rabaey;Alisha Menon;Anirudh Natarajan;Laura I. Galindez Olascoaga;Youbin Kim;Braeden Benedict;Jan M. Rabaey",
        "authorids": "/37088811286;/37089447142;/37086952031;/37088474343;/37088877460;/37276611300;/37088811286;/37089447142;/37086952031;/37088474343;/37088877460;/37276611300",
        "aff": "EECS Department, Berkeley Wireless Research Center, University of California, Berkeley; EECS Department, Berkeley Wireless Research Center, University of California, Berkeley; EECS Department, Berkeley Wireless Research Center, University of California, Berkeley; EECS Department, Berkeley Wireless Research Center, University of California, Berkeley; UC Berkeley/UC San Francisco Joint Program in Bioengineering; EECS Department, Berkeley Wireless Research Center, University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811939/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17755667740113372884&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "EECS Department",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812390",
        "title": "On-chip Continuous Pairing, Separation and Electrofusion of Cells Using a Microdroplet",
        "track": "main",
        "status": "Poster",
        "abstract": "Cell fusion has been widely applied in scientific research for cancer immunotherapy, antibody production, and nuclear reprogramming of somatic cells, and therefore the cell fusion technique that enable us to precisely control the fusion process with high throughput manner has been desired. Here, we present a novel microfluidic method for automatic cell pairing by microdroplets, separation of droplets containing cells, and electrofusion of cells inside a droplet. The proposed microfluidic device mainly composed of three sequential function parts for (i) encapsulation of cells into a droplet by microfluidic droplet generator, (ii) separation of droplets containing cells from empty droplets through a micropillar array, and (iii) electrofusion of cells inside the droplets by applying a voltage during the droplet passing over the pair of electrodes. In the microfluidic device, cell-encapsulated and empty droplets were generated at the upstream cross-junction; they then entered the micropillar array, separating the cell-encapsulated droplets from empty droplets continuously. After separation, they passed over the electrode pairs, and were collected the outside of the microchannel. This continuous process for cell fusion would enable us to observe and isolate the target fused cells for cell analysis.",
        "primary_area": "",
        "author": "Naotomo Tottori;Sora Sadamichi;Shinya Sakuma;Tomomi Tsubouchi;Yoko Yamanishi;Naotomo Tottori;Sora Sadamichi;Shinya Sakuma;Tomomi Tsubouchi;Yoko Yamanishi",
        "authorids": "/37088806116;/37089448902;/37409377200;/37089448391;/37295097600;/37088806116;/37089448902;/37409377200;/37089448391;/37295097600",
        "aff": "Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan; Kyushu University, Fukuoka, Japan; National Institute for Basic Biology, Okazaki, Aichi, Japan; Kyushu University, Fukuoka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812390/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3363721275285604005&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Kyushu University;National Institute for Basic Biology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kyushu-u.ac.jp;https://www.nibb.ac.jp/english/",
        "aff_unique_abbr": "Kyushu U;NIBB",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Fukuoka;Okazaki",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811740",
        "title": "Online Adaptive Identification and Switching of Soft Contact Model Based on ART-II Method",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to obtain a high-precision contact model that can properly describe the target soft tissue, this paper proposes a hybrid soft contact model based on a clustering algorithm ART-II, which selects the most suitable soft contact model according to the surgical environment. The least-square method is used to identify the parameters of the model online. In the experiments, different parts of animal tissues were used as the experimental objects. The hybrid model was used to identify and switch for the most appropriate soft contact model when dealing with a certain type of animal tissue. The performance of the hybrid model on force estimation was compared with several individual soft contact models. The results showed that the estimated/reconstructed force of the hybrid model was closer to the ground truth measured by the force sensor. In addition, a new reference soft contact model has been purposely added online to verify the expandability of the hybrid model.",
        "primary_area": "",
        "author": "Yi Liu;Di Wu;Fengtao Han;Jing Guo;Zhaoshui He;Chao Liu;Yi Liu;Di Wu;Fengtao Han;Jing Guo;Zhaoshui He;Chao Liu",
        "authorids": "/37085572453;/37088800633;/37089449339;/37896663300;/37557581500;/37280622900;/37085572453;/37088800633;/37089449339;/37896663300;/37557581500;/37280622900",
        "aff": "School of Automation, Guangdong University of Technology, Guangzhou, China; Department of Mechanical Engineering, KU Leuven, Belgium; ROKAE Robotics Co.,Ltd, Beijing, China; School of Automation, Guangdong University of Technology, Guangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; Department of Robotics, LIRMM, Univ Montpellier, CNRS, Montpellier, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811740/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14705624711912536504&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;3",
        "aff_unique_norm": "Guangdong University of Technology;KU Leuven;ROKAE Robotics Co.,Ltd;University of Montpellier",
        "aff_unique_dep": "School of Automation;Department of Mechanical Engineering;;Department of Robotics",
        "aff_unique_url": ";https://www.kuleuven.be;;https://www.univ-montp1.fr",
        "aff_unique_abbr": ";KU Leuven;;Univ Montpellier",
        "aff_campus_unique_index": "0;0;0;2",
        "aff_campus_unique": "Guangzhou;;Montpellier",
        "aff_country_unique_index": "0;1;0;0;0;2",
        "aff_country_unique": "China;Belgium;France"
    },
    {
        "id": "9812377",
        "title": "Online Assistance Control of a Pneumatic Gait Assistive Suit Using Physical Reservoir Computing Exploiting Air Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Wearable gait assistive devices have been im-proved by soft robotics in terms of safety and physical burden of the wearer. Currently, electrical sensors and computers around the wearer are bottlenecks in enhancing the wearer's activities. In this paper, we present a wearable gait assistive system using soft pneumatic system for all the actuation, sensing, and computation. Pneumatic artifical muscles (PAMs) on the thighs were used to generate assistance force, and thin PAMs on the whole legs were used for sensing the wearer's motion. All thin PAMs were connected to each other by tubes, and the pressure response in the tubes were exploited to compute the wearer's motion in manner of physical reservoir computing. The left thigh angular velocity estimated from the reservoir response was used for control the PAMs for actuation. Our experiment with the use of gait assistance showed that the system worked correctly. This paper shows that the pneumatic analog computation system for sensing soft body can help the functionality of soft wearable assistive devices.",
        "primary_area": "",
        "author": "Hiroyuki Hayashi;Toshihiro Kawase;Tetsuro Miyazaki;Maina Sogabe;Yoshikazu Nakajima;Kenji Kawashima;Hiroyuki Hayashi;Toshihiro Kawase;Tetsuro Miyazaki;Maina Sogabe;Yoshikazu Nakajima;Kenji Kawashima",
        "authorids": "/37089302553;/37086578826;/37086294776;/37088908615;/37542874700;/37280901500;/37089302553;/37086578826;/37086294776;/37088908615;/37542874700;/37280901500",
        "aff": "Graduate School of Medical and Dental Sciences, Tokyo Medical and Dental University, Tokyo, Japan; Institute of Innovative Research, Tokyo Institute of Technology, Kanagawa, Japan; Department of Information Physics and Computing, The University of Tokyo, Tokyo, Japan; Department of Information Physics and Computing, The University of Tokyo, Tokyo, Japan; Institute of Bio-materials and Bioengineering, Tokyo Medical and Dental University, Tokyo, Japan; Department of Information Physics and Computing, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812377/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13395577172035231098&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;0;2",
        "aff_unique_norm": "Tokyo Medical and Dental University;Tokyo Institute of Technology;University of Tokyo",
        "aff_unique_dep": "Graduate School of Medical and Dental Sciences;Institute of Innovative Research;Department of Information Physics and Computing",
        "aff_unique_url": "https://www.tmd.ac.jp;https://www.titech.ac.jp;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "TMDU;Titech;UTokyo",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Tokyo;Kanagawa",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811708",
        "title": "Online Learning of Centroidal Angular Momentum towards Enhancing DCM-based Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Gait generation frameworks for humanoid robots typically assume a constant centroidal angular momentum (CAM) throughout the walking cycle, which induces undesirable contact torques in the feet and results in performance degradation. In this work, we present a novel algorithm to learn the CAM online and include the obtained knowledge within the closed-form solutions of the Divergent Component of Motion (DCM) locomotion framework. To ensure a reduction of the contact torques at the desired center of pressure position, a CAM trajectory is generated and explicitly tracked by a whole-body controller. Experiments with the humanoid robot TORO demonstrate that the proposed method significantly increases the maximum step length and walking speed during locomotion.",
        "primary_area": "",
        "author": "Robert Schuller;George Mesesan;Johannes Englsberger;Jinoh Lee;Christian Ott;Robert Schuller;George Mesesan;Johannes Englsberger;Jinoh Lee;Christian Ott",
        "authorids": "/37088890750;/37086066822;/38281295100;/37085391573;/37282440400;/37088890750;/37086066822;/38281295100;/37085391573;/37282440400",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811708/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11677589619260741708&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Wessling",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811670",
        "title": "Online Non-linear Centroidal MPC for Humanoid Robot Locomotion with Step Adjustment",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a Non-Linear Model Predictive Controller for humanoid robot locomotion with online step adjustment capabilities. The proposed controller considers the Centroidal Dynamics of the system to compute the desired contact forces and torques and contact locations. Differently from bipedal walking architectures based on simplified models, the presented approach considers the reduced centroidal model, thus allowing the robot to perform highly dynamic movements while keeping the control problem still treatable online. We show that the proposed controller can automatically adjust the contact location both in single and double support phases. The overall approach is then tested with a simulation of one-leg and two-leg systems performing jumping and running tasks, respectively. We finally validate the proposed controller on the position-controlled Humanoid Robot iCub. Results show that the proposed strategy prevents the robot from falling while walking and pushed with external forces up to 40 Newton for 1 second applied at the robot arm.",
        "primary_area": "",
        "author": "Giulio Romualdi;Stefano Dafarra;Giuseppe L'Erario;Ines Sorrentino;Silvio Traversaro;Daniele Pucci;Giulio Romualdi;Stefano Dafarra;Giuseppe L'Erario;Ines Sorrentino;Silvio Traversaro;Daniele Pucci",
        "authorids": "/37086598289;/37086168241;/37087995791;/37088520348;/37085503650;/37706167200;/37086598289;/37086168241;/37087995791;/37088520348;/37085503650;/37706167200",
        "aff": "DIBRIS, University of Genoa, Genoa, Italy; Artificial and Mechanical Intelligence, Istituto Italiano di Tecnologia, Genoa, Italy; Machine Learning and Optimisation, University of Manchester, Manchester, UK; Machine Learning and Optimisation, University of Manchester, Manchester, UK; Artificial and Mechanical Intelligence, Istituto Italiano di Tecnologia, Genoa, Italy; Machine Learning and Optimisation, University of Manchester, Manchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811670/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13323763990321027863&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;1;2",
        "aff_unique_norm": "University of Genoa;Istituto Italiano di Tecnologia;University of Manchester",
        "aff_unique_dep": "DIBRIS;Artificial and Mechanical Intelligence;Machine Learning and Optimisation",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it;https://www.manchester.ac.uk",
        "aff_unique_abbr": ";IIT;UoM",
        "aff_campus_unique_index": "0;0;1;1;0;1",
        "aff_campus_unique": "Genoa;Manchester",
        "aff_country_unique_index": "0;0;1;1;0;1",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "9812440",
        "title": "Online Object Model Reconstruction and Reuse for Lifelong Improvement of Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a robotic pipeline for picking and constrained placement of objects without geometric shape priors. Compared to recent efforts developed for similar tasks, where every object was assumed to be novel, the proposed system recognizes previously manipulated objects and per-forms online model reconstruction and reuse. Over a lifelong manipulation process, the system keeps learning features of objects it has interacted with and updates their reconstructed models. Whenever an instance of a previously manipulated object reappears, the system aims to first recognize it and then register its previously reconstructed model given the current observation. This step greatly reduces object shape uncertainty allowing the system to even reason for parts of objects, which are currently not observable. This also results in better manipulation efficiency as it reduces the need for active perception of the target object during manipulation. To get a reusable reconstructed model, the proposed pipeline adopts: i) TSDF for object representation, and ii) a variant of the standard particle filter algorithm for pose estimation and tracking of the partial object model. Furthermore, an effective way to construct and maintain a dataset of manipulated objects is presented. A sequence of real-world manipulation experiments is performed. They show how future manipulation tasks become more effective and efficient by reusing reconstructed models of previously manipulated objects, which were generated during their prior manipulation, instead of treating objects as novel every time.",
        "primary_area": "",
        "author": "Shiyang Lu;Rui Wang;Yinglong Miao;Chaitanya Mitash;Kostas Bekris;Shiyang Lu;Rui Wang;Yinglong Miao;Chaitanya Mitash;Kostas Bekris",
        "authorids": "/37086579739;/37089654395;/37088664214;/37086289032;/37282424700;/37086579739;/37089654395;/37088664214;/37086289032;/37282424700",
        "aff": "Department of Computer Science at Rutgers, the State University of New Jersey, New Brunswick, NJ, USA; Department of Computer Science at Rutgers, the State University of New Jersey, New Brunswick, NJ, USA; Department of Computer Science at Rutgers, the State University of New Jersey, New Brunswick, NJ, USA; Department of Computer Science at Rutgers, the State University of New Jersey, New Brunswick, NJ, USA; Department of Computer Science at Rutgers, the State University of New Jersey, New Brunswick, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812440/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7397134908194030824&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811796",
        "title": "Online Optimal Landing Control of the MIT Mini Cheetah",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadrupedal landing is a complex process involving large impacts, elaborate contact transitions, and is a crucial recovery behavior observed in many biological animals. This work presents a real-time, optimal landing controller that is free of pre-specified contact schedules. The controller determines optimal touchdown postures and reaction force profiles and is able to recover from a variety of falling configurations. The quadrupedal platform used, the MIT Mini Cheetah, recovered safely from drops of up to 8 m in simulation, as well as from a range of orientations and planar velocities. The controller is also tested on hardware, successfully recovering from drops of up to 2 m.",
        "primary_area": "",
        "author": "Se Hwan Jeon;Sangbae Kim;Donghyun Kim;Se Hwan Jeon;Sangbae Kim;Donghyun Kim",
        "authorids": "/37089446754;/37537397200;/37085554176;/37089446754;/37537397200;/37085554176",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, University of Massachusetts Amherst, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811796/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7528087671206064825&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Massachusetts Amherst",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu;https://www.umass.edu",
        "aff_unique_abbr": "MIT;UMass Amherst",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Cambridge;Amherst",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811691",
        "title": "Online Payload Identification for Tactile Robots Using the Momentum Observer",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge of the robot's load inertial parameters is indispensable for accurate and safe operation, especially in collaborative robotics. However, an intuitive method for online inertial payload identification, usable while the robot is executing another online generated task, is still lacking. In this work, we propose an online payload identification approach based on the momentum observer using proprioceptive sensors of tactile robots and a novel filter design of kinematic measure-ments. Furthermore, we introduce a novel calibration scheme, that allows circumventing constraints of current calibration methods for payload identification. Specifically, the requirement of performing exactly the same motion for calibration as well as for the identification process is released. This is achieved by introducing an average virtual calibration object that improves the robot model for the identification process. In experiments with a Franka Emika Panda robot, it is shown that the proposed methods surpass common methods in terms of identification error. Especially, the novel calibration approach shows high robustness against temporal and spatial misalignment of the motions.",
        "primary_area": "",
        "author": "Alexander Kurdas;Mazin Hamad;Jonathan Vorndamme;Nico Mansfeld;Saeed Abdolshah;Sami Haddadin;Alexander Kurdas;Mazin Hamad;Jonathan Vorndamme;Nico Mansfeld;Saeed Abdolshah;Sami Haddadin",
        "authorids": "/37088861524;/37086346281;/37085761454;/38541896600;/37086148547;/37542865300;/37088861524;/37086346281;/37085761454;/38541896600;/37086148547;/37542865300",
        "aff": "Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany; Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich (TUM), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811691/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5670771404153277001&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Munich Institute of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812269",
        "title": "Online Prediction of Lane Change with a Hierarchical Learning-Based Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "In the foreseeable future, connected and auto-mated vehicles (CAVs) and human-driven vehicles will share the road networks together. In such a mixed traffic environment, CAVs need to understand and predict maneuvers of surrounding vehicles for safer and more efficient interactions, especially when human drivers bring in a wide range of uncertainties. In this paper, we propose a learning-based lane-change prediction algorithm that considers the driving behaviors of the target human driver. To provide accurate maneuver prediction, we adopt a hierarchical structure that seamlessly seals both the lane-change decision prediction and the vehicle trajectory pre-diction together. Specifically, we propose a lane-change decision prediction method based on a Long-Short Term Memory (LSTM) network, and a trajectories prediction considering driver preference and vehicular interactions based on Inverse Reinforcement Learning (IRL). To validate the performance of the proposed methodology, a case study of an on-ramp merging scenario is conducted on a uniquely built human-in-the-loop simulation platform that can provide an immersive driving environment, collect data of lane-change behaviors, and test drivers' reactions to the prediction results in real time. It is shown in the simulation results that we can predict the lane-change decision 3 seconds before the vehicle crosses the line to another lane, and the Mean Euclidean Distance between the predicted trajectory and ground truth is 0.39 meters within a 4-second prediction window.",
        "primary_area": "",
        "author": "Xishun Liao;Ziran Wang;Xuanpeng Zhao;Zhouqiao Zhao;Kyungtae Han;Prashant Tiwari;Matthew J. Barth;Guoyuan Wu;Xishun Liao;Ziran Wang;Xuanpeng Zhao;Zhouqiao Zhao;Kyungtae Han;Prashant Tiwari;Matthew J. Barth;Guoyuan Wu",
        "authorids": "/37088433233;/37086194317;/37088433227;/37087104888;/37086958428;/37087104382;/37356548800;/38251863100;/37088433233;/37086194317;/37088433227;/37087104888;/37086958428;/37087104382;/37356548800;/38251863100",
        "aff": "Department of Electrical and Computer Engineering, Center for Environmental Research and Technology, University of California, Riverside, CA; InfoTech Labs, Toyota Motor North America R&D, Mountain View, CA; Department of Electrical and Computer Engineering, Center for Environmental Research and Technology, University of California, Riverside, CA; Department of Electrical and Computer Engineering, Center for Environmental Research and Technology, University of California, Riverside, CA; InfoTech Labs, Toyota Motor North America R&D, Mountain View, CA; InfoTech Labs, Toyota Motor North America R&D, Mountain View, CA; Department of Electrical and Computer Engineering, Center for Environmental Research and Technology, University of California, Riverside, CA; Department of Electrical and Computer Engineering, Center for Environmental Research and Technology, University of California, Riverside, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812269/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12464897266142136902&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;1;1;0;0",
        "aff_unique_norm": "University of California, Riverside;Toyota Motor North America R&D",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;InfoTech Labs",
        "aff_unique_url": "https://www.ucr.edu;https://www.toyota.com",
        "aff_unique_abbr": "UCR;Toyota R&D",
        "aff_campus_unique_index": "0;1;0;0;1;1;0;0",
        "aff_campus_unique": "Riverside;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812436",
        "title": "Online State-Time Trajectory Planning Using Timed-ESDF in Highly Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Online state-time trajectory planning in highly dynamic environments remains an unsolved problem due to the curse of dimensionality of the state-time space. Existing state-time planners are typically implemented based on randomized sampling approaches or path searching on discrete graphs. The smoothness, path clearance, or planning efficiency is sometimes not satisfying. In this work, we propose a gradient-based planner on the state-time space for online trajectory generation in highly dynamic environments. To enable the gradient-based optimization, we propose a Timed-ESDT that supports distance and gradient queries with state-time keys. Based on the Timed-ESDT, we also define a smooth prior and an obstacle likelihood function that are compatible with the state-time space. The trajectory planning is then formulated to a MAP problem and solved by an efficient numerical optimizer. Moreover, to improve the optimality of the planner, we also define a state-time graph and conduct path searching on it to find a better initialization for the optimizer. By integrating the graph searching, the planning quality is significantly improved. Experiments on simulated and benchmark datasets demonstrate the superior performance of our proposes method over conventional ones.",
        "primary_area": "",
        "author": "Delong Zhu;Tong Zhou;Jiahui Lin;Yuqi Fang;Max Q.-H. Meng;Delong Zhu;Tong Zhou;Jiahui Lin;Yuqi Fang;Max Q.-H. Meng",
        "authorids": "/37086137408;/37086578215;/37088997220;/37086493133;/37274117000;/37086137408;/37086578215;/37088997220;/37086493133;/37274117000",
        "aff": "The authors are with the Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; The authors are with the Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; The authors are with the Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; The authors are with the Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; Shenzhen Research Institute of the Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812436/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2574628388411404709&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812248",
        "title": "OpenSceneVLAD: Appearance Invariant, Open Set Scene Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Scene classification is a well-established area of computer vision research that aims to classify a scene image into pre-defined categories such as playground, beach and airport. Recent work has focused on increasing the variety of pre-defined categories for classification, but so far failed to consider two major challenges: changes in scene appearance due to lighting and open set classification (the ability to classify unknown scene data as not belonging to the trained classes). Our first contribution, SceneVLAD, fuses scene classification and visual place recognition CNNs for appearance invariant scene classification that outperforms state-of-the-art scene classification by a mean F1 score of up to 0.1. Our second contribution, OpenSceneVLAD, extends the first to an open set classification scenario using intra-class splitting to achieve a mean increase in F1 scores of up to 0.06 compared to using state-of-the-art openmax layer. We achieve these results on three scene class datasets extracted from large scale outdoor visual localisation datasets, one of which we collected ourselves.",
        "primary_area": "",
        "author": "William H. B. Smith;Michael Milford;Klaus D. McDonald-Maier;Shoaib Ehsan;R. B. Fisher;William H. B. Smith;Michael Milford;Klaus D. McDonald-Maier;Shoaib Ehsan;R. B. Fisher",
        "authorids": "/37089450756;/37283633100;/38272117700;/37540520800;/37269308300;/37089450756;/37283633100;/38272117700;/37540520800;/37269308300",
        "aff": "School of Computer Science and Electronic Engineering, University of Essex, Colchester, United Kingdom; School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, QLD, Australia; School of Computer Science and Electronic Engineering, University of Essex, Colchester, United Kingdom; School of Computer Science and Electronic Engineering, University of Essex, Colchester, United Kingdom; School of Informatics, University of Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812248/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16858138434685130682&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "University of Essex;Queensland University of Technology;University of Edinburgh",
        "aff_unique_dep": "School of Computer Science and Electronic Engineering;School of Electrical Engineering and Computer Science;School of Informatics",
        "aff_unique_url": "https://www.essex.ac.uk;https://www.qut.edu.au;https://www.ed.ac.uk",
        "aff_unique_abbr": "Essex;QUT;Edinburgh",
        "aff_campus_unique_index": "0;1;0;0;2",
        "aff_campus_unique": "Colchester;Brisbane;Edinburgh",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United Kingdom;Australia"
    },
    {
        "id": "9811908",
        "title": "Optimal Control via Combined Inference and Numerical Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Derivative based optimization methods are efficient at solving optimal control problems near local optima. However, their ability to converge halts when derivative information vanishes. The inference approach to optimal control does not have strict requirements on the objective landscape. However, sampling, the primary tool for solving such problems, tends to be much slower in computation time. We propose a new method that combines second order methods with inference. We utilise the Kullback Leibler (KL) control framework to formulate an inference problem that computes the optimal controls from an adaptive distribution approximating the solution of the second order method. Our method allows for combining simple convex and non convex cost functions. This simplifies the process of cost function design and leverages the strengths of both inference and second order optimization. We compare our method to Model Predictive Path Integral (MPPI) and iterative Linear Quadratic Gaussian controller (iLQG), outperforming both in sample efficiency and quality on manipulation and obstacle avoidance tasks.",
        "primary_area": "",
        "author": "Daniel Layeghi;Steve Tonneau;Michael Mistry;Daniel Layeghi;Steve Tonneau;Michael Mistry",
        "authorids": "/37089449462;/37085790049;/37542865600;/37089449462;/37085790049;/37542865600",
        "aff": "School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811908/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13556387312238786064&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Informatics",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811775",
        "title": "Optimal Design and Control of an Aerial Manipulator with Elastic Suspension Using Unidirectional Thrusters",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial Manipulators with Elastic Suspension (AMES) may be seen as a hybrid robot mixing properties of classical Aerial Manipulators (AMs) and Cable-Driven Parallel Robots (CDPRs). The optimal design and control of an AMES using unidirectional thrusters are considered in this paper. To maximize the workspace, an optimization algorithm is proposed. The position and orientation of the thrusters are optimized by adapting methods borrowed from both the AM and CDPR communities. The resulting design is used to build a prototype. Preliminary experimentations are carried out to validate the theoretical workspace and assess the trajectory tracking performance of this AMES. Experiments highlight the significant improvements with respect to a previous suboptimal prototype.",
        "primary_area": "",
        "author": "Miguel Arpa Perozo;Jean Dussine;Arda Yi\u011fit;Lo\u00efc Cuvillon;Sylvain Durand;Jacques Gangloff;Miguel Arpa Perozo;Jean Dussine;Arda Yi\u011fit;Lo\u00efc Cuvillon;Sylvain Durand;Jacques Gangloff",
        "authorids": "/37088652283;/37089449057;/37088507420;/37563879500;/37411970500;/37283578200;/37088652283;/37089449057;/37088507420;/37563879500;/37411970500;/37283578200",
        "aff": "ICube Laboratory (UMR CNRS 7357), Strasbourg University, INSA, Strasbourg, France; ICube Laboratory (UMR CNRS 7357), Strasbourg University, INSA, Strasbourg, France; ICube Laboratory (UMR CNRS 7357), Strasbourg University, INSA, Strasbourg, France; ICube Laboratory (UMR CNRS 7357), Strasbourg University, INSA, Strasbourg, France; ICube Laboratory (UMR CNRS 7357), Strasbourg University, INSA, Strasbourg, France; ICube Laboratory (UMR CNRS 7357), Strasbourg University, INSA, Strasbourg, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811775/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7432099756883279762&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Strasbourg University",
        "aff_unique_dep": "ICube Laboratory (UMR CNRS 7357)",
        "aff_unique_url": "https://www.unistra.fr",
        "aff_unique_abbr": "UoS",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Strasbourg",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812409",
        "title": "Optimal Inverted Landing in a Small Aerial Robot with Varied Approach Velocities and Landing Gear Designs",
        "track": "main",
        "status": "Poster",
        "abstract": "Inverted landing is a challenging feat to perform in aerial robots, especially without external positioning. However, it is routinely performed by biological fliers such as bees, flies, and bats. Our previous observations of landing behaviors in flies suggest an open-loop causal relationship between their putative visual cues and the kinematics of the aerial maneuvers executed. For example, the degree of rotational maneuver (the amount of body inversion prior to touchdown) and the amount of leg-assisted body swing both depend on the flies' initial body states while approaching the ceiling. In this work, inspired by the inverted landing behavior of flies, we used a physics-based simulation with experimental validation to systematically investigate how optimized inverted landing maneuvers depend on the initial approach velocities with varied magnitude and direction. This was done by analyzing the putative visual cues (that can be derived from onboard measurements) during optimal maneuvering trajectories. We identified a three-dimensional policy region, from which a mapping to a global inverted landing policy can be developed without the use of external positioning data. Through simulation, we also investigated the effects of an array of landing gear designs on the optimized landing performance and identified their advantages and disadvantages. The above results have been partially validated using limited experimental testing and will continue to inform and guide our future experiments, for example by applying the calculated global policy.",
        "primary_area": "",
        "author": "Bryan Habas;Bader AlAttar;Brian Davis;Jack W. Langelaan;Bo Cheng;Bryan Habas;Bader AlAttar;Brian Davis;Jack W. Langelaan;Bo Cheng",
        "authorids": "/37089447550;/37089449129;/37089446847;/37546827400;/37536373700;/37089447550;/37089449129;/37089446847;/37546827400;/37536373700",
        "aff": "Department of Mechanical Engineering, Biological and Robotic Intelligent Fluid Locomotion Lab, The Pennsylvania State University, University Park, PA, USA; Department of Mechanical Engineering, Biological and Robotic Intelligent Fluid Locomotion Lab, The Pennsylvania State University, University Park, PA, USA; Department of Mechanical Engineering, Biological and Robotic Intelligent Fluid Locomotion Lab, The Pennsylvania State University, University Park, PA, USA; Department of Aerospace Engineering, Air Vehicle Intelligence and Autonomy Lab, The Pennsylvania State University, University Park, PA, USA; Department of Mechanical Engineering, Biological and Robotic Intelligent Fluid Locomotion Lab, The Pennsylvania State University, University Park, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812409/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17436452207661620837&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Pennsylvania State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.psu.edu",
        "aff_unique_abbr": "PSU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "University Park",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811938",
        "title": "Optimal Thrust Vector Control of an Electric Small-Scale Rocket Prototype",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in Model Predictive Control (MPC) algorithms and methodologies, combined with the surge of computational power of available embedded platforms, allows the use of real-time optimization-based control of fast mechatronic systems. This paper presents an implementation of an optimal guidance, navigation and control (GNC) system for the motion control of a small-scale electric prototype of a thrust-vectored rocket. The aim of this prototype is to provide an inexpensive platform to explore GNC algorithms for automatic landing of sounding rockets. The guidance and trajectory tracking are formulated as continuous-time optimal control problems and are solved in real-time on embedded hardware using the PolyMPC library. An Extended Kalman Filter (EKF) is designed to estimate external disturbances and actuators offsets. Finally, indoor and outdoor flight experiments are performed to validate the architecture.",
        "primary_area": "",
        "author": "Rapha\u00ebl Linsen;Petr Listov;Alb\u00e9ric de Lajarte;Roland Schwan;Colin N. Jones;Rapha\u00ebl Linsen;Petr Listov;Alb\u00e9ric de Lajarte;Roland Schwan;Colin N. Jones",
        "authorids": "/37089450589;/37089224489;/37089448948;/37089447075;/37291983100;/37089450589;/37089224489;/37089448948;/37089447075;/37291983100",
        "aff": "Laboratoire d\u2019 Automatique, EPFL, Switzerland; Laboratoire d\u2019 Automatique, EPFL, Switzerland; Laboratoire d\u2019 Automatique, EPFL, Switzerland; Laboratoire d\u2019 Automatique, EPFL, Switzerland; Laboratoire d\u2019 Automatique, EPFL, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811938/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18415311010845555973&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Laboratoire d\u2019Automatique",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9812020",
        "title": "Optimal and Bounded-Suboptimal Multi-Goal Task Assignment and Path Finding",
        "track": "main",
        "status": "Poster",
        "abstract": "We formalize and study the multi-goal task assignment and path finding (MG-TAPF) problem from theoretical and algorithmic perspectives. The MG-TAPF problem is to compute an assignment of tasks to agents, where each task consists of a sequence of goal locations, and collision-free paths for the agents that visit all goal locations of their assigned tasks in sequence. Theoretically, we prove that the MG-TAPF problem is NP-hard to solve optimally. We present algorithms that build upon algorithmic techniques for the multi-agent path finding problem and solve the MG-TAPF problem optimally and bounded-suboptimally. We experimentally compare these algorithms on a variety of different benchmark domains.",
        "primary_area": "",
        "author": "Xinyi Zhong;Jiaoyang Li;Sven Koenig;Hang Ma;Xinyi Zhong;Jiaoyang Li;Sven Koenig;Hang Ma",
        "authorids": "/37089450111;/37089447975;/37284916000;/37088998793;/37089450111;/37089447975;/37284916000;/37088998793",
        "aff": "School of Computing Science, Simon Fraser University, Canada; Department of Computer Science, University of Southern California, USA; Department of Computer Science, University of Southern California, USA; School of Computing Science, Simon Fraser University, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812020/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1985728136067787694&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Simon Fraser University;University of Southern California",
        "aff_unique_dep": "School of Computing Science;Department of Computer Science",
        "aff_unique_url": "https://www.sfu.ca;https://www.usc.edu",
        "aff_unique_abbr": "SFU;USC",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9812036",
        "title": "Optimal-Horizon Model Predictive Control with Differential Dynamic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an algorithm, based on the Differential Dynamic Programming framework, to handle trajectory optimization problems in which the horizon is determined online rather than fixed a priori. This algorithm exhibits exact one-step convergence for linear, quadratic, time-invariant problems and is fast enough for real-time nonlinear model-predictive control. We show derivations for the nonlinear algorithm in the discrete-time case, and apply this algorithm to a variety of nonlinear problems. Finally, we show the efficacy of the optimal-horizon model-predictive control scheme compared to a standard MPC controller, on an obstacle-avoidance problem with planar robots.",
        "primary_area": "",
        "author": "Kyle Stachowicz;Evangelos A. Theodorou;Kyle Stachowicz;Evangelos A. Theodorou",
        "authorids": "/37089281185;/37546007800;/37089281185;/37546007800",
        "aff": "Autonomous Control and Decision Systems Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Autonomous Control and Decision Systems Laboratory, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812036/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5308258702868808660&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Autonomous Control and Decision Systems Laboratory",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812042",
        "title": "Optimizing Camera Placements for Overlapped Coverage with 3D Camera Projections",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a method to compute camera 6 DoF poses to achieve a user defined coverage. The camera placement problem is modeled as a combinatorial optimization where given the maximum number of cameras, a camera set is selected from a larger pool of possible camera poses. We propose to minimize the squared error between the desired and the achieved coverage, and formulate the non-linear cost function as a mixed integer linear programming problem. A camera lens model is utilized to project the camera's view on a 3D voxel map to compute a coverage score which makes the optimization problem in real environments tractable. Experimental results in two real retail store environments demonstrate the better performance of the proposed formulation in terms of coverage and overlap for triangulation compared to existing methods.",
        "primary_area": "",
        "author": "Akshay Malhotra;Dhananjay Singh;Tushar Dadlani;Luis Yoichi Morales;Akshay Malhotra;Dhananjay Singh;Tushar Dadlani;Luis Yoichi Morales",
        "authorids": "/37089448479;/37089448370;/37089448020;/37086168151;/37089448479;/37089448370;/37089448020;/37086168151",
        "aff": "InterDigital Comm.; Standard Cognition; Walmart; Standard Cognition",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812042/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8584323919412929709&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "InterDigital;Standard Cognition;Walmart Inc.",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.interdigital.com;https://www.standardcognition.com;https://www.walmart.com",
        "aff_unique_abbr": "InterDigital;;Walmart",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812318",
        "title": "Optimizing Multi-Robot Placements for Wire Arc Additive Manufacturing",
        "track": "main",
        "status": "Poster",
        "abstract": "Wire arc additive manufacturing is a metal additive manufacturing process in which the material is deposited using arc welding technology. It is gaining popularity due to high material deposition rates and faster build time. It is en-abled using robotic manipulators and can build relatively large-scale parts faster when compared with other metal additive manufacturing processes. However, the size of the large-scale parts is limited by the size of the industrial manipulator being used for the process. This limitation is overcome by using a fixed configuration multi-robot cell in which manipulators work cooperatively to build large-scale parts quickly. A fixed multi-robot cell with closely spaced industrial manipulators has high flexibility, but it restricts the part size that can be built. If the manipulators are spread out, the cell loses its flexibility but can build relatively larger parts. This issue can be avoided by using larger size manipulators, which are expensive, or by moving the modest size manipulators based on the part geometries. This paper presents a novel algorithm to generate multi-robot placements for different part geometries to be built using wire arc additive manufacturing. Furthermore, the algorithm hierarchically optimizes the build time and the inverse kinematics consistency in robot paths to improve the process efficiency and part quality. We compare the results with fixed multi-robot cells and provide insights to users to make an informed decision on whether to use a fixed or a flexible multi-robot cell for wire arc additive manufacturing.",
        "primary_area": "",
        "author": "Prahar M. Bhatt;Andrzej Nycz;Satyandra K. Gupta;Prahar M. Bhatt;Andrzej Nycz;Satyandra K. Gupta",
        "authorids": "/37086936500;/37681756200;/37878971100;/37086936500;/37681756200;/37878971100",
        "aff": "Center for Advanced Manufacturing, University of Southern California, CA, USA; Oak Ridge National Laboratory, Oak Ridge, TN, USA; Center for Advanced Manufacturing, University of Southern California, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812318/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17160322424842030280&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Southern California;Oak Ridge National Laboratory",
        "aff_unique_dep": "Center for Advanced Manufacturing;",
        "aff_unique_url": "https://www.usc.edu;https://www.ornl.gov",
        "aff_unique_abbr": "USC;ORNL",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Los Angeles;Oak Ridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812357",
        "title": "Optimizing Space Utilization for More Effective Multi-Robot Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We perform a systematic exploration of the principle of Space Utilization Optimization (SUO) as a heuristic for planning better individual paths in a decoupled multi-robot path planner, with applications to both one-shot and life-long multi-robot path planning problems. We show that the heuristic set, SU - I, preserves single path optimality and significantly reduces congestion that naturally happens when many paths are planned without coordination. Integration of SU - I into complete planners brings dramatic reductions in computation time due to the significantly reduced number of conflicts and leads to sizable solution optimality gains in diverse evaluation scenarios over medium and large maps, for both one-shot and life-long problem settings.",
        "primary_area": "",
        "author": "Shuai D. Han;Jingjin Yu;Shuai D. Han;Jingjin Yu",
        "authorids": "/37086094452;/37536570700;/37086094452;/37536570700",
        "aff": "Amazon Robotics; Department of Computer Science, Rutgers University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812357/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2875673347702164260&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Amazon;Rutgers University",
        "aff_unique_dep": "Amazon Robotics;Department of Computer Science",
        "aff_unique_url": "https://www.amazonrobotics.com;https://www.rutgers.edu",
        "aff_unique_abbr": "Amazon Robotics;Rutgers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811789",
        "title": "Optimizing Terrain Mapping and Landing Site Detection for Autonomous UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "The next generation of Mars rotorcrafts requires on-board autonomous hazard avoidance landing. To this end, this work proposes a system that performs continuous multi-resolution height map reconstruction and safe landing spot detection. Structure-from-Motion measurements are aggregated in a pyramid structure using a novel Optimal Mixture of Gaus-sians formulation that provides a comprehensive uncertainty model. Our multiresolution pyramid is built more efficiently and accurately than past work by decoupling pyramid filling from the measurement updates of different resolutions. To detect the safest landing location, after an optimized hazard segmentation, we use a mean shift algorithm on multiple distance transform peaks to account for terrain roughness and uncertainty. The benefits of our contributions are evaluated on real and synthetic flight data.",
        "primary_area": "",
        "author": "Pedro F. Proen\u00e7a;Jeff Delaune;Rol;Brockers;Pedro F. Proen\u00e7a;Jeff Delaune;Rol;Brockers",
        "authorids": "/37086315258;/37086592626;/37089450603;/37089449947;/37086315258;/37086592626;/37089450603;/37089449947",
        "aff": "Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811789/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1221188723091206125&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811562",
        "title": "Optimizing Trajectories with Closed-Loop Dynamic SQP",
        "track": "main",
        "status": "Poster",
        "abstract": "Indirect trajectory optimization methods such as Differential Dynamic Programming (DDP) have found considerable success when only planning under dynamic feasibility constraints. Meanwhile, nonlinear programming (NLP) has been the state-of-the-art approach when faced with additional constraints (e.g., control bounds, obstacle avoidance). However, a na\u00efve implementation of NLP algorithms, e.g., shooting-based sequential quadratic programming (SQP), may suffer from slow convergence \u2013 caused from natural instabilities of the underlying system manifesting as poor numerical stability within the optimization. Re-interpreting the DDP closed-loop rollout policy as a sensitivity-based correction to a second-order search direction, we demonstrate how to compute analogous closedloop policies (i.e., feedback gains) for constrained problems. Our key theoretical result introduces a novel dynamic programmingbased constraint-set recursion that augments the canonical \u201ccost-to-go\u201d backward pass. On the algorithmic front, we develop a hybrid-SQP algorithm incorporating DDP-style closedloop rollouts, enabled via efficient parallelized computation of the feedback gains. Finally, we validate our theoretical and algorithmic contributions on a set of increasingly challenging benchmarks, demonstrating significant improvements in convergence speed over standard open-loop SQP.",
        "primary_area": "",
        "author": "Sumeet Singh;Jean-Jacques Slotine;Vikas Sindhwani;Sumeet Singh;Jean-Jacques Slotine;Vikas Sindhwani",
        "authorids": "/37085589975;/309145313398572;/37282057000;/37085589975;/309145313398572;/37282057000",
        "aff": "Robotics at Google, New York City, NY, USA; Robotics at Google, New York City, NY, USA; Robotics at Google, New York City, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811562/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14884415763900791922&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Robotics",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811610",
        "title": "Opto-electrotactile Feedback Enabled Text-line Tracking Control for A Finger-wearable Reading Aid for the Blind",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, to achieve the goal of aiding the blind and visually impaired (BVI) to read any text not written in Braille, a custom-built, finger-wearable, and electro-tactile based Braille reading system with its Rapid Optical Character Recognition (R-OCR) method is developed. The R-OCR is capable of processing text information in real time using a miniature fish-eye imaging device mounted at the finger-wearable system. This allows real-time translation of printed text to electro-Braille along with natural movement of user's fingertip as if reading any Braille sign or book. An electro-tactile neuro-stimulation feedback mechanism is further proposed and incorporated with the reading system, which facilitates a new opto-electrotactile-feedback-based text line tracking control approach that enables text line following by user's fingertip during reading. Extensive experiments were designed and conducted to test the ability of blindfolded participants to read through and follow the printed text lines based on this optoelectrotactile-feedback method. The experimental results show that as the outcome of the opto-electrotactile-feedback, the users who involved in the feedback loop were able to maintain their fingertips within a 2mm2mm distance of the text while \u201creading\u201d through a printed text line. Our work is a significant step to aid the BVI users with a portable means to read any printed texts to Braille through the following and the translation, whether in the digital realm or physically, on any surface.",
        "primary_area": "",
        "author": "Mehdi Rahimi;Yantao Shen;Cong Peng;Zhiming Liu;Fang Jiang;Mehdi Rahimi;Yantao Shen;Cong Peng;Zhiming Liu;Fang Jiang",
        "authorids": "/37085381800;/37274462800;/37087050834;/37086004314;/37087049985;/37085381800;/37274462800;/37087050834;/37086004314;/37087049985",
        "aff": "University of Colorado, Denver, USA; Department of Electrical and Biomedical Engineering, University of Nevada, Reno, USA; Department of Electrical and Biomedical Engineering, University of Nevada, Reno, USA; Department of Electrical and Biomedical Engineering, University of Nevada, Reno, USA; Department of Psychology, University of Nevada, Reno, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811610/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11922173669042130199&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "University of Colorado Denver;University of Nevada, Reno",
        "aff_unique_dep": ";Department of Electrical and Biomedical Engineering",
        "aff_unique_url": "https://www.ucdenver.edu;https://www.unr.edu",
        "aff_unique_abbr": "UC Denver;UNR",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Denver;Reno",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812289",
        "title": "Orientation to Pose: Continuum Robots Shape Reconstruction Based on the Multi-Attitude Solving Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Continuum robots are typically slender and flexible with infinite freedoms in theory, which poses a challenge for their control and application. The shape reconstruction of continuum robots is vital to realize closed-loop control. This paper proposes a novel general real-time shape reconstruction framework of continuum robots based on the piecewise polynomial curvature (PPC) kinematics model. We illustrate the coupling between orientation and position at any given location of the continuum robots. Further, the coupling relation could be bridged by the PPC kinematics. Therefore, we propose to estimate the shape through multi-attitude solving, using the off-the-shelf orientation sensors, e.g., IMUs, mounted on certain locations. The approach gives a valuable framework to real-time shape reconstruction of continuum robots, which is general, accurate and convenient. The accuracy of our approach is verified in the experiments of distinct physical prototypes.",
        "primary_area": "",
        "author": "Hao Cheng;Hejie Xu;Hongji Shang;Xueqian Wang;Houde Liu;Bin Liang;Hao Cheng;Hejie Xu;Hongji Shang;Xueqian Wang;Houde Liu;Bin Liang",
        "authorids": "/37088697832;/37089450860;/37089447903;/37085383477;/37085401214;/37270783900;/37088697832;/37089450860;/37089447903;/37085383477;/37085401214;/37270783900",
        "aff": "Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of Automation, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812289/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4948766022705148586&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Shenzhen International Graduate School",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Shenzhen;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811600",
        "title": "Oriented Surface Reachability Maps for Robot Placement",
        "track": "main",
        "status": "Poster",
        "abstract": "For a robot to perform a grasping and manipulation task, it has to determine possible robot placements in the workspace, from which target objects or environmental elements relevant to the given task are reachable. This work presents a novel approach for finding placements for the mobile base of a humanoid robot in an unknown environment with multiple support planes. We propose a novel type of reachability map - the Oriented Surface Reachability Map - that takes inclined surfaces in the environment into account and has the same complexity as reachability maps designed for flat surfaces. The resulting robot placements are not limited to SE(2) but can be applied to arbitrarily oriented planes in 3D space. The proposed method was evaluated in simulation and on the humanoid robot ARMAR-6 in real-world grasping experiments. The results show that a placement can be found for over 80% of the poses that are reachable in complicated, simulated environments, with only a small runtime overhead.",
        "primary_area": "",
        "author": "Timo Birr;Christoph Pohl;Tamim Asfour;Timo Birr;Christoph Pohl;Tamim Asfour",
        "authorids": "/37089449317;/37089404480;/37295529100;/37089449317;/37089404480;/37295529100",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811600/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3231487123544383996&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811995",
        "title": "PA-AWCNN: Two-stream Parallel Attention Adaptive Weight Network for RGB-D Action Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to overly relying on appearance information or adopting direct static feature fusion, most of the existing action recognition methods based on multi-modality have poor robustness and insufficient consideration of modality differences. To address these problems, we propose a two-stream adaptive weight integration network with a three-dimensional parallel attention module, PA-AWCNN. Firstly, a three-dimensional Parallel Attention (PA) module is proposed to effectively extract features of spatial, temporal and channel dimensions and reduce the cross-dimensional interference, to achieve better robustness. Secondly, a Common Feature-driven (CFD) feature integration module is proposed to dynamically integrate appearance and depth features with adaptive weights, utilizing modality differences to redeem the lack of each feature, thereby balance the influence of both. The proposed PA-AW CNN uses the representative integrated feature generated by attention enhancement and feature integration for action recognition; it can not only get higher recognition accuracy but also improve the performance of distinguishing similar actions. Experiments illustrate that the proposed method achieves com-parable performances to state-of-the-art methods and obtains the accuracy of 92.76% and 95.65% on NTU RGB+D Dataset and SBU Kinect Interaction Dataset, respectively. The code is publicly available at: https://github.com/Luu-Yao/PA-AWCNN.",
        "primary_area": "",
        "author": "Lu Yao;Sheng Liu;Chaonan Li;Siyu Zou;Shengyong Chen;Diyi Guan;Lu Yao;Sheng Liu;Chaonan Li;Siyu Zou;Shengyong Chen;Diyi Guan",
        "authorids": "/37089448191;/37599356700;/37089449020;/37089450389;/37290961700;/37089447739;/37089448191;/37599356700;/37089449020;/37089450389;/37290961700;/37089447739",
        "aff": "College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Engineering, Tianjin University of Technology, Tianjin, China; College of Humanities, Zhejiang University of Technology, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811995/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16150477531170361705&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Zhejiang University of Technology;Tianjin University of Technology",
        "aff_unique_dep": "College of Computer Science and Technology;College of Computer Science and Engineering",
        "aff_unique_url": "https://www.zjut.edu.cn;http://www.tjut.edu.cn",
        "aff_unique_abbr": "ZJUT;TUT",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Hangzhou;Tianjin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811653",
        "title": "PF-MOT: Probability Fusion Based 3D Multi-Object Tracking for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "3D Multi-Object Tracking (MOT) plays a crucial role in efficient and safe operation of automatic driving, especially in scenarios of occlusion or poor visibility. Most 3D MOT methods leverage only positional distance, which is insufficient for scenes with high density of objects or drastic changes in the motion state. In order to address this, we propose a new 3D MOT model which fuses information pertaining to positional distance and geometric similarity. Our proposed solution comprises of four parts: a) a feature extraction mechanism integrated into a commonly used detector to extract individual features for each detection, b) computation of two distance matrices based on Euclidean distance and feature similarity, c) conversion of the distance matrices to probability matrices by a cluster based Earth-Mover Distance (EMD) algorithm, and d) a data association method that fuses both sources to boost the tracking accuracy. Our proposed model demonstrates state-of-the-art performance on the nuScenes tracking dataset, with extensive experiments attesting to an improved tracking accuracy over baselines that operate solely on positional distance.",
        "primary_area": "",
        "author": "Tao Wen;Yanyong Zhang;Nikolaos M. Freris;Tao Wen;Yanyong Zhang;Nikolaos M. Freris",
        "authorids": "/37089446655;/37279961200;/38597035200;/37089446655;/37279961200;/38597035200",
        "aff": "School of Computer Science, University of Science and Technology of China; School of Computer Science, University of Science and Technology of China; School of Computer Science, University of Science and Technology of China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811653/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10978979656008315593&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811877",
        "title": "Panoptic Multi-TSDFs: a Flexible Representation for Online Multi-resolution Volumetric Mapping and Long-term Dynamic Scene Consistency",
        "track": "main",
        "status": "Poster",
        "abstract": "For robotic interaction in environments shared with other agents, access to volumetric and semantic maps of the scene is crucial. However, such environments are inevitably subject to long-term changes, which the map needs to account for. We thus propose panoptic multi-TSDFs as a novel representation for multi-resolution volumetric mapping in changing environments. By leveraging high-level information for 3D reconstruction, our proposed system allocates high resolution only where needed. Through reasoning on the object level, semantic consistency over time is achieved. This enables our method to maintain up-to-date reconstructions with high accuracy while improving coverage by incorporating previous data. We show in thorough experimental evaluation that our map can be efficiently constructed, maintained, and queried during online operation, and that the presented approach can operate robustly on real depth sensors using non-optimized panoptic segmentation as input.",
        "primary_area": "",
        "author": "Lukas Schmid;Jeffrey Delmerico;Johannes L. Sch\u00f6nberger;Juan Nieto;Marc Pollefeys;Roland Siegwart;Cesar Cadena;Lukas Schmid;Jeffrey Delmerico;Johannes L. Sch\u00f6nberger;Juan Nieto;Marc Pollefeys;Roland Siegwart;Cesar Cadena",
        "authorids": "/37086444000;/37391796500;/37085387107;/37085778635;/37271138500;/37281398300;/37593590400;/37086444000;/37391796500;/37085387107;/37085778635;/37271138500;/37281398300;/37593590400",
        "aff": "Autonomous Systems Lab., ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Mixed Reality -and AI Lab., Microsoft, Z\u00fcrich, Switzerland; Mixed Reality -and AI Lab., Microsoft, Z\u00fcrich, Switzerland; Mixed Reality -and AI Lab., Microsoft, Z\u00fcrich, Switzerland; Computer Vision and Geometry Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab., ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab., ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811877/",
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9424488270504814693&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;0;0;0",
        "aff_unique_norm": "ETH Zurich;Microsoft",
        "aff_unique_dep": "Autonomous Systems Lab.;Mixed Reality -and AI Lab.",
        "aff_unique_url": "https://www.ethz.ch;https://www.microsoft.com",
        "aff_unique_abbr": "ETH;Microsoft",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9812167",
        "title": "Parametric Path Optimization for Wheeled Robots Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Collision risk and smoothness are the most important factors in global path planning. Currently, planning methods that reduce global path collision risk and improve its smoothness through numerical optimization have achieved good results. However, these methods cannot always optimize the path. The reason is all points on the path are considered as decision variables, which leads to the high dimensionality of the defined optimization problem. Therefore, we propose a novel global path optimization method. The method characterizes the path as a parametric curve and then optimizes the curve's parameters with a defined objective function, which successfully reduces the dimension of optimization problem. The proposed method is compared with baseline and state-of-the-art methods. Experimental results show the path optimized by our method is not only optimal in collision risk, but also in efficiency and smoothness. Furthermore, the proposed method is also implemented and tested in both simulation and real robots.",
        "primary_area": "",
        "author": "Zhiqiang Jian;Songyi Zhang;Jiahui Zhang;Shitao Chen;Nanning Zheng;Zhiqiang Jian;Songyi Zhang;Jiahui Zhang;Shitao Chen;Nanning Zheng",
        "authorids": "/37086960603;/37086351843;/37089237205;/37086351761;/37271536700;/37086960603;/37086351843;/37089237205;/37086351761;/37271536700",
        "aff": "Shunan Academy of Artificial Intelligence, Ningbo, Zhejiang, P.R. China; Shunan Academy of Artificial Intelligence, Ningbo, Zhejiang, P.R. China; Shunan Academy of Artificial Intelligence, Ningbo, Zhejiang, P.R. China; Shunan Academy of Artificial Intelligence, Ningbo, Zhejiang, P.R. China; Institute of Artificial Intelligence and Robotics, Xi'an Jiaotong University, Xi'an, Shaanxi, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812167/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4432020988546034421&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Shunan Academy of Artificial Intelligence;Xi'an Jiao Tong University",
        "aff_unique_dep": ";Institute of Artificial Intelligence and Robotics",
        "aff_unique_url": ";http://www.xjtu.edu.cn",
        "aff_unique_abbr": ";XJTU",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Ningbo;Xi'an",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811953",
        "title": "PatchGraph: In-hand tactile tracking with learned surface normals",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of tracking 3D object poses from touch during in-hand manipulations. Specifically, we look at tracking small objects using vision-based tactile sensors that provide high-dimensional tactile image measurements at the point of contact. While prior work has relied on a-priori information about the object being localized, we remove this requirement. Our key insight is that an object is composed of several local surface patches, each informative enough to achieve reliable object tracking. Moreover, we can recover the geometry of this local patch online by extracting local surface normal information embedded in each tactile image. We propose a novel two-stage approach. First, we learn a mapping from tactile images to surface normals using an image translation network. Second, we use these surface normals within a factor graph to both reconstruct a local patch map and use it to infer 3D object poses. We demonstrate reliable object tracking for over 100 contact sequences across unique shapes with four objects in simulation and two objects in the real-world.",
        "primary_area": "",
        "author": "Paloma Sodhi;Michael Kaess;Mustafa Mukadanr;Stuart Anderson;Paloma Sodhi;Michael Kaess;Mustafa Mukadanr;Stuart Anderson",
        "authorids": "/38469682300;/37324200400;/37089446704;/37089001454;/38469682300;/37324200400;/37089446704;/37089001454",
        "aff": "Meta AI Research; Carnegie Mellon University; Meta AI Research; Meta AI Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811953/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2698969303489949382&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Meta;Carnegie Mellon University",
        "aff_unique_dep": "Meta AI Research;",
        "aff_unique_url": "https://meta.com;https://www.cmu.edu",
        "aff_unique_abbr": "Meta AI;CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812100",
        "title": "Path-Aware Graph Attention for HD Maps in Motion Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "The success of motion prediction for autonomous driving relies on integration of information from the HD maps. As maps are naturally graph-structured, investigation on graph neural networks (GNNs) for encoding HD maps is burgeoning in recent years. However, unlike many other applications where GNNs have been straightforwardly deployed, HD maps are heterogeneous graphs where vertices (lanes) are connected by edges (lane-lane interaction relationships) of various nature, and most graph-based models are not designed to understand the variety of edge types which provide crucial cues for predicting how the agents would travel the lanes. To overcome this challenge, we propose Path-Aware Graph Attention, a novel attention architecture that infers the attention between two vertices by parsing the sequence of edges forming the paths that connect them. Our analysis illustrates how the proposed attention mechanism can facilitate learning in a didactic problem where existing graph networks like GCN struggle. By improving map encoding, the proposed model surpasses previous state of the art on the Argoverse Motion Forecasting dataset, and won the first place in the 2021 Argoverse Motion Forecasting Competition.",
        "primary_area": "",
        "author": "Fang Da;Yu Zhang;Fang Da;Yu Zhang",
        "authorids": "/37089449259;/37089448966;/37089449259;/37089448966",
        "aff": "QCraft Inc; QCraft Inc",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812100/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10140953822347142708&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "QCraft Inc",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811791",
        "title": "Patient-tailored Adaptive Control for Robot-aided Orthopaedic Rehabilitation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot-aided rehabilitation is pushing forward novel robotic architectures to provide physical therapy. This paper presents a patient-tailored control architecture for upper-limb robot-aided orthopaedic rehabilitation capable of i) adapting the robot workspace on the basis of patient Range of Motion (RoM); ii) generating a tunnel, around the desired path to be followed by the patient, which guarantees spatial autonomy; iii) introducing a back-wall inside the tunnel sliding with variable speed on the basis of patient performance to ensure temporal autonomy; iv) rehabilitating to working gestures, thanks to a DMP-based trajectory planner, with the aim of favoring an effective translation of the patient's motor recovery results to the occupational sphere; v) ensuring a patient-tailored assistance also thanks to the evaluation of performance indicators. The designed system was validated demonstrating the adaptability of the system to orthopaedic patient motor imnrovements.",
        "primary_area": "",
        "author": "Christian Tamantini;Francesca Cordella;Clemente Lauretti;Francesco Scotto di Luzio;Marco Bravi;Federica Bressi;Francesco Draicchio;Silvia Sterzi;Loredana Zollo;Christian Tamantini;Francesca Cordella;Clemente Lauretti;Francesco Scotto di Luzio;Marco Bravi;Federica Bressi;Francesco Draicchio;Silvia Sterzi;Loredana Zollo",
        "authorids": "/37088199860;/38229848700;/37085839107;/37086152920;/37086944391;/37088728538;/37086481049;/37590406300;/37282448400;/37088199860;/38229848700;/37085839107;/37086152920;/37086944391;/37088728538;/37086481049;/37590406300;/37282448400",
        "aff": "Research Unit of Advanced Robotics and Human-Centred Technologies, Universit\u00e0 Campus Bio-Medico di Roma, Rome, Italy; Research Unit of Advanced Robotics and Human-Centred Technologies, Universit\u00e0 Campus Bio-Medico di Roma, Rome, Italy; Research Unit of Advanced Robotics and Human-Centred Technologies, Universit\u00e0 Campus Bio-Medico di Roma, Rome, Italy; Research Unit of Advanced Robotics and Human-Centred Technologies, Universit\u00e0 Campus Bio-Medico di Roma, Rome, Italy; Unit of Physical Medicine and Rehabilitation, Universit\u00e0 Campus Bio-Medico di Roma, Rome, Italy; Unit of Physical Medicine and Rehabilitation, Universit\u00e0 Campus Bio-Medico di Roma, Rome, Italy; Dept. of Occupational & Environmental Medicine, INAIL, Monte Porzio Catone, Rome, Italy; Unit of Physical Medicine and Rehabilitation, Universit\u00e0 Campus Bio-Medico di Roma, Rome, Italy; Research Unit of Advanced Robotics and Human-Centred Technologies, Universit\u00e0 Campus Bio-Medico di Roma, Rome, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811791/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14628830117281696569&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Universit\u00e0 Campus Bio-Medico di Roma;INAIL",
        "aff_unique_dep": "Research Unit of Advanced Robotics and Human-Centred Technologies;Dept. of Occupational & Environmental Medicine",
        "aff_unique_url": "https://www.unicampusroma.eu;https://www.inail.it",
        "aff_unique_abbr": ";INAIL",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Rome",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9811664",
        "title": "Pedestrian Stop and Go Forecasting with Hybrid Feature Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Forecasting pedestrians' future motions is essential for autonomous driving systems to safely navigate in urban areas. However, existing prediction algorithms often overly rely on past observed trajectories and tend to fail around abrupt dynamic changes, such as when pedestrians suddenly start or stop walking. We suggest that predicting these highly non-linear transitions should form a core component to improve the robustness of motion prediction algorithms. In this paper, we introduce the new task of pedestrian stop and go forecasting. Considering the lack of suitable existing datasets for it, we release TRANS, a benchmark for explicitly studying the stop and go behaviors of pedestrians in urban traffic. We build it from several existing datasets annotated with pedestrians' walking motions, in order to have various scenarios and behaviors. We also propose a novel hybrid model that leverages pedestrian-specific and scene features from several modalities, both video sequences and high-level attributes, and gradually fuses them to integrate multiple levels of context. We evaluate our model and several baselines on TRANS, and set a new benchmark for the community to work on pedestrian stop and go forecasting.",
        "primary_area": "",
        "author": "Dongxu Guo;Taylor Mordan;Alexandre Alahi;Dongxu Guo;Taylor Mordan;Alexandre Alahi",
        "authorids": "/37089449703;/37086229048;/37601323900;/37089449703;/37086229048;/37601323900",
        "aff": "Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Visual Intelligence for Transportation (VITA), Lausanne, Switzerland; Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Visual Intelligence for Transportation (VITA), Lausanne, Switzerland; Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Visual Intelligence for Transportation (VITA), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811664/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3857136928740476947&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Visual Intelligence for Transportation (VITA)",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9812178",
        "title": "Perception Engine Using a Multi-Sensor Head to Enable High-level Humanoid Robot Behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "For achieving significant levels of autonomy, legged robot behaviors require perceptual awareness of both the terrain for traversal, as well as structures and objects in their surroundings for planning, obstacle avoidance, and high-level decision making. In this work, we present a perception engine for legged robots that extracts the necessary information for developing semantic, contextual, and metric awareness of their surroundings. Our custom sensor configuration consists of (1) an active depth sensor, (2) two monocular cameras looking sideways, (3) a passive stereo sensor observing the terrain, (4) a forward facing active depth camera, and (5) a rotating 3D LIDAR with a large vertical field-of-view (FOV). The mutual overlap in the sensors' FOVs allows us to redundantly detect and track objects of both dynamic and static types. We fuse class masks generated by a semantic segmentation model with LIDAR and depth data to accurately identify and track individual instances of dynamically moving objects. In parallel, active depth and passive stereo streams of the terrain are also fused to map the terrain using the on-board GPU. We evaluate the engine using two different humanoid behaviors, (1) look-and-step and (2) track-and-follow, on the Boston Dynamics Atlas.",
        "primary_area": "",
        "author": "Bhavyansh Mishra;Duncan Calvert;Brendon Ortolano;Max Asselmeier;Luke Fina;Stephen McCrory;Hakki Erhan Sevil;Robert Griffin;Bhavyansh Mishra;Duncan Calvert;Brendon Ortolano;Max Asselmeier;Luke Fina;Stephen McCrory;Hakki Erhan Sevil;Robert Griffin",
        "authorids": "/37086319200;/37088689927;/37089372896;/37088489179;/37089373113;/37085793385;/38073914300;/37085631429;/37086319200;/37088689927;/37089372896;/37088489179;/37089373113;/37085793385;/38073914300;/37085631429",
        "aff": "University of West Florida (UWF), Pensacola, FL, USA; University of West Florida (UWF), Pensacola, FL, USA; University of West Florida (UWF), Pensacola, FL, USA; Institute of Human and Machine Cognition (IHMC), Pensacola, FL, USA; University of West Florida (UWF), Pensacola, FL, USA; University of West Florida (UWF), Pensacola, FL, USA; University of West Florida (UWF), Pensacola, FL, USA; University of West Florida (UWF), Pensacola, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812178/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12680788563827920874&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;0;0;0;0",
        "aff_unique_norm": "University of West Florida;Institute of Human and Machine Cognition",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uwf.edu;",
        "aff_unique_abbr": "UWF;IHMC",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Pensacola",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811870",
        "title": "Perception-Friendly Video Enhancement for Autonomous Driving under Adverse Weather Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual perception of an autonomous vehicle is a crucial component of autonomous driving technologies. While visual perception research has achieved promising performance in recent years, modern methods are mostly trained, applied, and tested on single clean images. Recently, deep learning-based perception methods have addressed multiple degrading effects to reflect real-world bad weather cases, but have achieved only limited success, mainly due to 1) less or no temporal information across adjacent frames and 2) poor correlation between image enhancement and visual perception performance. To solve these issues, in this paper we propose a simple and effective video enhancement network incorporating the perception module, one of the high-level vision tasks, which takes video degraded by adverse weather conditions as an input, and produces an enhanced image and a recognition result as output. Besides, this allows us to leverage temporal information across consecutive frames without flow estimation. We also introduce a new training strategy to robustly guide the high-level task model suitable for both high-quality restoration of images and highly accurate perception. Further, considering sequence-level discrimination, we propose a Sequential Contrastive Loss, called SCL, to maximize apparent discrimination over sequential input. By doing this, our algorithm achieves full interaction showing mutual influence between the enhancement and perception tasks. Further, we introduce a novel low memory network dropping out most of the layer connections of dense blocks to reduce memory usage and computational cost while maintaining high performance. Experiment results demonstrate that the proposed method significantly improves the performance on object detection, distance estimation, and memory usage under adverse weather.",
        "primary_area": "",
        "author": "Younkwan Lee;Yeongmin Ko;Yechan Kim;Moongu Jeon;Younkwan Lee;Yeongmin Ko;Yechan Kim;Moongu Jeon",
        "authorids": "/37086534149;/37086488058;/37089448783;/37666359200;/37086534149;/37086488058;/37089448783;/37666359200",
        "aff": "Samsung Electronics, Suwon, South Korea; Machine Learning & Vision Laboratory, EECS, Gwangju Institute of Science and Technology (GIST), Gwangju, South Korea; Machine Learning & Vision Laboratory, EECS, Gwangju Institute of Science and Technology (GIST), Gwangju, South Korea; Korea Culture Technology Institute, Gwangju, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811870/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15126024191281216036&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Samsung;Gwangju Institute of Science and Technology;Korea Culture Technology Institute",
        "aff_unique_dep": "Samsung Electronics;Electrical Engineering and Computer Science;",
        "aff_unique_url": "https://www.samsung.com;https://www.gist.ac.kr;",
        "aff_unique_abbr": "Samsung;GIST;",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Suwon;Gwangju",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811788",
        "title": "Performance Guarantees for Spectral Initialization in Rotation Averaging and Pose-Graph SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we present the first initialization methods equipped with explicit performance guarantees that are adapted to the pose-graph simultaneous localization and mapping (SLAM) and rotation averaging (RA) problems. SLAM and rotation averaging are typically formalized as large-scale nonconvex point estimation problems, with many bad local minima that can entrap the smooth optimization methods typically applied to solve them; the performance of standard SLAM and RA algorithms thus crucially depends upon the quality of the estimates used to initialize this local search. While many initialization methods for SLAM and RA have appeared in the literature, these are typically obtained as purely heuristic approximations, making it difficult to determine whether (or under what circumstances) these techniques can be reliably deployed. In contrast, in this work we study the problem of initialization through the lens of spectral relaxation. Specifically, we derive a simple spectral relaxation of SLAM and RA, the form of which enables us to exploit classical linear-algebraic techniques (eigenvector perturbation bounds) to control the distance from our spectral estimate to both the (unknown) ground-truth and the global minimizer of the estimation prob lem as a function of measurement noise. Our results reveal the critical role that spectral graph-theoretic properties of the measurement network play in controlling estimation accuracy; moreover, as a by-product of our analysis we obtain new bounds on the estimation error for the maximum likelihood estimators in SLAM and RA, which are likely to be of independent interest. Finally, we show experimentally that our spectral estimator is very effective in practice, producing initializations of comparable or superior quality at lower computational cost compared to existing state-of-the-art techniques.",
        "primary_area": "",
        "author": "Kevin J. Doherty;David M. Rosen;John J. Leonard;Kevin J. Doherty;David M. Rosen;John J. Leonard",
        "authorids": "/37085769742;/38252288400;/37329387400;/37085769742;/38252288400;/37329387400",
        "aff": "Massachusetts Institute of Technology (MIT), Cambridge, MA; Massachusetts Institute of Technology (MIT), Cambridge, MA; Massachusetts Institute of Technology (MIT), Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811788/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8953948184823991431&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811634",
        "title": "Periodic SLAM: Using Cyclic Constraints to Improve the Performance of Visual-Inertial SLAM on Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Methods for state estimation that rely on visual information are challenging on legged robots due to rapid changes in the viewing angle of onboard cameras. In this work, we show that by leveraging structure in the way that the robot locomotes, the accuracy of visual-inertial SLAM in these challenging scenarios can be increased. We present a method that takes advantage of the underlying periodic predictability often present in the motion of legged robots to improve the performance of the feature tracking module within a visual-inertial SLAM system. Our method performs multi-session SLAM on a single robot, where each session is responsible for mapping during a distinct portion of the robot's gait cycle. Our method produces lower absolute trajectory error than several state-of-the-art methods for visual-inertial SLAM in both a simulated environment and on data collected on a quadrupedal robot executing dynamic gaits. On real-world bounding gaits, our median trajectory error was less than 35% of the error of the next best estimate provided by state-of-the-art methods.",
        "primary_area": "",
        "author": "Hans Kumar;J. Joe Payne;Matthew Travers;Aaron M. Johnson;Howie Choset;Hans Kumar;J. Joe Payne;Matthew Travers;Aaron M. Johnson;Howie Choset",
        "authorids": "/37089449828;/37089448713;/37545390200;/37589025300;/37281322200;/37089449828;/37089448713;/37545390200;/37589025300;/37281322200",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811634/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13726189466863990011&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811848",
        "title": "Persistent Homology for Effective Non-Prehensile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This work explores the use of topological tools for achieving effective non-prehensile manipulation in cluttered, constrained workspaces. In particular, it proposes the use of persistent homology as a guiding principle in identifying the appropriate non-prehensile actions, such as pushing, to clean a cluttered space with a robotic arm so as to allow the retrieval of a target object. Persistent homology enables the automatic identification of connected components of blocking objects in the space without the need for manual input or tuning of parameters. The proposed algorithm uses this information to push groups of cylindrical objects together and aims to minimize the number of pushing actions needed to reach to the target. Simulated experiments in a physics engine using a model of the Baxter robot show that the proposed topology-driven solution is achieving significantly higher success rate in solving such constrained problems relatively to state-of-the-art alternatives from the literature. It manages to keep the number of pushing actions low, is computationally efficient and the resulting decisions and motion appear natural for effectively solving such tasks.",
        "primary_area": "",
        "author": "Ewerton R. Vieira;Daniel Nakhimovich;Kai Gao;Rui Wang;Jingjin Yu;Kostas E. Bekris;Ewerton R. Vieira;Daniel Nakhimovich;Kai Gao;Rui Wang;Jingjin Yu;Kostas E. Bekris",
        "authorids": "/37089447525;/37088995936;/37088997464;/37088013751;/37536570700;/37282424700;/37089447525;/37088995936;/37088997464;/37088013751;/37536570700;/37282424700",
        "aff": "Department of Computer Science and DIMACS (the Center for Discrete Mathematics and Theoretical Computer Science), Rutgers University, NJ, USA; Department of Computer Science and DIMACS (the Center for Discrete Mathematics and Theoretical Computer Science), Rutgers University, NJ, USA; Department of Computer Science and DIMACS (the Center for Discrete Mathematics and Theoretical Computer Science), Rutgers University, NJ, USA; Department of Computer Science and DIMACS (the Center for Discrete Mathematics and Theoretical Computer Science), Rutgers University, NJ, USA; Department of Computer Science and DIMACS (the Center for Discrete Mathematics and Theoretical Computer Science), Rutgers University, NJ, USA; Department of Computer Science and DIMACS (the Center for Discrete Mathematics and Theoretical Computer Science), Rutgers University, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811848/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5855116867135761515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812446",
        "title": "Personalized Car Following for Autonomous Driving with Inverse Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Driving automation is gradually replacing human driving maneuvers in different applications such as adaptive cruise control and lane keeping. However, contemporary driving automation applications based on expert systems or prede-fined control strategies are not in line with individual human driver's preference. To overcome this problem, we propose a Personalized Adaptive Cruise Control (P-ACC) system that can learn the driver's car-following preferences from historical data using model-based maximum entropy Inverse Reinforcement Learning (IRL). Once activated in real-time, the P-ACC system first classifies the driver type and the weather type (at that moment). The vehicle is then controlled using the pre-trained IRL model on the cloud of the associated class. The personalized IRL model on the cloud will be updated as more human driving data is collected from various scenarios. Numerical simulation with real-world naturalistic driving data shows that, the accuracy of reproducing the real-world driving profile improves up to 30.1% in terms of speed and 36.5% in terms of distance gap, when P-ACC is compared with the Intelligent Driver Model (IDM). Game engine-based human-in-the-loop simulation demonstrates that, the takeover frequency of the driver during the usage of P-ACC decreases up to 93.4%, compared with that during the usage of IDM-based ACC.",
        "primary_area": "",
        "author": "Zhouqiao Zhao;Ziran Wang;Kyungtae Han;Rohit Gupta;Prashant Tiwari;Guoyuan Wu;Matthew J. Barth;Zhouqiao Zhao;Ziran Wang;Kyungtae Han;Rohit Gupta;Prashant Tiwari;Guoyuan Wu;Matthew J. Barth",
        "authorids": "/37087104888;/37086194317;/37086958428;/37089446651;/37087104382;/38251863100;/37356548800;/37087104888;/37086194317;/37086958428;/37089446651;/37087104382;/38251863100;/37356548800",
        "aff": "Department of Electrical and Computer Engineering, Center for Environmental Research and Technology, University of California, Riverside, CA; Toyota Motor North America R&D, InfoTech Labs, Mountain View, CA; Toyota Motor North America R&D, InfoTech Labs, Mountain View, CA; Toyota Motor North America R&D, InfoTech Labs, Mountain View, CA; Toyota Motor North America R&D, InfoTech Labs, Mountain View, CA; Department of Electrical and Computer Engineering, Center for Environmental Research and Technology, University of California, Riverside, CA; Department of Electrical and Computer Engineering, Center for Environmental Research and Technology, University of California, Riverside, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812446/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17738519699791723333&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;0;0",
        "aff_unique_norm": "University of California, Riverside;Toyota Motor North America",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;R&D, InfoTech Labs",
        "aff_unique_url": "https://www.ucr.edu;https://www.toyota.com",
        "aff_unique_abbr": "UCR;Toyota",
        "aff_campus_unique_index": "0;1;1;1;1;0;0",
        "aff_campus_unique": "Riverside;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811894",
        "title": "Physical Property Estimation and Knife Trajectory Optimization During Robotic Cutting",
        "track": "main",
        "status": "Poster",
        "abstract": "Dexterous robotic cutting needs to demonstrate a skill level with smooth and efficient knife movements. The work performed by the knife mainly generates fracture and overcomes the blade-material friction. This paper presents a recursive least-squares method that repeatedly estimates relevant physical parameters such as Poisson's ratio, fracture toughness, and coefficient of friction, all varying with the knife's movement when cutting a natural food, from force sensor readings. Furthermore, we show that these estimates can be used for generating the knife's trajectory on the fly to either maximize the ease of fracturing or to minimize the rate of work.",
        "primary_area": "",
        "author": "Xiaoqian Mu;Yan-Bin Jia;Xiaoqian Mu;Yan-Bin Jia",
        "authorids": "/37086936335;/37273296400;/37086936335;/37273296400",
        "aff": "aescape, Brooklyn, NY, USA; Department of Computer Science, Iowa State University, Ames, IA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811894/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13444098884757565801&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "aescape;Iowa State University",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": ";https://www.iastate.edu",
        "aff_unique_abbr": ";ISU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Brooklyn;Ames",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812345",
        "title": "PixSelect: Less but Reliable Pixels for Accurate and Efficient Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate camera pose estimation is a fundamental requirement for numerous applications, such as autonomous driving, mobile robotics, and augmented reality. In this work, we address the problem of estimating the global 6 DoF camera pose from a single RGB image in a given environment. Previous works consider every part of the image valuable for localization. However, many image regions such as the sky, occlusions, and repetitive non-distinguishable patterns cannot be utilized for localization. In addition to adding unnecessary computation efforts, extracting and matching features from such regions pro-duce many wrong matches which in turn degrades the localization accuracy and efficiency. Our work addresses this particular issue and shows by exploiting an interesting concept of sparse 3D models that we can exploit discriminatory environment parts and avoid useless image regions for the sake of a single image localization. Interestingly, through avoiding selecting keypoints from non-reliable image regions such as trees, bushes, cars, pedestrians, and occlusions, our work acts naturally as an outlier filter. This makes our system highly efficient in that minimal set of correspondences is needed and highly accurate as the number of outliers is low. Our work exceeds state-of-the-art methods on outdoor Cambridge Landmarks dataset. With only relying on single image at inference, it outweighs in terms of accuracy methods that exploit pose priors and/or reference 3D models while being much faster. By choosing as little as 100 correspondences, it surpasses similar methods that localize from thousands of correspondences, while being more efficient. In particular, it achieves, compared to these methods, an improvement of localization by 33% on OldHospital scene. Furthermore, It outstands direct pose regressors even those that learn from sequence of images. Our work will be publicly available.",
        "primary_area": "",
        "author": "Mohammad Altillawi;Mohammad Altillawi",
        "authorids": "/37089450043;/37089450043",
        "aff": "Munich Research Center, Huawei",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812345/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9721980267413752545&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Research Center",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812416",
        "title": "Planning Natural Locomotion for Articulated Soft Quadrupeds",
        "track": "main",
        "status": "Poster",
        "abstract": "Embedding elastic elements into legged robots through mechanical design enables highly efficient oscillating patterns that resemble natural gaits. However, current trajectory planning techniques miss the opportunity of taking advantage of these natural motions. This work proposes a locomotion planning method that aims to unify traditional trajectory generation with modal oscillations. Our method utilizes task-space linearized modes for generating center of mass trajectories on the sagittal plane. We then use nonlinear optimization to find the gait timings that match these trajectories within the Divergent Component of Motion planning framework. This way, we can robustly translate the modes-aware centroidal motions into joint coordinates. We validate our approach with promising results and insights through experiments on a compliant quadrupedal robot.",
        "primary_area": "",
        "author": "Mathew Jose Pollayil;Cosimo Della Santina;George Mesesan;Johannes Englsberger;Daniel Seidel;Manolo Garabini;Christian Ott;Antonio Bicchi;Alin Albu-Schaffer;Mathew Jose Pollayil;Cosimo Della Santina;George Mesesan;Johannes Englsberger;Daniel Seidel;Manolo Garabini;Christian Ott;Antonio Bicchi;Alin Albu-Schaffer",
        "authorids": "/37088690055;/37085627033;/37086066822;/38281295100;/37085401300;/37947205100;/37282440400;/37278626700;/38270361100;/37088690055;/37085627033;/37086066822;/38281295100;/37085401300;/37947205100;/37282440400;/37278626700;/38270361100",
        "aff": "Reasearch Center \u201cE. Piaggio\u201d, Universit\u00e0 di Pisa, Pisa, Italy; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Reasearch Center \u201cE. Piaggio\u201d, Universit\u00e0 di Pisa, Pisa, Italy; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Reasearch Center \u201cE. Piaggio\u201d, Universit\u00e0 di Pisa, Pisa, Italy; Department of Informatics, Technical University of Munich (TUM), Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812416/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12232274140529563145&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;1;0;1;0;2",
        "aff_unique_norm": "Universit\u00e0 di Pisa;German Aerospace Center;Technical University of Munich",
        "aff_unique_dep": "Research Center \u201cE. Piaggio\u201d;Institute of Robotics and Mechatronics;Department of Informatics",
        "aff_unique_url": "https://www.unipi.it;https://www.dlr.de;https://www.tum.de",
        "aff_unique_abbr": ";DLR;TUM",
        "aff_campus_unique_index": "0;1;1;1;1;0;1;0;2",
        "aff_campus_unique": "Pisa;Wessling;Garching",
        "aff_country_unique_index": "0;1;1;1;1;0;1;0;1",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "9811765",
        "title": "Planning and Control for Cable-routing with Dual-arm Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a new framework for solving cable-routing problems with a dual-arm robot, where the objective is to clip a Deformable Linear Object (DLO) into several arbitrarily placed fixtures. The core of the framework is a task-space planner, which builds a roadmap from predefined tasks and employs a replanning strategy based on a genetic algorithm, if problems occur. The manipulation tasks are executed with either individual or coordinated control of the arms. Moreover, hierarchical quadratic programming is used to solve the inverse differential kinematics together with extra feasibility objectives. A vision system first identifies the desired fixture route and structure preserved registration estimates the state of the DLO in real-time. The framework is tested on real-world experiments with a YuMi robot, demonstrating a 90% success rate for 3 fixture problems.",
        "primary_area": "",
        "author": "Gabriel Arslan Waltersson;Rita Laezza;Yiannis Karayiannidis;Gabriel Arslan Waltersson;Rita Laezza;Yiannis Karayiannidis",
        "authorids": "/37089448301;/37088996941;/37300987100;/37089448301;/37088996941;/37300987100",
        "aff": "Department of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Sweden; Department of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Sweden; Department of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811765/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7209177828575756475&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chalmers University of Technology",
        "aff_unique_dep": "Department of Electrical Engineering, Division of Systems and Control",
        "aff_unique_url": "https://www.chalmers.se",
        "aff_unique_abbr": "Chalmers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9811980",
        "title": "Planning via model checking with decision-tree controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning problems can be solved not only by planners, but also by model checkers. While the former yield a plan that requires replanning as soon as any fault occurs, the latter provide a \u201cuniversal\u201d plan (a.k.a. strategy, policy, or controller) able to make decisions under all circumstances. One of the prohibitive aspects of the latter approach is stemming from this very advantage: since it is defined for all possible states of the system, it is typically so large that it does not fit into small memories of embedded devices. As another consequence of the size, its execution may be slow. In this paper, we provide a solution to this issue by linking the model checkers with decision-tree learners, resulting in decision-tree representations of the synthesized strategies. Not only are they dramatically smaller, but also more explainable and orders-of-magnitude faster to execute than plans with replanning. In addition, we describe a method for model validation and debugging via the model checker and the decision-tree learner in the loop. We illustrate the approach on our case study of a robotic arm for picking items in a real industrial setting.",
        "primary_area": "",
        "author": "Jonis Kiesbye;Kush Grover;Pranav Ashok;Jan K\u0159et\u00ednsk\u00fd;Jonis Kiesbye;Kush Grover;Pranav Ashok;Jan K\u0159et\u00ednsk\u00fd",
        "authorids": "/37089448795;/37089280594;/37089448626;/37087343659;/37089448795;/37089280594;/37089448626;/37087343659",
        "aff": "Technical University of Munich, Germany; Technical University of Munich, Germany; Fraunhofer IKS, Germany; Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811980/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7741051988196039064&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;Fraunhofer Institute for Integrated Systems and Device Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tum.de;https://www.iks.fraunhofer.de/",
        "aff_unique_abbr": "TUM;Fraunhofer IKS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811970",
        "title": "PogoDrone: Design, Model, and Control of a Jumping Quadrotor",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a design, model, and control for a novel jumping-flying robot that is called PogoDrone. The robot is composed of a quadrotor with a passive mechanism for jumping. The robot can continuously jump in place or fly like a normal quadrotor. Jumping in place allows the robot to quickly move and operate very close to the ground. For instance, in agricultural applications, the jumping mechanism allows the robot to take samples of soil. We propose a hybrid controller that switches from attitude to position control to allow the robot to fall horizontally and recover to the original position. We compare the jumping mode with the hovering mode to analyze the energy consumption. In simulations, we evaluate the effect of different factors on energy consumption. In real experiments, we show that our robot can repeatedly impact the ground, jump, and fly in a physical environment.",
        "primary_area": "",
        "author": "Brian Zhu;Jiawei Xu;Andrew Charway;David Salda\u00f1a;Brian Zhu;Jiawei Xu;Andrew Charway;David Salda\u00f1a",
        "authorids": "/37089450464;/37088996257;/37089447724;/38543033800;/37089450464;/37088996257;/37089447724;/38543033800",
        "aff": "Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, PA, USA; Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, PA, USA; Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, PA, USA; Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811970/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2633433532952732866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Lehigh University",
        "aff_unique_dep": "Autonomous and Intelligent Robotics Laboratory (AIRLab)",
        "aff_unique_url": "https://www.lehigh.edu",
        "aff_unique_abbr": "Lehigh",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "PA",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812437",
        "title": "Pose Estimation based on a Dual Quaternion Feedback Particle Filter",
        "track": "main",
        "status": "Poster",
        "abstract": "Fast and accurate pose estimation is essential for many robotic applications such as SLAM, manipulation, and 3D point registration. Existing solutions to this problem suffer from either high computation overhead due to the nonlinear features or accuracy loss due to linear approximation. In this paper, we propose a dual quaternion feedback particle filter (DQFPF) that can capture the nonlinear factors in the observation model and use the optimal control theory to estimate the pose. To avoid particle degeneracy caused by sequential importance sampling and resampling, we present a feedback particle update formula to speed up the optimization with fewer particles being sampled. Simulation results show that in known corresponding cases our approach can converge to the correct pose more efficiently than the state-of-the-art. A similar conclusion can also be drawn in real applications of unknown corresponding cases, i.e., point cloud stitching and visual odometry estimation.",
        "primary_area": "",
        "author": "Wenjie Li;Wasif Naeem;Wenhao Ji;Jia Liu;Wei Hao;Lijun Chen;Wenjie Li;Wasif Naeem;Wenhao Ji;Jia Liu;Wei Hao;Lijun Chen",
        "authorids": "/37086801037;/37300768500;/37089447495;/37085407367;/37089447969;/37292789300;/37086801037;/37300768500;/37089447495;/37085407367;/37089447969;/37292789300",
        "aff": "Department of Computer Science and Technology, Nanjing University, China; Electrical Engineering and Computer Science, School of Electronics, Queen's University Belfast, UK; Department of Computer Science and Technology, Nanjing University, China; Department of Computer Science and Technology, Nanjing University, China; Department of Computer Science and Technology, Nanjing University, China; Department of Computer Science and Technology, Nanjing University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812437/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11374959012677404993&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Nanjing University;Queen's University Belfast",
        "aff_unique_dep": "Department of Computer Science and Technology;School of Electronics",
        "aff_unique_url": "http://www.nju.edu.cn;https://www.qub.ac.uk",
        "aff_unique_abbr": "Nanjing U;QUB",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Belfast",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9812051",
        "title": "PoseSDF: Simultaneous 3D Human Shape Reconstruction and Gait Pose Estimation Using Signed Distance Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based 3D human pose estimation and shape reconstruction play important roles in robot-assisted healthcare monitoring and personal assistance. However, 3D data captured from a single viewpoint always encounter occlusions and exhibit substantial heterogeneity across different views, resulting in significant challenges for both tasks. Extensive approaches have been proposed to perform each task separately, but few of them present a unified solution. In this paper, we propose a novel network based on signed distance functions, namely PoseSDF, to simultaneously reconstruct 3D lower limb shape and estimate gait pose by two dedicated branches. To promote multi-task learning, several strategies are developed to ensure that these two branches leverage the same latent shape code while exchanging information between them. More importantly, an auxiliary RotNet is incorporated into the inference phase, overcoming the inherent limitations of implicit neural functions under cross-view scenarios. Experimental results demonstrate that our proposed PoseSDF can achieve both high-quality shape reconstruction and precise pose estimation, generalizing well on the data from novel views, gait patterns, as well as real-world.",
        "primary_area": "",
        "author": "Jianxin Yang;Yuxuan Liu;Xiao Gu;Guang-Zhong Yang;Yao Guo;Jianxin Yang;Yuxuan Liu;Xiao Gu;Guang-Zhong Yang;Yao Guo",
        "authorids": "/37089447797;/37089612525;/37086360965;/37276270800;/37086919325;/37089447797;/37089612525;/37086360965;/37276270800;/37086919325",
        "aff": "Institute of Medical Robotics, Shanghai Jiao Tong University, China; Institute of Medical Robotics, Shanghai Jiao Tong University, China; Hamlyn Centre, Imperial College London, United Kingdom; Institute of Medical Robotics, Shanghai Jiao Tong University, China; Institute of Medical Robotics, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812051/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5649120945248634121&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Imperial College London",
        "aff_unique_dep": "Institute of Medical Robotics;Hamlyn Centre",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.imperial.ac.uk",
        "aff_unique_abbr": "SJTU;Imperial College",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9812099",
        "title": "Post-Stall Navigation with Fixed-Wing UAVs using Onboard Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent research has enabled fixed-wing unmanned aerial vehicles (UAVs) to maneuver in constrained spaces through the use of direct nonlinear model predictive control (NMPC) [1]. However, this approach has been limited to a priori known maps and ground truth state measurements. In this paper, we present a direct NMPC approach that leverages NanoMap [2], a light-weight point cloud mapping framework, to generate collision-free trajectories using onboard stereo vision. We first explore our approach in simulation and demonstrate that our algorithm is sufficient to enable vision-based navigation in urban environments. We then demonstrate our approach in hardware using a 42-inch fixed-wing UAV and show that our motion planning algorithm is capable of navigating around a building using a minimalistic set of goal-points. We also show that point cloud history is important for navigating in these types of constrained environments.",
        "primary_area": "",
        "author": "Adam Polevoy;Max Basescu;Luca Scheuer;Joseph Moore;Adam Polevoy;Max Basescu;Luca Scheuer;Joseph Moore",
        "authorids": "/37088996357;/37086219768;/37089450955;/37086037338;/37088996357;/37086219768;/37089450955;/37086037338",
        "aff": "Johns Hopkins University Applied Physics Lab, Laurel, MD; Johns Hopkins University Applied Physics Lab, Laurel, MD; Johns Hopkins University Applied Physics Lab, Laurel, MD; Johns Hopkins University Applied Physics Lab, Laurel, MD",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812099/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15129072240784213687&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Applied Physics Lab",
        "aff_unique_url": "https://www.jhuapl.edu",
        "aff_unique_abbr": "JHU APL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Laurel",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811898",
        "title": "Pouring by Feel: An Analysis of Tactile and Proprioceptive Sensing for Accurate Pouring",
        "track": "main",
        "status": "Poster",
        "abstract": "As service robots begin to be deployed to assist humans, it is important for them to be able to perform a skill as ubiquitous as pouring. Specifically, we focus on the task of pouring an exact amount of water without any environmental instrumentation, that is, using only the robot's own sensors to perform this task in a general way robustly. In our approach we use a simple PID controller which uses the measured change in weight of the held container to supervise the pour. Unlike previous methods which use specialized force-torque sensors at the robot wrist, we use our robot joint torque sensors and investigate the added benefit of tactile sensors at the fingertips. We train three estimators from data which regress the poured weight out of the source container and show that we can accurately pour within 10 ml of the target on average while being robust enough to pour at novel locations and with different grasps on the source container.",
        "primary_area": "",
        "author": "Pedro Piacenza;Daewon Lee;Volkan Isler;Pedro Piacenza;Daewon Lee;Volkan Isler",
        "authorids": "/37086052256;/37599980600;/37298487800;/37086052256;/37599980600;/37298487800",
        "aff": "Samsung AI Center NY, New York; Samsung AI Center NY, New York; Samsung AI Center NY, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811898/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5797312508098266957&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "SAC NY",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812112",
        "title": "Powerful and dexterous multi-finger hand using dynamical pulley mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "A multi-fingered hand that can grasp and manipulate a variety of objects is an option for assisting people in their daily lives. However, the range of torque output that can be handled by the multi-fingered hand is very limited compared to the capability of the human hand. In this paper, we introduce a new multi-fingered hand consisting of a dynamic pulley and a linkage mechanism, aiming to achieve a human-like output torque with a human-like size. The proposed multi-fingered hand can achieve a fingertip force of 50N, which is equivalent to that of a human, and at the same time can perform delicate operations such as picking up a coin on a desk. In addition, we realized the stay-on-tab opening task of a can by utilizing fingertip strength.",
        "primary_area": "",
        "author": "Tadaaki Hasegawa;Hironori Waita;Tomohiro Kawakami;Yoshinari Takemura;Tetsuya Ishikawa;Yuta Kimura;Chiaki Tanaka;Kenichiro Sugiyama;Takahide Yoshiike;Tadaaki Hasegawa;Hironori Waita;Tomohiro Kawakami;Yoshinari Takemura;Tetsuya Ishikawa;Yuta Kimura;Chiaki Tanaka;Kenichiro Sugiyama;Takahide Yoshiike",
        "authorids": "/37086937319;/37087978817;/37088504439;/37089450053;/37088341376;/37085607513;/37089099277;/37087323154;/37682554700;/37086937319;/37087978817;/37088504439;/37089450053;/37088341376;/37085607513;/37089099277;/37087323154;/37682554700",
        "aff": "Frontier Robotics domain, Honda R&D Co., Ltd., Saitama, Japan; Frontier Robotics domain, Honda R&D Co., Ltd., Saitama, Japan; Frontier Robotics domain, Honda R&D Co., Ltd., Saitama, Japan; Frontier Robotics domain, Honda R&D Co., Ltd., Saitama, Japan; Frontier Robotics domain, Honda R&D Co., Ltd., Saitama, Japan; Frontier Robotics domain, Honda R&D Co., Ltd., Saitama, Japan; Frontier Robotics domain, Honda R&D Co., Ltd., Saitama, Japan; Frontier Robotics domain, Honda R&D Co., Ltd., Saitama, Japan; Frontier Robotics domain, Honda R&D Co., Ltd., Saitama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812112/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10020188233597045082&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Honda R&D Co., Ltd.",
        "aff_unique_dep": "Frontier Robotics domain",
        "aff_unique_url": "https://www.honda.com",
        "aff_unique_abbr": "Honda",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Saitama",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811358",
        "title": "Precise 3D Reconstruction of Plants from UAV Imagery Combining Bundle Adjustment and Template Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Monitoring individual plants and computing precise 3D reconstructions is highly relevant for crop breeding. In the conventional breeding approach, humans measure phenotypic traits by hand, requiring substantial manual labor. This paper addresses precise 3D plant reconstructions in a crop field or breeding plot based on UAV imagery. We explicitly address the challenges resulting from the thin structures of leaves and naturally occurring self-occlusions. We combine photogrammetric bundle adjustment with a template-based matching approach and produce accurate 3D models that allow us to derive common, geometric traits used by breeders to phenotype plants. We provide a thorough experimental evaluation on commercially used sugar beet breeding plots to illustrate the capabilities of our method as well as its real world applicability.",
        "primary_area": "",
        "author": "Elias Marks;Federico Magistri;Cyrill Stachniss;Elias Marks;Federico Magistri;Cyrill Stachniss",
        "authorids": "/37089447007;/37086805350;/37329668600;/37089447007;/37086805350;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; Department of Engineering Science, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811358/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5685528690712279577&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Bonn;University of Oxford",
        "aff_unique_dep": ";Department of Engineering Science",
        "aff_unique_url": "https://www.uni-bonn.de;https://www.ox.ac.uk",
        "aff_unique_abbr": "UBonn;Oxford",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "9811628",
        "title": "Precision fruit tree pruning using a learned hybrid vision/interaction controller",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic tree pruning requires highly precise manipulator control in order to accurately align a cutting implement with the desired pruning point at the correct angle. Simultaneously, the robot must avoid applying excessive force to rigid parts of the environment such as trees, support posts, and wires. In this paper, we propose a hybrid control system that uses a learned vision-based controller to initially align the cutter with the desired pruning point, taking in images of the environment and outputting control actions. This controller is trained entirely in simulation, but transfers easily to real trees via a neural network which transforms raw images into a simplified, segmented representation. Once contact is established, the system hands over control to an interaction controller that guides the cutter pivot point to the branch while minimizing interaction forces. With this simple, yet novel, approach we demonstrate an improvement of over 30 percentage points in accuracy over a baseline controller that uses camera depth data.",
        "primary_area": "",
        "author": "Alexander You;Hannah Kolano;Nidhi Parayil;Cindy Grimm;Joseph R. Davidson;Alexander You;Hannah Kolano;Nidhi Parayil;Cindy Grimm;Joseph R. Davidson",
        "authorids": "/37088504678;/37089448949;/37089450023;/37085798146;/37075739400;/37088504678;/37089448949;/37089450023;/37085798146;/37075739400",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811628/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13755953401262589853&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811972",
        "title": "Predicting Like A Pilot: Dataset and Method to Predict Socially-Aware Aircraft Trajectories in Non-Towered Terminal Airspace",
        "track": "main",
        "status": "Poster",
        "abstract": "Pilots operating aircraft in non-towered terminal airspace rely on their situational awareness and prior knowledge to predict the future trajectories of other agents. These predictions are conditioned on the past trajectories of other agents, agent-agent social interactions and environmental context such as airport location and weather. This paper provides a dataset, TrajAir, that captures this behaviour in non-towered terminal airspace around a regional airport. We also present a baseline socially-aware trajectory prediction algorithm, TrajAirNet, that uses the dataset to predict the trajectories of all agents. The dataset is collected for 111 days over 8 months and contains ADS-B transponder data along with the corresponding METAR weather data. The data is processed to be used as a benchmark with other publicly available social navigation datasets. To the best of the authors' knowledge, this is the first 3D social aerial navigation dataset, thus introducing social navigation for autonomous aviation. TrajAirNet combines state-of-the-art modules in social navigation to provide predictions in a static environment with a dynamic context. Both the TrajAir dataset and TrajAirNet prediction algorithm are open-source. [Dataset] 11Dataset: https://theairlab.org/trajair/ [Code]22Codebase: https://github.com/castacks/trajairnet [Video]33Video: https://youtu.be/e1AQXrxB2gw",
        "primary_area": "",
        "author": "Jay Patrikar;Brady Moon;Jean Oh;Sebastian Scherer;Jay Patrikar;Brady Moon;Jean Oh;Sebastian Scherer",
        "authorids": "/37086449345;/37086448648;/37933996900;/37584159000;/37086449345;/37086448648;/37933996900;/37584159000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811972/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8801295104466704235&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811822",
        "title": "Predicting the effects of oscillator-based assistance on stride-to-stride variability of Parkinsonian walkers",
        "track": "main",
        "status": "Poster",
        "abstract": "Parkinson's disease is a severe neurodegenerative disorder that affects sensorimotor control. In particular, several gait impairments are reported, including a decrease of long-range autocorrelations in stride duration time series. This complex statistics is potentially a biomarker of the risk of falling. This paper aims at developing model-based predictions about the loss of long-range autocorrelations in the gait of Parkinsonian patients, and how these autocorrelations can be restored by an oscillator-based walking assistance. Using a Super Central Pattern Generator model coupled with an adaptive oscillator, we show that this type of assistance has the potential to improve long-range autocorrelations in time series of Parkinsonian walkers. This requires however to tune the adaptive oscillator with slow learning gains, raising challenges for porting this method to an actual device.",
        "primary_area": "",
        "author": "Virginie Otlet;Renaud Ronsse;Virginie Otlet;Renaud Ronsse",
        "authorids": "/37089450529;/37299789300;/37089450529;/37299789300",
        "aff": "Institute of Mechanics, Materials, and Civil Engineering; the Institute of Neuroscience; and Louvain Bionics, UCLouvain, Louvain-Ia-Neuve, Belgium; Institute of Mechanics, Materials, and Civil Engineering; the Institute of Neuroscience; and Louvain Bionics, UCLouvain, Louvain-Ia-Neuve, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811822/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15716211012677407328&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1;2;0;1;2",
        "aff_unique_norm": "Institute of Mechanics, Materials, and Civil Engineering;Institute of Neuroscience;UCLouvain",
        "aff_unique_dep": "Mechanics, Materials, and Civil Engineering;Neuroscience;Louvain Bionics",
        "aff_unique_url": ";;https://www.uclouvain.be",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Louvain-Ia-Neuve",
        "aff_country_unique_index": "1;1",
        "aff_country_unique": ";Belgium"
    },
    {
        "id": "9812358",
        "title": "Prediction of Depth Camera Missing Measurements Using Deep Learning for Next Best View Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth images usually contain pixels with invalid measurements. This paper presents a deep learning approach that receives as input a partially-known volumetric model of the environment and a camera pose, and it predicts the probability that a pixel would contain a valid depth measurement if a camera was placed at the given pose. The proposed network architecture consists of a 3D Convolutional Neural Network (CNN) module and a 2D CNN module, connected by a deep learning attention-based projection module. The method was integrated into a CNN-based probabilistic Next Best View plan-ner, resulting in a more realistic prediction of the information gain for each possible viewpoint with respect to state of the art approaches. Experiments were carried out in tabletop scenarios using a robot manipulator with an eye-in-hand depth camera.",
        "primary_area": "",
        "author": "Riccardo Monica;Jacopo Aleotti;Riccardo Monica;Jacopo Aleotti",
        "authorids": "/37073241500;/37330820900;/37073241500;/37330820900",
        "aff": "Department of Engineering and Architecture, Robotics and Intelligent Machines Laboratory (RIM-Lab), University of Parma, Italy; Department of Engineering and Architecture, Robotics and Intelligent Machines Laboratory (RIM-Lab), University of Parma, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812358/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9409423084156094298&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Parma",
        "aff_unique_dep": "Department of Engineering and Architecture",
        "aff_unique_url": "https://www.unipr.it",
        "aff_unique_abbr": "Unipr",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9812287",
        "title": "Prediction of Metacarpophalangeal Joint Angles and Classification of Hand Configurations Based on Ultrasound Imaging of the Forearm",
        "track": "main",
        "status": "Poster",
        "abstract": "With the advancement in computing and robotics, it is necessary to develop fluent and intuitive methods for inter-acting with digital systems, augmented/virtual reality (AR/VR) interfaces, and physical robotic systems. Hand movement recognition is widely used to enable such interaction. Hand configuration classification and metacarpophalangeal (MCP) joint angle detection are important for a comprehensive reconstruction of hand motion. Surface electromyography (sEMG) and other technologies have been used for the detection of hand motions. Ultrasound images of the forearm offer a way to visualize the internal physiology of the hand from a musculoskeletal perspective. Recent works have shown that these images can be classified using machine learning to predict various hand configurations. In this paper, we propose a Convolutional Neu-ral Network (CNN) based deep learning pipeline for predicting the MCP joint angles. We supplement our results by using a Support Vector Classifier (SVC) to classify the ultrasound information into several predefined hand configurations based on activities of daily living (ADL). Ultrasound data from the forearm were obtained from six subjects who were instructed to move their hands according to predefined hand configurations relevant to ADLs. Motion capture data was acquired as the ground truth for hand movements at three speeds (0.5 Hz, 1 Hz, and 2 Hz) for the index, middle, ring, and pinky fingers. We demonstrated the perfect prediction of hand configurations through SVC classification and a correspondence between the predicted MCP joint angles and the actual MCP joint angles for the fingers, with an average root mean square error of 7.35 degrees. A low latency (6.25 \u2013 9.10 Hz) pipeline was implemented for the prediction of both MCP joint angles and hand configuration estimation aimed for real-time implementation.",
        "primary_area": "",
        "author": "Keshav Bimbraw;Christopher J. Nycz;Matthew J. Schueler;Ziming Zhang;Haichong K. Zhang;Keshav Bimbraw;Christopher J. Nycz;Matthew J. Schueler;Ziming Zhang;Haichong K. Zhang",
        "authorids": "/37085662372;/37085752368;/37089447654;/37088400388;/37088589789;/37085662372;/37085752368;/37089447654;/37088400388;/37088589789",
        "aff": "Medical FUSION Lab, Worcester Polytechnic Institute, Worcester, MA, USA; PracticePoint, Worcester Polytechnic Institute, Worcester, MA, USA; Medical FUSION Lab, Worcester Polytechnic Institute, Worcester, MA, USA; Vision, Intelligence, and System Laboratory (VISLab), Worcester Polytechnic Institute (WPI), Worcester, MA, USA; Medical FUSION Lab, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812287/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12200726167135739339&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Medical FUSION Lab",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812223",
        "title": "PredictionNet: Real-Time Joint Probabilistic Traffic Prediction for Planning, Control, and Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting the future motion of traffic agents is crucial for safe and efficient autonomous driving. To this end, we present PredictionNet, a deep neural network (DNN) that predicts the motion of all surrounding traffic agents together with the ego-vehicle's motion. All predictions are probabilistic and are represented in a simple top-down rasterization that allows an arbitrary number of agents. Conditioned on a multi-layer map with lane information, the network outputs future positions, velocities, and backtrace vectors jointly for all agents including the ego-vehicle in a single pass. Trajectories are then extracted from the output. The network can be used to simulate realistic traffic, and it produces competitive results on popular benchmarks. More importantly, it has been used to successfully control a real-world vehicle for hundreds of kilometers, by combining it with a motion planning/control subsystem. The network runs faster than real-time on an embedded GPU, and the system shows good generalization (across sensory modalities and locations) due to the choice of input representation. Furthermore, we demonstrate that by extending the DNN with reinforcement learning (RL), it can better handle rare or unsafe events like aggressive maneuvers and crashes.",
        "primary_area": "",
        "author": "Alexey Kamenev;Lirui Wang;Ollin Boer Bohan;Ishwar Kulkarni;Bilal Kartal;Artem Molchanov;Stan Birchfield;David Nist\u00e9r;Nikolai Smolyanskiy;Alexey Kamenev;Lirui Wang;Ollin Boer Bohan;Ishwar Kulkarni;Bilal Kartal;Artem Molchanov;Stan Birchfield;David Nist\u00e9r;Nikolai Smolyanskiy",
        "authorids": "/37086318151;/37089286365;/37089447770;/37089448766;/37085584209;/37085487060;/37371627300;/37282920200;/37086317225;/37086318151;/37089286365;/37089447770;/37089448766;/37085584209;/37085487060;/37371627300;/37282920200;/37086317225",
        "aff": "NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812223/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=368126994774818567&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "NVIDIA",
        "aff_unique_dep": "NVIDIA Corporation",
        "aff_unique_url": "https://www.nvidia.com",
        "aff_unique_abbr": "NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811558",
        "title": "Preemptive Motion Planning for Human-to-Robot Indirect Placement Handovers",
        "track": "main",
        "status": "Poster",
        "abstract": "As technology advances, the need for safe, efficient, and collaborative human-robot-teams has become increasingly important. One of the most fundamental collaborative tasks in any setting is the object handover. Human-to-robot handovers can take either of two approaches: (1) direct hand-to-hand or (2) indirect hand-to-placement-to-pick-up. The latter approach ensures minimal contact between the human and robot but can also result in increased idle time due to having to wait for the object to first be placed down on a surface. To minimize such idle time, the robot must preemptively predict the human intent of where the object will be placed. Furthermore, for the robot to preemptively act in any sort of productive manner, predictions and motion planning must occur in real-time. We introduce a novel prediction-planning pipeline that allows the robot to preemptively move towards the human agent's intended placement location using gaze and gestures as model inputs. In this paper, we investigate the performance and drawbacks of our early intent predictor-planner as well as the practical benefits of using such a pipeline through a human-robot case study.",
        "primary_area": "",
        "author": "Andrew Choi;Mohammad Khalid Jawed;Jungseock Joo;Andrew Choi;Mohammad Khalid Jawed;Jungseock Joo",
        "authorids": "/37089300728;/37088686728;/37076035400;/37089300728;/37088686728;/37076035400",
        "aff": "Department of Computer Science, University of California, Los Angeles; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles; Department of Communication, University of California, Los Angeles",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811558/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1799350153292037795&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811780",
        "title": "Preliminary Investigation of Powered Knee Prosthesis with Small-Scale, Light-Weight, and Affordable Series-Elastic Actuator for Walking Rehabilitation of a Patient with Four-limb Deficiency",
        "track": "main",
        "status": "Poster",
        "abstract": "Powered knee prosthesis commonly improves locomotion of above-knee amputees by generating net positive mechanical work at the knee joint which is especially required for movements with active knee extension and flexion such as sit-to-stand maneuvers, level-ground walking with various walking speed, stair/slope ascent ambulation and so forth. These studies tend to refer and trace normal human locomotion, and have amputees move \u201cnormally\u201d, which is quite difficult for patients with severe disability such as four-limb deficiency. In this study, a powered knee prosthesis with small-scale, light-weight and affordable series elastic actuator (PKP-SEA) is developed and adopted to a walking rehabilitation of a patient with four-limb deficiency. A subject is 45 years old and has no experience to walk on prosthetic devices in his life. During the experiment, walking performance is investigated by turning PKP-SEA control parameters. As a result, the PKP-SEA shows capability of improving his walking performance in terms of walking speed and consistency not by replicating normal human walking, but suggesting an original walking gait based on his body condition and remaining functionality.",
        "primary_area": "",
        "author": "Ken Endo;Naoki Uchida;Ryusuke Morita;Tetsuo Tawara;Ken Endo;Naoki Uchida;Ryusuke Morita;Tetsuo Tawara",
        "authorids": "/37575041700;/37089450378;/37086823070;/37087426248;/37575041700;/37089450378;/37086823070;/37087426248",
        "aff": "Sony Computer Science Laboratories, Inc, Tokyo, Japan; Sony Computer Science Laboratories, Inc, Tokyo, Japan; Sony Computer Science Laboratories, Inc, Tokyo, Japan; Sony Computer Science Laboratories, Inc, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811780/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9207379758436116305&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Sony Computer Science Laboratories, Inc",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sony.net/SCL/",
        "aff_unique_abbr": "SCL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812002",
        "title": "Printable Origami Bistable Structures for Foldable Jumpers",
        "track": "main",
        "status": "Poster",
        "abstract": "Origami/kirigami robotics are opening a path that leads to lightweight, compact, and expandable robots. However, it is generally challenging to design agile motions for origami/kirigami robots due to their size and the intrinsic limitation of the materials. In this paper, we propose to use the bistability of the waterbomb base structure to generate the swift motion of the robots. We evaluate the bistability of the waterbomb-based structure and build origami jumpers with different configurations of the body to help analyze the behavior of the waterbomb base bistable structure. The jumper is actuated by a phase change liquid pouch actuator. Our jumper is lightweight (0.3 g), flattenable, and able to jump to more than 12 times of its diameter and 112 times of its height.",
        "primary_area": "",
        "author": "Tung D. Ta;Zekun Chang;Koya Narumi;Takuya Umedachi;Yoshihiro Kawahara;Tung D. Ta;Zekun Chang;Koya Narumi;Takuya Umedachi;Yoshihiro Kawahara",
        "authorids": "/37086454689;/37089448989;/37087189175;/37546535500;/37269138700;/37086454689;/37089448989;/37087189175;/37546535500;/37269138700",
        "aff": "Graduate School of Engineering, The University of Tokyo, Tokyo, Japan; Computing and Information Science, Cornell University, Ithaca, NY; Graduate School of Engineering, The University of Tokyo, Tokyo, Japan; Falcuty of Textile Science and Technology, Shinshu University, Ueda, Nagano, Japan; Graduate School of Engineering, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812002/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5598891351279183183&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "University of Tokyo;Cornell University;Shinshu University",
        "aff_unique_dep": "Graduate School of Engineering;Computing and Information Science;Falcuty of Textile Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.cornell.edu;https://www.shinshu-u.ac.jp",
        "aff_unique_abbr": "UTokyo;Cornell;",
        "aff_campus_unique_index": "0;1;0;2;0",
        "aff_campus_unique": "Tokyo;Ithaca;Ueda",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "9812315",
        "title": "Prioritized Planning for Cooperative Range-Only Localization in Multi-Robot Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel path-planning algorithm to reduce localization error for a network of robots cooperatively localizing via inter-robot range measurements. The quality of localization with range measurements depends on the configuration of the network, and poor configurations can cause substantial localization errors. To reduce the effect of network configuration on localization error for moving networks we consider various optimality measures of the Fisher information matrix (FIM), which have well-known relationships with localization error. We pose a trajectory planning problem with constraints on the FIM optimality measures. By constraining these optimality measures we can control the statistical properties of the localization error. To efficiently generate trajectories which satisfy these FIM constraints we present a prioritized planner which leverages graph-based planning and properties of the range-only FIM. We demonstrate in simulations that the trajectories generated by our algorithm reduce worst-case localization error by up to 42% in comparison to existing planners and can scalably plan distance-efficient trajectories in complicated environments for large numbers of robots.",
        "primary_area": "",
        "author": "Alan Papalia;Nicole Thumma;John Leonard;Alan Papalia;Nicole Thumma;John Leonard",
        "authorids": "/37088569409;/37089446918;/37329387400;/37088569409;/37089446918;/37329387400",
        "aff": "Department of Applied Ocean Physics and Engineering, Woods Hole Oceanographic Institution, Woods Hole, MA, USA; Computer Science and Artificial Intelligence Lab (CSAIL), Mas-sachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab (CSAIL), Mas-sachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812315/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6261129294852002206&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Woods Hole Oceanographic Institution;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Applied Ocean Physics and Engineering;Computer Science and Artificial Intelligence Lab (CSAIL)",
        "aff_unique_url": "https://www.whoi.edu;https://www.mit.edu",
        "aff_unique_abbr": "WHOI;MIT",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Woods Hole;Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812255",
        "title": "Proactive And Smooth Maneuvering For Navigation Around Pedestrians",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigation in close proximity with pedestrians is a challenge on the way to fully automated vehicles. Pedestrian-friendly navigation requires an understanding of pedestrian reaction and intention. Merely safety based reactive systems can lead to sub-optimal navigation solutions resulting in the freezing of the vehicle in many scenarios. Moreover, a strictly reactive method can produce unnatural driving patterns which cannot guarantee the legibility or social acceptance of the automated vehicle. This work presents a proactive maneuvering method adapted to navigation in close interaction with pedestrians using a dynamic channel approach. The method allows to proactively explore the navigation options based on anticipating pedestrians cooperation. The navigation is tested in frontal and lateral crossing scenarios with variable space density. The system is implemented under ROS, and compared with the probabilistic Risk-RRT planning method. The results are evaluated based on the safety and comfort of the pedestrians, and the quality of the vehicle's trajectory.",
        "primary_area": "",
        "author": "Maria Kabtoul;Anne Spalanzani;Philippe Martinet;Maria Kabtoul;Anne Spalanzani;Philippe Martinet",
        "authorids": "/37088504060;/37443478900;/37277258700;/37088504060;/37443478900;/37277258700",
        "aff": "Universit\u00e9 Cote d'Azur, Inria, Sophia Antipolis, France; Univ. Grenoble Alpes, Inria, Grenoble, France; Universit\u00e9 Cote d'Azur, Inria, Sophia Antipolis, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812255/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7782336871718518740&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universit\u00e9 Cote d'Azur;Universite Grenoble Alpes",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.univ-cotedazur.fr;https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": "UCA;UGA",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Sophia Antipolis;Grenoble",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812293",
        "title": "Probabilistic Inference of Simulation Parameters via Parallel Differentiable Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Reproducing real world dynamics in simulation is critical for the development of new control and perception methods. This task typically involves the estimation of simu-lation parameter distributions from observed rollouts through an inverse inference problem characterized by multi-modality and skewed distributions. We address this challenging problem through a novel Bayesian inference approach that approximates a posterior distribution over simulation parameters given real sensor measurements. By extending the commonly used Gaus-sian likelihood model for trajectories via the multiple-shooting formulation, our gradient-based particle inference algorithm, Stein Variational Gradient Descent, is able to identify highly nonlinear, underactuated systems. We leverage GPU code gen-eration and differentiable simulation to evaluate the likelihood and its gradient for many particles in parallel. Our algorithm infers nonparametric distributions over simulation parame-ters more accurately than comparable baselines and handles constraints over parameters efficiently through gradient-based optimization. We evaluate estimation performance on several physical experiments. On an underactuated mechanism where a 7-DOF robot arm excites an object with an unknown mass configuration, we demonstrate how the inference technique can identify symmetries between the parameters and provide highly accurate predictions. Website: https://uscresl.github.io/prob-diff-sim",
        "primary_area": "",
        "author": "Eric Heiden;Christopher E. Denniston;David Millard;Fabio Ramos;Gaurav S. Sukhatme;Eric Heiden;Christopher E. Denniston;David Millard;Fabio Ramos;Gaurav S. Sukhatme",
        "authorids": "/37990849700;/37086855837;/37088996818;/37285364500;/37278934100;/37990849700;/37086855837;/37088996818;/37285364500;/37278934100",
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA; NVIDIA, Seattle, USA; Department of Computer Science, University of Southern California, Los Angeles, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812293/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12840410202137009091&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Southern California;NVIDIA",
        "aff_unique_dep": "Department of Computer Science;NVIDIA",
        "aff_unique_url": "https://www.usc.edu;https://www.nvidia.com",
        "aff_unique_abbr": "USC;NV",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Los Angeles;Seattle",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811888",
        "title": "Promoting Quality and Diversity in Population-based Reinforcement Learning via Hierarchical Trajectory Space Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "Quality Diversity (QD) algorithms in population-based reinforcement learning aim to optimize agents' returns and diversity among the population simultaneously. It is conducive to solving exploration problems in reinforcement learning and potentially getting multiple good and diverse strategies. However, previous methods typically define behavioral embedding in action space or outcome space, which neglect trajectory characteristics during the execution process. In this paper, we introduce a trajectory embedding model trained by Variational Autoencoder with similarity constraint to characterize trajectory features. Based on that, we propose a hierarchical trajectory-space exploration (HTSE) framework using Determinantal Point Processes (DPP) to generate high-quality and diverse solutions in the selection and mutation process. The experimental results show that our HTSE method effectively completes several simulated tasks, outperforming other Quality-Diversity Reinforcement Learning algorithms.",
        "primary_area": "",
        "author": "Jiayu Miao;Tianze Zhou;Kun Shao;Ming Zhou;Weinan Zhang;Jianye Hao;Yong Yu;Jun Wang;Jiayu Miao;Tianze Zhou;Kun Shao;Ming Zhou;Weinan Zhang;Jianye Hao;Yong Yu;Jun Wang",
        "authorids": "/37089448093;/37089173571;/37089448716;/37089449315;/37086030166;/38008836600;/37279646800;/37086377041;/37089448093;/37089173571;/37089448716;/37089449315;/37086030166;/38008836600;/37279646800;/37086377041",
        "aff": "Work done as an intern at Huawei Noah's Ark Lab; Work done as an intern at Huawei Noah's Ark Lab; Noah's Ark Lab, Huawei Technologies; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Noah's Ark Lab, Huawei Technologies; Shanghai Jiao Tong University; University College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811888/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12718203438524631301&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;1;0;1;2",
        "aff_unique_norm": "Huawei;Shanghai Jiao Tong University;University College London",
        "aff_unique_dep": "Huawei Noah's Ark Lab;;",
        "aff_unique_url": "https://www.huawei.com/en/research/labs/noahs-ark-lab;https://www.sjtu.edu.cn;https://www.ucl.ac.uk",
        "aff_unique_abbr": "Huawei Noah's Ark Lab;SJTU;UCL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9811776",
        "title": "Propagating State Uncertainty Through Trajectory Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Uncertainty pervades through the modern robotic autonomy stack, with nearly every component (e.g., sensors, detection, classification, tracking, behavior prediction) producing continuous or discrete probabilistic distributions. Trajectory forecasting, in particular, is surrounded by uncertainty as its inputs are produced by (noisy) upstream perception and its outputs are predictions that are often probabilistic for use in downstream planning. However, most trajectory forecasting methods do not account for upstream uncertainty, instead taking only the most-likely values. As a result, perceptual uncer-tainties are not propagated through forecasting and predictions are frequently overconfident. To address this, we present a novel method for incorporating perceptual state uncertainty in trajectory forecasting, a key component of which is a new statistical distance-based loss function which encourages predicting uncertainties that better match upstream perception. We evaluate our approach both in illustrative simulations and on large-scale, real-world data, demonstrating its efficacy in propagating perceptual state uncertainty through prediction and producing more calibrated predictions.",
        "primary_area": "",
        "author": "Boris Ivanovic;Yifeng Lin;Shubham Shrivastava;Punarjay Chakravarty;Marco Pavone;Boris Ivanovic;Yifeng Lin;Shubham Shrivastava;Punarjay Chakravarty;Marco Pavone",
        "authorids": "/37086527859;/37089448661;/37088448814;/37952596000;/37307912900;/37086527859;/37089448661;/37088448814;/37952596000;/37307912900",
        "aff": "NVIDIA; NVIDIA; Ford Green-field Labs; Ford Green-field Labs; Department of Aeronautics and Astronautics, Stanford University, and with NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811776/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9000078424804368684&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;2",
        "aff_unique_norm": "NVIDIA;Ford Motor Company;Stanford University",
        "aff_unique_dep": "NVIDIA Corporation;Green-field Labs;Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.nvidia.com;https://www.ford.com;https://www.stanford.edu",
        "aff_unique_abbr": "NVIDIA;Ford;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811638",
        "title": "Prototype-Voxel Contrastive Learning for LiDAR Point Cloud Panoptic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR point cloud panoptic segmentation, including both semantic and instance segmentation, plays a critical role in meticulous scene understanding for autonomous driving. Existing 3D voxelized approaches either utilize 3D sparse convolution that only focuses on local scene understanding, or add extra and time-consuming PointNet branch to capture global feature structures. To address these limitations, we propose an end-to-end Prototype-Voxel Contrastive Learning (PVCL) framework for learning stable and discriminative semantic representations, which includes voxel-level and prototype-level contrastive learning (CL). The voxel-level CL decreases intra-class distance and increases inter-class distance among sample representations, while the prototype-level CL further reduces the dependence of CL on negative sampling and avoids the influence of outliers from the same class, enabling PVCL to be more effective for outdoor point cloud panoptic segmentation. Extensive experiments are conducted on the public point cloud panoptic segmentation datasets, Semantic-KITTI and nuScenes, where evaluations and ablation studies demonstrate PVCL achieves superior performance compared with the state-of-the-art. Our approach ranks the top on the public leaderboard of Semantic-KITTI at the time of submission, and surpasses the published 2nd rank, EfficientLPS, by 1.7% in PQ.",
        "primary_area": "",
        "author": "Minzhe Liu;Qiang Zhou;Hengshuang Zhao;Jianing Li;Yuan Du;Kurt Keutzer;Li Du;Shanghang Zhang;Minzhe Liu;Qiang Zhou;Hengshuang Zhao;Jianing Li;Yuan Du;Kurt Keutzer;Li Du;Shanghang Zhang",
        "authorids": "/37089447691;/37089450264;/37087233627;/37089736358;/37072435200;/37267034900;/38467916100;/37088934723;/37089447691;/37089450264;/37087233627;/37089736358;/37072435200;/37267034900;/38467916100;/37088934723",
        "aff": "School of Electronic Science and Engineering, Nanjing University; Institute for AI Industry Research (AIR), Tsinghua University; The University of Hong Kong; School of Electronic Science and Engineering, Nanjing University; School of Electronic Science and Engineering, Nanjing University; UC Berkeley; School of Electronic Science and Engineering, Nanjing University; Peking University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811638/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13044896458908725763&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;0;0;3;0;4",
        "aff_unique_norm": "Nanjing University;Tsinghua University;University of Hong Kong;University of California, Berkeley;Peking University",
        "aff_unique_dep": "School of Electronic Science and Engineering;Institute for AI Industry Research (AIR);;;",
        "aff_unique_url": "http://www.nju.edu.cn;https://www.tsinghua.edu.cn;https://www.hku.hk;https://www.berkeley.edu;http://www.pku.edu.cn",
        "aff_unique_abbr": "Nanjing U;Tsinghua;HKU;UC Berkeley;Peking U",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Hong Kong SAR;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9811698",
        "title": "Provably Safe Deep Reinforcement Learning for Robotic Manipulation in Human Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (RL) has shown promising results in the motion planning of manipulators. However, no method guarantees the safety of highly dynamic obstacles, such as humans, in RL-based manipulator control. This lack of formal safety assurances prevents the application of RL for manipulators in real-world human environments. Therefore, we propose a shielding mechanism that ensures ISO- verified human safety while training and deploying RL algorithms on manipulators. We utilize a fast reachability analysis of humans and manipulators to guarantee that the manipulator comes to a complete stop before a human is within its range. Our proposed method guarantees safety and significantly improves the RL performance by preventing episode-ending collisions. We demonstrate the performance of our proposed method in simulation using human motion capture data.",
        "primary_area": "",
        "author": "Jakob Thumm;Matthias Althoff;Jakob Thumm;Matthias Althoff",
        "authorids": "/37089307978;/37541135900;/37089307978;/37541135900",
        "aff": "Department of Informatics, Technical Univer-sity of Munich, Garching, Germany; Department of Informatics, Technical Univer-sity of Munich, Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811698/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11895609849259176790&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Garching",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812033",
        "title": "Providing Local Resilience to Vulnerable Areas in Robotic Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We study how information flows through a multi-robot network in order to better understand how to provide resilience to malicious information. While the notion of global resilience is well studied, one way existing methods provide global resilience is by bringing robots closer together to improve the connectivity of the network. However, large changes in network structure can impede the team from performing other functions such as coverage, where the robots need to spread apart. Our goal is to mitigate the trade-off between resilience and network structure preservation by applying resilience locally in areas of the network where it is needed most. We introduce a metric, Influence, to identify vulnerable regions in the network requiring resilience. We design a control law targeting local resilience to the vulnerable areas by improving the connectivity of robots within these areas so that each robot has at least 2F+12F+1 vertex-disjoint communication paths between itself and the high influence robot in the vulnerable area. We demonstrate the performance of our local resilience controller in simulation and in hardware by applying it to a coverage problem and comparing our results with an existing global resilience strategy. For the specific hardware experiments, we show that our control provides local resilience to vulnerable areas in the network while only requiring 9.90% and 15.14% deviations from the desired team formation compared to the global strategy.",
        "primary_area": "",
        "author": "Matthew Cavorsi;Stephanie Gil;Matthew Cavorsi;Stephanie Gil",
        "authorids": "/37089228056;/37396689900;/37089228056;/37396689900",
        "aff": "School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812033/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7789083639222902283&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811645",
        "title": "Push-to-See: Learning Non-Prehensile Manipulation to Enhance Instance Segmentation via Deep Q-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Efficient robotic manipulation of objects for sorting and searching often rely upon how well the objects are perceived and the available grasp poses. The challenge arises when the objects are irregular, have similar visual features (e.g., textureless objects) and the scene is densely cluttered. In such cases, non-prehensile manipulation (e.g., pushing) can facilitate grasping or searching by improving object perception and singulating the objects from the clutter via physical interaction. The current robotics literature in interactive segmentation focuses solely on isolated cases, where the central aim is on searching or singulating a single target object, or segmenting sparsely cluttered scenes, mainly through matching visual futures in successive scenes before and after the robotic interaction. On the other hand, in this paper, we introduce the first interactive segmentation model in the literature that can autonomously enhance the instance segmentation of such challenging scenes as a whole via optimising a Q-value function that predicts appropriate pushing actions for singulation. We achieved this by training a deep reinforcement learning model with reward signals generated by a Mask-RCNN trained solely on depth images. We evaluated our model in experiments by comparing its success on segmentation quality with a heuristic baseline, as well as the state-of-the-art Visual Pushing and Grasping (VPG) model [1]. Our model significantly outperformed both baselines in all benchmark scenarios. Furthermore, decreasing the segmentation error inherently enabled the autonomous singulation of the scene as a whole. Our evaluation experiments also serve as a benchmark for interactive segmentation research.",
        "primary_area": "",
        "author": "Baris Serhan;Harit Pandya;Ayse Kucukyilmaz;Gerhard Neumann;Baris Serhan;Harit Pandya;Ayse Kucukyilmaz;Gerhard Neumann",
        "authorids": "/37087014195;/37085346690;/37396376800;/38542033100;/37087014195;/37085346690;/37396376800;/38542033100",
        "aff": "School of Computer Science, University of Nottingham, UK; Toshiba Research, Cambridge, UK; School of Computer Science, University of Nottingham, UK; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811645/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11365794787161909239&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "University of Nottingham;Toshiba Research Europe Limited;Karlsruhe Institute of Technology",
        "aff_unique_dep": "School of Computer Science;;Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.nottingham.ac.uk;https://www.toshiba-research.eu;https://www.kit.edu",
        "aff_unique_abbr": "UoN;TREL;KIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "9811619",
        "title": "Put the Bear on the Chair! Intelligent Robot Interaction with Previously Unseen Chairs via Robot Imagination",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the problem of autonomously seating a teddy bear on a previously unseen chair. To achieve this goal, we present a novel method for robots to imagine the sitting pose of the bear by physically simulating a virtual humanoid agent sitting on the chair. We also develop a robotic system which leverages motion planning to plan SE(2) motions for a humanoid robot to walk to the chair and whole-body motions to put the bear on it. Furthermore, to cope with cases where the chair is not in an accessible pose for placing the bear, a human assistance module is introduced for a human to follow language instructions given by the robot to rotate the chair and help make the chair accessible. We implement our method with a robot arm and a humanoid robot. We calibrate the proposed system with 3 chairs and test on 12 previously unseen chairs in both accessible and inaccessible poses extensively. Results show that our method enables the robot to autonomously seat the teddy bear on the 12 previously unseen chairs with a very high success rate. The human assistance module is also shown to be very effective in changing the accessibility of the chair. Video demos and more details are available at https://chirikjianlab.github.io/putbearonchair/.",
        "primary_area": "",
        "author": "Hongtao Wu;Xin Meng;Sipu Ruan;Gregory S. Chirikjian;Hongtao Wu;Xin Meng;Sipu Ruan;Gregory S. Chirikjian",
        "authorids": "/37087010228;/37089450929;/37086110413;/37283175100;/37087010228;/37089450929;/37086110413;/37283175100",
        "aff": "Laboratory for Computational Sensing and Robotics (LCSR), Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, National University of Singapore, Singapore; Department of Mechanical Engineering, National University of Singapore, Singapore; Department of Mechanical Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811619/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12140841860576912562&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Johns Hopkins University;National University of Singapore",
        "aff_unique_dep": "Laboratory for Computational Sensing and Robotics;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu;https://www.nus.edu.sg",
        "aff_unique_abbr": "JHU;NUS",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Baltimore;",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "United States;Singapore"
    },
    {
        "id": "9812069",
        "title": "PyROBOCOP: Python-based Robotic Control & Optimization Package for Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "PyROBOCOP is a Python-based package for control, optimization and estimation of robotic systems described by nonlinear Differential Algebraic Equations (DAEs). In particular, the package can handle systems with contacts that are described by complementarity constraints and provides a general framework for specifying obstacle avoidance constraints. The package performs direct transcription of the DAEs into a set of nonlinear equations by performing orthogonal collocation on finite elements. PyROBOCOP provides automatic reformulation of the complementarity constraints that are tractable to NLP solvers to perform optimization of robotic systems. The package is interfaced with ADOL-C [1] for obtaining sparse derivatives by automatic differentiation and IPOPT [2] for performing optimization. We evaluate PyROBOCOP on several manipulation problems for control and estimation.",
        "primary_area": "",
        "author": "Arvind U. Raghunathan;Devesh K. Jha;Diego Romeres;Arvind U. Raghunathan;Devesh K. Jha;Diego Romeres",
        "authorids": "/37401365500;/37072717800;/37086098761;/37401365500;/37072717800;/37086098761",
        "aff": "Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812069/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5926650018321551431&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.merl.com",
        "aff_unique_abbr": "MERL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811839",
        "title": "QuadRunner: A Transformable Quasi-Wheel Quadruped",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents QuadRunner, a transformable quasi-wheel legged robot that achieves both quadruped locomotion and wheel locomotion by exploiting a novel semicircular leg-wheel design with a Trotting Wheel gait. We built upon the Stanford Doggo open architecture platform and integrated it with a transformable leg-wheel design to enhance its locomotion capabilities. On its gait control, improvements were made to its trot gait kinematics with end-effector considerations as well as the design of a new trotting wheel gait. Our proposed locomotion strategy found that the robot's legged locomotion improves by an average speed of 10%. In addition, wheel to leg transition takes around 300 ms, and the speed of its wheel locomotion can reach more than five times its body-length/s (2.2 m/s) on flat terrain. Lastly, detailed experiments are conducted to observe the wheel-leg transition performance and gait verification under the absence of foot contact sensors.",
        "primary_area": "",
        "author": "Alper Yeldan;Abhimanyu Arora;Gim Song Soh;Alper Yeldan;Abhimanyu Arora;Gim Song Soh",
        "authorids": "/37089447852;/37089447364;/37085341418;/37089447852;/37089447364;/37085341418",
        "aff": "Singapore University of Technology and Design, Engineering Product Development Pillar, Singapore; Singapore University of Technology and Design, Engineering Product Development Pillar, Singapore; Singapore University of Technology and Design, Engineering Product Development Pillar, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811839/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=711283282175428645&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "Engineering Product Development Pillar",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9811880",
        "title": "R-PCC: A Baseline for Range Image-based Point Cloud Compression",
        "track": "main",
        "status": "Poster",
        "abstract": "In autonomous vehicles or robots, point clouds from LiDAR can provide accurate depth information of objects compared with 2D images, but they also suffer a large volume of data, which is inconvenient for data storage or transmission. In this paper, we propose a Range image-based Point Cloud Compression method, R-PCC, which can reconstruct the point cloud with uniform or non-uniform accuracy loss. We segment the original large-scale point cloud into small and compact regions for spatial redundancy and salient region classification. Our range image-based method can keep and align all points from the original point cloud in the reconstructed point cloud, and the setting of the quantization module restricts the maximum reconstruction error. In the experiments, we prove that our easier FPS-based segmentation method can achieve better performance than instance-based segmentation methods such as DBSCAN, and our non-uniform compression framework shows a great improvement on the downstream tasks compared with the state-of-the-art large-scale point cloud compression methods. Our real-time method can achieve 40 \u00d7 compression ratio without affecting downstream tasks, to act as a baseline for range image-based point cloud compression. The code is available on https://github.com/StevenWang30/R-PCC.git.",
        "primary_area": "",
        "author": "Sukai Wang;Jianhao Jiao;Peide Cai;Lujia Wang;Sukai Wang;Jianhao Jiao;Peide Cai;Lujia Wang",
        "authorids": "/37088235358;/37086552343;/37087104388;/37406752700;/37088235358;/37086552343;/37087104388;/37406752700",
        "aff": "Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811880/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2866684961816340480&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Hong Kong;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811923",
        "title": "R2poweR: The Proof-of-Concept of a Backdrivable, High-Ratio Gearbox for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic engineers face major challenges to solve the complex actuation needs of Human-Robot Collaboration with existing act robotic gearboxes. Available technologies comprise high-ratio Planetary Gearheads, Cycloid Drives and Harmonic Drives, inherited from conventional industrial robotics. Alternative approaches include Direct-Drive and Quasi Direct-Drive actuation strategies, which propose to cancel or substantially reduce gear ratio, in order to minimize reflected inertia and attain enough backdrivability for collaborative tasks. This paper presents the proof-of-concept validation of a novel high-ratio, Wolfrom-based, gearbox technology that follows a different approach to attain the same objective. Testing five different gearbox prototypes, we confirm the ability of the R2poweR technology to improve efficiency and backdrivability while retaining the weight and control advantages derived from the use of high reduction ratios. The result is a highly efficient, backdrivable, high-ratio gearbox with exciting Huma-Robot Collaboration potential.",
        "primary_area": "",
        "author": "P. L. Garcia;S. Crispel;A. Varadharajan;E. Saerens;T. Verstraten;B. Vanderborght;D. Lefeber;P. L. Garcia;S. Crispel;A. Varadharajan;E. Saerens;T. Verstraten;B. Vanderborght;D. Lefeber",
        "authorids": "/37088685943;/37087051472;/37089115209;/37086301634;/37085436323;/37295389300;/37295410400;/37088685943;/37087051472;/37089115209;/37086301634;/37085436323;/37295389300;/37295410400",
        "aff": "Robotics & Multibody Mechanics group of the Vrije Universiteit Brussel, Brussels, Belgium; Research Foundation Flanders (FWO). Stein Crispel and Elias Saerens as SB PhD Fellows and Tom Verstraten as a Postdoctoral Fellow; Robotics & Multibody Mechanics group of the Vrije Universiteit Brussel, Brussels, Belgium; Research Foundation Flanders (FWO). Stein Crispel and Elias Saerens as SB PhD Fellows and Tom Verstraten as a Postdoctoral Fellow; Research Foundation Flanders (FWO). Stein Crispel and Elias Saerens as SB PhD Fellows and Tom Verstraten as a Postdoctoral Fellow; Flanders Make, Leuven, Belgium; Research Foundation Flanders (FWO). Stein Crispel and Elias Saerens as SB PhD Fellows and Tom Verstraten as a Postdoctoral Fellow",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811923/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13207138466758969983&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;1;1;2;1",
        "aff_unique_norm": "Vrije Universiteit Brussel;Research Foundation Flanders;Flanders Make",
        "aff_unique_dep": "Robotics & Multibody Mechanics group;;",
        "aff_unique_url": "https://www.vub.be;https://www.fwo.be;https://www.flandersmake.be",
        "aff_unique_abbr": "VUB;FWO;",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Brussels;;Leuven",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9811935",
        "title": "R3LIVE: A Robust, Real-time, RGB-colored, LiDAR-Inertial-Visual tightly-coupled state Estimation and mapping package",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel LiDAR-Inertial-Visual sensor fusion framework termed R3LIVE, which takes advantage of measurement of LiDAR, inertial, and visual sensors to achieve robust and accurate state estimation. R3LIVE consists of two subsystems, a LiDAR-Inertial odometry (LIO) and a Visual-Inertial odometry (VIO). The LIO subsystem (FAST-LIO) utilizes the measurements from LiDAR and inertial sensors and builds the geometric structure (i.e., the positions of 3D points) of the map. The VIO subsystem uses the data of Visual-Inertial sensors and renders the map's texture (i.e., the color of 3D points). More specifically, the VIO subsystem fuses the visual data directly and effectively by minimizing the frame-to-map photometric error. The proposed system R3LIVE is developed based on our previous work R2LIVE, with a completely different VIO architecture design. The overall system is able to reconstruct the precise, dense, 3D, RGB-colored maps of the surrounding environment in real-time (see our attached video 11https://youtu.be/j5fT8NE5fdg). Our experiments show that the resultant system achieves higher robustness and accuracy in state estimation than its current counterparts. To share our findings and make contributions to the community, we open source R3LIVE on our Github 22https://github.com/hku-mars/r31ive",
        "primary_area": "",
        "author": "Jiarong Lin;Fu Zhang;Jiarong Lin;Fu Zhang",
        "authorids": "/37087012222;/38245883800;/37087012222;/38245883800",
        "aff": "Jiarong Lin; Fu Zhang",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811935/",
        "gs_citation": 364,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17994390404317137397&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9812320",
        "title": "RAPID-RL: A Reconfigurable Architecture with Preemptive-Exits for Efficient Deep-Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Present-day Deep Reinforcement Learning (RL) systems show great promise towards building intelligent agents surpassing human-level performance. However, the computational complexity associated with the underlying deep neural networks (DNNs) leads to power-hungry implementations. This makes deep RL systems unsuitable for deployment on resource-constrained edge devices. To address this challenge, we propose a reconfigurable architecture with preemptive exits for effi-cient deep RL (RAPID-RL). RAPID-RL enables conditional activation of DNN layers based on the difficulty level of inputs. This allows to dynamically adjust the compute effort during inference while maintaining competitive performance. We achieve this by augmenting a deep Q-network (DQN) with side-branches capable of generating intermediate predictions along with an associated confidence score. We also propose a novel training methodology for learning the actions and branch confidence scores in a dynamic RL setting. Our experiments evaluate the proposed framework for Atari 2600 gaming tasks and a realistic Drone navigation task on an open-source drone simulator (PEDRA). We show that RAPID-RL incurs 0.34 \u00d7 (0.25 \u00d7) number of operations (OPS) while maintaining performance above 0.88 \u00d7 (0.91 \u00d7) on Atari (Drone navigation) tasks, compared to a baseline-DQN without any side-branches. The reduction in OPS leads to fast and efficient inference, proving to be highly beneficial for the resource-constrained edge where making quick decisions with minimal compute is essential.",
        "primary_area": "",
        "author": "Adarsh Kumar Kosta;Malik Aqeel Anwar;Priyadarshini Panda;Arijit Raychowdhury;Kaushik Roy;Adarsh Kumar Kosta;Malik Aqeel Anwar;Priyadarshini Panda;Arijit Raychowdhury;Kaushik Roy",
        "authorids": "/37087935885;/37085475613;/37085624150;/37273985900;/37274519700;/37087935885;/37085475613;/37085624150;/37273985900;/37274519700",
        "aff": "Purdue University, West Lafayette, IN, USA; Georgia Institute of Technology, Atlanta, GA, USA; Yale University, New Haven, CT, USA; Georgia Institute of Technology, Atlanta, GA, USA; Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812320/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11457685543860209140&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "Purdue University;Georgia Institute of Technology;Yale University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.purdue.edu;https://www.gatech.edu;https://www.yale.edu",
        "aff_unique_abbr": "Purdue;Georgia Tech;Yale",
        "aff_campus_unique_index": "0;1;2;1;0",
        "aff_campus_unique": "West Lafayette;Atlanta;New Haven",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812046",
        "title": "RE:BT-Espresso: Improving Interpretability and Expressivity of Behavior Trees Learned from Robot Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Behavior trees (BTs) are hierarchical agent control architectures popular for robot task-level planning that can be autonomously learned from robot demonstrations via decision tree (DT) intermediaries, making them accessible to non-expert users. Conversion algorithms from DTs to BTs, such as the BT-Espresso algorithm, focus on replicating DT logic in a BT format but do not exploit the strengths of the BT architecture. We introduce the Representation Exploitation of BT-Espresso (RE:BT-Espresso) algorithm, which builds on BT-Espresso and improves the learned BT's interpretability and expressivity. RE:BT-Espresso improves interpretability by removing logical redundancies in the generated BTs and improves expressivity by exploiting desired BT structures, such as adding Inverter nodes, Repeater sequences, and Parallel Selector Action nodes that gives the user a choice of actions for state spaces that did not resolve to a concise action in the DT. The RE:BT-Espresso algorithm was evaluated against BT-Espresso using demonstration data synthesized by BTs. When compared to the synthesized BTs using graph edit distance (GED), RE:BT-Espresso outscored BT-Espresso on 54 subtrees, tied on 178, and lost on 2. Further, the proposed reduction strategies reduced the number of nodes in a generated tree by a median of 7.82%. The results validate improved interpretability and expressivity of learned RE:BT-Espresso task-level BT policies from robot demonstration.",
        "primary_area": "",
        "author": "Adam Wathieu;Thomas R. Groechel;Haemin Jenny Lee;Chloe Kuo;Maja J. Matari\u0107;Adam Wathieu;Thomas R. Groechel;Haemin Jenny Lee;Chloe Kuo;Maja J. Matari\u0107",
        "authorids": "/37089447890;/37087237103;/37089447934;/37089447854;/38300930600;/37089447890;/37087237103;/37089447934;/37089447854;/38300930600",
        "aff": "Department of Computer Science, Northwestern University, Evanston, IL, USA; Department of Computer Science, Interaction Lab, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, Interaction Lab, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, Interaction Lab, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, Interaction Lab, University of Southern California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812046/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3027011272102626473&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Northwestern University;University of Southern California",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.northwestern.edu;https://www.usc.edu",
        "aff_unique_abbr": "NU;USC",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Evanston;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812072",
        "title": "RF-Annotate: Automatic RF-Supervised Image Annotation of Common Objects in Context",
        "track": "main",
        "status": "Poster",
        "abstract": "Wireless tags are increasingly used to track and identify common items of interest such as retail goods, food, medicine, clothing, books, documents, keys, equipment, and more. At the same time, there is a need for labelled visual data featuring such items for the purpose of training object detection and recognition models for robots operating in homes, warehouses, stores, libraries, pharmacies, and so on. In this paper, we ask: can we leverage the tracking and identification capabilities of such tags as a basis for a large-scale automatic image annotation system for robotic perception tasks? We present RF-Annotate, a pipeline for autonomous pixel-wise image annotation which enables robots to collect labelled visual data of objects of interest as they encounter them within their environment. Our pipeline uses unmodified commodity RFID readers and RGB-D cameras, and exploits arbitrary small-scale motions afforded by mobile robotic platforms to spatially map RFIDs to corresponding objects in the scene. Our only assumption is that the objects of interest within the environment are pre-tagged with inexpensive battery-free RFIDs costing 3\u201315 cents each. We demonstrate the efficacy of our pipeline on several RGB-D sequences of tabletop scenes featuring common objects in a variety of indoor environments.",
        "primary_area": "",
        "author": "Emerson Sie;Deepak Vasisht;Emerson Sie;Deepak Vasisht",
        "authorids": "/37089448577;/37085471961;/37089448577;/37085471961",
        "aff": "University of Illinois at Urbana-Champaign; University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812072/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7450244689605190751&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811986",
        "title": "RMPs for Safe Impedance Control in Contact-Rich Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Variable impedance control in operation-space is a promising approach to learning contact-rich manipulation behaviors. One of the main challenges with this approach is producing a manipulation behavior that ensures the safety of the arm and the environment. Such behavior is typically implemented via a reward function that penalizes unsafe actions (e.g. obstacle collision, joint limit extension), but that approach is not always effective and does not result in behaviors that can be reused in slightly different environments. We show how to combine Riemannian Motion Policies, a class of policies that dynamically generate motion in the presence of safety and collision constraints, with variable impedance operation-space control to learn safer contact-rich manipulation behaviors.",
        "primary_area": "",
        "author": "Seiji Shaw;Ben Abbatematteo;George Konidaris;Seiji Shaw;Ben Abbatematteo;George Konidaris",
        "authorids": "/37089450120;/37089197450;/38318614200;/37089450120;/37089197450;/38318614200",
        "aff": "Department of Computer Science, Brown University, Providence RI; Department of Computer Science, Brown University, Providence RI; Department of Computer Science, Brown University, Providence RI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811986/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5154045580604971697&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Providence",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811981",
        "title": "RMS-FlowNet: Efficient and Robust Multi-Scale Scene Flow Estimation for Large-Scale Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "The proposed RMS-FlowNet is a novel end-to-end learning-based architecture for accurate and efficient scene flow estimation which can operate on point clouds of high density. For hierarchical scene flow estimation, the existing methods depend on either expensive Farthest-Point-Sampling (FPS) or structure-based scaling which decrease their ability to handle a large number of points. Unlike these methods, we base our fully supervised architecture on Random-Sampling (RS) for multiscale scene flow prediction. To this end, we propose a novel flow embedding design which can predict more robust scene flow in conjunction with RS. Exhibiting high accuracy, our RMS-FlowNet provides a faster prediction than state-of-the-art methods and works efficiently on consecutive dense point clouds of more than 250K points at once. Our comprehensive experiments verify the accuracy of RMS-FlowNet on the established FlyingThings3D data set with different point cloud densities and validate our design choices. Additionally, we show that our model presents a competitive ability to generalize towards the real-world scenes of KITTI data set without fine-tuning.",
        "primary_area": "",
        "author": "Ramy Battrawy;Ren\u00e9 Schuster;Mohammad\u2013Ali Nikouei Mahani;Didier Stricker;Ramy Battrawy;Ren\u00e9 Schuster;Mohammad\u2013Ali Nikouei Mahani;Didier Stricker",
        "authorids": "/37086784293;/37086375640;/37089045697;/37326112700;/37086784293;/37086375640;/37089045697;/37326112700",
        "aff": "DFKI - German Research Center for Artificial Intelligence, Germany; DFKI - German Research Center for Artificial Intelligence, Germany; BMW Group, Germany; DFKI - German Research Center for Artificial Intelligence, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811981/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8292853575499621154&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "German Research Center for Artificial Intelligence;BMW Group",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.dFKI.de;https://www.bmwgroup.com",
        "aff_unique_abbr": "DFKI;BMW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812321",
        "title": "ROMAX: Certifiably Robust Deep Multiagent Reinforcement Learning via Convex Relaxation",
        "track": "main",
        "status": "Poster",
        "abstract": "In a multirobot system, a number of cyber-physical attacks (e.g., communication hijack, observation per-turbations) can challenge the robustness of agents. This robust-ness issue worsens in multiagent reinforcement learning because there exists the non-stationarity of the environment caused by simultaneously learning agents whose changing policies affect the transition and reward functions. In this paper, we propose a minimax MARL approach to infer the worst-case policy update of other agents. As the minimax formulation is computationally intractable to solve, we apply the convex relaxation of neural networks to solve the inner minimization problem. Such convex relaxation enables robustness in interacting with peer agents that may have significantly different behaviors and also achieves a certified bound of the original optimization problem. We eval-uate our approach on multiple mixed cooperative-competitive tasks and show that our method outperforms the previous state of the art approaches on this topic.",
        "primary_area": "",
        "author": "Chuangchuang Sun;Dong-Ki Kim;Jonathan P. How;Chuangchuang Sun;Dong-Ki Kim;Jonathan P. How",
        "authorids": "/37085353469;/37087324178;/37276347700;/37085353469;/37087324178;/37276347700",
        "aff": "Department of Aerospace Engineering, Mississippi State University, MS; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812321/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3756001854130013679&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Mississippi State University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aerospace Engineering;Laboratory for Information & Decision Systems",
        "aff_unique_url": "https://www.msstate.edu;https://web.mit.edu",
        "aff_unique_abbr": "MSU;MIT",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812417",
        "title": "ROS2SWARM - A ROS 2 Package for Swarm Robot Behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "Developing reusable software for mobile robots is still challenging. Even more so for swarm robots, despite the desired simplicity of the robot controllers. Prototyping and experimenting are difficult due to the multi-robot setting and often require robot-robot communication. Also, the diversity of swarm robot hardware platforms increases the need for hardware-independent software concepts. The main advantages of the commonly used robot software architecture ROS 2 are modularity and platform independence. We propose a new ROS 2 package, ROS2sWARM, for applications of swarm robotics that provides a library of ready-to-use swarm behavioral primitives. We show the successful application of our approach on three different platforms, the TurtleBot3 Burger, the TurtleBot3 Waffle Pi, and the Jackal UGV, and with a set of different behavioral primitives, such as aggregation, dispersion, and collective decision-making. The proposed approach is easy to maintain, extendable, and has good potential for simplifying swarm robotics experiments in future applications.",
        "primary_area": "",
        "author": "Tanja Katharina Kaiser;Marian Johannes Begemann;Tavia Plattenteich;Lars Schilling;Georg Schildbach;Heiko Hamann;Tanja Katharina Kaiser;Marian Johannes Begemann;Tavia Plattenteich;Lars Schilling;Georg Schildbach;Heiko Hamann",
        "authorids": "/37086935951;/37089448408;/37089449163;/37089195213;/38232682600;/37683321200;/37086935951;/37089448408;/37089449163;/37089195213;/38232682600;/37683321200",
        "aff": "Institute of Computer Engineering, University of L\u00fcbeck, Germany; Institute of Computer Engineering, University of L\u00fcbeck, Germany; Institute of Computer Engineering, University of L\u00fcbeck, Germany; Institute of Robotics, University of L\u00fcbeck, Germany; Institute for Electrical Engineering in Medicine, University of L\u00fcbeck, Germany; Institute of Computer Engineering, University of L\u00fcbeck, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812417/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14433870415673582676&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of L\u00fcbeck",
        "aff_unique_dep": "Institute of Computer Engineering",
        "aff_unique_url": "https://www.uni-luebeck.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811745",
        "title": "ROW-SLAM: Under-Canopy Cornfield Semantic SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "We study a semantic SLAM problem where a robot is tasked with autonomous weeding under the corn canopy. The goal is to detect corn stalks and localize them in a global coordinate frame. This is a challenging scenario for existing algorithms because there is very little space between the camera and the plants, and the camera motion is primarily restricted to be along the row. To overcome these challenges, we present a multi-camera system where a side camera (facing the plants) is used for detection, whereas front and back cameras are used for motion estimation. Next, we show how semantic features in the environment (corn stalks, ground, and crop planes) can be used to develop a robust semantic SLAM solution and present results from field trials performed throughout the growing season across various cornfields.",
        "primary_area": "",
        "author": "Jiacheng Yuan;Jungseok Hong;Junaed Sattar;Volkan Isler;Jiacheng Yuan;Jungseok Hong;Junaed Sattar;Volkan Isler",
        "authorids": "/37088998450;/37088505608;/37546394500;/37298487800;/37088998450;/37088505608;/37546394500;/37298487800",
        "aff": "Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, USA; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811745/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5783941104999214308&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811701",
        "title": "ROZZ: Property-based Fuzzing for Robotic Programs in ROS",
        "track": "main",
        "status": "Poster",
        "abstract": "ROS is popular in robotic-software development, and thus detecting bugs in ROS programs is important for modern robots. Fuzzing is a promising technique of runtime testing. But existing fuzzing approaches are limited in testing ROS programs, due to neglecting ROS properties, such as multi-dimensional inputs, temporal features of inputs and the distributed node model. In this paper, we develop a new fuzzing framework named ROZZ, to effectively test ROS programs and detect bugs based on ROS properties. ROZZ has three key techniques: (1) a multi-dimensional generation method to generate test cases of ROS programs from multiple dimensions, including user data, configuration parameters and sensor messages; (2) a distributed branch coverage to describe the overall code coverage of multiple ROS nodes in the robot task; (3) a temporal mutation strategy to generate test cases with temporal information. We evaluate ROZZ on 10 common robotic programs in ROS2, and it finds 43 real bugs. 20 of these bugs have been confirmed and fixed by related ROS developers. We compare ROZZ to existing approaches for testing robotic programs, and ROZZ finds more bugs with higher code coverage.",
        "primary_area": "",
        "author": "Kai-Tao Xie;Jia-Ju Bai;Yong-Hao Zou;Yu-Ping Wang;Kai-Tao Xie;Jia-Ju Bai;Yong-Hao Zou;Yu-Ping Wang",
        "authorids": "/37089449731;/37085383997;/37088999910;/37085396500;/37089449731;/37085383997;/37088999910;/37085396500",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811701/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3030830542896600346&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812104",
        "title": "RTGNN: A Novel Approach to Model Stochastic Traffic Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling stochastic traffic dynamics is critical to developing self-driving cars. Because it is difficult to develop first principle models of cars driven by humans, there is great potential for using data driven approaches in developing traffic dynamical models. While there is extensive literature on this subject, previous works mainly address the prediction accuracy of data-driven models. Moreover, it is often difficult to apply these models to common planning frameworks since they fail to meet the assumptions therein. In this work, we propose a new stochastic traffic model, Recurrent Traffic Graph Neural Network (RTGNN), by enforcing additional structures on the model so that the proposed model can be seamlessly integrated with existing motion planning algorithms. RTGNN is a Markovian model and is able to infer future traffic states conditioned on the motion of the ego vehicle. Specifically, RTGNN uses a definition of the traffic state that includes the state of all players in a local region and is therefore able to make joint predictions for all agents of interest. Meanwhile, we explicitly model the hidden states of agents, \u201cintentions,\u201d as part of the traffic state to reflect the inherent partial observability of traffic dynamics. The above mentioned properties are critical for integrating RTGNN with motion planning algorithms coupling prediction and decision making. Despite the additional structures, we show that RTGNN is able to achieve state-of-the-art accuracy through comparisons with other similar works.",
        "primary_area": "",
        "author": "Ke Sun;Stephen Chaves;Paul Martin;Vijay Kumar;Ke Sun;Stephen Chaves;Paul Martin;Vijay Kumar",
        "authorids": "/37086192986;/37085502862;/37088686044;/37280341400;/37086192986;/37085502862;/37088686044;/37280341400",
        "aff": "GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA; Qualcomm Technologies Inc., Philadelphia, PA, USA; Qualcomm Technologies Inc., Philadelphia, PA, USA; GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812104/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=860299216354593900&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Pennsylvania;Qualcomm Technologies Inc.",
        "aff_unique_dep": "GRASP Lab;",
        "aff_unique_url": "https://www.upenn.edu;https://www.qualcomm.com",
        "aff_unique_abbr": "UPenn;QTI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811998",
        "title": "RangeBird: Multi View Panoptic Segmentation of 3D Point Clouds with Neighborhood Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "Panoptic segmentation of point clouds is one of the key challenges of 3D scene understanding, requiring the simultaneous prediction of semantics and object instances. Tasks like autonomous driving strongly depend on these information to get a holistic understanding of their 3D environment. This work presents a novel proposal free framework for lidar-based panoptic segmentation, which exploits three different point cloud representations, leveraging their strengths and compensating their weaknesses. The efficient projection-based range view and bird's eye view are combined and further extended by a point-based network with a novel attention-based neighborhood aggregation for improved semantic features. Cluster-based object recognition in bird's eye view enables an efficient and high-quality instance segmentation. Semantic and instance segmentation are fused and further refined by a novel instance classification for the final panoptic segmentation. The results on two challenging large-scale datasets, nuScenes and SemanticKITTI, show the success of the proposed framework, which outperforms all existing approaches on nuScenes and achieves state-of-the-art results on SemanticKITTI.",
        "primary_area": "",
        "author": "Fabian Duerr;Hendrik Weigel;J\u00fcrgen Beyerer;Fabian Duerr;Hendrik Weigel;J\u00fcrgen Beyerer",
        "authorids": "/37088598308;/37571559800;/37571783200;/37088598308;/37571559800;/37571783200",
        "aff": "Vision and Fusion Lab, Karlsruhe Institute of Technology, Germany; Audi AG, Ingolstadt, Germany; Fraunhofer Institute of Optronics, System Technologies and Image Exploitation, Fraunhofer Center for Machine Learning, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811998/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4973080630163370352&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Karlsruhe Institute of Technology;AUDI AG;Fraunhofer Institute of Optronics, System Technologies and Image Exploitation",
        "aff_unique_dep": "Vision and Fusion Lab;;Fraunhofer Center for Machine Learning",
        "aff_unique_url": "https://www.kit.edu;https://www.audi.de;https://www.ioe.fraunhofer.de/",
        "aff_unique_abbr": "KIT;Audi;Fraunhofer IOE",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812088",
        "title": "Rapid and Reliable Quadruped Motion Planning with Omnidirectional Jumping",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic jumping with legged robots poses a challenging problem in planning and control. Formulating the jump optimization to allow fast online execution is difficult; efficiently using this capability to generate long-horizon motion plans further complicates the problem. In this work, we present a hierarchical planning framework to address this problem. We first formulate a real-time tractable trajectory optimization for performing omnidirectional jumping. We then embed the results of this optimization into a low dimensional jump feasibility classifier. This classifier is leveraged to produce geometric motion plans that select dynamically feasible jumps while mitigating the effects of the process noise. We deploy our framework on the Mini Cheetah Vision quadruped, demonstrating the robot's ability to generate and execute reliable, goal-oriented plans that involve forward, lateral, and rotational jumps onto surfaces as tall as the robot's nominal hip height. The ability to plan through omnidirectional jumping greatly expands the robot's mobility relative to planners that restrict jumping to the sagittal or frontal planes.",
        "primary_area": "",
        "author": "Matthew Chignoli;Savva Morozov;Sangbae Kim;Matthew Chignoli;Savva Morozov;Sangbae Kim",
        "authorids": "/37088344884;/37089449714;/37537397200;/37088344884;/37089449714;/37537397200",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812088/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7382247289071201815&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811566",
        "title": "ReDUCE: Reformulation of Mixed Integer Programs Using Data from Unsupervised Clusters for Learning Efficient Strategies",
        "track": "main",
        "status": "Poster",
        "abstract": "Mixed integer convex and nonlinear programs, MICP and MINLP, are expressive but require long solving times. Recent work that combines learning methods on solver heuristics has shown potential to overcome this issue allowing for applications on larger scale practical problems. Gathering sufficient training data to employ these methods still present a challenge since getting data from traditional solvers are slow and newer learning approaches still require large amounts of data. In order to scale up and make these hybrid learning approaches more manageable we propose ReDUCE, a method that exploits structure within small to medium size datasets. We also introduce the bookshelf organization problem as an MINLP as a way to measure performance of solvers with ReDUCE. Results show that existing algorithms with ReDUCE can solve this problem within a few seconds, a significant improvement over the original formulation. ReDUCE is demonstrated as a high level planner for a robotic arm for the bookshelf problem.",
        "primary_area": "",
        "author": "Xuan Lin;Gabriel I. Fernandez;Dennis W. Hong;Xuan Lin;Gabriel I. Fernandez;Dennis W. Hong",
        "authorids": "/37085891795;/37087324390;/37575333900;/37085891795;/37087324390;/37575333900",
        "aff": "Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811566/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3873342216178606751&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811949",
        "title": "ReachBot: A Small Robot with Exceptional Reach for Rough Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "ReachBot is a new concept for planetary exploration, consisting of a small body and long, lightweight extending arms loaded primarily in tension. The arms are equipped with spined grippers for anchoring on rock surfaces. The design and testing of a planar prototype is presented here. Experiments with rock grasping and coordinated locomotion illustrate the advantages of low inertia passive grippers, triggered by impact and using stored mechanical energy for the internal force. Gripper design involves a trade-off among the range of possible grasp angles, maximum grasp force, required triggering force, and required reset force. The current prototype can pull with up to 8N when gripping volcanic rock, limited only by the strength of the 3D printed components. Calculations predict a maximum pull of 26N for the same spines and stronger materials.",
        "primary_area": "",
        "author": "Tony G. Chen;Becky Miller;Crystal Winston;Stephanie Schneider;Andrew Bylard;Marco Pavone;Mark R. Cutkosky;Tony G. Chen;Becky Miller;Crystal Winston;Stephanie Schneider;Andrew Bylard;Marco Pavone;Mark R. Cutkosky",
        "authorids": "/37086420715;/37089447441;/37086961977;/37345833100;/37085786338;/37307912900;/37329470000;/37086420715;/37089447441;/37086961977;/37345833100;/37085786338;/37307912900;/37329470000",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA; Department of Mechanical Engineering, Stanford University, Stanford, CA; Department of Mechanical Engineering, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA; Department of Mechanical Engineering, Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811949/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9381764316974150828&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811642",
        "title": "Reactive Informative Planning for Mobile Manipulation Tasks under Sensing and Environmental Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we address mobile manipulation planning problems in the presence of sensing and environmental uncertainty. In particular, we consider mobile sensing manipulators operating in environments with unknown geometry and uncertain movable objects, while being responsible for accomplishing tasks requiring grasping and releasing objects in a logical fashion. Existing algorithms either do not scale well or neglect sensing and/or environmental uncertainty. To face these challenges, we propose a hybrid control architecture, where a symbolic controller generates high-level manipulation commands (e.g., grasp an object) based on environmental feedback, an informative planner designs paths to actively decrease the uncertainty of objects of interest, and a continuous reactive controller tracks the sparse waypoints comprising the informative paths while avoiding a priori unknown obstacles. The overall architecture can handle environmental and sensing uncertainty online, as the robot explores its workspace. Using numerical simulations, we show that the proposed architecture can handle tasks of increased complexity while responding to unanticipated adverse configurations.",
        "primary_area": "",
        "author": "Mariliza Tzes;Vasileios Vasilopoulos;Yiannis Kantaros;George J. Pappas;Mariliza Tzes;Vasileios Vasilopoulos;Yiannis Kantaros;George J. Pappas",
        "authorids": "/37086395388;/37085350448;/37085499544;/37281547100;/37086395388;/37085350448;/37085499544;/37281547100",
        "aff": "GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), MIT, Cambridge, MA; Department of Electrical and Systems Engineering, Washington University in St. Louis, St. Louis, MO; GRASP Lab, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811642/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15749693610834075694&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Pennsylvania;Massachusetts Institute of Technology;Washington University in St. Louis",
        "aff_unique_dep": "GRASP Lab;Computer Science and Artificial Intelligence Laboratory;Department of Electrical and Systems Engineering",
        "aff_unique_url": "https://www.upenn.edu;https://www.mit.edu;https://wustl.edu",
        "aff_unique_abbr": "UPenn;MIT;WUSTL",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Philadelphia;Cambridge;St. Louis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812068",
        "title": "Reactive Locomotion Decision-Making and Robust Motion Planning for Real-Time Perturbation Recovery",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we examine the problem of push recovery for bipedal robot locomotion and present a reactive decision-making and robust planning framework for locomotion resilient to external perturbations. Rejecting perturbations is an essential capability of bipedal robots and has been widely studied in the locomotion literature. However, adversarial disturbances and aggressive turning can lead to negative lateral step width (i.e., crossed-leg scenarios) with unstable motions and self-collision risks. These motion planning problems are computationally difficult and have not been explored under a hierarchically integrated task and motion planning method. We explore a planning and decision-making framework that closely ties linear-temporal-logic-based reactive synthesis with trajectory optimization incorporating the robot's full-body dynamics, kinematics, and leg collision avoidance constraints. Between the high-level discrete symbolic decision-making and the low-level continuous motion planning, behavior trees serve as a reactive interface to handle perturbations occurring at any time of the locomotion process. Our experimental results show the efficacy of our method in generating resilient recovery behaviors in response to diverse perturbations from any direction with bounded magnitudes.",
        "primary_area": "",
        "author": "Zhaoyuan Gu;Nathan Boyd;Ye Zhao;Zhaoyuan Gu;Nathan Boyd;Ye Zhao",
        "authorids": "/37089613574;/37089436717;/37088450720;/37089613574;/37089436717;/37088450720",
        "aff": "Laboratory for Intelligent Decision and Autonomous Robots, Woodruff School of Mechanical Engineering, Georgia Institute of Technology; Laboratory for Intelligent Decision and Autonomous Robots, Woodruff School of Mechanical Engineering, Georgia Institute of Technology; Laboratory for Intelligent Decision and Autonomous Robots, Woodruff School of Mechanical Engineering, Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812068/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1696094117614852492&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Woodruff School of Mechanical Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812023",
        "title": "Real-Robot Deep Reinforcement Learning: Improving Trajectory Tracking of Flexible-Joint Manipulator with Reference Correction",
        "track": "main",
        "status": "Poster",
        "abstract": "Flexible-joint manipulators are governed by complex nonlinear dynamics, defining a challenging control problem. In this work, we propose an approach to learn an outer-loop joint trajectory tracking controller with deep reinforcement learning. The controller represented by a stochastic policy is learned in under two hours directly on the real robot. This is achieved through bounded reference correction actions and use of a model-free off-policy learning method. In addition, an informed policy initialization is proposed, where the agent is pre-trained in a learned simulation. We test our approach on the 7 DOF manipulator of a Baxter robot. We demonstrate that the proposed method is capable of consistent learning across multiple runs when applied directly on the real robot. Our method yields a policy which significantly improves the trajectory tracking accuracy in comparison to the vendor-provided controller, generalizing to an unseen payload.",
        "primary_area": "",
        "author": "Dmytro Pavlichenko;Sven Behnke;Dmytro Pavlichenko;Sven Behnke",
        "authorids": "/37086224850;/37295987100;/37086224850;/37295987100",
        "aff": "Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany; Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812023/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1102430889501161045&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Computer Science Institute VI",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "Uni Bonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811957",
        "title": "Real-Time Multi-Contact Model Predictive Control via ADMM",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a hybrid model predictive control algorithm, consensus complementarity control (C3), for systems that make and break contact with their environment. Many state-of-the-art controllers for tasks which require initiating contact with the environment, such as locomotion and manipulation, require a priori mode schedules or are so computationally complex that they cannot run at real-time rates. We present a method, based on the alternating direction method of multipliers (ADMM), capable of high-speed reasoning over potential contact events. Via a consensus formulation, our approach enables parallelization of the contact scheduling problem. We validate our results on three numerical examples, including two frictional contact problems, and physical experimentation on an underactuated multi-contact system.",
        "primary_area": "",
        "author": "Alp Aydinoglu;Michael Posa;Alp Aydinoglu;Michael Posa",
        "authorids": "/37088334657;/37085767813;/37088334657;/37085767813",
        "aff": "General Robotics, Automation, Sensing and Perception (GRASP) Laboratory, University of Pennsylvania, Philadelphia, PA, USA; General Robotics, Automation, Sensing and Perception (GRASP) Laboratory, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811957/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=438033964827956243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "General Robotics, Automation, Sensing and Perception (GRASP) Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812405",
        "title": "Real-Time Trajectory Planning for Autonomous Driving with Gaussian Process and Incremental Refinement",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time kinodynamic trajectory planning in dy-namic environments is critical yet challenging for autonomous driving. In this paper, we propose an efficient trajectory plan-ning system for autonomous driving in complex dynamic sce-narios through iterative and incremental path-speed optimization. Exploiting the decoupled structure of the planning prob-lem, a path planner based on Gaussian process first generates a continuous arc-length parameterized path in the Fren\u00e9t frame, considering static obstacle avoidance and curvature constraints. We theoretically prove that it is a good generalization of the well-known jerk optimal solution. An efficient s-t graph search method is introduced to find a speed profile along the generated path to deal with dynamic environments. Finally, the path and speed are optimized incrementally and iteratively to ensure kinodynamic feasibility. Various simulated scenarios with both static obstacles and dynamic agents verify the effectiveness and robustness of our proposed method. Experimental results show that our method can run at 20 Hz. The source code is released as an open-source package.",
        "primary_area": "",
        "author": "Jie Cheng;Yingbing Chen;Qingwen Zhang;Lu Gan;Chengju Liu;Ming Liu;Jie Cheng;Yingbing Chen;Qingwen Zhang;Lu Gan;Chengju Liu;Ming Liu",
        "authorids": "/37088809524;/37088809905;/37089449650;/37088809207;/37677379800;/37085398677;/37088809524;/37088809905;/37089449650;/37088809207;/37677379800;/37085398677",
        "aff": "Hong Kong University of Science and Technology, Hong Kong SAR, China; Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China; Department of Electronics and Information Engineering, Tongji University, Shanghai, China; Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812405/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17279410145661441093&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Tongji University",
        "aff_unique_dep": ";Department of Electronics and Information Engineering",
        "aff_unique_url": "https://www.ust.hk;https://www.tongji.edu.cn",
        "aff_unique_abbr": "HKUST;Tongji",
        "aff_campus_unique_index": "0;1;1;1;2;1",
        "aff_campus_unique": "Hong Kong;Guangzhou;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812137",
        "title": "Real-time Full-stack Traffic Scene Perception for Autonomous Driving with Roadside Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel and pragmatic framework for traffic scene perception with roadside cameras. The proposed framework covers a full-stack of roadside perception pipeline for infrastructure-assisted autonomous driving, including object detection, object localization, object tracking, and multi-camera information fusion. Unlike previous vision-based perception frameworks rely upon depth offset or 3D annotation at training, we adopt a modular decoupling design and introduce a landmark-based 3D localization method, where the detection and localization can be well decoupled so that the model can be easily trained based on only 2D annotations. The proposed framework applies to either optical or thermal cameras with pinhole or fish-eye lenses. Our framework is deployed at a two-lane roundabout located at Ellsworth Rd. and State St., Ann Arbor, MI, USA, providing 7\u00d7247\\times 24 real-time traffic flow monitoring and high-precision vehicle trajectory extraction. The whole system runs efficiently on a low-power edge computing device with all-component end-to-end delay of less than 20ms.",
        "primary_area": "",
        "author": "Zhengxia Zou;Rusheng Zhang;Shengyin Shen;Gaurav Pandey;Punarjay Chakravarty;Armin Parchami;Henry X. Liu;Zhengxia Zou;Rusheng Zhang;Shengyin Shen;Gaurav Pandey;Punarjay Chakravarty;Armin Parchami;Henry X. Liu",
        "authorids": "/37085457701;/37086570200;/37089449375;/37084693200;/37952596000;/37089448770;/37086194067;/37085457701;/37086570200;/37089449375;/37084693200;/37952596000;/37089448770;/37086194067",
        "aff": "Department of Civil and Environmental Engineering, University of Michigan, Ann Arbor; Department of Civil and Environmental Engineering, University of Michigan, Ann Arbor; Department of Civil and Environmental Engineering, University of Michigan, Ann Arbor; Ford Motor Company; Ford Motor Company; Ford Motor Company; Department of Civil and Environmental Engineering, University of Michigan, Ann Arbor",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812137/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=515296426838091385&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;1;0",
        "aff_unique_norm": "University of Michigan;Ford Motor Company",
        "aff_unique_dep": "Department of Civil and Environmental Engineering;",
        "aff_unique_url": "https://www.umich.edu;https://www.ford.com",
        "aff_unique_abbr": "UM;Ford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812214",
        "title": "Real-time Inertial Parameter Identification of Floating-Base Robots Through Iterative Primitive Shape Division",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic models play a key role in robot motion generation and control and the identification of inertial parameters is a critical component for obtaining an accurate dynamic model of a robot. This paper presents a novel iterative primitive shape division method for the inertia parameter identification of floating-base robots. Describing a robot by a set of primitive shapes with uniform mass distributions, the method iteratively divides the primitive shapes into smaller ones and refines their masses, which quickly converges to yielding the true inertia parameters of the robot. This method guarantees the physical consistency of the obtained parameters, possesses a high computational efficiency for online deployment, and works without contact force measurement. Furthermore, it can be used to estimate the position and magnitude of an external load applied to the robot. Simulations and experiments on a quadruped robot have been conducted to verify the effectiveness and efficiency of the proposed method.",
        "primary_area": "",
        "author": "Jiafeng Xu;Yu Zheng;Xinyang Jiang;Sicheng Yang;Lingzhu Xiang;Zhengyou Zhang;Jiafeng Xu;Yu Zheng;Xinyang Jiang;Sicheng Yang;Lingzhu Xiang;Zhengyou Zhang",
        "authorids": "/37086443289;/37086993722;/37089450681;/37089448525;/37089449920;/37088690693;/37086443289;/37086993722;/37089450681;/37089448525;/37089449920;/37088690693",
        "aff": "Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812214/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3173495681547138205&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tencent",
        "aff_unique_dep": "Robotics X",
        "aff_unique_url": "https://robotics.tencent.com",
        "aff_unique_abbr": "Tencent Robotics X",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811651",
        "title": "Real2Sim2Real: Self-Supervised Learning of Physical Single-Step Dynamic Actions for Planar Robot Casting",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces the task of Planar Robot Casting (PRC): where one planar motion of a robot arm holding one end of a cable causes the other end to slide across the plane toward a desired target. PRC allows the cable to reach points beyond the robot workspace and has applications for cable management in homes, warehouses, and factories. To efficiently learn a PRC policy for a given cable, we propose Real2Sim2Real, a self-supervised framework that automatically collects physical trajectory examples to tune parameters of a dynamics simulator using Differential Evolution, generates many simulated examples, and then learns a policy using a weighted combination of simulated and physical data. We evaluate Real2Sim2Real with three simulators, Isaac Gym-segmented, Isaac Gym-hybrid, and PyBullet, two function approximators, Gaussian Processes and Neural Networks (NNs), and three cables with differing stiffness, torsion, and friction. Results with 240 physical trials suggest that the PRC policies can attain median error distance (as % of cable length) ranging from 8 % to 14 %, outperforming baselines and policies trained on only real or only simulated examples. Code, data, and videos are available at https://tinyurl.com/robotcast.",
        "primary_area": "",
        "author": "Vincent Lim;Huang Huang;Lawrence Yunliang Chen;Jonathan Wang;Jeffrey Ichnowski;Daniel Seita;Michael Laskey;Ken Goldberg;Vincent Lim;Huang Huang;Lawrence Yunliang Chen;Jonathan Wang;Jeffrey Ichnowski;Daniel Seita;Michael Laskey;Ken Goldberg",
        "authorids": "/37089450526;/37088985585;/37089447531;/37089001305;/38541287200;/37086012763;/37085370242;/37273026700;/37089450526;/37088985585;/37089447531;/37089001305;/38541287200;/37086012763;/37085370242;/37273026700",
        "aff": "AUTOLab, UC Berkeley; AUTOLab, UC Berkeley; AUTOLab, UC Berkeley; AUTOLab, UC Berkeley; AUTOLab, UC Berkeley; AUTOLab, UC Berkeley; Toyota Research Institute, CA, USA; AUTOLab, UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811651/",
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2982709300302628517&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;Toyota Research Institute",
        "aff_unique_dep": "AUTOLab;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.tri.global",
        "aff_unique_abbr": "UC Berkeley;TRI",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;0",
        "aff_campus_unique": "Berkeley;CA",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812418",
        "title": "Realtime Trajectory Smoothing with Neural Nets",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to safely and efficiently collaborate with humans, industrial robots need the ability to alter their motions quickly to react to sudden changes in the environment, such as an obstacle appearing across a planned trajectory. In Realtime Motion Planning, obstacles are detected in real time through a vision system, and new trajectories are planned with respect to the current positions of the obstacles, and immediately executed on the robot. Existing realtime motion planners, however, lack the smoothing post-processing step - which are crucial in sampling-based motion planning - resulting in the planned trajectories being jerky, and therefore inefficient and less human-friendly. Here we propose a Realtime Trajectory Smoother based on the shortcutting technique to address this issue. Leveraging fast clearance inference by a novel neural network, the proposed method is able to consistently smooth the trajectories of a 6-DOF industrial robot arm within 200 ms on a commercial GPU. We integrate the proposed smoother into a full Vision-Motion Planning-Execution loop and demonstrate a realtime, smooth, performance of an industrial robot subject to dynamic obstacles.",
        "primary_area": "",
        "author": "Shohei Fujii;Quang-Cuong Pham;Shohei Fujii;Quang-Cuong Pham",
        "authorids": "/37089610589;/38191381800;/37089610589;/38191381800",
        "aff": "DENSO CORP., Japan; Eureka Robotics, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812418/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5395300242214342475&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "DENSO Corporation;Eureka Robotics",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.denso.com;",
        "aff_unique_abbr": "DENSO;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Japan;Singapore"
    },
    {
        "id": "9811882",
        "title": "Receding Horizon Tracking of an Unknown Number of Mobile Targets using a Bearings-Only Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning the motion of bearings-only sensors is critical for enabling accurate tracking of the positions of moving targets. In this paper, we demonstrate planning the observer's motion over horizons greater than one step for estimating an unknown and varying number of indistinguishable, maneuvering targets of interest using a probability hypothesis density (PHD) filter, with a R\u00e9riyi divergence reward for selecting actions. We describe approximations to make this approach computationally feasible, and we propose using Monte Carlo tree search (MCTS) to further reduce the cost. Finally, we present simulation results showing that longer planning horizons reduce the error in the estimates and that MCTS can reduce the cost of planning without sacrificing the quality of the estimates.",
        "primary_area": "",
        "author": "James D. Turner;James McMahon;Michael M. Zavlanos;James D. Turner;James McMahon;Michael M. Zavlanos",
        "authorids": "/37089448208;/37085353635;/37300758300;/37089448208;/37085353635;/37300758300",
        "aff": "Department of Mechanical Engineering & Materials Science, Duke University, Durham, NC, USA; Naval Research Laboratory, Physical Acoustics Branch, Code 7130, Washington, D.C., USA; Department of Mechanical Engineering & Materials Science, Duke University, Durham, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811882/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4553956346665139223&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Duke University;Naval Research Laboratory",
        "aff_unique_dep": "Department of Mechanical Engineering & Materials Science;Physical Acoustics Branch",
        "aff_unique_url": "https://www.duke.edu;https://www.nrl.navy.mil",
        "aff_unique_abbr": "Duke;NRL",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Durham;Washington, D.C.",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811738",
        "title": "Reconfigurable Underactuated Adaptive Gripper Designed by Morphological Computation",
        "track": "main",
        "status": "Poster",
        "abstract": "Anthropomorphic robotic grippers are required for robots, prostheses, and orthosis to enable manipulation of a priori unknown and variable-shape objects. It has to meet a wide range of sometimes contradictory requirements in terms of adaptivity, dexterity, high payload to weight ratio, robustness, aesthetics, compactness, lightweight, etc. Within this paper, we utilize the morphological computation approach to introduce design for anthropomorphic re-configurable underactuated grippers. The key to fingers' adaptivity is embedded passive variable length links and elastic elements at input joints. Based on this concept, we designed a palm-size five-finger gripper, where 14 DoFs, including thumb, are controlled by just 4 motors, such that it can perform both precision pinch and encompassing power grasps of various objects. The paper describes synthesized linkages for digits, hand design overview, control strategy, and test results of a physical prototype.",
        "primary_area": "",
        "author": "Ivan I. Borisov;Evgenii E. Khornutov;Dmitriy V. Ivolga;Nikita A. Molchanov;Ivan A. Maksimov;Sergey A. Kolyubin;Ivan I. Borisov;Evgenii E. Khornutov;Dmitriy V. Ivolga;Nikita A. Molchanov;Ivan A. Maksimov;Sergey A. Kolyubin",
        "authorids": "/37086250938;/37089448237;/37089446944;/37089448761;/37089450564;/37887676700;/37086250938;/37089448237;/37089446944;/37089448761;/37089450564;/37887676700",
        "aff": "Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Sber Robotics Lab, Moscow, Russia; Sber Robotics Lab, Moscow, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811738/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9586023963096331074&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "ITMO University;Sberbank",
        "aff_unique_dep": "Biomechatronics and Energy-Efficient Robotics Lab;Sber Robotics Lab",
        "aff_unique_url": "https://www.itmo.ru;https://www.sberbank.ru",
        "aff_unique_abbr": "ITMO;Sber",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Saint Petersburg;Moscow",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "9812398",
        "title": "Recursive Feasibility Guided Optimal Parameter Adaptation of Differential Convex Optimization Policies for Safety-Critical Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadratic Program(QP) based state-feedback controllers, whose inequality constraints bound the rate of change of control barrier (CBFs) and lyapunov function with a class-\\mathcal{K}\\mathcal{K} function of their values, are sensitive to the parameters of these class-\\mathcal{K}\\mathcal{K} functions. The construction of valid CBFs, however, is not straightforward, and for arbitrarily chosen parameters of the QP, the system trajectories may enter states at which the QP either eventually becomes infeasible, or may not achieve desired performance. In this work, we pose the control synthesis problem as a differential policy whose parameters are optimized for performance over a time horizon at high level, thus resulting in a bi-level optimization routine. In the absence of knowledge of the set of feasible parameters, we develop a Recursive Feasibility Guided Gradient Descent approach for updating the parameters of QP so that the new solution performs at least as well as previous solution. By considering the dynamical system as a directed graph over time, this work presents a novel way of optimizing performance of a QP controller over a time horizon for multiple CBFs by (1) using the gradient of its solution with respect to its parameters by employing sensitivity analysis, and (2) backpropagating these as well as system dynamics gradients to update parameters while maintaining feasibility of QPs.",
        "primary_area": "",
        "author": "Hardik Parwana;Dimitra Panagou;Hardik Parwana;Dimitra Panagou",
        "authorids": "/37089227815;/37403362000;/37089227815;/37403362000",
        "aff": "Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Aerospace Engineering, Robotics Institute, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812398/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=162236109876643255&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811801",
        "title": "Reducing Tactile Sim2Real Domain Gaps via Deep Texture Generation Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently simulation methods have been developed for optical tactile sensors to enable the Sim2Real learning, i.e., first training models in simulation before deploying them on a real robot. However, some artefacts in real objects are unpredictable, such as imperfections caused by fabrication processes, or scratches by natural wear and tear, and thus cannot be represented in the simulation, resulting in a significant gap between the simulated and real tactile images. To address this Sim2Real gap, we propose a novel texture generation network to map the simulated images into photorealistic tactile images that resemble a real sensor contacting a real imperfect object. Each simulated tactile image is first divided into two types of regions: areas that are in contact with the object and areas that are not. The former is applied with generated textures learned from real textures in the real tactile images, whereas the latter maintains its appearance as when the sensor is not in contact with any object. This makes sure that the artefacts are only applied to deformed regions of the sensor. Our extensive experiments show that the proposed texture generation network can generate realistic artefacts on the deformed regions of the sensor, while avoiding leaking the textures into areas of no contact. Quantitative experiments further reveal that when using the adapted images generated by our proposed network for a Sim2Real classification task, the drop in accuracy caused by the Sim2Real gap is reduced from 38.43% to merely 0.81%. As such, this work has potential to accelerate the Sim2Real learning for robotic tasks requiring tactile sensing.",
        "primary_area": "",
        "author": "Tudor Jianu;Daniel Fernandes Gomes;Shan Luo;Tudor Jianu;Daniel Fernandes Gomes;Shan Luo",
        "authorids": "/37089448075;/37088689978;/37085478830;/37089448075;/37088689978;/37085478830",
        "aff": "Department of Computer Science, University of Liverpool, Liverpool, United Kingdom; Department of Computer Science, University of Liverpool, Liverpool, United Kingdom; Department of Engineering, King's College London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811801/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9442706200364582024&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Liverpool;King's College London",
        "aff_unique_dep": "Department of Computer Science;Department of Engineering",
        "aff_unique_url": "https://www.liverpool.ac.uk;https://www.kcl.ac.uk",
        "aff_unique_abbr": "Liv Uni;KCL",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Liverpool;London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812052",
        "title": "Refactoring ISP for High-Level Vision Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "The image signal processing (ISP) pipeline, which transforms raw sensor measurement to a color image, is composed of a sequence of processing modules. Traditionally, the ISP pipeline is manually tuned by experts for human perception. The resulting handcrafted ISP configuration does not necessarily benefit the downstream high-level vision tasks. To mitigate these problems, this paper presents a simple yet effective framework based on Evolutionary Algorithm to search for a set of compact ISP configurations for high-level vision tasks. In particular, we encode ISP structure into a binary string and ISP parameters into a set of float numbers. Then we jointly optimize them with task-specific loss and ISP computation budgets (e.g., running time) through solving a nonlinear multi-objective optimization problem. By mutating the configurations of the ISP pipeline, we are able to remove redundant modules and design an ISP with both low cost and high accuracy. We validate the proposed method on extreme noisy and low-light raw images, and experimental results show that our framework can help find effective and efficient ISP configurations for both object detection and semantic segmentation tasks. We further provide a detailed analysis on the importance of different modules in the ISP configurations, which benefits the design of ISP for downstream tasks in the future.",
        "primary_area": "",
        "author": "Yongjie Shi;Songjiang Li;Xu Jia;Jianzhuang Liu;Yongjie Shi;Songjiang Li;Xu Jia;Jianzhuang Liu",
        "authorids": "/37086160371;/37089014060;/37088217934;/37279465500;/37086160371;/37089014060;/37088217934;/37279465500",
        "aff": "Noah's Ark Lab, Huawei Technologies, Shenzhen, China; Noah's Ark Lab, Huawei Technologies, Shenzhen, China; School of Artificial Intelligence, Dalian University of Technology, Dalian, China; Noah's Ark Lab, Huawei Technologies, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812052/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4426827919581213064&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Huawei;Dalian University of Technology",
        "aff_unique_dep": "Noah's Ark Lab;School of Artificial Intelligence",
        "aff_unique_url": "https://www.huawei.com;http://en.dlut.edu.cn/",
        "aff_unique_abbr": "Huawei;DUT",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Shenzhen;Dalian",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811608",
        "title": "Regulations Aware Motion Planning for Autonomous Surface Vessels in Urban Canals",
        "track": "main",
        "status": "Poster",
        "abstract": "In unstructured urban canals, regulation-aware interactions with other vessels are essential for collision avoidance and social compliance. In this paper, we propose a regulations aware motion planning framework for Autonomous Surface Vessels (ASVs) that accounts for dynamic and static obstacles. Our method builds upon local model predictive contouring control (LMPCC) to generate motion plans satisfying kino-dynamic and collision constraints in real-time while including regulation awareness. To incorporate regulations in the planning stage, we propose a cost function encouraging compliance with rules describing interactions with other vessels similar to COLlision avoidance REGulations at sea (COLREGs). These regulations are essential to make an ASV behave in a predictable and socially compliant manner with regard to other vessels. We compare the framework against baseline methods and show more effective regulation-compliant avoidance of moving obstacles with our motion planner. Additionally, we present experimental results in an outdoor environment.",
        "primary_area": "",
        "author": "Jitske de Vries;Elia Trevisan;Jules van der Toorn;Tuhin Das;Bruno Brito;Javier Alonso-Mora;Jitske de Vries;Elia Trevisan;Jules van der Toorn;Tuhin Das;Bruno Brito;Javier Alonso-Mora",
        "authorids": "/37089448259;/37089446928;/37089450750;/37089446828;/37086963867;/38271697300;/37089448259;/37089446928;/37089450750;/37089446828;/37086963867;/38271697300",
        "aff": "Department of Cognitive Robotics, Delft University of Technology, Delft, The Netherlands; Department of Cognitive Robotics, Delft University of Technology, Delft, The Netherlands; Department of Cognitive Robotics, Delft University of Technology, Delft, The Netherlands; Department of Cognitive Robotics, Delft University of Technology, Delft, The Netherlands; Department of Cognitive Robotics, Delft University of Technology, Delft, The Netherlands; Department of Cognitive Robotics, Delft University of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811608/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3848745306280085415&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Department of Cognitive Robotics",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9812128",
        "title": "Reinforcement Learning as a Method for Tuning CPG Controllers for Underwater Multi-Fin Propulsion",
        "track": "main",
        "status": "Poster",
        "abstract": "CPG-Based oscillator networks are increasingly being used to drive multi-limbed robots. To produce effective gaits with these networks, the relationship between the CPG parameters and the characteristics of the gait must be determined. However, due to the nonlinear nature of the oscillators, this relationship is challenging to ascertain. In this work a reinforcement learning algorithm is used to determine the CPG parameters that produce propulsively beneficial kinematics in a multi-fin underwater robot. Due to the high computational cost in creating high fidelity simulations of underwater systems, an alternate method using a low fidelity simulation is explored. To better simulate the dynamics of a two-finned swimming robot a thorough force sweep is conducted on the subject robot in a controlled environment. The resulting force data is used as the dynamic information in a simple simulation. This method allows for the learning of CPG weight settings that produce desired kinematic operating conditions and their resulting forces in simulation. Using this method, when the learned CPG parameters were applied directly to the physical robot, the robot executed the same desired kinematics and forces as expected from simulation with no additional learning needed.",
        "primary_area": "",
        "author": "Anthony Drago;Gabe Carryon;James Tangorra;Anthony Drago;Gabe Carryon;James Tangorra",
        "authorids": "/37089449476;/38228822900;/37427102300;/37089449476;/38228822900;/37427102300",
        "aff": "Anthony Drago; Gabe Carryon; James Tangorra",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812128/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16322788117204442677&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9811911",
        "title": "Reinforcement Learning for Picking Cluttered General Objects with Dense Object Descriptors",
        "track": "main",
        "status": "Poster",
        "abstract": "Picking cluttered general objects is a challenging task due to the complex geometries and various stacking configurations. Many prior works utilize pose estimation for picking, but pose estimation is difficult on cluttered objects. In this paper, we propose Cluttered Objects Descriptors (CODs), a dense cluttered objects descriptor which can represent rich object structures, and use the pre-trained CODs network along with its intermediate outputs to train a picking policy. Additionally, we train the policy with reinforcement learning, which enable the policy to learn picking without supervision. We conduct experiments to demonstrate that our CODs is able to consistently represent seen and unseen cluttered objects, which allowed for the picking policy to robustly pick cluttered general objects. The resulting policy can pick 96.69% of unseen objects in our experimental environment that are twice as cluttered as the training scenarios.",
        "primary_area": "",
        "author": "Hoang\u2013Giang Cao;Weihao Zeng;I\u2013Chen Wu;Hoang\u2013Giang Cao;Weihao Zeng;I\u2013Chen Wu",
        "authorids": "/37089449331;/37089449340;/37089448023;/37089449331;/37089449340;/37089448023",
        "aff": "Research Center for IT Innovation, Academia Sinica, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Taiwan; Research Center for IT Innovation, Academia Sinica, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811911/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12313842405196678237&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Academia Sinica;National Yang Ming Chiao Tung University",
        "aff_unique_dep": "Research Center for IT Innovation;Department of Computer Science",
        "aff_unique_url": "https://www.sinica.edu.tw;https://www.nctu.edu.tw",
        "aff_unique_abbr": "AS;NYCU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812263",
        "title": "Relative Distributed Formation and Obstacle Avoidance with Multi-agent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent formation as well as obstacle avoid-ance is one of the most actively studied topics in the field of multi-agent systems. Although some classic controllers like model predictive control (MPC) and fuzzy control achieve a certain measure of success, most of them require precise global information which is not accessible in harsh environments. On the other hand, some reinforcement learning (RL) based approaches adopt the leader-follower structure to organize different agents' behaviors, which sacrifices the collaboration between agents thus suffering from bottlenecks in maneuver-ability and robustness. In this paper, we propose a distributed formation and obstacle avoidance method based on multi-agent reinforcement learning (MARL). Agents in our system only utilize local and relative information to make decisions and control themselves distributively, and will reorganize themselves into a new topology quickly in case that any of them is dis-connected. Our method achieves better performance regarding formation error, formation convergence rate and on-par success rate of obstacle avoidance compared with baselines (both classic control methods and another RL-based method). The feasibility of our method is verified by both simulation and hardware implementation with Ackermann-steering vehicles.",
        "primary_area": "",
        "author": "Yuzi Yan;Xiaoxiang Li;Xinyou Qiu;Jiantao Qiu;Jian Wang;Yu Wang;Yuan Shen;Yuzi Yan;Xiaoxiang Li;Xinyou Qiu;Jiantao Qiu;Jian Wang;Yu Wang;Yuan Shen",
        "authorids": "/37089448164;/37087031193;/37088445782;/37085859616;/37406476300;/37089263227;/37400482800;/37089448164;/37087031193;/37088445782;/37085859616;/37406476300;/37089263227;/37400482800",
        "aff": "Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Shanghai AI Laboratory, Shanghai, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812263/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10737013384359109738&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "Tsinghua University;Shanghai AI Laboratory",
        "aff_unique_dep": "Department of Electronic Engineering;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.shanghaiailab.com",
        "aff_unique_abbr": "THU;SAIL",
        "aff_campus_unique_index": "0;0;0;1;0;0;0",
        "aff_campus_unique": "Beijing;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812207",
        "title": "Rendering Virtual Inertia in Haptic Interfaces: Analysis and Limitations",
        "track": "main",
        "status": "Poster",
        "abstract": "Virtual environments designed for haptic applications are usually rendered as a combination of spring and damper elements. The resulting haptic experience can be greatly enhanced by also adding virtual inertia, for example when interacting with mobile virtual objects. This paper analyzes the impact of implementing virtual inertia on haptic rendering stability. It describes the methodology followed to identify the physical inertia of a mechanism, to derive the acceleration from position, and the implications of this process on stability. Main results show how digital filtering and internal flexibility of the device affect the expected uncoupled stability region.",
        "primary_area": "",
        "author": "Jorge Juan Gil;Axier Ugartemendia;I\u00f1aki D\u00edaz;Jorge Juan Gil;Axier Ugartemendia;I\u00f1aki D\u00edaz",
        "authorids": "/37275210100;/37087705786;/37587577000;/37275210100;/37087705786;/37587577000",
        "aff": "University of Navarra, Tecnun - School of Engineering, Donostia / San Sebasti\u00e1n, Spain; CEIT-Basque Research and Technology Alliance (BRTA), Donostia / San Sebasti\u00e1n, Spain; CEIT-Basque Research and Technology Alliance (BRTA), Donostia / San Sebasti\u00e1n, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812207/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13419802133243886602&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Navarra;CEIT-Basque Research and Technology Alliance",
        "aff_unique_dep": "Tecnun - School of Engineering;",
        "aff_unique_url": "https://www.unav.edu;",
        "aff_unique_abbr": "UNAV;BRTA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Donostia / San Sebasti\u00e1n",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9811881",
        "title": "ReorientBot: Learning Object Reorientation for Specific-Posed Placement",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots need the capability of placing objects in arbitrary, specific poses to rearrange the world and achieve various valuable tasks. Object reorientation plays a crucial role in this as objects may not initially be oriented such that the robot can grasp and then immediately place them in a specific goal pose. In this work, we present a vision-based manipulation system, ReorientBot, which consists of 1) visual scene understanding with pose estimation and volumetric reconstruction using an onboard RGB-D camera; 2) learned waypoint selection for successful and efficient motion generation for reorientation; 3) traditional motion planning to generate a collision-free trajectory from the selected waypoints. We evaluate our method using the YCB objects in both simulation and the real world, achieving 93% overall success, 81% improvement in success rate, and 22% improvement in execution time compared to a heuristic approach. We demonstrate extended multi-object rearrangement showing the general capability of the system.",
        "primary_area": "",
        "author": "Kentaro Wada;Stephen James;Andrew J. Davison;Kentaro Wada;Stephen James;Andrew J. Davison",
        "authorids": "/37086073523;/37087233054;/37293837200;/37086073523;/37087233054;/37293837200",
        "aff": "Dyson Robotics Laboratory, Imperial College London; Dyson Robotics Laboratory, Imperial College London; Dyson Robotics Laboratory, Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811881/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18123216163666695327&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dyson Robotics Laboratory",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812394",
        "title": "RepAr-Net: Re-Parameterized Encoders and Attentive Feature Arsenals for Fast Video Denoising",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time video denoising finds applications in several fields like mobile robotics, satellite television, and surveillance systems. Traditional denoising approaches are more common in such systems than their deep learning-based counterparts despite their inferior performance. The large size and heavy computational requirements of neural network-based denoising models pose a serious impediment to their deployment in real-time applications. In this paper, we propose RepAr-Net, a simple yet efficient architecture for fast video de noising. We propose to use temporally separable encoders to generate feature maps called arsenals that can be cached for reuse. We also incorporate re-parameterizable blocks that improve the representative power of the network without affecting the run-time. We benchmark our model on the Set-8 and 2017 DAVIS-Test datasets. Our model achieves state-of-the-art results with up to 29.62% improvement in PSNR and a 50% decrease in run times over existing methods. Our codes are open-sourced at: github.com/spider-tronix/RepAr-Net.",
        "primary_area": "",
        "author": "S P Sharan;Adithya K Krishna;A Siddharth Rao;Varun P Gopi;S P Sharan;Adithya K Krishna;A Siddharth Rao;Varun P Gopi",
        "authorids": "/37085774993;/37088356803;/37089449935;/37546023500;/37085774993;/37088356803;/37089449935;/37546023500",
        "aff": "Department of Electronics and Communication Engineering, National Institute of Technology Tiruchirappalli, India; Department of Electronics and Communication Engineering, National Institute of Technology Tiruchirappalli, India; Department of Electrical and Electronics Engineering, National Institute of Technology Tiruchirappalli, India; Department of Electronics and Communication Engineering, National Institute of Technology Tiruchirappalli, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812394/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17106066938577198676&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Technology Tiruchirappalli",
        "aff_unique_dep": "Department of Electronics and Communication Engineering",
        "aff_unique_url": "https://www.nitt.edu",
        "aff_unique_abbr": "NIT Trichy",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9812232",
        "title": "Repeated Jumping with the REBOund: Self-Righting Jumping Robot Leveraging Bistable Origami-Inspired Design",
        "track": "main",
        "status": "Poster",
        "abstract": "Repeated jumping is crucial to the mobility of jumping robots. In this paper, we extend upon the REBOund jumping robot design, an origami-inspired jumping robot that uses the Reconfigurable Expanding Bistable Origami (REBO) pattern as its body. The robot design takes advantage of the pattern's bistability to jump with controllable timing. For jump repeatedly, we also add self-righting legs that utilize a single motor actuation mechanism. We describe a dynamic model that captures the compression of the REBO pattern and the REBOund self-righting process and compared it to the physical robot. Our experiments show that the REBOund is able to successfully self-right and jump repeatedly over tens of jumps.",
        "primary_area": "",
        "author": "Yuchen Sun;Joanna Wang;Cynthia Sung;Yuchen Sun;Joanna Wang;Cynthia Sung",
        "authorids": "/37089450786;/37089450810;/37086639646;/37089450786;/37089450810;/37086639646",
        "aff": "General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania, Philadelphia, PA, USA; General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania, Philadelphia, PA, USA; General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812232/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6863915855528453954&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "General Robotics, Automation, Sensing & Perception (GRASP) Lab",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812323",
        "title": "Repeated Robot-Assisted Unilateral Stiffness Perturbations Result in Significant Aftereffects Relevant to Post-Stroke Gait Rehabilitation",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to hemiparesis, stroke survivors frequently develop a dysfunctional gait that is often characterized by an overall decrease in walking speed and a unilateral decrease in step length. With millions currently affected by this dys-functional gait, robust and effective rehabilitation protocols are needed. Although robotic devices have been used in numerous rehabilitation protocols for gait, the lack of significant afteref-fects that translate to effective therapy makes their application still questionable. This paper proposes a novel type of robot-assisted intervention that results in significant aftereffects that last much longer than any other previous study. With the utilization of a novel robotic device, the Variable Stiffness Treadmill (VST), the stiffness of the walking surface underneath one leg is decreased for a number of steps. This unilateral stiffness perturbation results in a significant aftereffect that is both useful for stroke rehabilitation and often lasts for over 200 gait cycles after the intervention has concluded. More specifically, the aftereffect created is an increase in both left and right step lengths, with the unperturbed step length increasing significantly more than the perturbed. These effects may be helpful in correcting two of the most common issues in post-stroke gait: overall decrease in walking speed and a unilateral shortened step length. The results of this work show that a robot-assisted therapy protocol involving repeated unilateral stiffness perturbations can lead to a more permanent and effective solution to post-stroke gait.",
        "primary_area": "",
        "author": "Vaughn Chambers;Panagiotis Artemiadis;Vaughn Chambers;Panagiotis Artemiadis",
        "authorids": "/37088848452;/38495840200;/37088848452;/38495840200",
        "aff": "Mechanical Engineering Department, University of Delaware, Newark, DE, USA; Mechanical Engineering Department, University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812323/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17472611910484921492&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811627",
        "title": "Reproduction of Human Demonstrations with a Soft-Robotic Arm based on a Library of Learned Probabilistic Movement Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we introduce a novel technique that aims to control a two-module bio-inspired soft-robotic arm in order to qualitatively reproduce human demonstrations. The main idea behind the proposed methodology is based on the assumption that a complex trajectory can be derived from the composition and asynchronous activation of learned parameterizable simple movements constituting a knowledge base. The present work capitalises on recent research progress in Movement Primitive (MP) theory in order to initially build a library of Probabilistic MPs (ProMPs), and subsequently to compute on the fly their proper combination in the task space resulting in the requested trajectory. At the same time, a model learning method is assigned with the task to approximate the inverse kinematics, while a replanning procedure handles the sequential and/or parallel ProMPs' asynchronous activation. Taking advantage of the mapping at the primitive-level that the ProMP framework provides, the composition is transferred into the actuation space for execution. The proposed control architecture is experimentally evaluated on a real soft-robotic arm, where its capability to simplify the trajectory control task for robots of complex unmodeled dynamics is exhibited.",
        "primary_area": "",
        "author": "Paris Oikonomou;Athanasios Dometios;Mehdi Khamassi;Costas S. Tzafestas;Paris Oikonomou;Athanasios Dometios;Mehdi Khamassi;Costas S. Tzafestas",
        "authorids": "/37088507451;/37085837403;/37085730247;/37296005200;/37088507451;/37085837403;/37085730247;/37296005200",
        "aff": "School of Electrical and Computer Engineering, National Technical University of Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Greece; Sorbonne Universit\u00e9, CNRS, Institute of Intelligent Systems and Robotics, Paris, France; School of Electrical and Computer Engineering, National Technical University of Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811627/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10236358096414462531&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "National Technical University of Athens;Sorbonne Universit\u00e9",
        "aff_unique_dep": "School of Electrical and Computer Engineering;Institute of Intelligent Systems and Robotics",
        "aff_unique_url": "https://www.ntua.gr;https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "NTUA;Sorbonne U",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Paris",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Greece;France"
    },
    {
        "id": "9811850",
        "title": "Resolution-Optimal Motion Planning for Steerable Needles",
        "track": "main",
        "status": "Poster",
        "abstract": "Medical steerable needles can follow 3D curvilinear trajectories inside body tissue, enabling them to move around critical anatomical structures and precisely reach clinically significant targets in a minimally invasive way. Automating needle steering, with motion planning as a key component, has the potential to maximize the accuracy, precision, speed, and safety of steerable needle procedures. In this paper, we introduce the first resolution-optimal motion planner for steerable needles that offers excellent practical performance in terms of runtime while simultaneously providing strong theoretical guarantees on completeness and the global optimality of the motion plan in finite time. Compared to state-of-the-art steerable needle motion planners, simulation experiments on realistic scenarios of lung biopsy demonstrate that our proposed planner is faster in generating higher-quality plans while incorporating clinically relevant cost functions. This indicates that the theoretical guarantees of the proposed planner have a practical impact on the motion plan quality, which is valuable for computing motion plans that minimize patient trauma.",
        "primary_area": "",
        "author": "Mengyu Fu;Kiril Solovey;Oren Salzman;Ron Alterovitz;Mengyu Fu;Kiril Solovey;Oren Salzman;Ron Alterovitz",
        "authorids": "/37086578786;/37085671184;/37077497700;/37320259800;/37086578786;/37085671184;/37077497700;/37320259800",
        "aff": "Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Computer Science Department, Technion - Israel Institute of Technology, Israel; Computer Science Department, Technion - Israel Institute of Technology, Israel; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811850/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3373703210790270492&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of North Carolina at Chapel Hill;Technion - Israel Institute of Technology",
        "aff_unique_dep": "Department of Computer Science;Computer Science Department",
        "aff_unique_url": "https://www.unc.edu;https://www.technion.ac.il",
        "aff_unique_abbr": "UNC Chapel Hill;Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chapel Hill;",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "9812039",
        "title": "Rethinking LiDAR Object Detection in adverse weather conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR sensors are becoming crucial for achieving higher levels of autonomy. With the current sensor technology, LiDAR sensors are still susceptible to erroneous measurements in adverse weather conditions due to weather artifacts observed in the point cloud data. In this work, we analyze the performance of deep learning LiDAR object detectors in adverse weather conditions. We study the under-researched albeit crucial aspect of deep learning - the size and the content of the training data, as we believe that efforts in data curation bring more benefit than often preferred complex algorithmic enhancements. We argue that with sufficient data, learning-based object detectors are inherently capable of distinguishing between points from a true object and weather-induced artifacts in an end-to-end manner, thus, making explicit, handcrafted and computationally expensive point cloud prefiltering steps obsolete. We corroborate our hypothesis by conducting experiments on a variety of LiDAR object detection architectures over two subsets of training data - one comprising of all weather conditions and the other one comprising of only clear conditions. Contrary to popular belief that object detectors need to be trained on data from adverse weather conditions to be performant in adverse weather, we show that training on datasets with a higher number of annotated objects, predominantly acquired in clear conditions, is sufficient to achieve almost similar or sometimes better KPIs across all weather conditions. This makes the data collection more accessible and convenient compared to adverse weather conditions that are often hardly accessible (e.g., heavy snow and fog). Finally, our proposed methodology streamlines the LiDAR perception pipeline in the direction of keeping well-known end-to-end trainable architectures, removing additional pre-processing blocks that are often handcrafted and bring an additional computational cost.",
        "primary_area": "",
        "author": "Teja Vattem;George Sebastian;Luka Lukic;Teja Vattem;George Sebastian;Luka Lukic",
        "authorids": "/37089016602;/37089017522;/37089141489;/37089016602;/37089017522;/37089141489",
        "aff": "Hyundai Mobis Technical Center Europe (MTCE), Frankfurt, Germany; Hyundai Mobis Technical Center Europe (MTCE), Frankfurt, Germany; Hyundai Mobis Technical Center Europe (MTCE), Frankfurt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812039/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15176685631781958410&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hyundai Mobis Technical Center Europe",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.hyundaimobis.com",
        "aff_unique_abbr": "MTCE",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Frankfurt",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811785",
        "title": "Retriever: Point Cloud Retrieval in Compressed 3D Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "Most autonomous driving and robotic applications require retrieving map data around the vehicle's current location. Those maps can cover large areas and are often stored in a compressed form to save memory and allow for efficient transmission. In this paper, we address the problem of place recognition in a compressed point cloud map. To this end, we propose a novel deep neural network architecture that directly operates on a compressed feature representation produced by a compression encoder. This enables us to bypass compute-heavy decompression of the map and exploits the compact as well as descriptive nature of the compressed features. Additionally, we propose an alternative to the commonly used NetVLAD layer to aggregate local descriptors. Here, we utilize an attention mechanism between local features and a latent code. Our experiments suggest that this produces a more descriptive feature representation of the point clouds for place recognition. We experimentally validate all architectural choices we made by our ablation studies and compare our performance to other state-of-the-art baselines on two commonly used datasets.",
        "primary_area": "",
        "author": "Louis Wiesmann;Rodrigo Marcuzzi;Cyrill Stachniss;Jens Behley;Louis Wiesmann;Rodrigo Marcuzzi;Cyrill Stachniss;Jens Behley",
        "authorids": "/37088802930;/37089239255;/37329668600;/37593243900;/37088802930;/37089239255;/37329668600;/37593243900",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; Department of Engineering Science, University of Oxford, UK; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811785/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8083493067433951990&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Bonn;University of Oxford",
        "aff_unique_dep": ";Department of Engineering Science",
        "aff_unique_url": "https://www.uni-bonn.de;https://www.ox.ac.uk",
        "aff_unique_abbr": "UBonn;Oxford",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "9812265",
        "title": "Roboethics as a Design Challenge: Lessons Learned from the Roboethics to Design and Development Competition",
        "track": "main",
        "status": "Poster",
        "abstract": "How do we make concrete progress towards de-signing robots that can navigate ethically sensitive contexts? Almost two decades after the word \u2018roboethics\u2019 was coined, translating interdisciplinary roboethics discussions into techni-cal design still remains a daunting task. This paper describes our first attempt at addressing these challenges through a roboethics-themed design competition. The design competition setting allowed us to (a) formulate ethical considerations as an engineering design task that anyone with basic programming skills can tackle; and (b) develop a prototype evaluation scheme that incorporates diverse normative perspectives of multiple stakeholders. The initial implementation of the competition was held online at the RO-MAN 2021 conference. The competition task involved programming a simulated mobile robot (TIAGo) that delivers items for individuals in the home environment, where many of these tasks involve ethically sensitive con-texts (e.g., an underage family member asks for an alcoholic drink). This paper outlines our experiences implementing the competition and the lessons we learned. We highlight design competitions as a promising mechanism to enable a new wave of roboethics research equipped with technical design solutions.",
        "primary_area": "",
        "author": "Jimin Rhim;Cheng Lin;Alexander Werner;Brandon DeHart;Vivian Qiang;Shalaleh Rismani;AJung Moon;Jimin Rhim;Cheng Lin;Alexander Werner;Brandon DeHart;Vivian Qiang;Shalaleh Rismani;AJung Moon",
        "authorids": "/37087120992;/37089450409;/38541778400;/38228243000;/37089448347;/37085422978;/37088901874;/37087120992;/37089450409;/38541778400;/38228243000;/37089448347;/37085422978;/37088901874",
        "aff": "Dept. of Electrical & Computer Engineering, McGill University, Montreal, Canada; Dept. of Electrical & Computer Engineering, McGill University, Montreal, Canada; Waterloo RoboHub, Faculty of Engineering, University of Waterloo, Waterloo, Canada; Waterloo RoboHub, Faculty of Engineering, University of Waterloo, Waterloo, Canada; Dept. of Epidemiology, Biostatistics, & Occupational Health, McGill University, Montreal, Canada; Dept. of Electrical & Computer Engineering, McGill University, Montreal, Canada; Dept. of Electrical & Computer Engineering, McGill University, Montreal, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812265/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6939475636524389358&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;0;0;0",
        "aff_unique_norm": "McGill University;University of Waterloo",
        "aff_unique_dep": "Dept. of Electrical & Computer Engineering;Faculty of Engineering",
        "aff_unique_url": "https://www.mcgill.ca;https://uwaterloo.ca",
        "aff_unique_abbr": "McGill;UW",
        "aff_campus_unique_index": "0;0;1;1;0;0;0",
        "aff_campus_unique": "Montreal;Waterloo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9811721",
        "title": "Robot Grasping through a Joint-Initiative Supervised Autonomy Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot grasping applications are faced with challenges and limitations leading to errors that affect their performance and accuracy. Although these errors are reduced in expensive industrial systems, low-cost robots are still prone to inaccurate perception and execution due to their limited hardware and software capabilities. To mitigate these challenges and limitations, this work develops a Joint-Initiative Supervised Autonomy (JISA) framework for robot grasping. In the proposed system, a human supervisor provides assistance to the robot's perception and planning modules, where the assistance is triggered by requests made by the robot based on its self confidence (SC) metric. Moreover, the human supervisor can also assist the robot in eliminating execution errors based on his/her situation awareness (SA). Through experimental validation, we show that including a human supervisor in the loop for grasping tasks in low-cost robots outperforms full autonomy. In fact, our proposed system showed a marked performance improvement by increasing the end-to-end success rate of the baseline approach, which we implemented JISA on, from 35.0% to 87.6%.",
        "primary_area": "",
        "author": "Abbas Sidaoui;Naseem Daher;Daniel Asmar;Abbas Sidaoui;Naseem Daher;Daniel Asmar",
        "authorids": "/37086576742;/37085823601;/37424435700;/37086576742;/37085823601;/37424435700",
        "aff": "Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon; Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon; Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811721/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:ymvsPGVqDOkJ:scholar.google.com/&scioq=Robot+Grasping+through+a+Joint-Initiative+Supervised+Autonomy+Framework&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "American University of Beirut",
        "aff_unique_dep": "Vision and Robotics Lab",
        "aff_unique_url": "https://www.aub.edu.lb",
        "aff_unique_abbr": "AUB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beirut",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Lebanon"
    },
    {
        "id": "9811725",
        "title": "Robot Learning Physical Object Properties from Human Visual Cues: A novel approach to infer the fullness level in containers",
        "track": "main",
        "status": "Poster",
        "abstract": "For collaborative tasks, involving handovers, humans are able to exploit visual, non-verbal cues, to infer physical object properties, like mass, to modulate their actions. In this paper, we investigate how the different levels of liquid inside a cup can be inferred from the observation of the movement of the person handling the cup. We model this mechanism from human experiments and incorporate it in an online human-to-robot handover. Finally, we provide a new dataset with human eye+head+hand motion data for human-to-human handovers and human pick-and-place of a cup with three levels of liquid: empty, half-full, and full of water. Our results show that it is possible to model (non-verbal) signals exchanged by humans during interaction and classify the level of water inside the cup being handed over.",
        "primary_area": "",
        "author": "Nuno Ferreira Duarte;Mirko Rakovi\u0107;Jos\u00e9 Santos-Victor;Nuno Ferreira Duarte;Mirko Rakovi\u0107;Jos\u00e9 Santos-Victor",
        "authorids": "/37086436863;/37705388700;/38274231800;/37086436863;/37705388700;/38274231800",
        "aff": "Vislab, Institute for Systems and Robotics, Instituto Superior Tecnico, Universidade de Lisboa, Portugal; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Vislab, Institute for Systems and Robotics, Instituto Superior Tecnico, Universidade de Lisboa, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811725/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=92562747924995941&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universidade de Lisboa;University of Novi Sad",
        "aff_unique_dep": "Institute for Systems and Robotics, Instituto Superior Tecnico;Faculty of Technical Sciences",
        "aff_unique_url": "https://www IST.edu.pt;https://www.uns.ac.rs",
        "aff_unique_abbr": "IST;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Novi Sad",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Portugal;Serbia"
    },
    {
        "id": "9811770",
        "title": "Robot Skill Adaptation via Soft Actor-Critic Gaussian Mixture Models",
        "track": "main",
        "status": "Poster",
        "abstract": "AA core challenge for an autonomous agent acting in the real world is to adapt its repertoire of skills to cope with its noisy perception and dynamics. To scale learning of skills to long-horizon tasks, robots should be able to learn and later refine their skills in a structured manner through trajectories rather than making instantaneous decisions individually at each time step. To this end, we propose the Soft Actor- Critic Gaussian Mixture Model (SAC-GMM), a novel hybrid approach that learns robot skills through a dynamical system and adapts the learned skills in their own trajectory distribution space through interactions with the environment. Our approach combines classical robotics techniques of learning from demonstration with the deep reinforcement learning framework and exploits their complementary nature. We show that our method utilizes sensors solely available during the execution of preliminarily learned skills to extract relevant features that lead to faster skill refinement. Extensive evaluations in both simulation and real-world environments demonstrate the effectiveness of our method in refining robot skills by leveraging physical interactions, high-dimensional sensory data, and sparse task completion rewards. Videos, code, and pre-trained models are available at http://sac-gmm.cs.uni-freiburg.de.",
        "primary_area": "",
        "author": "Iman Nematollahi;Erick Rosete-Beas;Adrian R\u00f6fer;Tim Welschehold;Abhinav Valada;Wolfram Burgard;Iman Nematollahi;Erick Rosete-Beas;Adrian R\u00f6fer;Tim Welschehold;Abhinav Valada;Wolfram Burgard",
        "authorids": "/37086495410;/37089427788;/37089447622;/37085678776;/38075825200;/37270485300;/37086495410;/37089427788;/37089447622;/37085678776;/38075825200;/37270485300",
        "aff": "University of Freiburg, Germany; University of Freiburg, Germany; University of Freiburg, Germany; University of Freiburg, Germany; University of Freiburg, Germany; University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811770/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6343489667773358304&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Freiburg",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-freiburg.de",
        "aff_unique_abbr": "UoF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812455",
        "title": "Robotic Autonomous Trolley Collection with Progressive Perception and Nonlinear Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous mobile manipulation robots that can collect trolleys are widely used to liberate human resources and fight epidemics. Most prior robotic trolley collection solutions only detect trolleys with 2D poses or are merely based on spe-cific marks and lack the formal design of planning algorithms. In this paper, we present a novel mobile manipulation system with applications in luggage trolley collection. The proposed system integrates a compact hardware design and a progressive perception and planning framework, enabling the system to efficiently and robustly collect trolleys in dynamic and complex environments. For perception, we first develop a 3D trolley detection method that combines object detection and keypoint estimation. Then, a docking process in a short distance is achieved with an accurate point cloud plane detection method and a novel manipulator design. On the planning side, we formulate the robot's motion planning under a nonlinear model predictive control framework with control barrier functions to improve obstacle avoidance capabilities while maintaining the target in the sensors' field of view at close distances. We demonstrate our design and framework by deploying the system on actual trolley collection tasks, and their effectiveness and robustness are experimentally validated. (Video 11Video demonstration: https://youtu.be/6SwjgGvRtno.)",
        "primary_area": "",
        "author": "Anxing Xiao;Hao Luan;Ziqi Zhao;Yue Hong;Jieting Zhao;Weinan Chen;Jiankun Wang;Max Q.-H. Meng;Anxing Xiao;Hao Luan;Ziqi Zhao;Yue Hong;Jieting Zhao;Weinan Chen;Jiankun Wang;Max Q.-H. Meng",
        "authorids": "/37088981835;/37089448105;/37087246176;/37089449136;/37089450222;/37086099846;/37086100720;/37274117000;/37088981835;/37089448105;/37087246176;/37089449136;/37089450222;/37086099846;/37086100720;/37274117000",
        "aff": "Department of Electronic and Electrical Engineering of Southern, Shenzhen Key Laboratory of Robotics Perception and Intelligence, University of Science and Technology in Shenzhen, China; Department of Electronic and Electrical Engineering of Southern, Shenzhen Key Laboratory of Robotics Perception and Intelligence, University of Science and Technology in Shenzhen, China; Department of Electronic and Electrical Engineering of Southern, Shenzhen Key Laboratory of Robotics Perception and Intelligence, University of Science and Technology in Shenzhen, China; Department of Electronic and Electrical Engineering of Southern, Shenzhen Key Laboratory of Robotics Perception and Intelligence, University of Science and Technology in Shenzhen, China; Department of Electronic and Electrical Engineering of Southern, Shenzhen Key Laboratory of Robotics Perception and Intelligence, University of Science and Technology in Shenzhen, China; Department of Electronic and Electrical Engineering of Southern, Shenzhen Key Laboratory of Robotics Perception and Intelligence, University of Science and Technology in Shenzhen, China; Department of Electronic and Electrical Engineering of Southern, Shenzhen Key Laboratory of Robotics Perception and Intelligence, University of Science and Technology in Shenzhen, China; Shenzhen Research Institute of the Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812455/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5817519878956156905&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;1",
        "aff_unique_norm": "University of Science and Technology in Shenzhen;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic and Electrical Engineering;Shenzhen Research Institute",
        "aff_unique_url": "https://www.usts.edu.cn;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "USTS;CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812246",
        "title": "Robotic Cell Manipulation for Blastocyst Biopsy",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft tissue cutting is used for incision, separation and removal of tissues or cells. Due to high deformation of soft tissues resulting from their viscosity and elasticity, it is challenging to accurately cut the tissue along a desired path and control the force applied to the tissue for reducing invasiveness, especially at the microscale. This paper presents a robotic biopsy system for cutting and collecting trophectoderm cells from a highly deformable blastocyst. The system, for the first time, enables TE cell junction detection for laser ablation throughout the blastocyst biopsy process by using a convolutional neural network. The overall detection error was 2.13% in every 1,000 cell junctions with position RMSE of 1.63\\ \\mu \\mathrm{m}\\pm 0.29\\ \\mu \\mathrm{m}1.63\\ \\mu \\mathrm{m}\\pm 0.29\\ \\mu \\mathrm{m}. A dynamics model was developed to describe the motion of the trophectoderm cells inside a biopsy micropipette. Based on this model, an adaptive control method was developed for trophectoderm cell aspiration and positioning inside the biopsy micropipette. Experimental results revealed that the controller was capable of effectively compensating for the cell positioning error by updating the varying system parameters according to the adaptation law. The success rate was 100%, the cell aggregate positioning accuracy was \\pm 1\\ \\mu \\mathrm{m}\\pm 1\\ \\mu \\mathrm{m}, the average settling time was 2 s, and the largest overshoot was 4.3\\ \\mu \\mathrm{m}4.3\\ \\mu \\mathrm{m}. Compared to manual blastocyst biopsy, the robotic biopsy system shortened the blastocyst's recovery time (35 min vs. 50 min) which indicates lower invasiveness.",
        "primary_area": "",
        "author": "Guanqiao Shan;Zhuoran Zhang;Changsheng Dai;Hang Liu;Xian Wang;Wenkun Dou;Yu Sun;Guanqiao Shan;Zhuoran Zhang;Changsheng Dai;Hang Liu;Xian Wang;Wenkun Dou;Yu Sun",
        "authorids": "/37086937807;/37085810781;/37086292072;/37089448862;/37086017090;/37089296453;/37309639100;/37086937807;/37085810781;/37086292072;/37089448862;/37086017090;/37089296453;/37309639100",
        "aff": "Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON, Canada; Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON, Canada; Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON, Canada; Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON, Canada; Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON, Canada; Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON, Canada; Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812246/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9314366547668947325&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Department of Mechanical and Industrial Engineering",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812029",
        "title": "Robotic Manipulators Performing Smart Sanding Operation: A Vibration Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design of a novel expert system for robotic manipulators performing sanding tasks on work surfaces. The expert system adjusts the velocity of the robotic manipulator based on the observed surface quality. These observation are obtained by an analysis of the raw force data provided by a force-torque sensor at the end-effector level. The expert system consists of two governing control laws that act in parallel, a variable velocity generation law and a pose regulation-based law. The variable velocity law regulates the velocity of the manipulator along a set path, in the tangent direction, based on an analysis of the frequency and amplitude of the force signal generated during the sanding process. The pose regulation-based law drives the manipulator in the bi-normal and rotational direction, ensuring the manipulators remain on the sanding path with the desired orientation. The proposed strategy is experimentally evaluated using the UR5e collaborative robotic manipulator sanding wood and metal panels. The obtained results show that such an approach is beneficial to ensure accurate contact between the sanding tool and the working environment, robust path tracking, and smart sanding.",
        "primary_area": "",
        "author": "Joshua Nguyen;Manuel Bailey;Ignacio Carlucho;Corina Barbalata;Joshua Nguyen;Manuel Bailey;Ignacio Carlucho;Corina Barbalata",
        "authorids": "/37089450813;/37089303554;/37085995376;/37085557718;/37089450813;/37089303554;/37085995376;/37085557718",
        "aff": "Department of Mechanical & Industrial Engineering, Louisiana State University, Baton Rouge, USA; Department of Mechanical & Industrial Engineering, Louisiana State University, Baton Rouge, USA; Department of Mechanical & Industrial Engineering, Louisiana State University, Baton Rouge, USA; Department of Mechanical & Industrial Engineering, Louisiana State University, Baton Rouge, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812029/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10551794554538185168&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Louisiana State University",
        "aff_unique_dep": "Department of Mechanical & Industrial Engineering",
        "aff_unique_url": "https://www.lsu.edu",
        "aff_unique_abbr": "LSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Baton Rouge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812428",
        "title": "Robotically-Aligned Optical Coherence Tomography with Gaze Tracking for Live Image Montaging of the Retina",
        "track": "main",
        "status": "Poster",
        "abstract": "Optical coherence tomography (OCT) has revolutionized diagnostics in ophthalmology. However, it requires pa-tient cooperation to fixate on multiple targets and stabilize their head utilizing both chin and forehead rests. Patient cooperation is particularly important for image montaging, where patients are asked to fixate on multiple targets to sequentially image different regions of interest on the retina. These individual volumes are then combined into a single large field of view volume. To automate the OCT image acquisition process, we previously developed a robot-mounted OCT scanner that auto-aligned with the retinal region of interest while compensating for subject motion. We utilized this system to self-align at multiple regions-of-interest and acquire stabilized volumes. We then montaged volume projections into a larger field of view image. The system tracked the 3D location of the subject's eye as well as their gaze orientation using a combination of face and pupil tracking cameras. We demonstrated automated OCT acquisition for live image montaging on free-standing subjects and evaluated the consistency of our live volumetric mapping on human subject data. Our results demonstrate that the system not only stabilized images, but also provided sufficient control of region-of-interest specific alignment to automatically acquire and montage OCT images, synthetically increasing the system's field of view by 20^{\\circ}20^{\\circ}.",
        "primary_area": "",
        "author": "Pablo Ortiz;Mark Draelos;Amit Narawane;Ryan P. McNabb;Anthony N. Kuo;Joseph A. Izatt;Pablo Ortiz;Mark Draelos;Amit Narawane;Ryan P. McNabb;Anthony N. Kuo;Joseph A. Izatt",
        "authorids": "/37086938347;/38505451100;/37089450691;/37086630493;/37086278811;/37281539700;/37086938347;/38505451100;/37089450691;/37086630493;/37086278811;/37281539700",
        "aff": "Department of Biomedical Engineering, Duke University, Durham, NC, USA; Department of Biomedical Engineering, Duke University, Durham, NC, USA; Department of Biomedical Engineering, Duke University, Durham, NC, USA; Department of Ophthalmology, Duke University Medical Center, Durham, NC, USA; Department of Ophthalmology, Duke University Medical Center, Durham, NC, USA; Department of Biomedical Engineering, Duke University, Durham, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812428/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15686638071686053053&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "Department of Biomedical Engineering",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Durham",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811557",
        "title": "Robust Control Under Uncertainty via Bounded Rationality and Differential Privacy",
        "track": "main",
        "status": "Poster",
        "abstract": "The rapid development of affordable and compact high-fidelity sensors (e.g., cameras and LIDAR) allows robots to construct detailed estimates of their states and environments. However, the availability of such rich sensor information introduces two challenges: (i) the lack of analytic sensing models, which makes it difficult to design controllers that are robust to sensor failures, and (ii) the computational expense of processing the high-dimensional sensor information in real time. This paper addresses these challenges using the theory of differential privacy, which allows us to (i) design controllers with bounded sensitivity to errors in state estimates, and (ii) bound the amount of state information used for control (i.e., to impose decision-making under bounded rationality). The resulting framework approximates the separation principle and allows us to derive an upper-bound on the cost incurred with a faulty state estimator in terms of three quantities: the cost incurred using a perfect state estimator, the magnitude of state estimation errors, and the level of differential privacy. We demonstrate the efficacy of our framework numerically on different robotics problems, including nonlinear system stabilization and motion planning.",
        "primary_area": "",
        "author": "Vincent Pacelli;Anirudha Majumdar;Vincent Pacelli;Anirudha Majumdar",
        "authorids": "/37086293250;/37086027485;/37086293250;/37086027485",
        "aff": "Mechanical and Aerospace Engineering department, Princeton University, Princeton, NJ, USA; Mechanical and Aerospace Engineering department, Princeton University, Princeton, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811557/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3898691349729710298&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Princeton",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812013",
        "title": "Robust Impedance Control for Dexterous Interaction Using Fractal Impedance Controller with IK-Optimisation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust dynamic interactions are required to move robots in daily environments alongside humans. Optimisation and learning methods have been used to mimic and reproduce human movements. However, they are often not robust and their generalisation is limited. This work proposed a hierarchical control architecture for robot manipulators and provided capabilities of reproducing human-like motions during unknown interaction dynamics. Our results show that the reproduced end-effector trajectories can preserve the main characteristics of the initial human motion recorded via a motion capture system, and are robust against external perturbations. The data indicate that some detailed movements are hard to reproduce due to the physical limits of the hardware that cannot reach the same velocity recorded in human movements. Nevertheless, these technical problems can be addressed by using better hardware and our proposed algorithms can still be applied to produce imitated motions.",
        "primary_area": "",
        "author": "Carlo Tiseo;Quentin Rouxel;Zhibin Li;Michael Mistry;Carlo Tiseo;Quentin Rouxel;Zhibin Li;Michael Mistry",
        "authorids": "/37085404832;/37085642431;/37857029500;/37542865600;/37085404832;/37085642431;/37857029500;/37542865600",
        "aff": "Edinburgh Centre for Robotics, Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh, UK; Edinburgh Centre for Robotics, Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh, UK; Edinburgh Centre for Robotics, Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh, UK; Edinburgh Centre for Robotics, Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812013/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8617073355238148845&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Informatics",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812266",
        "title": "Robust Monocular Localization in Sparse HD Maps Leveraging Multi-Task Uncertainty Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust localization in dense urban scenarios using a low-cost sensor setup and sparse HD maps is highly relevant for the current advances in autonomous driving, but remains a challenging topic in research. We present a novel monocular localization approach based on a sliding-window pose graph that leverages predicted uncertainties for increased precision and robustness against challenging scenarios and per-frame failures. To this end, we propose an efficient multi-task uncertainty-aware perception module, which covers semantic segmentation, as well as bounding box detection, to enable the localization of vehicles in sparse maps, containing only lane borders and traffic lights. Further, we design differentiable cost maps that are directly generated from the estimated uncertainties. This opens up the possibility to minimize the reprojection loss of amorphous map elements in an association-free and uncertainty-aware manner. Extensive evaluation on the Lyft 5 dataset shows that, despite the sparsity of the map, our approach enables robust and accurate 6D localization in challenging urban scenarios using only monocular camera images and vehicle odometry.",
        "primary_area": "",
        "author": "K\u00fcrsat Petek;Kshitij Sirohi;Daniel B\u00fcscher;Wolfram Burgard;K\u00fcrsat Petek;Kshitij Sirohi;Daniel B\u00fcscher;Wolfram Burgard",
        "authorids": "/37088689752;/37088282357;/37086455193;/37270485300;/37088689752;/37088282357;/37086455193;/37270485300",
        "aff": "Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany; Department of Computer Science, University of Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812266/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8803631155620009321&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Freiburg",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uni-freiburg.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811812",
        "title": "Robust Pivoting: Exploiting Frictional Stability Using Bilevel Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Generalizable manipulation requires that robots be able to interact with novel objects and environment. This requirement makes manipulation extremely challenging as a robot has to reason about complex frictional interaction with uncertainty in physical properties of the object. In this paper, we study robust optimization for control of pivoting manipulation in the presence of uncertainties. We present insights about how friction can be exploited to compensate for the inaccuracies in the estimates of the physical properties during manipulation. In particular, we derive analytical expressions for stability margin provided by friction during pivoting manipulation. This margin is then used in a bilevel trajectory optimization algorithm to design a controller that maximizes this stability margin to provide robustness against uncertainty in physical properties of the object. We demonstrate our proposed method using a 6 DoF manipulator for manipulating several different objects.",
        "primary_area": "",
        "author": "Yuki Shirai;Devesh K. Jha;Arvind U. Raghunathan;Diego Romeres;Yuki Shirai;Devesh K. Jha;Arvind U. Raghunathan;Diego Romeres",
        "authorids": "/37086344073;/37072717800;/37401365500;/37086098761;/37086344073;/37072717800;/37401365500;/37086098761",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811812/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11257734801668028675&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of California, Los Angeles;Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;",
        "aff_unique_url": "https://www.ucla.edu;https://www.merl.com",
        "aff_unique_abbr": "UCLA;MERL",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Los Angeles;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812420",
        "title": "Robust Reinforcement Learning via Genetic Curriculum",
        "track": "main",
        "status": "Poster",
        "abstract": "Achieving robust performance is crucial when applying deep reinforcement learning (RL) in safety critical systems. Some of the state of the art approaches try to address the problem with adversarial agents, but these agents often require expert supervision to fine tune and prevent the adversary from becoming too challenging to the trainee agent. While other approaches involve automatically adjusting environment setups during training, they have been limited to simple environments where low-dimensional encodings can be used. Inspired by these approaches, we propose genetic curriculum, an algorithm that automatically identifies scenarios in which the agent currently fails and generates an associated curriculum to help the agent learn to solve the scenarios and acquire more robust behaviors. As a non-parametric optimizer, our approach uses a raw, non-fixed encoding of scenarios, reducing the need for expert supervision and allowing our algorithm to adapt to the changing performance of the agent. Our empirical studies show improvement in robustness over the existing state of the art algorithms, providing training curricula that result in agents being 2 - 8x times less likely to fail without sacrificing cumulative reward. We include an ablation study and share insights on why our algorithm outperforms prior approaches.",
        "primary_area": "",
        "author": "Yeeho Song;Jeff Schneider;Yeeho Song;Jeff Schneider",
        "authorids": "/37089448697;/37281084800;/37089448697;/37281084800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812420/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11385897267906103318&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811862",
        "title": "Robust Semantic Mapping and Localization on a Free-Flying Robot in Microgravity",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a system that uses semantic object detections to localize a microgravity free-flyer. Many applications require absolute localization in a known reference frame, such as the execution of waypoint trajectories defined by human operators. Classical geometric methods build a map of point features, which may not be able to be associated after lighting or environmental changes. By contrast, semantics remain invariant to changes up to the robustness of the detection algorithm and motion of the semantic objects. In this work, we describe our approaches for both offline semantic map generation as well as online localization against a semantic map, intended to run in real-time on the robot. We additionally demonstrate how our semantic localizer outperforms image-feature matching in some cases, and show the robustness of the algorithm to environmental changes. Crucially, we show in our experiments that when semantics are used to supplement point features, localization is always improved. To our knowledge, these experiments demonstrate the first use of learned semantics for localization on a free-flying robot in microgravity.",
        "primary_area": "",
        "author": "Ian D. Miller;Ryan Soussan;Brian Coltin;Trey Smith;Vijay Kumar;Ian D. Miller;Ryan Soussan;Brian Coltin;Trey Smith;Vijay Kumar",
        "authorids": "/37086928894;/37088229840;/37592328000;/37085701375;/37280341400;/37086928894;/37088229840;/37592328000;/37085701375;/37280341400",
        "aff": "GRASP Lab, University of Pennsylvania, Philadelphia, PA; NASA Ames Intelligent Robotics Group, Moffett Field, CA; NASA Ames Intelligent Robotics Group, Moffett Field, CA; NASA Ames Intelligent Robotics Group, Moffett Field, CA; GRASP Lab, University of Pennsylvania, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811862/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16588479270076022880&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of Pennsylvania;NASA Ames Research Center",
        "aff_unique_dep": "GRASP Lab;Intelligent Robotics Group",
        "aff_unique_url": "https://www.upenn.edu;https://www.nasa.gov/ames",
        "aff_unique_abbr": "UPenn;NASA Ames",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Philadelphia;Moffett Field",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812366",
        "title": "Robust and Accurate Multi-Agent SLAM with Efficient Communication for Smart Mobiles",
        "track": "main",
        "status": "Poster",
        "abstract": "In a long-term large-scenario application, the multi-agent collaborative SLAM is expected to improve the robustness and efficiency of executing tasks for mobile agents. In this paper, a multi-agent collaborative visual-inertial SLAM system is proposed based on a centralized client-server (CS) architecture, where the clients run on smart mobiles. In general, multi-agent collaborative SLAM relies on robust and precise experience sharing and efficient communication among agents. The experience sharing requires the place recognition with a high recall and accuracy, the precise estimation of transformation between looping frames, and the map fusion with globally consistency. To this end, we devise an enhanced geometric verification, a re-projection optimization based on the error-aware weighting strategy, and a strategy of flexible fusion to meet these requirements. In addition, the multi-agent collaborative SLAM needs to exchange abundant information, which requires the efficient communication. Therefore, we design a CS collaborative loop detection mechanism which is more robust to network transmission. We perform extensive experiments on the EuRoc dataset and in real environments. Experimental results show that the proposed system achieves better results than state-of-the-art methods. Furthermore, we demonstrate the stability of the proposed collaborative SLAM in real environments with a bandwidth of 7.55Mbps.",
        "primary_area": "",
        "author": "Jialing Liu;Kaiqi Chen;Ruyu Liu;Yanhong Yang;Zhenhua Wang;Jianhua Zhang;Jialing Liu;Kaiqi Chen;Ruyu Liu;Yanhong Yang;Zhenhua Wang;Jianhua Zhang",
        "authorids": "/37088570563;/37088570441;/37086354166;/37088405322;/37075914500;/37678556700;/37088570563;/37088570441;/37086354166;/37088405322;/37075914500;/37678556700",
        "aff": "College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; School of Information Science and Technology, Hangzhou Normal University, Hangzhou, China; School of Computer Science and Engineering, Tianjin University of Technology, Tianjin, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; School of Computer Science and Engineering, Tianjin University of Technology, Tianjin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812366/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3137106507276181823&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;2",
        "aff_unique_norm": "Zhejiang University of Technology;Hangzhou Normal University;Tianjin University of Technology",
        "aff_unique_dep": "College of Computer Science and Technology;School of Information Science and Technology;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.zjut.edu.cn;http://www.hgh.edu.cn;http://www.tjut.edu.cn",
        "aff_unique_abbr": "ZJUT;;TUT",
        "aff_campus_unique_index": "0;0;0;1;0;1",
        "aff_campus_unique": "Hangzhou;Tianjin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812333",
        "title": "Robust-by-Design Plans for Multi-Robot Pursuit-Evasion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies a multi-robot visibility-based pursuit-evasion problem in which a group of pursuer robots are tasked with detecting an evader within a two dimensional polygonal environment. The primary contribution is a novel formulation of the pursuit-evasion problem that modifies the pursuers' objective by requiring that the evader still be de-tected, even in spite of the failure of any single pursuer robot. This novel constraint, whereby two pursuers are required to detect an evader, has the benefit of providing redundancy to the search, should any member of the team become unresponsive, suffer temporary sensor disruption/failure, or otherwise become incapacitated. Existing methods, even those that are designed to respond to failures, rely on the pursuers to replan and update their search pattern to handle such occurrences. In contrast, the proposed formulation produces plans that are inherently tolerant of some level of disturbance. Building upon this new formulation, we introduce an augmented data structure for encoding the problem state and a novel sampling technique to ensure that the generated plans are robust to failures of any single pursuer robot. An implementation and simulation results illustrating the effectiveness of this approach are described.",
        "primary_area": "",
        "author": "Trevor Olsen;Nicholas M. Stiffler;Jason M. O'Kane;Trevor Olsen;Nicholas M. Stiffler;Jason M. O'Kane",
        "authorids": "/37089000508;/37947254000;/37279835400;/37089000508;/37947254000;/37279835400",
        "aff": "Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science, University of Dayton, Dayton, OH, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812333/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14241950548200113421&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of South Carolina;University of Dayton",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.sc.edu;https://www.udayton.edu",
        "aff_unique_abbr": "USC;UD",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Columbia;Dayton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812034",
        "title": "Runtime Detection of Executional Errors in Robot-Assisted Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite significant developments in the design of surgical robots and automated techniques for objective evaluation of surgical skills, there are still challenges in ensuring safety in robot-assisted minimally-invasive surgery (RMIS). This paper presents a runtime monitoring system for the detection of executional errors during surgical tasks through the analysis of kinematic data. The proposed system incorporates dual Siamese neural networks and knowledge of surgical context, including surgical tasks and gestures, their distributional similarities, and common error modes, to learn the differences between normal and erroneous surgical trajectories from small training datasets. We evaluate the performance of the error detection using Siamese networks compared to single CNN and LSTM networks trained with different levels of contextual knowledge and training data, using the dry-lab demonstrations of the Suturing and Needle Passing tasks from the JIGSAWS dataset. Our results show that gesture specific task nonspecific Siamese networks obtain micro F1 scores of 0.94 (Siamese-CNN) and 0.95 (Siamese-LSTM), and perform better than single CNN (0.86) and LSTM (0.87) networks. These Siamese networks also outperform gesture nonspecific task specific Siamese-CNN and Siamese-LSTM models for Suturing and Needle Passing.",
        "primary_area": "",
        "author": "Zongyu Li;Kay Hutchinson;Homa Alemzadeh;Zongyu Li;Kay Hutchinson;Homa Alemzadeh",
        "authorids": "/37089448451;/37088639509;/37601630800;/37089448451;/37088639509;/37601630800",
        "aff": "Department of Electrical and Computer Engineering (ECE), University of Virginia, Charlottesville, VA, USA; Department of Electrical and Computer Engineering (ECE), University of Virginia, Charlottesville, VA, USA; Department of Electrical and Computer Engineering (ECE), University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812034/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16797698088879530391&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812177",
        "title": "Runtime Safety Assurance for Learning-enabled Control of Autonomous Driving Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Providing safety guarantees for Autonomous Vehicle (AV) systems with machine-learning based controllers remains a challenging issue. In this work, we propose Simplex-Drive, a framework that can achieve runtime safety assurance for machine-learning enabled controllers of AVs. The proposed Simplex-Drive consists of an unverified Deep Reinforcement Learning (DRL)-based advanced controller (AC) that achieves desirable performance in complex scenarios, a Velocity-Obstacle (VO) based baseline safe controller (BC) with provably safety guarantees, and a verified mode management unit that monitors the operation status and switches the control authority between AC and BC based on safety-related conditions. We provide a formal correctness proof of Simplex-Drive and conduct a lane-changing case study in dense traffic scenarios. The simulation experiment results demonstrate that Simplex-Drive can always ensure the operation safety without sacrificing control performance, even if the DRL policy may lead to deviations from the safe status.",
        "primary_area": "",
        "author": "Shengduo Chen;Yaowei Sun;Dachuan Li;Qiang Wang;Qi Hao;Joseph Sifakis;Shengduo Chen;Yaowei Sun;Dachuan Li;Qiang Wang;Qi Hao;Joseph Sifakis",
        "authorids": "/37088504241;/37089450859;/37087103652;/38239098700;/37403530000;/37355101600;/37088504241;/37089450859;/37087103652;/38239098700;/37403530000;/37355101600",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Research Institute for Trustworthy Autonomous Systems, Shenzhen, China; Artificial Intelligence Research Center, Defense Innovation Institute, Chinese Academy of Military Science, Beijing, China; Research Institute for Trustworthy Autonomous Systems, Shenzhen, China; Research Institute for Trustworthy Autonomous Systems, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812177/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18021456454571688885&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;1;1",
        "aff_unique_norm": "Southern University of Science and Technology;Research Institute for Trustworthy Autonomous Systems;Chinese Academy of Military Science",
        "aff_unique_dep": "Department of Computer Science and Engineering;;Artificial Intelligence Research Center",
        "aff_unique_url": "https://www.sustech.edu.cn;;",
        "aff_unique_abbr": "SUSTech;;",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Shenzhen;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811747",
        "title": "SAFIT: Segmentation-Aware Scene Flow with Improved Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "Scene flow prediction is a challenging task that aims at jointly estimating the 3D structure and 3D motion of dynamic scenes. The previous methods concentrate more on point-wise estimation instead of considering the correspondence between objects as well as lacking the sensation of high-level semantic knowledge. In this paper, we propose a concise yet effective method for scene flow prediction. The key idea is to extend the view of all points for computing point cloud features into object-level, thus simultaneously modeling the relationships of the object-level and point-level via an improved transformer. In addition, we introduce a novel unsupervised loss called segmentation-aware loss, which can model semanticaware details to help predict scene flow more accurately and robustly. Since this loss can be trained without any ground truth, it can be used in both supervised training and self-supervised training. Experiments on both supervised training and self-supervised training demonstrate the effectiveness of our method. On supervised training, 3.8%, 22.58%, 10.90% and 21.82 % accuracy boosts than FLOT [23] can be observed on FT3Ds, KITTIs, FT3Do and KITTIo datasets. On self-supervised scheme, 48.23% and 48.96% accuracy boost than PointPWC-Net [40] can be observed on KITTIo and KITTIs datasets.",
        "primary_area": "",
        "author": "Yukang Shi;Kaisheng Ma;Yukang Shi;Kaisheng Ma",
        "authorids": "/37089450710;/37085341005;/37089450710;/37085341005",
        "aff": "School of Computer Science and Technology, Xi'an Jiaotong University, Xi'an, China; Institute for Interdisciplinary In-formation Sciences, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811747/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2323652344870259287&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Xi'an Jiao Tong University;Tsinghua University",
        "aff_unique_dep": "School of Computer Science and Technology;Institute for Interdisciplinary Information Sciences",
        "aff_unique_url": "http://www.xjtu.edu.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "XJTU;Tsinghua",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Xi'an;Beijing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811859",
        "title": "SAGCI-System: Towards Sample-Efficient, Generalizable, Compositional, and Incremental Robot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Building general-purpose robots to perform a diverse range of tasks in a large variety of environments in the physical world at the human level is extremely challenging. According to [1], it requires the robot learning to be sample-efficient, generalizable, compositional, and incremental. In this work, we introduce a systematic learning framework called SAGCI-system towards achieving these above four requirements. Our system first takes the raw point clouds gathered by the camera mounted on the robot's wrist as the inputs and produces initial modeling of the surrounding environment represented as a file of Unified Robot Description Format (URDF). Our system adopts a learning-augmented differentiable simulation that loads the URDF. The robot then utilizes the interactive perception to interact with the environment to online verify and modify the URDF. Leveraging the differentiable simulation, we propose a model-based learning algorithm combining object-centric and robot-centric stages to efficiently produce policies to accomplish manipulation tasks. We apply our system to perform articulated object manipulation tasks, both in the simulation and the real world. Extensive experiments demonstrate the effectiveness of our proposed learning framework. Supplemental materials and videos are available on our project webpage https://sites.google.com/view/egci.",
        "primary_area": "",
        "author": "Jun Lv;Qiaojun Yu;Lin Shao;Wenhai Liu;Wenqiang Xu;Cewu Lu;Jun Lv;Qiaojun Yu;Lin Shao;Wenhai Liu;Wenqiang Xu;Cewu Lu",
        "authorids": "/37089449764;/37089450989;/37086423705;/37085683936;/37088221545;/37085483529;/37089449764;/37089450989;/37086423705;/37085683936;/37088221545;/37085483529",
        "aff": "Department of Computer Science, Shanghai Jiao Tong University, China; Department of Computer Science, Shanghai Jiao Tong University, China; Artificial Intelligence Lab, Stanford University, USA; School of Mechanical Engineering, Shanghai Jiao Tong University, China; Department of Computer Science, Shanghai Jiao Tong University, China; Department of Computer Science, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811859/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16254252671408671387&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Stanford University",
        "aff_unique_dep": "Department of Computer Science;Artificial Intelligence Lab",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.stanford.edu",
        "aff_unique_abbr": "SJTU;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9812257",
        "title": "SAGE: SLAM with Appearance and Geometry Prior for Endoscopy",
        "track": "main",
        "status": "Poster",
        "abstract": "In endoscopy, many applications (e.g., surgical navigation) would benefit from a real-time method that can simultaneously track the endoscope and reconstruct the dense 3D geometry of the observed anatomy from a monocular endoscopic video. To this end, we develop a Simultaneous Localization and Mapping system by combining the learning-based appearance and optimizable geometry priors and factor graph optimization. The appearance and geometry priors are explicitly learned in an end-to-end differentiable training pipeline to master the task of pair-wise image alignment, one of the core components of the SLAM system. In our experiments, the proposed SLAM system is shown to robustly handle the challenges of texture scarceness and illumination variation that are commonly seen in endoscopy. The system generalizes well to unseen endoscopes and subjects and performs favorably compared with a state-of-the-art feature-based SLAM system. The code repository is available at https://github.com/lppllpp1920/SAGE-SLAM.git.",
        "primary_area": "",
        "author": "Xingtong Liu;Zhaoshuo Li;Masaru Ishii;Gregory D. Hager;Russell H. Taylor;Mathias Unberath;Xingtong Liu;Zhaoshuo Li;Masaru Ishii;Gregory D. Hager;Russell H. Taylor;Mathias Unberath",
        "authorids": "/37088393930;/37087325398;/37404527700;/37276163200;/37277162900;/37085410714;/37088393930;/37087325398;/37404527700;/37276163200;/37277162900;/37085410714",
        "aff": "Computer Science Department, Johns Hopkins University (JHU), Baltimore, MD, USA; Computer Science Department, Johns Hopkins University (JHU), Baltimore, MD, USA; Johns Hopkins Medical Institutions, Baltimore, MD, USA; Computer Science Department, Johns Hopkins University (JHU), Baltimore, MD, USA; Computer Science Department, Johns Hopkins University (JHU), Baltimore, MD, USA; Computer Science Department, Johns Hopkins University (JHU), Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812257/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11823157220003746097&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Johns Hopkins University;Johns Hopkins Medical Institutions",
        "aff_unique_dep": "Computer Science Department;",
        "aff_unique_url": "https://www.jhu.edu;https://www.hopkinsmedicine.org",
        "aff_unique_abbr": "JHU;JHMI",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811840",
        "title": "SEHLNet: Separate Estimation of High- and Low-Frequency components for Depth Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth completion refers to inferring the dense depth map from a sparse depth map with or without corre-sponding color image. Numerous neural networks have been proposed to accomplish this task. However, insufficient uti-lization of heteromorphic data and the fact that predicted dense depth prefers a sparse depth enormously damage the performance of approaches. To reduce data preference and fully utilize two modalities, this paper proposes a novel network that predicts high- and low-frequency components of dense depth separately. Specifically, the framework consists of a Low-Frequency(LF) branch and a High-Frequency(HF) branch. In the LF branch, we recover the low-frequency depth component from sparse depth through an Adaptive Graph-Generate Graph Attention Network, which can be seen as a low-pass filter. In the HF branch, we model the high-frequency component, e.g. boundaries, as residuals to mitigate the impact of data preferences. Moreover, in this branch, we propose an Attention-based Self-Fusion mechanism to efficiently fuse multi-scale features extracted from the sparse depth and color image. Extensive experiments demonstrate that our approach achieves state-of-the-art performance on the KITTI benchmark and ranks 1st in root mean squared error among other published approaches.",
        "primary_area": "",
        "author": "Qiang Liu;Haosong Yue;Zhanggang Lyu;Wei Wang;Zhong Liu;Weihai Chen;Qiang Liu;Haosong Yue;Zhanggang Lyu;Wei Wang;Zhong Liu;Weihai Chen",
        "authorids": "/37089450746;/37851695500;/37089449080;/37086943823;/38475386500;/37279188000;/37089450746;/37851695500;/37089449080;/37086943823;/38475386500;/37279188000",
        "aff": "School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Beijing Aerospace Automatic Control Institute, Beijing, China; Department of Computer Science, University of Oxford, Oxford, U.K; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811840/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10578899655071966991&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;0",
        "aff_unique_norm": "Beihang University;Beijing Aerospace Automatic Control Institute;University of Oxford",
        "aff_unique_dep": "School of Automation Science and Electrical Engineering;;Department of Computer Science",
        "aff_unique_url": "http://www.buaa.edu.cn;;https://www.ox.ac.uk",
        "aff_unique_abbr": "BUAA;;Oxford",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Beijing;Oxford",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9811979",
        "title": "SEMI: Self-supervised Exploration via Multisensory Incongruity",
        "track": "main",
        "status": "Poster",
        "abstract": "Efficient exploration is a long-standing problem in reinforcement learning since extrinsic rewards are usually sparse or missing. A popular solution to this issue is to feed an agent with novelty signals as intrinsic rewards. In this work, we introduce SEMI, a self-supervised exploration policy by incentivizing the agent to maximize a new novelty signal: multisensory incongruity, which can be measured in two aspects, perception incongruity and action incongruity. The former represents the misalignment of the multisensory inputs, while the latter represents the variance of an agent's policies under different sensory inputs. Specifically, an alignment predictor is learned to detect whether multiple sensory inputs are aligned, the error of which is used to measure perception incongruity. A policy model takes different combinations of the multisensory observations as input, and outputs actions for exploration. The variance of actions is further used to measure action incongruity. Using both incongruities as intrinsic rewards, SEMI allows an agent to learn skills by exploring in a self-supervised manner without any external rewards. We further show that SEMI is compatible with extrinsic rewards and it improves sample efficiency of policy learning. The effectiveness of SEMI is demonstrated across a variety of benchmark environments including object manipulation and audio-visual games.",
        "primary_area": "",
        "author": "Jianren Wang;Ziwen Zhuang;Hang Zhao;Jianren Wang;Ziwen Zhuang;Hang Zhao",
        "authorids": "/37087079357;/37089450901;/37086232492;/37087079357;/37089450901;/37086232492",
        "aff": "Carnegie Mellon University; ShanghaiTech University and Shanghai Qi Zhi Institute; Tsinghua University and Shanghai Qi Zhi Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811979/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17925539428000264116&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Carnegie Mellon University;ShanghaiTech University;Tsinghua University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.cmu.edu;https://www.shanghaitech.edu.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "CMU;ShanghaiTech;THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9812408",
        "title": "SMAC-Seg: LiDAR Panoptic Segmentation via Sparse Multi-directional Attention Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "Panoptic segmentation aims to address semantic and instance segmentation simultaneously in a unified framework. However, an efficient solution of panoptic segmentation in applications like autonomous driving is still an open research problem. In this work, we propose a novel LiDAR-based panoptic system, called SMAC-Seg. We present a learnable sparse multi-directional attention clustering to segment multi-scale foreground instances. SMAC-Seg is a real-time clustering-based approach, which removes the complex proposal network to segment instances. Most existing clustering-based methods use the difference of the predicted and ground truth center offset as the only loss to supervise the instance centroid regression. However, this loss function only considers the centroid of the current object, but its relative position with respect to the neighbouring objects is not considered when learning to cluster. Thus, we propose to use a novel centroid-aware repel loss as an additional term to effectively supervise the network in order to differentiate each object cluster with its neighbours. Our experimental results show that SMAC-Seg achieves state-of-the-art performance among all real-time deployable networks on both large-scale public SemanticKITTI and nuScenes panoptic segmentation datasets.",
        "primary_area": "",
        "author": "Enxu Li;Ryan Razani;Yixuan Xu;Bingbing Liu;Enxu Li;Ryan Razani;Yixuan Xu;Bingbing Liu",
        "authorids": "/37089013811;/37086404456;/37089448639;/38572992400;/37089013811;/37086404456;/37089448639;/38572992400",
        "aff": "Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812408/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11220692214900110579&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Noah's Ark Lab",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812044",
        "title": "SMORS: A soft multirotor UAV for multimodal locomotion and robust interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "We present SMORS, the first Soft fully actuated MultirOtoR System for multimodal locomotion. Unlike conventional hexarotors, SMORS is equipped with three rigid and three continuously soft arms, with each arm hosting a propeller. We create a bridge between the fields of soft and aerial robotics by mechanically coupling the actuation of a fully actuated flying platform with the actuation of a soft robotic manipulator. Each rotor is slightly tilted, allowing for full actuation of the platform. The soft components combined with the platform's full actuation allow for a robust interaction, in the form of efficient multimodal locomotion. In this work, we present the dynamical model of the platform, derive a closed-loop control, and present simulation results fortifying the robustness of the platform under a jumping-flying maneuver. We demonstrate in simulations that our multimodal locomotion approach can be more energy-efficient than the flight with a hexarotor.",
        "primary_area": "",
        "author": "Markus Ryll;Robert K. Katzschmann;Markus Ryll;Robert K. Katzschmann",
        "authorids": "/38251847500;/37085423557;/38251847500;/37085423557",
        "aff": "Department of Aerospace and Geodesy, Autonomous Aerial Systems, TU M\u00fcnchen, Taufkirchen/Ottobrunn, Germany; Department of Mechanical and Process Engineering, ETH Zurich, Soft Robotics Lab, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812044/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7287259559792112813&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Technical University of Munich;ETH Zurich",
        "aff_unique_dep": "Department of Aerospace and Geodesy;Department of Mechanical and Process Engineering",
        "aff_unique_url": "https://www.tum.de;https://www.ethz.ch",
        "aff_unique_abbr": "TUM;ETHZ",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Taufkirchen/Ottobrunn;Zurich",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "9812134",
        "title": "SPIN Road Mapper: Extracting Roads from Aerial Images via Spatial and Interaction Space Graph Reasoning for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Road extraction is an essential step in building autonomous navigation systems. Detecting road segments is challenging as they are of varying widths, bifurcated throughout the image, and are often occluded by terrain, cloud, or other weather conditions. Using just convolution neural networks (ConvNets) for this problem is not effective as it is inefficient at capturing distant dependencies between road segments in the image which is essential to extract road connectivity. To this end, we propose a Spatial and Interaction Space Graph Reasoning (SPIN) module which when plugged into a ConvNet performs reasoning over graphs constructed on spatial and interaction spaces projected from the feature maps. Reasoning over spatial space extracts dependencies between different spatial regions and other contextual information. Reasoning over a projected interaction space helps in appropriate delineation of roads from other topographies present in the image. Thus, SPIN extracts long-range dependencies between road segments and effectively delineates roads from other semantics. We also introduce a SPIN pyramid which performs SPIN graph reasoning across multiple scales to extract multi-scale features. We propose a network based on stacked hourglass modules and SPIN pyramid for road segmentation which achieves better performance compared to existing methods. Moreover, our method is computationally efficient and significantly boosts the convergence speed during training, making it feasible for applying on large-scale high-resolution aerial images. Code available at: https://github.com/wgcban/SPIN_RoadMapper.git.",
        "primary_area": "",
        "author": "Wele Gedara Chaminda Bandara;Jeya Maria Jose Valanarasu;Vishal M. Patel;Wele Gedara Chaminda Bandara;Jeya Maria Jose Valanarasu;Vishal M. Patel",
        "authorids": "/37086609898;/37088760866;/37391395200;/37086609898;/37088760866;/37391395200",
        "aff": "Department of Electrical and Computer Engineering, The Johns Hopkins University, Baltimore, MD, USA; Department of Electrical and Computer Engineering, The Johns Hopkins University, Baltimore, MD, USA; Department of Electrical and Computer Engineering, The Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812134/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8159579131794562143&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811814",
        "title": "ST-RRT*: Asymptotically-Optimal Bidirectional Motion Planning through Space-Time",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a motion planner for planning through space-time with dynamic obstacles, velocity constraints, and unknown arrival time. Our algorithm, Space-Time RRT*(ST-RRT*), is a probabilistically complete, bidirectional motion planning algorithm, which is asymptotically optimal with respect to the shortest arrival time. We experimentally evaluate ST-RRT* in both abstract (2D disk, 8D disk in cluttered spaces, and on a narrow passage problem), and simulated robotic path planning problems (sequential planning of 8DoF mobile robots, and 7DoF robotic arms). The proposed planner outperforms RRT-Connect and RRT* on both initial solution time, and attained final solution cost. The code for ST-RRT* is available in the Open Motion Planning Library (OMPL).",
        "primary_area": "",
        "author": "Francesco Grothe;Valentin N. Hartmann;Andreas Orthey;Marc Toussaint;Francesco Grothe;Valentin N. Hartmann;Andreas Orthey;Marc Toussaint",
        "authorids": "/37089448181;/37088690890;/37077150400;/37528418600;/37089448181;/37088690890;/37077150400;/37528418600",
        "aff": "Learning and Intelligent Systems Group, TU Berlin, Germany; Machine Learning & Robotics Lab, University of Stuttgart, Germany; Learning and Intelligent Systems Group, TU Berlin, Germany; Learning and Intelligent Systems Group, TU Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811814/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9476197339613643818&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Berlin;University of Stuttgart",
        "aff_unique_dep": "Learning and Intelligent Systems Group;Machine Learning & Robotics Lab",
        "aff_unique_url": "https://www.tu-berlin.de;https://www.uni-stuttgart.de",
        "aff_unique_abbr": "TU Berlin;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berlin;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811952",
        "title": "SaRA: A Tool for Safe Human-Robot Coexistence and Collaboration through Reachability Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Current safety mechanisms implementing industry standards for human-robot coexistence separate humans and robots through caging. Other approaches allowing humans to enter the workspace of manipulators do not provide formal safety guarantees. Thus, this study aims to facilitate the widespread adoption of collaborative robots by presenting SaRA, an extensible tool that performs set-based reachability analysis and formally guarantees safety. Our experimental results show that the set-based prediction of a human can be computed in a few microseconds, using SaRA, allowing for real-time consideration of many surrounding humans in an environment.",
        "primary_area": "",
        "author": "Sven R. Schepp;Jakob Thumm;Stefan B. Liu;Matthias Althoff;Sven R. Schepp;Jakob Thumm;Stefan B. Liu;Matthias Althoff",
        "authorids": "/37089448134;/37089307978;/37086297522;/37541135900;/37089448134;/37089307978;/37086297522;/37541135900",
        "aff": "Department of Informatics, Technical University of Munich, Garching, Germany; Department of Informatics, Technical University of Munich, Garching, Germany; Department of Informatics, Technical University of Munich, Garching, Germany; Department of Informatics, Technical University of Munich, Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811952/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4427866556800951946&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Garching",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811359",
        "title": "Safe endoscope holding in minimally invasive surgery: zero stiffness and adaptive weight compensation",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the major functions brought by robots in Minimally Invasive Surgery is endoscope holding. This consists, for the user, in placing the camera at a desired location which the robot will maintain still once he/she releases it. This behavior is usually achieved with rigid position servoing, leading to possibly high forces generated and safety issues. Model-based weight compensation is an alternative solution. However, endoscopic cameras' weight is difficult to model as their gravity parameters can change during the same surgery. In this paper, an algorithm is presented as an option to cope with this variability in the gravity model without using rigid position servoing. The surgeon first positions the camera in a comanipulation mode (gravity compensation). When he/she releases the camera, if the gravity model is not accurate, the endoscope presents a drift. In this case, a controller brings the endoscope back to its release position by combining low gain position control and model adaptation. Once stabilized, the system is switched back to a zero-stiffness mode. Two in-vitro experiments were performed in which a user manipulates an endoscope whose configuration of mass is changed. In one case, the mass in the gravity model was set to half of the actual one. In the second case, a variable weight was attached to the endoscope. The algorithm successfully updated the model for each experiment reducing position errors by 95% and 57%, respectively.",
        "primary_area": "",
        "author": "Jesus Mago;Fran\u00e7ois Louveau;Marie-Aude Vitrani;Guillaume Morel;Jesus Mago;Fran\u00e7ois Louveau;Marie-Aude Vitrani;Guillaume Morel",
        "authorids": "/37086933852;/37089193927;/37563937400;/37274022000;/37086933852;/37089193927;/37563937400;/37274022000",
        "aff": "Haption SARL; Haption SARL; Sorbonne Universit\u00e9 INSERM U1150, CNRS UMR 7222, Institut des Syst\u00e8mes Intelligents et de Robotique (ISIR), Paris, France; Sorbonne Universit\u00e9 INSERM U1150, CNRS UMR 7222, Institut des Syst\u00e8mes Intelligents et de Robotique (ISIR), Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811359/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:gDo6v4t_QuMJ:scholar.google.com/&scioq=Safe+endoscope+holding+in+minimally+invasive+surgery:+zero+stiffness+and+adaptive+weight+compensation&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Haption SARL;Sorbonne Universit\u00e9",
        "aff_unique_dep": ";Institut des Syst\u00e8mes Intelligents et de Robotique (ISIR)",
        "aff_unique_url": "https://www.haption.com;https://www.sorbonne-universite.fr",
        "aff_unique_abbr": ";Sorbonne U",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Paris",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812259",
        "title": "Safe multi-agent motion planning via filtered reinforcement learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of safe multi-agent motion planning in cluttered environments. Existing multi-agent reinforcement learning-based motion planners only provide approximate safety enforcement. We propose a safe reinforcement learning algorithm that leverages single-agent reinforcement learning for target regulation and a subsequent convex optimization-based filtering that ensures the collective safety of the system. Our approach yields a safe, real-time implementable multi-agent motion planner that is simpler to train and enforces safety as hard constraints. Our approach can handle state and control constraints on the agents, and enforce collision avoidance among themselves and with static obstacles in the environment. Numerical simulations and hardware experiments show the efficacy of the approach.",
        "primary_area": "",
        "author": "Abraham P. Vinod;Sleiman Safaoui;Ankush Chakrabarty;Rien Quirynen;Nobuyuki Yoshikawa;Stefano Di Cairano;Abraham P. Vinod;Sleiman Safaoui;Ankush Chakrabarty;Rien Quirynen;Nobuyuki Yoshikawa;Stefano Di Cairano",
        "authorids": "/37085593103;/37086937131;/37072629700;/38547099900;/37089557346;/37545385600;/37085593103;/37086937131;/37072629700;/38547099900;/37089557346;/37545385600",
        "aff": "Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA; Mitsubishi Electric Corporation, Japan; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812259/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3665401816601119947&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Mitsubishi Electric Research Laboratories;Mitsubishi Electric Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.merl.com;https://www.mitsubishielectric.com",
        "aff_unique_abbr": "MERL;MEC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9812009",
        "title": "SafePicking: Learning Safe Object Extraction via Object-Level Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots need object-level scene understanding to manipulate objects while reasoning about contact, support, and occlusion among objects. Given a pile of objects, object recognition and reconstruction can identify the boundary of object instances, giving important cues as to how the objects form and support the pile. In this work, we present a system, SafePicking, that integrates object-level mapping and learning-based motion planning to generate a motion that safely extracts occluded target objects from a pile. Planning is done by learning a deep Q-network that receives observations of predicted poses and a depth-based heightmap to output a motion trajectory, trained to maximize a safety metric reward. Our results show that the observation fusion of poses and depth-sensing gives both better performance and robustness to the model. We evaluate our methods using the YCB objects in both simulation and the real world, achieving safe object extraction from piles.",
        "primary_area": "",
        "author": "Kentaro Wada;Stephen James;Andrew J. Davison;Kentaro Wada;Stephen James;Andrew J. Davison",
        "authorids": "/37086073523;/37087233054;/37293837200;/37086073523;/37087233054;/37293837200",
        "aff": "Dyson Robotics Laboratory, Imperial College London; Dyson Robotics Laboratory, Imperial College London; Dyson Robotics Laboratory, Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812009/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6526399092367865559&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dyson Robotics Laboratory",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812048",
        "title": "Safety Assurances for Human-Robot Interaction via Confidence-aware Game-theoretic Human Models",
        "track": "main",
        "status": "Poster",
        "abstract": "An outstanding challenge with safety methods for human-robot interaction is reducing their conservatism while maintaining robustness to variations in human behavior. In this work, we propose that robots use confidence-aware game-theoretic models of human behavior when assessing the safety of a human-robot interaction. By treating the influence between the human and robot as well as the human's rationality as unobserved latent states, we succinctly infer the degree to which a human is following the game-theoretic interaction model. We leverage this model to restrict the set of feasible human controls during safety verification, enabling the robot to confidently modulate the conservatism of its safety monitor online. Evaluations in simulated human-robot scenarios and ablation studies demonstrate that imbuing safety monitors with confidence-aware game-theoretic models enables both safe and efficient human-robot interaction. Moreover, evaluations with real traffic data show that our safety monitor is less conservative than traditional safety methods in real human driving scenarios.",
        "primary_area": "",
        "author": "Ran Tian;Liting Sun;Andrea Bajcsy;Masayoshi Tomizuka;Anca D. Dragan;Ran Tian;Liting Sun;Andrea Bajcsy;Masayoshi Tomizuka;Anca D. Dragan",
        "authorids": "/37085997198;/37085425729;/37086934087;/37281933000;/37960625200;/37085997198;/37085425729;/37086934087;/37281933000;/37960625200",
        "aff": "UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812048/",
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15692418746286443445&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812334",
        "title": "Safety-Critical Control and Planning for Obstacle Avoidance between Polytopes with Control Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Obstacle avoidance between polytopes is a chal-lenging topic for optimal control and optimization-based tra-jectory planning problems. Existing work either solves this problem through mixed-integer optimization, relying on simpli-fication of system dynamics, or through model predictive control with dual variables using distance constraints, requiring long horizons for obstacle avoidance. In either case, the solution can only be applied as an offline planning algorithm. In this paper, we exploit the property that a smaller horizon is sufficient for obstacle avoidance by using discrete-time control barrier function (DCBF) constraints and we propose a novel optimization formulation with dual variables based on DCBFs to generate a collision-free dynamically-feasible trajectory. The proposed optimization formulation has lower computational complexity compared to existing work and can be used as a fast online algorithm for control and planning for general nonlinear dynamical systems. We validate our algorithm on different robot shapes using numerical simulations with a kinematic bicycle model, resulting in successful navigation through maze environments with polytopic obstacles.",
        "primary_area": "",
        "author": "Akshay Thirugnanam;Jun Zeng;Koushil Sreenath;Akshay Thirugnanam;Jun Zeng;Koushil Sreenath",
        "authorids": "/37089449903;/37086963288;/37563179200;/37089449903;/37086963288;/37563179200",
        "aff": "Department of Mechanical Engineering, Hybrid Robotics Group, Berkeley, UC, USA; Department of Mechanical Engineering, Hybrid Robotics Group, Berkeley, UC, USA; Department of Mechanical Engineering, Hybrid Robotics Group, Berkeley, UC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812334/",
        "gs_citation": 82,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18347625616644011236&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811576",
        "title": "SafetyNet: Safe Planning for Real-World Self-Driving Vehicles Using Machine-Learned Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present the first safe system for full control of self-driving vehicles trained from human demonstrations and deployed in challenging, real-world, urban environments. Current industry-standard solutions use rule-based systems for planning. Although they perform reasonably well in common scenarios, the engineering complexity renders this approach incompatible with human-level performance. On the other hand, the performance of machine-learned (ML) planning solutions can be improved by simply adding more exemplar data. However, ML methods cannot offer safety guarantees and sometimes behave unpredictably. To combat this, our approach uses a simple yet effective rule-based fallback layer that performs sanity checks on an ML planner's decisions (e.g. avoiding collision, assuring physical feasibility). This allows us to leverage ML to handle complex situations while still assuring the safety, reducing ML planner-only collisions by 95%. We train our ML planner on 300 hours of expert driving demonstrations using imitation learning and deploy it along with the fallback layer in downtown San Francisco, where it takes complete control of a real vehicle and navigates a wide variety of challenging urban driving scenarios.",
        "primary_area": "",
        "author": "Matt Vitelli;Yan Chang;Yawei Ye;Ana Ferreira;Maciej Wo\u0142czyk;B\u0142a\u017cej Osi\u0144ski;Moritz Niendorf;Hugo Grimmett;Qiangui Huang;Ashesh Jain;Peter Ondruska;Matt Vitelli;Yan Chang;Yawei Ye;Ana Ferreira;Maciej Wo\u0142czyk;B\u0142a\u017cej Osi\u0144ski;Moritz Niendorf;Hugo Grimmett;Qiangui Huang;Ashesh Jain;Peter Ondruska",
        "authorids": "/37089449403;/37089448954;/37088998185;/37089448879;/37088954864;/37088504220;/37085486759;/37076422900;/37089447697;/37089447994;/37085460486;/37089449403;/37089448954;/37088998185;/37089448879;/37088954864;/37088504220;/37085486759;/37076422900;/37089447697;/37089447994;/37085460486",
        "aff": "Matt Vitelli; Yan Chang; Yawei Ye; Ana Ferreira; Maciej Wo\u0142czyk; B\u0142a\u017cej Osi\u0144ski; Moritz Niendorf; Hugo Grimmett; Qiangui Huang; Ashesh Jain; Peter Ondruska",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811576/",
        "gs_citation": 82,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9351184063572009787&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "1;2",
        "aff_unique_norm": ";Yan Chang;Yawei Ye",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";;",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9811951",
        "title": "Sampling Over Riemannian Manifolds Using Kernel Herding",
        "track": "main",
        "status": "Poster",
        "abstract": "Kernel herding is a deterministic sampling algorithm designed to draw \u2018super samples' from probability distributions when provided with their kernel mean embeddings in a reproducing kernel Hilbert space (RKHS). Empirical expectations of functions in the RKHS formed using these super samples tend to converge even faster than random sampling from the true distribution itself. Standard implementations of kernel herding have been restricted to sampling over flat Euclidean spaces, which is not ideal for applications such as robotics where more general Riemannian manifolds may be appropriate. We propose to adapt kernel herding to Riemannian manifolds by (1) using geometry-aware kernels that incorporate the appropriate distance metric for the manifold and (2) using Riemannian optimization to constrain herded samples to lie on the manifold. We evaluate our approach on problems involving various manifolds commonly used in robotics including the SO(3) manifold of rotation matrices, the spherical manifold used to encode unit quaternions, and the manifold of symmetric positive definite matrices. We demonstrate that our approach outperforms existing alternatives on the task of resampling from empirical distributions of weighted particles, a problem encountered in applications such as particle filtering. We also demonstrate how Riemannian kernel herding can be used as part of the kernel recursive approximate Bayesian computation algorithm to estimate parameters of black-box simulators, including inertia matrices of an Adroit robot hand simulator. Our results confirm that exploiting geometric information through our approach to kernel herding yields better results than alternatives including standard kernel herding with heuristic projections.",
        "primary_area": "",
        "author": "Sandesh Adhikary;Byron Boots;Sandesh Adhikary;Byron Boots",
        "authorids": "/37089448231;/37085459219;/37089448231;/37085459219",
        "aff": "University of Washington, Seattle, WA, USA; University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811951/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7374218741517365705&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812262",
        "title": "Scalable Gradient Ascent for Controllers in Constrained POMDPs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel gradient ascent al-gorithm and nonlinear programming algorithm for finite state controller policies in constrained partially observable Markov decision processes (CPOMDPs). A key component of the gradient ascent algorithm is a constraint projection to ensure constraints are satisfied. Both an optimal and an approximate projection are formally defined. A theoretical analysis of the algorithm and its projections is presented, formally proving aspects of projection correctness and algorithm convergence. Experiments evaluate the baseline and novel algorithms, as well as both constraint projections, on seven CPOMDP benchmark domains. The proposed novel algorithm is demonstrated on an actual robot performing a navigation task in a real household environment.",
        "primary_area": "",
        "author": "Kyle Hollins Wray;Kenneth Czuprynski;Kyle Hollins Wray;Kenneth Czuprynski",
        "authorids": "/37086208879;/37088997154;/37086208879;/37088997154",
        "aff": "Kyle Hollins Wray; Kenneth Czuprynski",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812262/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15878577761039614871&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9812053",
        "title": "Scalable Minimally Actuated Leg Extension Bipedal Walker Based on 3D Passive Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "We present simplified 2D dynamic models of the 3D, passive dynamic inspired walking gait of a physical quasi-passive walking robot. Quasi-passive walkers are robots that integrate passive walking principles and some form of actuation. Our ultimate goal is to better understand the dynamics of actuated walking in order to create miniature, untethered, bipedal walking robots. At these smaller scales there is limited space and power available, and so in this work we leverage the passive dynamics of walking to reduce the burden on the actuators and controllers. Prior quasi-passive walkers are much larger than our intended scale, have more complicated mechanical designs, and require more precise feedback control and/or learning algorithms. By leveraging the passive 3D dynamics, carefully designing the spherical feet, and changing the actuation scheme, we are able to produce a very simple 3D bipedal walking model that has a total of 5 rigid bodies and a single actuator per leg. Additionally, the model requires no feedback as each actuator is controlled by an open-loop sinusoidal profile. We validate this model in 2D simulations in which we measure the stability properties while varying the leg length/amplitude ratio, the frequency of actuation, and the spherical foot profile. These results are also validated experimentally on a 3D walking robot (15cm leg length) that implements the modeled walking dynamics. Finally, we experimentally investigate the ability to control the heading of the robot by changing the open-loop control parameters of the robot.",
        "primary_area": "",
        "author": "Sharfin Islam;Kamal Carter;Justin Yim;James Kyle;Sarah Bergbreiter;Aaron M. Johnson;Sharfin Islam;Kamal Carter;Justin Yim;James Kyle;Sarah Bergbreiter;Aaron M. Johnson",
        "authorids": "/37089447618;/37089448049;/37085518088;/37089449263;/37542605000;/37589025300;/37089447618;/37089448049;/37085518088;/37089449263;/37542605000;/37589025300",
        "aff": "Department of Mechanical Engineering, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812053/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12292312763655206722&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;1",
        "aff_unique_norm": "Columbia University;Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.columbia.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Columbia;CMU",
        "aff_campus_unique_index": "0;1;1;1;1;1",
        "aff_campus_unique": "New York;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811927",
        "title": "Scalable Simulation and Demonstration of Jumping Piezoelectric 2-D Soft Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots have drawn great interest due to their ability to take on a rich range of shapes and motions, compared to traditional rigid robots. However, the motions, and underlying statics and dynamics, pose significant challenges to forming well-generalized and robust models necessary for robot design and control. In this work, we demonstrate a five-actuator soft robot capable of complex motions and develop a scalable simulation framework that reliably predicts robot motions. The simulation framework is validated by comparing its predictions to experimental results, based on a robot constructed from piezoelectric layers bonded to a steel-foil substrate. The simulation framework exploits the physics engine PyBullet, and employs discrete rigid-link elements connected by motors to model the actuators. We perform static and AC analyses to validate a single-unit actuator cantilever setup and observe close agreement between simulation and experiments for both the cases. The analyses are extended to the five-actuator robot, where simulations accurately predict the static and AC robot motions, including shapes for applied DC voltage inputs, nearly-static \u201cinchworm\u201d motion, and jumping (in vertical as well as vertical and horizontal directions). These motions exhibit complex non-linear behavior, with forward robot motion reaching \u03341 cm/s. Our open-source code can be found at: https://github.com/zhiwuz/sfers.",
        "primary_area": "",
        "author": "Zhiwu Zheng;Prakhar Kumar;Yenan Chen;Hsin Cheng;Sigurd Wagner;Minjie Chen;Naveen Verma;James C. Sturm;Zhiwu Zheng;Prakhar Kumar;Yenan Chen;Hsin Cheng;Sigurd Wagner;Minjie Chen;Naveen Verma;James C. Sturm",
        "authorids": "/37086703543;/37086380734;/37089226755;/37088918703;/37275442700;/37086129263;/37399412400;/37270459200;/37086703543;/37086380734;/37089226755;/37088918703;/37275442700;/37086129263;/37399412400;/37270459200",
        "aff": "Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A; Department of Electrical and Computer Engineering, Princeton University, Princeton, New Jersey, U.S.A",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811927/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=660339570814183636&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Princeton",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811575",
        "title": "Search-Based Task Planning with Learned Skill Effect Models for Lifelong Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots deployed in many real-world settings need to be able to acquire new skills and solve new tasks over time. Prior works on planning with skills often make assumptions on the structure of skills and tasks, such as subgoal skills, shared skill implementations, or task-specific plan skeletons, which limit adaptation to new skills and tasks. By contrast, we propose doing task planning by jointly searching in the space of parameterized skills using high-level skill effect models learned in simulation. We use an iterative training procedure to efficiently generate relevant data to train such models. Our approach allows flexible skill parameterizations and task specifications to facilitate lifelong learning in general-purpose domains. Experiments demonstrate the ability of our planner to integrate new skills in a lifelong manner, finding new task strategies with lower costs in both train and test tasks. We additionally show that our method can transfer to the real world without further fine-tuning.",
        "primary_area": "",
        "author": "Jacky Liang;Mohit Sharma;Alex LaGrassa;Shivam Vats;Saumya Saxena;Oliver Kroemer;Jacky Liang;Mohit Sharma;Alex LaGrassa;Shivam Vats;Saumya Saxena;Oliver Kroemer",
        "authorids": "/37088504798;/37086376038;/37088689868;/37088690871;/37086365761;/37593222300;/37088504798;/37086376038;/37088689868;/37088690871;/37086365761;/37593222300",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811575/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6431591617424936277&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812211",
        "title": "Secure Multi-Robot Information Sampling with Periodic and Opportunistic Connectivity",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot teams are becoming an increasingly popular approach for information gathering in large geographic areas, with applications in precision agriculture, surveying the aftermath of natural disasters or tracking pollution. These robot teams are often assembled from untrusted devices not owned by the user, making the maintenance of the integrity of the collected samples an important challenge. Furthermore, such robots often operate under conditions of opportunistic, or periodic connectivity and are limited in their energy budget and computational power. In this paper, we propose algorithms that build on blockchain technology to address the data integrity problem, but also take into account the limitations of the robots' resources and communication. We evaluate the proposed algorithms along the perspective of the tradeoffs between data integrity, model accuracy, and time consumption.",
        "primary_area": "",
        "author": "Tamim Samman;Ayan Dutta;O. Patrick Kreidl;Swapnoneel Roy;Ladislau B\u00f6l\u00f6ni;Tamim Samman;Ayan Dutta;O. Patrick Kreidl;Swapnoneel Roy;Ladislau B\u00f6l\u00f6ni",
        "authorids": "/37089031122;/37085783239;/37299803900;/37085480699;/37301527000;/37089031122;/37085783239;/37299803900;/37085480699;/37301527000",
        "aff": "University of North Florida, USA; University of North Florida, USA; University of North Florida, USA; University of North Florida, USA; University of Central Florida, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812211/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2923044853504905536&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of North Florida;University of Central Florida",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.unf.edu;https://www.ucf.edu",
        "aff_unique_abbr": "UNF;UCF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812310",
        "title": "See Yourself in Others: Attending Multiple Tasks for Own Failure Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robots deal with unexpected scenarios in real environments. Given input images, various visual perception tasks can be performed, e.g., semantic segmentation, depth estimation and normal estimation. These different tasks provide rich information for the whole robotic perception system. All tasks have their own characteristics while sharing some latent correlations. However, some of the task predictions may suffer from the unreliability dealing with complex scenes and anomalies. We propose an attention-based failure detection approach by exploiting the correlations among multiple tasks. The proposed framework infers task failures by evaluating the individual prediction, across multiple visual perception tasks for different regions in an image. The formulation of the evaluations is based on an attention network supervised by multi-task uncertainty estimation and their corresponding prediction errors. Our proposed framework11Code link https://github.com/ethz-asl/uncertainty_with_multiple_tasks. generates more accurate estimations of the prediction error for the different task's predictions.",
        "primary_area": "",
        "author": "Boyang Sun;Jiaxu Xing;Hermann Blum;Roland Siegwart;Cesar Cadena;Boyang Sun;Jiaxu Xing;Hermann Blum;Roland Siegwart;Cesar Cadena",
        "authorids": "/37089450938;/37089450881;/37086048087;/37281398300;/37593590400;/37089450938;/37089450881;/37086048087;/37281398300;/37593590400",
        "aff": "Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812310/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7247257569469408622&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9811663",
        "title": "Seeking Visual Discomfort: Curiosity-driven Representations for Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based reinforcement learning (RL) is a promising approach to solve control tasks involving images as the main observation. State-of-the-art RL algorithms still struggle in terms of sample efficiency, especially when using image observations. This has led to increased attention on integrating state representation learning (SRL) techniques into the RL pipeline. Work in this field demonstrates a substantial improvement in sample efficiency among other benefits. However, to take full advantage of this paradigm, the quality of samples used for training plays a crucial role. More importantly, the diversity of these samples could affect the sample efficiency of vision-based RL, but also its generalization capability. In this work, we present an approach to improve sample diversity for state representation learning. Our method enhances the exploration capability of RL algorithms, by taking advantage of the SRL setup. Our experiments show that our proposed approach boosts the visitation of problematic states, improves the learned state representation, and outperforms the baselines for all tested environments. These results are most apparent for environments where the baseline methods struggle. In simple environments, our method contributes to stabilizing the training, reducing the reward variance, and improving sample efficiency.",
        "primary_area": "",
        "author": "Elie Aljalbout;Maximilian Ulmer;Rudolph Triebel;Elie Aljalbout;Maximilian Ulmer;Rudolph Triebel",
        "authorids": "/37089446763;/37089448343;/37542908700;/37089446763;/37089448343;/37542908700",
        "aff": "Technical University of Munich (TUM), Munich, Germany; German Aerospace Center, Insitute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center, Insitute of Robotics and Mechatronics, Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811663/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16955525625388672650&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Technical University of Munich;German Aerospace Center",
        "aff_unique_dep": ";Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.tum.de;https://www.dlr.de",
        "aff_unique_abbr": "TUM;DLR",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811551",
        "title": "Segmentation and Shape Estimation of Multiple Deformed Cloths Using a CNN-Based Landmark Detector and Clustering",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a method for segmentation and shape estimation of multiple deformed cloths stacked on a floor from an image using a CNN-based landmark detector and clustering. The proposed method first estimates landmark positions from the heatmaps generated from the landmark detector and then clusters them using their attributes also given from the landmark detector. The contributions of the proposed method are twofold: (1) it can perform segmentation and shape estimation of multiple cloths of the same type or different types simultaneously by modeling a cloth as a grid of landmarks and estimating their positions and attributes, (2) it can correctly segment severely occluded or seemingly disjointed cloths by estimating and classifying landmark attributes including grid index, cloth position, cloth orientation, and cloth type. We evaluate the proposed method on both synthetic and real image datasets and show that the proposed method outperforms three baseline methods. We also show that the proposed method enables our humanoid robot to pick up the desired type of cloth from a pile of cloths.",
        "primary_area": "",
        "author": "Daiki Sonegawa;Koichi Ogawara;Daiki Sonegawa;Koichi Ogawara",
        "authorids": "/37089446692;/37339602900;/37089446692;/37339602900",
        "aff": "Faculty of Systems Engineering, Wakayama University, Wakayama, JAPAN; Faculty of Systems Engineering, Wakayama University, Wakayama, JAPAN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811551/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:qmmEeCX0xL8J:scholar.google.com/&scioq=Segmentation+and+Shape+Estimation+of+Multiple+Deformed+Cloths+Using+a+CNN-Based+Landmark+Detector+and+Clustering&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Wakayama University",
        "aff_unique_dep": "Faculty of Systems Engineering",
        "aff_unique_url": "https://www.wakayama-u.ac.jp",
        "aff_unique_abbr": "Wakayama U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Wakayama",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811863",
        "title": "Self-Reconfiguring Robotic Gantries Powered by Modular Magnetic Lead Screws",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper outlines the design, specifications, and algorithms for a new modular self-reconfigurable robotic system; at its foundation is a novel modular magnetically geared linear actuator paired with a kinematic coupling connector. Motivating this work is the core idea that high performance actuators as well as inexpensive, precise and repeatable connectors are the key ingredients required for useful real-world self-reconfiguring machines. This work builds upon existing research in the areas of modular self-reconfigurable robots, magnetic lead screws, modular machine tools and kinematic couplings. Magnetic lead screws (MLS) have many desirable characteristics applicable to modular robots, including a tolerance for slight misalignments, high efficiency, zero backlash, robustness, inherent series elasticity, high force capability, and the ability to gracefully separate and reattach. Due to their high mechanical efficiency, MLS actuators are able to be combined in parallel to provide for increased forces and stiffness. Our system implements a MLS through two separable elements: brushless motor powered actuators called carts which pair with modular passive tracks which constrain the carts' movement to a line. This paper also explores the design for a connector which is able to precisely align modules through the use of a 4-way symmetric kinematic coupling.",
        "primary_area": "",
        "author": "John Romanishin;James M. Bern;Daniela Rus;John Romanishin;James M. Bern;Daniela Rus",
        "authorids": "/37077931000;/37086293656;/37279652300;/37077931000;/37086293656;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Laboratory, MIT; Computer Science and Artificial Intelligence Laboratory, MIT; Computer Science and Artificial Intelligence Laboratory, MIT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811863/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15332211328294252178&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811784",
        "title": "Self-Supervised Camera Self-Calibration from Video",
        "track": "main",
        "status": "Poster",
        "abstract": "Camera calibration is integral to robotics and computer vision algorithms that seek to infer geometric properties of the scene from visual input streams. In practice, calibration is a laborious procedure requiring specialized data collection and careful tuning. This process must be repeated whenever the parameters of the camera change, which can be a frequent occurrence for mobile robots and autonomous vehicles. In contrast, self-supervised depth and ego-motion estimation approaches can bypass explicit calibration by in-ferring per-frame projection models that optimize a view-synthesis objective. In this paper, we extend this approach to explicitly calibrate a wide range of cameras from raw videos in the wild. We propose a learning algorithm to regress per-sequence calibration parameters using an efficient family of general camera models. Our procedure achieves self-calibration results with sub-pixel reprojection error, outperforming other learning-based methods. We validate our approach on a wide variety of camera geometries, including perspective, fisheye, and catadioptric. Finally, we show that our approach leads to improvements in the downstream task of depth estimation, achieving state-of-the-art results on the EuRoC dataset with greater computational efficiency than contemporary methods. The project page: https://sites.google.com/ttic.edu/self-sup-self-calib",
        "primary_area": "",
        "author": "Jiading Fang;Igor Vasiljevic;Vitor Guizilini;Rares Ambrus;Greg Shakhnarovich;Adrien Gaidon;Matthew R. Walter;Jiading Fang;Igor Vasiljevic;Vitor Guizilini;Rares Ambrus;Greg Shakhnarovich;Adrien Gaidon;Matthew R. Walter",
        "authorids": "/37089448442;/37088638660;/37946098900;/37871304500;/37332123300;/37945420900;/37392432700;/37089448442;/37088638660;/37946098900;/37871304500;/37332123300;/37945420900;/37392432700",
        "aff": "Toyota Technological Institute at Chicago; Toyota Technological Institute at Chicago; Toyota Research Institute; Toyota Research Institute; Toyota Technological Institute at Chicago; Toyota Research Institute; Toyota Technological Institute at Chicago",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811784/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17713723740061370021&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;0;1;0",
        "aff_unique_norm": "Toyota Technological Institute at Chicago;Toyota Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tti-chicago.org;https://www.tri.global",
        "aff_unique_abbr": "TTI Chicago;TRI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chicago;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811842",
        "title": "Self-Supervised Ego-Motion Estimation Based on Multi-Layer Fusion of RGB and Inferred Depth",
        "track": "main",
        "status": "Poster",
        "abstract": "In existing self-supervised depth and ego-motion estimation methods, ego-motion estimation is usually limited to only leveraging RGB information. Recently, several methods have been proposed to further improve the accuracy of self-supervised ego-motion estimation by fusing information from other modalities, e.g., depth, acceleration, and angular velocity. However, they rarely focus on how different fusion strategies affect performance. In this paper, we investigate the effect of different fusion strategies for ego-motion estimation and pro-pose a new framework for self-supervised learning of depth and ego-motion estimation, which performs ego-motion estimation by leveraging RGB and inferred depth information in a Multi-Layer Fusion manner. As a result, we have achieved state-of-the-art performance among learning-based methods on the KITTI odometry benchmark. Detailed studies on the design choices of leveraging inferred depth information and fusion strategies have also been carried out, which clearly demonstrate the advantages of our proposed framework.3",
        "primary_area": "",
        "author": "Zijie Jiang;Hajime Taira;Naoyuki Miyashita;Masatoshi Okutomi;Zijie Jiang;Hajime Taira;Naoyuki Miyashita;Masatoshi Okutomi",
        "authorids": "/37088889945;/37086067081;/37088452990;/37270663800;/37088889945;/37086067081;/37088452990;/37270663800",
        "aff": "Dept. of Systems and Control Engineering, Tokyo Institute of Technology; Dept. of Systems and Control Engineering, Tokyo Institute of Technology; R&D Group, Olympus; Dept. of Systems and Control Engineering, Tokyo Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811842/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11979713847959741353&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Tokyo Institute of Technology;Olympus Corporation",
        "aff_unique_dep": "Dept. of Systems and Control Engineering;R&D Group",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.olympus.com",
        "aff_unique_abbr": "Titech;Olympus",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812183",
        "title": "Self-Supervised Online Learning for Safety-Critical Control using Stereo Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "With the increasing prevalence of complex vision-based sensing methods for use in obstacle identification and state estimation, characterizing environment-dependent measurement errors has become a difficult and essential part of modern robotics. This paper presents a self-supervised learning approach to safety-critical control. In particular, the uncertainty associated with stereo vision is estimated, and adapted online to new visual environments, wherein this estimate is leveraged in a safety-critical controller in a robust fashion. To this end, we propose an algorithm that exploits the structure of stereo-vision to learn an uncertainty estimate without the need for ground-truth data. We then robustify existing Control Barrier Function-based controllers to provide safety in the presence of this uncertainty estimate. We demonstrate the efficacy of our method on a quadrupedal robot in a variety of environments. When not using our method safety is violated. With offline training alone we observe the robot is safe, but overly-conservative. With our online method the quadruped remains safe and conservatism is reduced.",
        "primary_area": "",
        "author": "Ryan K. Cosner;Ivan D. Jimenez Rodriguez;Tamas G. Molnar;Wyatt Ubellacker;Yisong Yue;Aaron D. Ames;Katherine L. Bouman;Ryan K. Cosner;Ivan D. Jimenez Rodriguez;Tamas G. Molnar;Wyatt Ubellacker;Yisong Yue;Aaron D. Ames;Katherine L. Bouman",
        "authorids": "/37088901068;/37089197749;/38152008100;/37077831700;/37085390468;/37300877900;/37972984900;/37088901068;/37089197749;/38152008100;/37077831700;/37085390468;/37300877900;/37972984900",
        "aff": "Department of Control and Dynamical Systems, the Department of Mechanical and Civil Engineering, Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Control and Dynamical Systems, the Department of Mechanical and Civil Engineering, Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Control and Dynamical Systems, the Department of Mechanical and Civil Engineering, Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Control and Dynamical Systems, the Department of Mechanical and Civil Engineering, Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Control and Dynamical Systems, the Department of Mechanical and Civil Engineering, Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Control and Dynamical Systems, the Department of Mechanical and Civil Engineering, Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Control and Dynamical Systems, the Department of Mechanical and Civil Engineering, Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812183/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10571566548871603185&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Control and Dynamical Systems",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812150",
        "title": "Self-supervised Monocular Multi-robot Relative Localization with Efficient Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Relative localization is an important ability for multiple robots to perform cooperative tasks in GPS-denied environments. This paper presents a novel autonomous positioning framework for monocular relative localization of multiple tiny flying robots. This approach does not require any groundtruth data from external systems or manual labeling. Instead, the proposed framework is able to label real-world images with 3D relative positions between robots based on another onboard relative estimation technology, using ultra-wideband (UWB). After training in this self-supervised manner, the proposed deep neural network (DNN) can predict relative positions of peer robots by purely using a monocular camera. This deep learning-based visual relative localization is scalable, distributed, and autonomous. We also built an open-source and lightweight simulation pipeline by using Blender for 3D rendering, which allows synthetic image generation of other robots, and generalized training of the neural network. The proposed localization framework is tested on two real-world Crazyflie2 quadrotors by running the DNN on the onboard AIdeck (a tiny AI chip and monocular camera). All results demonstrate the effectiveness of the self-supervised multi-robot localization method. Video: https://youtu.be/7arkaIblPps",
        "primary_area": "",
        "author": "Shushuai Li;Christophe De Wagter;Guido C. H. E. De Croon;Shushuai Li;Christophe De Wagter;Guido C. H. E. De Croon",
        "authorids": "/37086938217;/37862967200;/37698062600;/37086938217;/37862967200;/37698062600",
        "aff": "Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812150/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11883862699355850037&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Faculty of Aerospace Engineering",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9811954",
        "title": "Self-supervised Representation Learning for Reliable Robotic Monitoring of Fruit Anomalies",
        "track": "main",
        "status": "Poster",
        "abstract": "Data augmentation can be a simple yet powerful tool for autonomous robots to fully utilise available data for self-supervised identification of atypical scenes or objects. State-of-the-art augmentation methods arbitrarily embed \u201cstructural\u201d peculiarity on typical images so that classifying these artefacts can provide guidance for learning representations for the detection of anomalous visual signals. In this paper, however, we argue that learning such structure-sensitive representations can be a suboptimal approach to some classes of anomaly (e.g., unhealthy fruits) which could be better recognised by a different type of visual element such as \u201ccolour\u201d. We thus propose Channel Randomisation as a novel data augmentation method for restricting neural networks to learn encoding of \u201ccolour irregularity\u201d whilst predicting channel-randomised images to ultimately build reliable fruit-monitoring robots identifying atypical fruit qualities. Our experiments show that (1) this colour-based alternative can better learn representations for consistently accurate identification of fruit anomalies in various fruit species, and also, (2) unlike other methods, the validation accuracy can be utilised as a criterion for early stopping of training in practice due to positive correlation between the performance in the self-supervised colour-differentiation task and the subsequent detection rate of actual anomalous fruits. Also, the proposed approach is evaluated on a new agricultural dataset, Riseholme-2021, consisting of 3.5K strawberry images gathered by a mobile robot, which we share online to encourage active agri-robotics research.",
        "primary_area": "",
        "author": "Taeyeong Choi;Owen Would;Adrian Salazar-Gomez;Grzegorz Cielniak;Taeyeong Choi;Owen Would;Adrian Salazar-Gomez;Grzegorz Cielniak",
        "authorids": "/37086265117;/37089446962;/37089447058;/37550177700;/37086265117;/37089446962;/37089447058;/37550177700",
        "aff": "Lincoln Agri-Robotics (LAR) Centre, University of Lincoln, UK; Lincoln Agri-Robotics (LAR) Centre, University of Lincoln, UK; Lincoln Agri-Robotics (LAR) Centre, University of Lincoln, UK; Lincoln Agri-Robotics (LAR) Centre, University of Lincoln, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811954/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13635445210125318813&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Lincoln",
        "aff_unique_dep": "Lincoln Agri-Robotics (LAR) Centre",
        "aff_unique_url": "https://www.lincoln.ac.uk",
        "aff_unique_abbr": "UoL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812000",
        "title": "Self-supervised Transparent Liquid Segmentation for Robotic Pouring",
        "track": "main",
        "status": "Poster",
        "abstract": "Liquid state estimation is important for robotics tasks such as pouring; however, estimating the state of transparent liquids is a challenging problem. We propose a novel segmentation pipeline that can segment transparent liquids such as water from a static, RGB image without requiring any manual annotations or heating of the liquid for training. Instead, we use a generative model that is capable of translating images of colored liquids into synthetically generated transparent liquid images, trained only on an unpaired dataset of colored and transparent liquid images. Segmentation labels of colored liquids are obtained automatically using background subtraction. Our experiments show that we are able to accurately predict a segmentation mask for transparent liquids without requiring any manual annotations. We demonstrate the utility of transparent liquid segmentation in a robotic pouring task that controls pouring by perceiving the liquid height in a transparent cup. Accompanying video and supplementary materials can be found at https://sites.google.com/view/transparentliquidpouring.",
        "primary_area": "",
        "author": "Gautham Narasimhan;Kai Zhang;Ben Eisner;Xingyu Lin;David Held;Gautham Narasimhan;Kai Zhang;Ben Eisner;Xingyu Lin;David Held",
        "authorids": "/37089450889;/37089448835;/37089447812;/37089447209;/37408101800;/37089450889;/37089448835;/37089447812;/37089447209;/37408101800",
        "aff": "Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; University of Notre Dame; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA; Robotics Institute at Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812000/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13291719580779812094&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Notre Dame",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;https://www.nd.edu",
        "aff_unique_abbr": "CMU;Notre Dame",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811639",
        "title": "SelfTune: Metrically Scaled Monocular Depth Estimation through Self-Supervised Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular depth estimation in the wild inherently predicts depth up to an unknown scale. To resolve scale ambiguity issue, we present a learning algorithm that leverages monocular simultaneous localization and mapping (SLAM) with proprioceptive sensors. Such monocular SLAM systems can provide metrically scaled camera poses. Given these metric poses and monocular sequences, we propose a self-supervised learning method for the pre-trained supervised monocular depth networks to enable metrically scaled depth estimation. Our approach is based on a teacher-student formulation which guides our network to predict high-quality depths. We demonstrate that our approach is useful for various applications such as mobile robot navigation and is applicable to diverse environments. Our full system shows improvements over recent self-supervised depth estimation and completion methods on EuRoC, OpenLORIS, and ScanNet datasets.",
        "primary_area": "",
        "author": "Jaehoon Choi;Dongki Jung;Yonghan Lee;Deokhwa Kim;Dinesh Manocha;Donghwan Lee;Jaehoon Choi;Dongki Jung;Yonghan Lee;Deokhwa Kim;Dinesh Manocha;Donghwan Lee",
        "authorids": "/37089319189;/37088996964;/37089001508;/37088888616;/37267825600;/37088886388;/37089319189;/37088996964;/37089001508;/37088888616;/37267825600;/37088886388",
        "aff": "University of Maryland; NAVER LABS; NAVER LABS; NAVER LABS; University of Maryland; NAVER LABS",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811639/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7307111275432551916&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;1",
        "aff_unique_norm": "University of Maryland;NAVER Corporation",
        "aff_unique_dep": ";NAVER LABS",
        "aff_unique_url": "https://www/umd.edu;https://www.naverlabs.com",
        "aff_unique_abbr": "UMD;NAVER LABS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1;0;1",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9811925",
        "title": "SemLoc: Accurate and Robust Visual Localization with Semantic and Structural Constraints from Prior Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic information and geometrical structures of a prior map can be leveraged in visual localization to bound drift errors and improve accuracy. In this paper, we propose SemLoc, a pure visual localization system, for accurate localization in a prior semantic map. To tightly couple semantic and structure information from prior maps, a hybrid constraint is presented by using the Dirichlet distribution. Then, with the local landmarks and their semantic states tracked in the frontend, the camera poses and data associations are jointly optimized through Expectation-Maximization (EM) algorithm. We validate the effectiveness of our approach in both monocular and stereo modes on the public KITTI dataset. Experimental results demonstrate that our system can greatly reduce drift errors with an satisfying real-time performance. Compared with several state-of-the-art visual localization systems, the proposed framework achieves a competitive localization performance.",
        "primary_area": "",
        "author": "Shiwen Liang;Yunzhou Zhang;Rui Tian;Delong Zhu;Linghao Yang;Zhenzhong Cao;Shiwen Liang;Yunzhou Zhang;Rui Tian;Delong Zhu;Linghao Yang;Zhenzhong Cao",
        "authorids": "/37088996631;/37310459100;/37086594833;/37086137408;/37089239543;/37089239385;/37088996631;/37310459100;/37086594833;/37086137408;/37089239543;/37089239385",
        "aff": "College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811925/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13882132582191856298&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Northeastern University;Chinese University of Hong Kong",
        "aff_unique_dep": "College of Information Science and Engineering;Department of Electronic Engineering",
        "aff_unique_url": "http://www.neu.edu.cn/;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "NEU;CUHK",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Shenyang;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812457",
        "title": "Semantic-aware Texture-Structure Feature Collaboration for Underwater Image Enhancement",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater image enhancement has become an attractive topic as a significant technology in marine engi-neering and aquatic robotics. However, the limited number of datasets and imperfect hand-crafted ground truth weaken its robustness to unseen scenarios, and hamper the application to high-level vision tasks. To address the above limitations, we develop an efficient and compact enhancement network in collaboration with a high-level semantic-aware pretrained model, aiming to exploit its hierarchical feature representation as an auxiliary for the low-level underwater image enhance-ment. Specifically, we tend to characterize the shallow layer features as textures while the deep layer features as structures in the semantic-aware model, and propose a multi-path Contextual Feature Refinement Module (CFRM) to refine features in multiple scales and model the correlation between different features. In addition, a feature dominative network is devised to perform channel-wise modulation on the aggregated texture and structure features for the adaptation to different feature patterns of the enhancement network. Extensive experiments on benchmarks demonstrate that the proposed algorithm achieves more appealing results and outperforms state-of-the-art meth-ods by large margins. We also apply the proposed algorithm to the underwater salient object detection task to reveal the favorable semantic-aware ability for high-level vision tasks.",
        "primary_area": "",
        "author": "Di Wang;Long Ma;Risheng Liu;Xin Fan;Di Wang;Long Ma;Risheng Liu;Xin Fan",
        "authorids": "/37089503129;/37086452963;/38237556200;/37401468400;/37089503129;/37086452963;/38237556200;/37401468400",
        "aff": "School of Software Technology, Dalian University of Technology, Dalian, China; School of Software Technology, Dalian University of Technology, Dalian, China; DUT-RU International School of Information Science & Engineering, Dalian University of Technology, Dalian, China; DUT-RU International School of Information Science & Engineering, Dalian University of Technology, Dalian, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812457/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3356713342458596420&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Dalian University of Technology",
        "aff_unique_dep": "School of Software Technology",
        "aff_unique_url": "http://www.dlut.edu.cn",
        "aff_unique_abbr": "DUT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Dalian",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811817",
        "title": "Semantically Grounded Object Matching for Robust Robotic Scene Rearrangement",
        "track": "main",
        "status": "Poster",
        "abstract": "Object rearrangement has recently emerged as a key competency in robot manipulation, with practical solutions generally involving object detection, recognition, grasping and high-level planning. Goal-images describing a desired scene configuration are a promising and increasingly used mode of instruction. A key outstanding challenge is the accurate inference of matches between objects in front of a robot, and those seen in a provided goal image, where recent works have struggled in the absence of object-specific training data. In this work, we explore the deterioration of existing methods' ability to infer matches between objects as the visual shift between observed and goal scenes increases. We find that a fundamental limitation of the current setting is that source and target images must contain the same instance of every object, which restricts practical deployment. We present a novel approach to object matching that uses a large pre-trained vision-language model to match objects in a cross-instance setting by leveraging semantics together with visual features as a more robust, and much more general, measure of similarity. We demonstrate that this provides considerably improved matching performance in cross-instance settings, and can be used to guide multi-object rearrangement with a robot manipulator from an image that shares no object instances with the robot's scene. Our code is available at https://github.com/applied-ai-lab/object_matching.",
        "primary_area": "",
        "author": "Walter Goodwin;Sagar Vaze;Ioannis Havoutis;Ingmar Posner;Walter Goodwin;Sagar Vaze;Ioannis Havoutis;Ingmar Posner",
        "authorids": "/37089332972;/37088357901;/37542879900;/37601368300;/37089332972;/37088357901;/37542879900;/37601368300",
        "aff": "Oxford Robotics Institute, University of Oxford, Oxford; Visual Geometry Group, University of Oxford, Oxford; Oxford Robotics Institute, University of Oxford, Oxford; Oxford Robotics Institute, University of Oxford, Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811817/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7692414162060120779&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811823",
        "title": "Semi-Autonomous Teleoperation via Learning Non-Prehensile Manipulation Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a semi-autonomous teleoperation framework for a pick-and-place task using an RGB-D sensor. In particular, we assume that the target object is located in a cluttered environment where both prehensile grasping and non-prehensile manipulation are combined for efficient teleoperation. A trajectory-based reinforcement learning is utilized for learning the non-prehensile manipulation to rearrange the objects for enabling direct grasping. From the depth image of the cluttered environment and the location of the goal object, the learned policy can provide multiple options of non-prehensile manipulation to the human operator. We carefully design a reward function for the rearranging task where the policy is trained in a simulational environment. Then, the trained policy is transferred to a real-world and evaluated in a number of real-world experiments with the varying number of objects where we show that the proposed method outperforms manual keyboard control in terms of the time duration for the grasping.",
        "primary_area": "",
        "author": "Sangbeom Park;Yoonbyung Chai;Sunghyun Park;Jeongeun Park;Kyungjae Lee;Sungjoon Choi;Sangbeom Park;Yoonbyung Chai;Sunghyun Park;Jeongeun Park;Kyungjae Lee;Sungjoon Choi",
        "authorids": "/37089447330;/37089446718;/37089447326;/37089447938;/176686969759170;/37085405040;/37089447330;/37089446718;/37089447326;/37089447938;/176686969759170;/37085405040",
        "aff": "Department of Artificial Intelligence, Korea University, Seoul, Korea; Department of Artificial Intelligence, Korea University, Seoul, Korea; Department of Artificial Intelligence, Korea University, Seoul, Korea; Department of Artificial Intelligence, Korea University, Seoul, Korea; Department of Artificial Intelligence, Chungang University, Seoul, Korea; Department of Artificial Intelligence, Korea University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811823/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12775679360804599779&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Korea University;Chungang University",
        "aff_unique_dep": "Department of Artificial Intelligence;Department of Artificial Intelligence",
        "aff_unique_url": "https://www.korea.ac.kr;http://www.chungang.edu",
        "aff_unique_abbr": "KU;CGU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811802",
        "title": "Semi-Supervised Learning with Mutual Distillation for Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a semi-supervised learning framework for monocular depth estimation. Compared to existing semi-supervised learning methods, which inherit limitations of both sparse supervised and unsupervised loss functions, we achieve the complementary advantages of both loss functions, by building two separate network branches for each loss and distilling each other through the mutual distillation loss function. We also present to apply different data augmentation to each branch, which improves the robustness. We conduct experiments to demonstrate the effectiveness of our framework over the latest methods and provide extensive ablation studies.",
        "primary_area": "",
        "author": "Jongbeom Baek;Gyeongnyeon Kim;Seungryong Kim;Jongbeom Baek;Gyeongnyeon Kim;Seungryong Kim",
        "authorids": "/37089448779;/37089446614;/37072295000;/37089448779;/37089446614;/37072295000",
        "aff": "CVLAB, Korea University, Seoul, Korea; CVLAB, Korea University, Seoul, Korea; CVLAB, Korea University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811802/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4030554846626592430&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea University",
        "aff_unique_dep": "CVLAB",
        "aff_unique_url": "http://www.korea.ac.kr",
        "aff_unique_abbr": "KU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812412",
        "title": "Sen-Glove: A Lightweight Wearable Glove for Hand Assistance with Soft Joint Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Perception and portability are critical issues for wearable gloves in hand assistive engineering. However, available wearable gloves either lack flexible sensing or are bulky. In this paper, we present a tendon-driven lightweight wearable glove with soft joint sensing, Sen-Glove. Sen-Glove is equipped with 14 soft strain sensors, which enables full bending motion monitoring of 14 joints of five fingers and greatly reduces the weight of the glove. Besides, modular design makes Sen-Glove more compact and weighs 161g in total, reducing the burden on hand. A series of mechanical tests are conducted to evaluate the characteristics of Sen-Glove. Experimental results show that Sen-Glove can withstand 500 bending cycles, assist the subject in grasping 21 multi-scale objects, and recognize 11 gestures. The classification accuracy of 11 different gestures reaches 98.6 %, which verifies the efficacy of the strain sensors.",
        "primary_area": "",
        "author": "Linan Deng;Yi Shen;Yang Hong;Yunlong Dong;Xin He;Ye Yuan;Zhi Li;Han Ding;Linan Deng;Yi Shen;Yang Hong;Yunlong Dong;Xin He;Ye Yuan;Zhi Li;Han Ding",
        "authorids": "/37088932176;/37085460821;/37087041414;/37087317885;/37089340594;/37401229100;/37089448402;/37855758100;/37088932176;/37085460821;/37087041414;/37087317885;/37089340594;/37401229100;/37089448402;/37855758100",
        "aff": "School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Key Laboratory of Image Processing and Intelligent Control, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Key Laboratory of Image Processing and Intelligent Control, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Key Laboratory of Image Processing and Intelligent Control, Huazhong University of Science and Technology, Wuhan, China; School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wuhan, China; State Key Lab of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China; State Key Laboratory of Synthetical Automation for Process Industries, Northeastern University, Shenyang, China; State Key Lab of Digital Manufacturing Equipment and Technology, Huazhong University of Science and Technology, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812412/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16233796865453503785&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;1;0",
        "aff_unique_norm": "Huazhong University of Science and Technology;Northeastern University",
        "aff_unique_dep": "School of Mechanical Science and Engineering;State Key Laboratory of Synthetical Automation for Process Industries",
        "aff_unique_url": "http://www.hust.edu.cn;http://www.neu.edu.cn/",
        "aff_unique_abbr": "HUST;NEU",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;0",
        "aff_campus_unique": "Wuhan;Shenyang",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812159",
        "title": "SenSnake: A snake robot with contact force sensing for studying locomotion in complex 3-D terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite advances in a diversity of environments, snake robots are still far behind snakes in traversing complex 3-D terrain with large obstacles. This is due to a lack of understanding of how to control 3-D body bending to push against terrain features to generate and control propulsion. Biological studies suggested that generalist snakes use contact force sensing to adjust body bending in real time to do so. However, studying this sensory-modulated force control in snakes is challenging, due to a lack of basic knowledge of how their force sensing organs work. Here, we take a robophysics approach to make progress, starting by developing a snake robot capable of 3-D body bending with contact force sensing to enable systematic locomotion experiments and force measurements. Through two development and testing iterations, we created a 12-segment robot with 36 piezo-resistive sheet sensors distributed on all segments with compliant shells with a sampling frequency of 30 Hz. The robot measured contact forces while traversing a large obstacle using vertical bending with high repeatability, achieving the goal of providing a platform for systematic experiments. Finally, we explored model-based calibration considering the viscoelastic behavior of the piezo-resistive sensor, which will for useful for future studies.",
        "primary_area": "",
        "author": "Divya Ramesh;Qiyuan Fu;Chen Li;Divya Ramesh;Qiyuan Fu;Chen Li",
        "authorids": "/37087996296;/37089447232;/37086208270;/37087996296;/37089447232;/37086208270",
        "aff": "Dept. of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Dept. of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Dept. of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812159/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3087885992492885485&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812202",
        "title": "Sequential Joint Shape and Pose Estimation of Vehicles with Application to Automatic Amodal Segmentation Labeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Shape and pose estimation is a critical perception problem for a self-driving car to fully understand its surrounding environment. One fundamental challenge in solving this problem is the incomplete sensor signal (e.g., LiDAR scans), especially for faraway or occluded objects. In this paper, we propose a novel algorithm to address this challenge, which explicitly leverages the sensor signal captured over consecutive time: the consecutive signals can provide more information about an object, including different viewpoints and its motion. By encoding the consecutive signals via a recurrent neural network, not only our algorithm improves the shape and pose estimates, but also produces a labeling tool that can benefit other tasks in autonomous driving research. Specifically, building upon our algorithm, we propose a novel pipeline to automatically annotate high-quality labels for amodal segmentation on images, which are hard and laborious to annotate manually. Our code and data will be made publicly available.",
        "primary_area": "",
        "author": "Josephine Monica;Wei-Lun Chao;Mark Campbell;Josephine Monica;Wei-Lun Chao;Mark Campbell",
        "authorids": "/37086939060;/37086876034;/37272971700;/37086939060;/37086876034;/37272971700",
        "aff": "Mechanical and Aerospace Engineering Department, Cornell University, NY, USA; Computer Science and Engineering Department, The Ohio State University, OH, USA; Mechanical and Aerospace Engineering Department, Cornell University, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812202/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17357821207201282209&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Cornell University;Ohio State University",
        "aff_unique_dep": "Mechanical and Aerospace Engineering Department;Computer Science and Engineering Department",
        "aff_unique_url": "https://www.cornell.edu;https://www.osu.edu",
        "aff_unique_abbr": "Cornell;OSU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Ithaca;OH",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812244",
        "title": "Shape Control of Deformable Linear Objects with Offline and Online Learning of Local Linear Deformation Models",
        "track": "main",
        "status": "Poster",
        "abstract": "The shape control of deformable linear objects (DLOs) is challenging, since it is difficult to obtain the deformation models. Previous studies often approximate the models in purely offline or online ways. In this paper, we propose a scheme for the shape control of DLOs, where the unknown model is estimated with both offline and online learning. The model is formulated in a local linear format, and approximated by a neural network (NN). First, the NN is trained offline to provide a good initial estimation of the model, which can directly migrate to the online phase. Then, an adaptive controller is proposed to achieve the shape control tasks, in which the NN is further updated online to compensate for any errors in the offline model caused by insufficient training or changes of DLO properties. The simulation and real-world experiments show that the proposed method can precisely and efficiently accomplish the DLO shape control tasks, and adapt well to new and untrained DLOs.",
        "primary_area": "",
        "author": "Mingrui Yu;Hanzhong Zhong;Xiang Li;Mingrui Yu;Hanzhong Zhong;Xiang Li",
        "authorids": "/37089448870;/37089446640;/37280877200;/37089448870;/37089446640;/37280877200",
        "aff": "Department of Automation, Tsinghua University, China; School of Aerospace Engineering, Tsinghua University, China; Department of Automation, Tsinghua University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812244/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18091531733780758539&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812040",
        "title": "ShapeMap 3-D: Efficient shape mapping through dense touch and vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge of 3-D object shape is of great importance to robot manipulation tasks, but may not be readily available in unstructured environments. While vision is often occluded during robot-object interaction, high-resolution tactile sensors can give a dense local perspective of the object. However, tactile sensors have limited sensing area and the shape representation must faithfully approximate non-contact areas. In addition, a key challenge is efficiently incorporating these dense tactile measurements into a 3-D mapping framework. In this work, we propose an incremental shape mapping method using a GelSight tactile sensor and a depth camera. Local shape is recovered from tactile images via a learned model trained in simulation. Through efficient inference on a spatial factor graph informed by a Gaussian process, we build an implicit surface representation of the object. We demonstrate visuo-tactile mapping in both simulated and real-world experiments, to incrementally build 3-D reconstructions of household objects.",
        "primary_area": "",
        "author": "Sudharshan Suresh;Zilin Si;Joshua G. Mangelson;Wenzhen Yuan;Michael Kaess;Sudharshan Suresh;Zilin Si;Joshua G. Mangelson;Wenzhen Yuan;Michael Kaess",
        "authorids": "/37086609669;/37089194088;/37086109836;/37085486405;/37324200400;/37086609669;/37089194088;/37086109836;/37085486405;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Electrical and Computer Engineering Department, Brigham Young University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812040/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9224631698121006217&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Brigham Young University",
        "aff_unique_dep": "Robotics Institute;Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.cmu.edu;https://www.byu.edu",
        "aff_unique_abbr": "CMU;BYU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812327",
        "title": "SiamX: An Efficient Long-term Tracker Using Cross-level Feature Correlation and Adaptive Tracking Scheme",
        "track": "main",
        "status": "Poster",
        "abstract": "Siamese network based trackers have achieved significant progress in visual object tracking. For the sake of speed, they mainly rely on offline training to learn a mono-level feature correlation between a target template and a search region. During the tracking period, they use a fixed strategy to infer target positions over sequences regardless of target states. However, such approaches are vulnerable in case of long-term challenges e.g. large variance, presence of distractors, fast motion, or target disappearing and the like. In this paper, we propose a new tracking framework, referred to as SiamX, by exploiting cross-level Siamese features to learn robust correlations between the target template and search regions, and also adaptive inference strategies to prevent tracking loss and realize fast target re-localization. Extensive experiments on four benchmarks including VOT-2019, LaSOT, GOT-10k, and TrackingNet show our method significantly enhances the tracker's ability to resist variance and interference, and achieve state-of-the-art results at around 50 FPS.",
        "primary_area": "",
        "author": "Huajian Huang;Sai-Kit Yeung;Huajian Huang;Sai-Kit Yeung",
        "authorids": "/37088691434;/37529101500;/37088691434;/37529101500",
        "aff": "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812327/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6735543704998267869&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811783",
        "title": "Sim-to-Real Learning for Bipedal Locomotion Under Unsensed Dynamic Loads",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work on sim-to-real learning for bipedal locomotion has demonstrated new levels of robustness and agility over a variety of terrains. However, that work, and most prior bipedal locomotion work, have not considered locomotion under a variety of external loads that can significantly influence the overall system dynamics. In many applications, robots will need to maintain robust locomotion under a wide range of potential dynamic loads, such as pulling a cart or carrying a large container of sloshing liquid, ideally without requiring additional load-sensing capabilities. In this work, we explore the capabilities of reinforcement learning (RL) and sim-to-real transfer for bipedal locomotion under dynamic loads using only proprioceptive feedback. We show that prior RL policies trained for unloaded locomotion fail for some loads and that simply training in the context of loads is enough to result in successful and improved policies. We also compare training specialized policies for each load versus a single policy for all considered loads and analyze how the resulting gaits change to accommodate different loads. Finally, we demonstrate sim-to-real transfer, which is successful but shows a wider sim-to-real gap than prior unloaded work, which points to interesting future research.",
        "primary_area": "",
        "author": "Jeremy Dao;Kevin Green;Helei Duan;Alan Fern;Jonathan Hurst;Jeremy Dao;Kevin Green;Helei Duan;Alan Fern;Jonathan Hurst",
        "authorids": "/37086114282;/37087323965;/37086154386;/37353413400;/37267365600;/37086114282;/37087323965;/37086154386;/37353413400;/37267365600",
        "aff": "Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811783/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6011808005864230935&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812015",
        "title": "Sim-to-Real Learning of Footstep-Constrained Bipedal Dynamic Walking",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, work on reinforcement learning (RL) for bipedal robots has successfully learned controllers for a variety of dynamic gaits with robust sim-to-real demonstrations. In order to maintain balance, the learned controllers have full freedom of where to place the feet, resulting in highly robust gaits. In the real world however, the environment will often impose constraints on the feasible footstep locations, typically identified by perception systems. Unfortunately, most demonstrated RL controllers on bipedal robots do not allow for specifying and responding to such constraints. This missing control interface greatly limits the real-world application of current RL controllers. In this paper, we aim to maintain the robust and dynamic nature of learned gaits while also respecting footstep constraints imposed externally. We develop an RL formulation for training dynamic gait controllers that can respond to specified touchdown locations. We then successfully demonstrate simulation and sim-to-real performance on the bipedal robot Cassie. In addition, we use supervised learning to induce a transition model for accurately predicting the next touchdown locations that the controller can achieve given the robot's proprioceptive observations. This model paves the way for integrating the learned controller into a full-order robot locomotion planner that robustly satisfies both balance and environmental constraints.",
        "primary_area": "",
        "author": "Helei Duan;Ashish Malik;Jeremy Dao;Aseem Saxena;Kevin Green;Jonah Siekmann;Alan Fern;Jonathan Hurst;Helei Duan;Ashish Malik;Jeremy Dao;Aseem Saxena;Kevin Green;Jonah Siekmann;Alan Fern;Jonathan Hurst",
        "authorids": "/37086154386;/37086805622;/37086114282;/37089448379;/37087323965;/37088997435;/37353413400;/37267365600;/37086154386;/37086805622;/37086114282;/37089448379;/37087323965;/37088997435;/37353413400;/37267365600",
        "aff": "Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Agility Robotics, Albany, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812015/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10545416069679168117&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Oregon State University;Agility Robotics",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems Institute;",
        "aff_unique_url": "https://oregonstate.edu;",
        "aff_unique_abbr": "OSU;",
        "aff_campus_unique_index": "0;0;0;0;0;1;0;0",
        "aff_campus_unique": "Corvallis;Albany",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811844",
        "title": "Simulation and Fabrication of Soft Robots with Embedded Skeletons",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots can be incredibly robust and safe but typically fail to match the strength and precision of rigid robots. This dichotomy between soft and rigid is recently starting to break down, with emerging research interest in hybrid soft-rigid robots. In this work, we draw inspiration from Nature, which achieves the best of both worlds by coupling soft and rigid tissues-like muscle and bone-to produce biological systems capable of both robustness and strength. We present foundational, general-purpose pipelines to simulate and fabricate cable-driven soft-rigid robots with embedded skeletons. We show that robots built using these methods can fluidly mimic biological systems while achieving greater force output and external load resistance than purely soft robots. Finally, we show how our simulation and fabrication pipelines can be leveraged to create more complex robots and do model-based control.",
        "primary_area": "",
        "author": "James M. Bern;Fatemeh Zargarbashi;Annan Zhang;Josie Hughes;Daniela Rus;James M. Bern;Fatemeh Zargarbashi;Annan Zhang;Josie Hughes;Daniela Rus",
        "authorids": "/37086293656;/37088653208;/37089449090;/37085816016;/37279652300;/37086293656;/37088653208;/37089449090;/37085816016;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Laboratory, MIT; Computational Robot Design & Fabrication Lab, EPFL; Computer Science and Artificial Intelligence Laboratory, MIT; Computational Robot Design & Fabrication Lab, EPFL; Computer Science and Artificial Intelligence Laboratory, MIT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811844/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6494915060914835347&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;EPFL",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Computational Robot Design & Fabrication Lab",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.epfl.ch",
        "aff_unique_abbr": "MIT;EPFL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "9811875",
        "title": "Simultaneous Control and Trajectory Estimation for Collision Avoidance of Autonomous Robotic Spacecraft Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose factor graph optimization for simultaneous planning, control, and trajectory estimation for collision-free navigation of autonomous systems in environments with moving objects. The proposed online probabilistic motion planning and trajectory estimation navigation technique generates optimal collision-free state and control trajectories for autonomous vehicles when the obstacle motion model is both unknown and known. We evaluate the utility of the algorithm to support future autonomous robotic space missions.",
        "primary_area": "",
        "author": "Matthew King\u2013Smith;Panagiotis Tsiotras;Frank Dellaert;Matthew King\u2013Smith;Panagiotis Tsiotras;Frank Dellaert",
        "authorids": "/37087606478;/37330609800;/37282902200;/37087606478;/37330609800;/37282902200",
        "aff": "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811875/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1294267115055848920&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812340",
        "title": "Single User WiFi Structure from Motion in the Wild",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel motion estimation algorithm using WiFi networks and IMU sensor data in large uncontrolled environments, dubbed \u201cWiFi Structure-from-Motion\u201d (WiFi SfM). Given smartphone sensor data through day-to-day activities from a single user over a month, our WiFi SfM algorithm estimates smartphone motion tra-jectories and the structure of the environment represented as a WiFi radio map. The approach 1) establishes frame-to-frame correspondences based on WiFi fingerprints while exploiting our repetitive behavior patterns; 2) aligns trajectories via bundle adjustment; and 3) trains a self-supervised neural network to extract further motion constraints. We have col-lected 235 hours of smartphone data, spanning 38 days of daily activities in a university campus. Our experiments demonstrate the effectiveness of our approach over the competing methods with qualitative evaluations of the estimated motions and quantitative evaluations of indoor localization accuracy based on the reconstructed WiFi radio map. The WiFi SfM technology will potentially allow digital mapping companies to build better radio maps automatically by asking users to share WiFi/IMU sensor data in their daily activities.",
        "primary_area": "",
        "author": "Yiming Qian;Hang Yan;Sachini Herath;Pyojin Kim;Yasutaka Furukawa;Yiming Qian;Hang Yan;Sachini Herath;Pyojin Kim;Yasutaka Furukawa",
        "authorids": "/37085580008;/37088506488;/37085715341;/37085573756;/37086288534;/37085580008;/37088506488;/37085715341;/37085573756;/37086288534",
        "aff": "University of Manitoba; Washington University in St. Louis.; Simon Fraser University; Sookmyung Women's University; Simon Fraser University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812340/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12254186597254884964&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;2",
        "aff_unique_norm": "University of Manitoba;Washington University in St. Louis;Simon Fraser University;Sookmyung Women's University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://umanitoba.ca;https://wustl.edu;https://www.sfu.ca;https://www.sookmyung.ac.kr",
        "aff_unique_abbr": "U of M;WUSTL;SFU;SWU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";St. Louis",
        "aff_country_unique_index": "0;1;0;2;0",
        "aff_country_unique": "Canada;United States;South Korea"
    },
    {
        "id": "9812299",
        "title": "Single-Stage Keypoint- Based Category-Level Object Pose Estimation from an RGB Image",
        "track": "main",
        "status": "Poster",
        "abstract": "Prior work on 6-DoF object pose estimation has largely focused on instance-level processing, in which a textured CAD model is available for each object being detected. Category-level 6- DoF pose estimation represents an important step toward developing robotic vision systems that operate in unstructured, real-world scenarios. In this work, we propose a single-stage, keypoint-based approach for category-level object pose estimation that operates on unknown object instances within a known category using a single RGB image as input. The proposed network performs 2D object detection, detects 2D keypoints, estimates 6- DoF pose, and regresses relative bounding cuboid dimensions. These quantities are estimated in a sequential fashion, leveraging the recent idea of convGRU for propagating information from easier tasks to those that are more difficult. We favor simplicity in our design choices: generic cuboid vertex coordinates, single-stage network, and monocular RGB input. We conduct extensive experiments on the challenging Objectron benchmark, outperforming state-of-the-art methods on the 3D IoU metric (27.6% higher than the MobilePose single-stage approach and 7.1 % higher than the related two-stage approach).",
        "primary_area": "",
        "author": "Yunzhi Lin;Jonathan Tremblay;Stephen Tyree;Patricio A. Vela;Stan Birchfield;Yunzhi Lin;Jonathan Tremblay;Stephen Tyree;Patricio A. Vela;Stan Birchfield",
        "authorids": "/37088506366;/37086455314;/37074894100;/37329553400;/37371627300;/37088506366;/37086455314;/37074894100;/37329553400;/37371627300",
        "aff": "Georgia Institute of Technology; NVIDIA; NVIDIA; Georgia Institute of Technology; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812299/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14728048708922565798&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Georgia Institute of Technology;NVIDIA",
        "aff_unique_dep": ";NVIDIA Corporation",
        "aff_unique_url": "https://www.gatech.edu;https://www.nvidia.com",
        "aff_unique_abbr": "Georgia Tech;NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812127",
        "title": "Skeletal Feature Compensation for Imitation Learning with Embodiment Mismatch",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from demonstrations in the wild (e.g. YouTube videos) is a tantalizing goal in imitation learning. However, for this goal to be achieved, imitation learning algorithms must deal with the fact that the demonstrators and learners may have bodies that differ from one another. This condition \u2014 \u201cembodiment mismatch\u201d \u2014 is ignored by many recent imitation learning algorithms. Our proposed imitation learning technique, SILEM (Skeletal feature compensation for Imitation Learning with Embodiment Mismatch), addresses a particular type of embodiment mismatch by introducing a learned affine transform to compensate for differences in the skeletal features obtained from the learner and expert. We create toy domains based on PyBullet's HalfCheetah and Ant to assess SILEM's benefits for this type of embodiment mismatch. We also provide qualitative and quantitative results on more realistic problems \u2014 teaching simulated humanoid agents, including Atlas from Boston Dynamics, to walk by observing human demonstrations.",
        "primary_area": "",
        "author": "Eddy Hudson;Garrett Warnell;Faraz Torabi;Peter Stone;Eddy Hudson;Garrett Warnell;Faraz Torabi;Peter Stone",
        "authorids": "/37089447750;/37079072000;/37088467305;/37269574900;/37089447750;/37079072000;/37088467305;/37269574900",
        "aff": "The University of Texas at Austin, Austin, Texas, USA; Army Research Laboratory, Austin, Texas, USA; The University of Texas at Austin, Austin, Texas, USA; Sony AI, Austin, Texas, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812127/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15764094647816850007&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "University of Texas at Austin;Army Research Laboratory;Sony AI",
        "aff_unique_dep": ";;AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.arl.army.mil;https://www.sony.ai",
        "aff_unique_abbr": "UT Austin;ARL;Sony AI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812005",
        "title": "Sliding Mode Controller for Positioning of an Underwater Vehicle Subject to Disturbances and Time Delays",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned underwater vehicles are crucial for deep-sea exploration and inspection without imposing any danger to human life due to extreme environmental conditions. But, designing a robust controller that can cope with model uncertainties, external disturbances, and time delays for such vehicles is a challenge. This paper implements a sliding mode position control algorithm with a time-delay estimation term to a remotely operated underwater vehicle to deal with disturbances, such as waves, and time delays. The controller is implemented on an underwater vehicle (BlueRov) and compared with a proportional-integral-derivative (PID) controller in a wave tank with different disturbances and when there exist delays within the communication channel. The experimental results show that the proposed control method provides better performance than the conventional PID in the presence of extreme disturbances with less control efforts.",
        "primary_area": "",
        "author": "Harun Tugal;Kamil Cetin;Xiaoran Han;Ibrahim Kucukdemiral;Joshua Roe;Yvan Petillot;M. Suphi Erden;Harun Tugal;Kamil Cetin;Xiaoran Han;Ibrahim Kucukdemiral;Joshua Roe;Yvan Petillot;M. Suphi Erden",
        "authorids": "/38229689100;/37543065000;/37089447096;/37274812000;/37089303114;/37282015500;/38577478400;/38229689100;/37543065000;/37089447096;/37274812000;/37089303114;/37282015500;/38577478400",
        "aff": "Institute of Sensors, Signals and Systems, School of Engineering and Physical Sciences, Heriot-Watt University; Edinburgh Centre for Robotics, Edinburgh, UK; Edinburgh Centre for Robotics, Edinburgh, UK; School of Computing, Engineering and Built Environment, Glasgow Caledonian University, Glasgow, UK; Edinburgh Centre for Robotics, Edinburgh, UK; Edinburgh Centre for Robotics, Edinburgh, UK; Edinburgh Centre for Robotics, Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812005/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10166705308567886950&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;2;1;1;1",
        "aff_unique_norm": "Heriot-Watt University;Edinburgh Centre for Robotics;Glasgow Caledonian University",
        "aff_unique_dep": "Institute of Sensors, Signals and Systems;;School of Computing, Engineering and Built Environment",
        "aff_unique_url": "https://www.hw.ac.uk;;https://www.gcu.ac.uk",
        "aff_unique_abbr": "HWU;;GCU",
        "aff_campus_unique_index": "1;1;2;1;1;1",
        "aff_campus_unique": ";Edinburgh;Glasgow",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811563",
        "title": "Smoothing Away From The Edge For Mesh Estimation in Urban Outdoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "3D meshes offer a computationally efficient but still quite accurate path to the understanding of a robot's environment. While mesh reconstructions are often employed in indoor regions where regular planar surfaces dominate the scene, their use in urban outdoor environments has been under-explored. This is as outdoor urban environments produce a significant contrast between preserving discontinuities between different objects and maintaining smoothness in the solution. When coupled with the natural sparse nature of meshes this presents a significant challenge to their optimisation. Motivated by these challenges and leveraging insights from computer graphics, we firstly balance previously introduced real-time definitions of variational smoothing on meshes with their \u2018canonical\u2019 definitions. In doing so we introduce a novel Delaunay-Voronoi formulation for real-time mesh smoothing that allows for the accumulation of information away from the triangular edges. This allows for the use of more powerful non-convex regularisers that are able to more finely balance smoothness and object discontinuities and showcase more faithful reconstructions of the urban outdoor scene. In doing so the benefits of non-convex regularisers promised in the \u2018every-pixel\u2019 scenarios can now be inherited by sparse mesh formulations.",
        "primary_area": "",
        "author": "Jason Pilbrough;Paul Amayo;Jason Pilbrough;Paul Amayo",
        "authorids": "/37089194207;/37085789648;/37089194207;/37085789648",
        "aff": "African Robotics Unit, Dept. Electrical Engineering, University of Cape Town, South Africa; African Robotics Unit, Dept. Electrical Engineering, University of Cape Town, South Africa",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811563/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:aXN2pKeBXg4J:scholar.google.com/&scioq=Smoothing+Away+From+The+Edge+For+Mesh+Estimation+in+Urban+Outdoor+Environments&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Cape Town",
        "aff_unique_dep": "Dept. Electrical Engineering",
        "aff_unique_url": "https://www.ru.ac.za",
        "aff_unique_abbr": "UCT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Africa"
    },
    {
        "id": "9811779",
        "title": "SnailBot: A Continuously Dockable Modular Self-reconfigurable Robot Using Rocker-bogie Suspension",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel modular self-assembling, self-reconfiguring robot with the 3D continuous dock called \u201cSnailBot\u201d. SnailBot mainly consists of a spherical ferromagnetic shell and a six-wheel rocker chassis with embedded magnets. Unlike many other existing modular self-reconfigurable robots with fixed docking locations, SnailBot uses the 3D continuous dock to attach to its peers regardless of alignment. This freeform docking mechanism can greatly improve the efficiency of self-reconfiguration and reduce docking failures because there is nearly no constraint in the location of the connector. Compared with the existing freeform MSRR, SnailBot can form a more structurally stable connection to its peers without loss of connection efficiency. Owing to the excellent obstacle crossing ability of the rocker-bogie suspension, the robot can freely crawl on other modules in the form of a sliding sphere. Experiments demonstrate the basic actions of a single module and some applications of SnailBots, such as a manipulator.",
        "primary_area": "",
        "author": "Da Zhao;Tin Lun Lam;Da Zhao;Tin Lun Lam",
        "authorids": "/37088583709;/37571111600;/37088583709;/37571111600",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811779/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2384324954364246259&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.siarfs.org/",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812094",
        "title": "Soft-Jig: A Flexible Sensing Jig for Simultaneously Fixing and Estimating Orientation of Assembly Parts",
        "track": "main",
        "status": "Poster",
        "abstract": "For assembly tasks, it is essential to fix target parts firmly and accurately estimate their poses. Several rigid jigs for individual parts are frequently used in assembly factories to achieve a precise and time-efficient product assembly. However, providing customized jigs is time-consuming. In this study, to address the lack of versatility in the shapes for which jigs can be used, we developed a flexible jig with a soft membrane including transparent beads and oil with a tuned refractive index. The bead-based jamming transition was accomplished by discharging only the oil, enabling the part to be firmly fixed. Because the two cameras under the jig can capture membrane shape changes, we proposed a sensing method to estimate the orientation of the part based on the behaviors of markers created on the jig's inner surface. Through estimation experiments, the proposed system can estimate the orientation of a cylindrical object with a diameter larger than 50 mm and an RMSE of less than 3\u00b0.",
        "primary_area": "",
        "author": "Tatsuya Sakuma;Takuya Kiyokawa;Jun Takamatsu;Takahiro Wada;Tsukasa Ogasawara;Tatsuya Sakuma;Takuya Kiyokawa;Jun Takamatsu;Takahiro Wada;Tsukasa Ogasawara",
        "authorids": "/37086581398;/37086694759;/37324010500;/37329590300;/37269488400;/37086581398;/37086694759;/37324010500;/37329590300;/37269488400",
        "aff": "Division of Information Science, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Nara Institute of Science and Technology (NAIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812094/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14267811423251928630&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Nara Institute of Science and Technology",
        "aff_unique_dep": "Division of Information Science",
        "aff_unique_url": "https://www.naist.jp",
        "aff_unique_abbr": "NAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9812277",
        "title": "Spatial Acoustic Projection for 3D Imaging Sonar Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we present a novel method for reconstructing 3D surfaces using a multi-beam imaging sonar. We integrate the intensities measured by the sonar from different viewpoints for fixed cell positions in a 3D grid. For each cell we integrate a feature vector that holds the mean intensity for a discretized range of viewpoints. Based on the feature vectors and independent sparse range measurements that act as ground truth information, we train convolutional neural networks that allow us to predict the signed distance and direction to the nearest surface for each cell. The predicted signed distances can be projected into a truncated signed distance field (TSDF) along the predicted directions. Utilizing the marching cubes algorithm, a polygon mesh can be rendered from the TSDF. Our method allows a dense 3D reconstruction from a limited set of viewpoints and was evaluated on three real-world datasets.",
        "primary_area": "",
        "author": "Sascha Arnold;Bilal Wehbe;Sascha Arnold;Bilal Wehbe",
        "authorids": "/37085667822;/37085591788;/37085667822;/37085591788",
        "aff": "German Research Center for Artificial Intelligence, Bremen, Germany; German Research Center for Artificial Intelligence, Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812277/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12072110781165816585&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "German Research Center for Artificial Intelligence",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.dfki.de",
        "aff_unique_abbr": "DFKI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812348",
        "title": "SpecTac: A Visual-Tactile Dual-Modality Sensor Using UV Illumination",
        "track": "main",
        "status": "Poster",
        "abstract": "Perceiving the dynamical environment both visually and tactilely is crucial for the survival of animals, and therefore, is considered of importance in robotics research. Recently, there has been an increasing interest in vision-based tactile sensors due to their high sensing resolution and robustness to environmental changes. However, almost all vision-based tactile sensors make only partial use of the camera, specifically, only when contact occurs, and stay idle at other times, which results in a waste of the camera information bandwidth. In this paper, we propose a new visual-tactile dual-modality sensor called SpecTac, which can visually inspect the environment and make tactile observations. The main novelty of the sensor is the use of ultraviolet (UV) LEDs and randomly distributed UV fluorescent markers. When the LEDs are on, those markers will be bright and can easily be distinguished and tracked from the background. Besides, by controlling the on and off of the UV LEDs, due to the switchable visibility of those markers, the sensor will switch between visual and tactile sensing mode. The qualities of tactile and visual perception are evaluated quantitatively by force estimation, visual triangulation and visual feature matching. By combining both modalities into one compact sensor, the information from the camera is better utilized, and it is hoped that the sensor will achieve more flexibility in the motion of the robot arm, especially in tasks where the workspace is narrow.",
        "primary_area": "",
        "author": "Qi Wang;Yipai Du;Michael Yu Wang;Qi Wang;Yipai Du;Michael Yu Wang",
        "authorids": "/37089450439;/37088526419;/37280913900;/37089450439;/37088526419;/37280913900",
        "aff": "Hong Kong University of Science and Technology; Hong Kong University of Science and Technology; HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute, Futian, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812348/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9611277253749906059&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812136",
        "title": "Speed Planning in Dynamic Environments over a Fixed Path for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel convex optimization approach to address the minimum-time speed planning problem over a fixed path with dynamic obstacle constraints and point-wise speed and acceleration constraints. The contributions of this paper are three-fold. First, we formulate the speed planning as an iterative convex optimization problem based on space discretization. Our formulation allows imposing dynamic obstacle constraints and point-wise speed and acceleration constraints simultaneously. Second, we propose a modified vertical cell decomposition method to handle dynamic obstacles. It divides the freespace into channels, where each channel represents a homotopy of free paths and defines convex constraints for dynamic obstacles. Third, we demonstrate significant improvement over previous work on speed planning for typical driving scenarios such as following, merging, and crossing.",
        "primary_area": "",
        "author": "Wenda Xu;John M. Dolan;Wenda Xu;John M. Dolan",
        "authorids": "/37085555642;/37283756800;/37085555642;/37283756800",
        "aff": "Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA; Faculty of the Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812136/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7932757582226608328&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812313",
        "title": "Speeding up deep neural network-based planning of local car maneuvers via efficient B-spline path construction",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper demonstrates how an efficient repre-sentation of the planned path using B-splines, and a construction procedure that takes advantage of the neural network's inductive bias, speed up both the inference and training of a DNN-based motion planner. We build upon our recent work on learning local car maneuvers from past experience using a DNN architecture, introducing a novel B-spline path construction method, making it possible to generate local maneuvers in almost constant time of about 11 ms, respecting a number of constraints imposed by the environment map and the kinematics of a car-like vehicle. We evaluate thoroughly the new planner employing the recent Bench-MR framework to obtain quantitative results showing that our method outperforms state-of-the-art planners by a large margin in the considered task.",
        "primary_area": "",
        "author": "Piotr Kicki;Piotr Skrzypczy\u0144ski;Piotr Kicki;Piotr Skrzypczy\u0144ski",
        "authorids": "/37086604933;/37611911500;/37086604933;/37611911500",
        "aff": "Institute of Robotics and Machine Intelligence, Poz-nan University of Technology, Poznan, Poland; Institute of Robotics and Machine Intelligence, Poz-nan University of Technology, Poznan, Poland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812313/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11368928092058077087&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Poznan University of Technology",
        "aff_unique_dep": "Institute of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.put.poznan.pl/",
        "aff_unique_abbr": "PUT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Poznan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Poland"
    },
    {
        "id": "9812382",
        "title": "Stable 3D Human Pose Estimation in Low- Resolution Videos with a Few Views",
        "track": "main",
        "status": "Poster",
        "abstract": "We discuss the problem of 3D pose estimation for multi-view videos. With previous frame-by-frame multi-view methods, it has been difficult to achieve stable estimation under challenging settings such as low-resolution or with only a few views. Temporal approaches are effective ways of addressing such problems, but enforcing temporal consistency with neigh-boring frames sometimes damages the precision of the results. We propose a temporal approach with selective corrections based on the observation that errors in the frame-by-frame approach are concentrated under certain adverse conditions. Our method evaluates the confidence of the frame-by-frame results and compensates for the inaccurate keypoints with temporal information while retaining the accurate keypoints. In our experiments on the CMU Panoptic dataset customized for low-resolution and a few views, we reported 32.98 mm for MPJPE and 98.64% for 3D-PCK@150. Compared to the state-of-the-art method, our method improved MPJPE by 1.14 mm and corrected 16 % of incorrect keypoints.",
        "primary_area": "",
        "author": "Chihiro Nakatsuka;Satoshi Komorita;Chihiro Nakatsuka;Satoshi Komorita",
        "authorids": "/37089194968;/37400201100;/37089194968;/37400201100",
        "aff": "KDDI Research, Inc., Saitama, Japan; KDDI Research, Inc., Saitama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812382/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4397535387785210236&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KDDI Research, Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kddi-research.com",
        "aff_unique_abbr": "KDDI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9811655",
        "title": "Stable Object Reorientation using Contact Plane Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a system for accurately predicting stable orientations for diverse rigid objects. We propose to overcome the critical issue of modelling multimodality in the space of rotations by using a conditional generative model to accurately classify contact surfaces. Our system is capable of operating from noisy and partially-observed pointcloud observations captured by real world depth cameras. Our method substantially outperforms the current state-of-the-art systems on a simulated stacking task requiring highly accurate rotations, and demonstrates strong sim2real zero-shot transfer results across a variety of unseen objects on a real world reorientation task.",
        "primary_area": "",
        "author": "Richard Li;Carlos Esteves;Ameesh Makadia;Pulkit Agrawal;Richard Li;Carlos Esteves;Ameesh Makadia;Pulkit Agrawal",
        "authorids": "/37088505915;/37086301091;/37270620600;/37085611190;/37088505915;/37086301091;/37270620600;/37085611190",
        "aff": "Improbable AI Lab, Massachusetts Institute of Technology, USA; Google Research, New York; Google Research, New York; Improbable AI Lab, Massachusetts Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811655/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1375117403618317405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Google",
        "aff_unique_dep": "Improbable AI Lab;Google Research",
        "aff_unique_url": "https://www.mit.edu;https://research.google",
        "aff_unique_abbr": "MIT;Google",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Cambridge;New York",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811626",
        "title": "Stable and Efficient Shapley Value-Based Reward Reallocation for Multi-Agent Reinforcement Learning of Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "With the development of sensing and communication technologies in networked cyber-physical systems (CPSs), multi-agent reinforcement learning (MARL)-based methodologies are integrated into the control process of physical systems and demonstrate prominent performance in a wide array of CPS domains, such as connected autonomous vehicles (CAVs). However, it remains challenging to mathematically characterize the improvement of the performance of CAVs with communication and cooperation capability. When each individual autonomous vehicle is originally self-interest, we can not assume that all agents would cooperate naturally during the training process. In this work, we propose to reallocate the system's total reward efficiently to motivate stable cooperation among autonomous vehicles. We formally define and quantify how to reallocate the system's total reward to each agent under the proposed transferable utility game, such that communication-based cooperation among multi-agents increases the system's total reward. We prove that Shapley value-based reward reallocation of MARL locates in the core if the transferable utility game is a convex game. Hence, the cooperation is stable and efficient and the agents should stay in the coalition or the cooperating group. We then propose a cooperative policy learning algorithm with Shapley value reward reallocation. In experiments, compared with several literature algorithms, we show the improvement of the mean episode system reward of CAV systems using our proposed algorithm.",
        "primary_area": "",
        "author": "Songyang Han;He Wang;Sanbao Su;Yuanyuan Shi;Fei Miao;Songyang Han;He Wang;Sanbao Su;Yuanyuan Shi;Fei Miao",
        "authorids": "/37088333832;/37088660488;/37086457798;/37089450695;/37072758500;/37088333832;/37088660488;/37086457798;/37089450695;/37072758500",
        "aff": "Department of Computer Science and Engineering, University of Connecticut, Storrs Mansfield, CT, USA; School of Information Science and Technology, ShanghaiTech University, Shanghai, China; Department of Computer Science and Engineering, University of Connecticut, Storrs Mansfield, CT, USA; Electrical and Computer Engineering Department, University of California, San Diego, La Jolla, CA, USA; Department of Computer Science and Engineering, University of Connecticut, Storrs Mansfield, CT, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811626/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10651513747867860240&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "University of Connecticut;ShanghaiTech University;University of California, San Diego",
        "aff_unique_dep": "Department of Computer Science and Engineering;School of Information Science and Technology;Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.uconn.edu;https://www.shanghaitech.edu.cn;https://www.ucsd.edu",
        "aff_unique_abbr": "UConn;ShanghaiTech;UCSD",
        "aff_campus_unique_index": "0;1;0;2;0",
        "aff_campus_unique": "Storrs Mansfield;Shanghai;La Jolla",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9811678",
        "title": "Stackelberg Strategic Guidance for Heterogeneous Robots Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we explore the application of game theory, in particular Stackelberg games, to address the issue of effective coordination strategy generation for heterogeneous robots with one-way communication. To that end, focusing on the task of multi-object rearrangement, we develop a theoretical and algorithmic framework that provides strategic guidance for a pair of robot arms, a leader and a follower where the leader has a model of the follower's decision-making process, through the computation of a feedback Stackelberg equilibrium. With built-in tolerance of model uncertainty, the strategic guidance generated by our planning algorithm not only improves the overall efficiency in solving the rearrangement tasks, but is also robust to common pitfalls in collaboration, e.g., chattering.",
        "primary_area": "",
        "author": "Yuhan Zhao;Baichuan Huang;Jingjin Yu;Quanyan Zhu;Yuhan Zhao;Baichuan Huang;Jingjin Yu;Quanyan Zhu",
        "authorids": "/37089451013;/37088981654;/37536570700;/37085449829;/37089451013;/37088981654;/37536570700;/37085449829",
        "aff": "Department of Electrical and Computer Engineering, New York University; Department of Computer Science, Rutgers University; Department of Computer Science, Rutgers University; Department of Electrical and Computer Engineering, New York University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811678/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16536632632218055731&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "New York University;Rutgers University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.nyu.edu;https://www.rutgers.edu",
        "aff_unique_abbr": "NYU;Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811578",
        "title": "Stair Ascent Phase-Variable Control of a Powered Knee-Ankle Prosthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "Passive prostheses cannot provide the net positive work required at the knee and ankle for step-over stair ascent. Powered prostheses can provide this net positive work, but user synchronization of joint motion and power input are critical to enabling natural stair ascent gaits. In this work, we build on previous phase variable-based control methods for walking and propose a stair ascent controller driven by the motion of the user's residual thigh. We use reference kinematics from an able-bodied dataset to produce knee and ankle joint trajectories parameterized by gait phase. We redefine the gait cycle to begin at the point of maximum hip flexion instead of heel strike to improve the phase estimate. Able-bodied bypass adapter experiments demonstrate that the phase variable controller replicates normative able-bodied kinematic trajectories with a root mean squared error of 12.66\u00b0 and 2.64\u00b0 for the knee and ankle, respectively. The knee and ankle joints provided on average 0.39 J/kg and 0.21 J/kg per stride, compared to the normative averages of 0.34 J/kg and 0.21 J/kg, respectively. Thus, this controller allows powered knee-ankle prostheses to perform net positive mechanical work to assist stair ascent.",
        "primary_area": "",
        "author": "Ross J. Cortino;Edgar Bol\u00edvar-Nieto;T. Kevin Best;Robert D. Gregg;Ross J. Cortino;Edgar Bol\u00edvar-Nieto;T. Kevin Best;Robert D. Gregg",
        "authorids": "/37089448486;/37086859696;/37089197029;/37547699100;/37089448486;/37086859696;/37089197029;/37547699100",
        "aff": "Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI; Department of Electrical Engineering and Computer Science, Robotics Institute, University of Michigan, Ann Arbor, MI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811578/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3479152125483649894&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812158",
        "title": "Star-Convex Constrained Optimization for Visibility Planning with Application to Aerial Inspection",
        "track": "main",
        "status": "Poster",
        "abstract": "The visible capability is critical in many robot applications, such as inspection and surveillance, etc. Without the assurance of the visibility to targets, some tasks end up not being complete or even failing. In this paper, we propose a visibility guaranteed planner by star-convex constrained optimization. The visible space is modeled as star convex polytope (SCP) by nature and is generated by finding the visible points directly on point cloud. By exploiting the properties of the SCP, the visibility constraint is formulated for trajectory optimization. The trajectory is confined in the safe and visible flight corridor which consists of convex polytopes and SCPs. We further make a relaxation to the visibility constraints and transform the constrained trajectory optimization problem into an unconstrained one that can be reliably and efficiently solved. To validate the capability of the proposed planner, we present the practical application in site inspection. The experimental results show that the method is efficient, scalable, and visibility guaranteed, presenting the prospect of application to various other applications in the future.",
        "primary_area": "",
        "author": "Tianyu Liu;Qianhao Wang;Xingguang Zhong;Zhepei Wang;Chao Xu;Fu Zhang;Fei Gao;Tianyu Liu;Qianhao Wang;Xingguang Zhong;Zhepei Wang;Chao Xu;Fu Zhang;Fei Gao",
        "authorids": "/37089449484;/37089197978;/37089001168;/37086601081;/37404060100;/37089448838;/37086045143;/37089449484;/37089197978;/37089001168;/37086601081;/37404060100;/37089448838;/37086045143",
        "aff": "Department of Mechanical Engineering, The University of Hong Kong; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Department of Mechanical Engineering, The University of Hong Kong; Huzhou Institute of Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812158/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4877779270593362922&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;0;1",
        "aff_unique_norm": "University of Hong Kong;Zhejiang University",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.hku.hk;http://www.zju.edu.cn",
        "aff_unique_abbr": "HKU;ZJU",
        "aff_campus_unique_index": "0;1;1;1;1;0;1",
        "aff_campus_unique": "Hong Kong SAR;Huzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811612",
        "title": "Star-Convolution for Image-Based 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "3D object detection with only image inputs is an interesting and important problem in computer vision and autonomous driving. Nowadays, most existing monocular 3D object detection algorithms rely solely on the approximation power of convolutional neural networks to learn a mapping from pixels to 3D predictions without knowing the projection matrix of the camera. To endow the networks with camera projection knowledge, we propose the Star-Convolution module for application to image-based 3D detection. The introduced module increases the receptive field of the detector and embeds the camera's projection geometry inside the network while keeping the network end-to-end trainable. We test the module with different baselines in both monocular and stereo 3D object detection, and we achieve significant improvements on both tasks. The code will be published at https://github.com/Owen-Liuyuxuan/visualDet3D.",
        "primary_area": "",
        "author": "Yuxuan Liu;Zhenhua Xu;Ming Liu;Yuxuan Liu;Zhenhua Xu;Ming Liu",
        "authorids": "/37088664461;/37088656714;/37085398677;/37088664461;/37088656714;/37085398677",
        "aff": "Department of Electronic and Computer Engineering, Robotics and Multi-Perception Laborotary, The Hong Kong University of Science and Technology; Department of Electronic and Computer Engineering, Robotics and Multi-Perception Laborotary, The Hong Kong University of Science and Technology; Department of Electronic and Computer Engineering, Robotics and Multi-Perception Laborotary, The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811612/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3807866832751304665&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811656",
        "title": "Stein Variational Probabilistic Roadmaps",
        "track": "main",
        "status": "Poster",
        "abstract": "Efficient and reliable generation of global path plans are necessary for safe execution and deployment of autonomous systems. In order to generate planning graphs which adequately resolve the topology of a given environment, many sampling-based motion planners resort to coarse, heuristically-driven strategies which often fail to generalize to new and varied surroundings. Further, many of these approaches are not designed to contend with partial-observability. We posit that such uncertainty in environment geometry can, in fact, help drive the sampling process in generating feasible, and probabilistically-safe planning graphs. We propose a method for Probabilistic Roadmaps which relies on particle-based Variational Inference to efficiently cover the posterior distribution over feasible regions in configuration space. Our approach, Stein Variational Probabilistic Roadmap (SV-PRM), results in sample-efficient generation of planning-graphs and large improvements over traditional sampling approaches. We demonstrate the approach on a variety of challenging planning problems, including real-world probabilistic occupancy maps and high-dof manipulation problems common in robotics. Video, additional material and results can be found here: https://sites.google.com/view/stein-prm.",
        "primary_area": "",
        "author": "Alexander Lambert;Brian Hou;Rosario Scalise;Siddhartha S. Srinivasa;Byron Boots;Alexander Lambert;Brian Hou;Rosario Scalise;Siddhartha S. Srinivasa;Byron Boots",
        "authorids": "/37086452975;/37088506431;/37085901034;/37339877600;/37085459219;/37086452975;/37088506431;/37085901034;/37339877600;/37085459219",
        "aff": "Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, WA; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, WA; DEVCOM Army Research Laboratory, Oak Ridge Associated University; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, WA; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, WA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811656/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3802058240453695830&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Washington;DEVCOM Army Research Laboratory",
        "aff_unique_dep": "Paul G. Allen School of Computer Science & Engineering;",
        "aff_unique_url": "https://www.washington.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "UW;ARL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seattle;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811830",
        "title": "StopNet: Scalable Trajectory and Occupancy Prediction for Urban Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a motion forecasting (behavior prediction) method that meets the latency requirements for autonomous driving in dense urban environments without sacrificing accuracy. A whole-scene sparse input representation allows StopNet to scale to predicting trajectories for hundreds of road agents with reliable latency. In addition to predicting trajectories, our scene encoder lends itself to predicting whole-scene probabilistic occupancy grids, a complementary output representation suitable for busy urban environments. Occupancy grids allow the AV to reason collectively about the behavior of groups of agents without processing their individual trajectories. We demonstrate the effectiveness of our sparse input representation and our model in terms of computation and accuracy over three datasets. We further show that co-training consistent trajectory and occupancy predictions improves upon state-of-the-art performance under standard metrics.",
        "primary_area": "",
        "author": "Jinkyu Kim;Reza Mahjourian;Scott Ettinger;Mayank Bansal;Brandyn White;Ben Sapp;Dragomir Anguelov;Jinkyu Kim;Reza Mahjourian;Scott Ettinger;Mayank Bansal;Brandyn White;Ben Sapp;Dragomir Anguelov",
        "authorids": "/37088448945;/37938208600;/37088454602;/37088450195;/37089448312;/37089406608;/37278026400;/37088448945;/37938208600;/37088454602;/37088450195;/37089448312;/37089406608;/37278026400",
        "aff": "Department of Computer Science and Engineering, Korea University, Seoul, South Korea; Waymo, Mountain View, CA, USA; Waymo, Mountain View, CA, USA; Waymo, Mountain View, CA, USA; Waymo, Mountain View, CA, USA; Waymo, Mountain View, CA, USA; Waymo, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811830/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5264799477369025176&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;1;1",
        "aff_unique_norm": "Korea University;Waymo",
        "aff_unique_dep": "Department of Computer Science and Engineering;",
        "aff_unique_url": "https://www.korea.ac.kr;https://waymo.com",
        "aff_unique_abbr": "KU;Waymo",
        "aff_campus_unique_index": "0;1;1;1;1;1;1",
        "aff_campus_unique": "Seoul;Mountain View",
        "aff_country_unique_index": "0;1;1;1;1;1;1",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "9812303",
        "title": "Strawberry picking point localization ripeness and weight estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Labour shortage, difficulties in labour management, the digitalization of fruit production pipeline to reduce the fruit production costs have made robotic systems for selective harvesting of strawberries an important industry and academic research. One of the important components of such technologies yet to be developed is fruit picking perception. For picking strawberries, a robot needs to infer the location of picking points from the images of strawberries. Moreover, the size and weight of strawberries to be picked can help the robot to place the picked strawberries in proper punnets directly to be delivered to customers in supermarkets. This can save significant time and packing costs in packhouses. Geometry-based approaches are the most common approach to determine the picking point but they suffer from inaccuracies due to noise, occlusion, and varying shape and orientation of the berries. In contrast, we present two novel datasets of strawberries annotated with picking points, key-points (such as the shoulder points, the contact point between the calyx and flesh, and the point on the flesh farthest from the calyx), and the weight and size of the berries. We performed experiments with Detectron-2, which is an extended version of Mask-RCNN with key-points detection capability. The results show that the key-points detection approach works well for picking and grasping point localization. The second dataset also presents the dimensions and weight of strawberries. Our novel baseline model for weight estimation outperforms many state-of-the-art deep networks. The datasets and annotations are available at https://github.com/imanlab/strawberry-pp-w-r-dataset.",
        "primary_area": "",
        "author": "Alessandra Tafuro;Adeayo Adewumi;Soran Parsa;Ghalamzan E. Amir;Bappaditya Debnath;Alessandra Tafuro;Adeayo Adewumi;Soran Parsa;Ghalamzan E. Amir;Bappaditya Debnath",
        "authorids": "/37085859004;/37089446902;/37088526645;/37088526674;/37086637895;/37085859004;/37089446902;/37088526645;/37088526674;/37086637895",
        "aff": "LN25TS, Lincoln Institute for Agri-food Technology, University of Lincoln, Lincoln, United Kingdom; LN25TS, Lincoln Institute for Agri-food Technology, University of Lincoln, Lincoln, United Kingdom; LN25TS, Lincoln Institute for Agri-food Technology, University of Lincoln, Lincoln, United Kingdom; LN25TS, Lincoln Institute for Agri-food Technology, University of Lincoln, Lincoln, United Kingdom; LN25TS, Lincoln Institute for Agri-food Technology, University of Lincoln, Lincoln, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812303/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8736067225242481091&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Lincoln",
        "aff_unique_dep": "Lincoln Institute for Agri-food Technology",
        "aff_unique_url": "https://www.lincoln.ac.uk",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Lincoln",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9811702",
        "title": "Striking the Right Balance: Recall Loss for Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Class imbalance is a fundamental problem in computer vision applications such as semantic segmentation. Specifically, uneven class distributions in a training dataset often result in unsatisfactory performance on under-represented classes. Many works have proposed to weight the standard cross entropy loss function with pre-computed weights based on class statistics, such as the number of samples and class margins. There are two major drawbacks to these methods: 1) constantly up-weighting minority classes can introduce excessive false positives in semantic segmentation; 2) a minority class is not necessarily a hard class. The consequence is low precision due to excessive false positives. In this regard, we propose a hard-class mining loss by reshaping the vanilla cross entropy loss such that it weights the loss for each class dynamically based on instantaneous recall performance. We show that the novel recall loss changes gradually between the standard cross entropy loss and the inverse frequency weighted loss. Recall loss also leads to improved mean accuracy while offering competitive mean Intersection over Union (IoU) performance. On Synthia dataset11Synthia-Sequence Summer split, recall loss achieves 9% relative improvement on mean accuracy with competitive mean IoU using DeepLab-ResNet18 compared to the cross entropy loss. Code available at https://github.com/PotatoTian/recall-semseg.",
        "primary_area": "",
        "author": "Junjiao Tian;Niluthpol Chowdhury Mithun;Zachary Seymour;Han-Pang Chiu;Zsolt Kira;Junjiao Tian;Niluthpol Chowdhury Mithun;Zachary Seymour;Han-Pang Chiu;Zsolt Kira",
        "authorids": "/37088456016;/37845735800;/37088996752;/37596940200;/37681676600;/37088456016;/37845735800;/37088996752;/37596940200;/37681676600",
        "aff": "Junjiao Tian; Niluthpol Chowdhury Mithun; Zachary Seymour; Han-Pang Chiu; Zsolt Kira",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811702/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12388630651248455895&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9811565",
        "title": "Stronger Generalization Guarantees for Robot Learning by Combining Generative Models and Real-World Data",
        "track": "main",
        "status": "Poster",
        "abstract": "We are motivated by the problem of learning policies for robotic systems with rich sensory inputs (e.g., vision) in a manner that allows us to guarantee generalization to environments unseen during training. We provide a framework for providing such generalization guarantees by leveraging a finite dataset of real-world environments in combination with a (potentially inaccurate) generative model of environments. The key idea behind our approach is to utilize the generative model in order to implicitly specify a prior over policies. This prior is updated using the real-world dataset of environments by minimizing an upper bound on the expected cost across novel environments derived via Probably Approximately Correct (PAC)-Bayes generalization theory. We demonstrate our approach on two simulated systems with nonlinear/hybrid dynamics and rich sensing modalities: (i) quadrotor navigation with an onboard vision sensor, and (ii) grasping objects using a depth sensor. Comparisons with prior work demonstrate the ability of our approach to obtain stronger generalization guarantees by utilizing generative models. We also present hardware experiments for validating our bounds for the grasping task.",
        "primary_area": "",
        "author": "Abhinav Agarwal;Sushant Veer;Allen Z. Ren;Anirudha Majumdar;Abhinav Agarwal;Sushant Veer;Allen Z. Ren;Anirudha Majumdar",
        "authorids": "/37089449270;/37085702725;/37089231729;/37086027485;/37089449270;/37085702725;/37089231729;/37086027485",
        "aff": "Department of Mechanical and Aerospace Engineering, Princeton University, Princeton; NVIDIA Research, Princeton University, Santa Clara, U.S.A; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811565/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3680614788333991185&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Princeton;Santa Clara",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811931",
        "title": "StructFormer: Learning Spatial Structure for Language-Guided Semantic Rearrangement of Novel Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Geometric organization of objects into semantically meaningful arrangements pervades the built world. As such, assistive robots operating in warehouses, offices, and homes would greatly benefit from the ability to recognize and rearrange objects into these semantically meaningful structures. To be useful, these robots must contend with previously unseen objects and receive instructions without significant programming. While previous works have examined recognizing pairwise semantic relations and sequential manipulation to change these simple relations none have shown the ability to arrange objects into complex structures such as circles or table settings. To address this problem we propose a novel transformer-based neural network, StructFormer, which takes as input a partial-view point cloud of the current object arrangement and a structured language command encoding the desired object configuration. We show through rigorous experiments that StructFormer enables a physical robot to rearrange novel objects into semantically meaningful structures with multi-object relational constraints inferred from the language command.",
        "primary_area": "",
        "author": "Weiyu Liu;Chris Paxton;Tucker Hermans;Dieter Fox;Weiyu Liu;Chris Paxton;Tucker Hermans;Dieter Fox",
        "authorids": "/37088504929;/37085403975;/38230909600;/37284329000;/37088504929;/37085403975;/38230909600;/37284329000",
        "aff": "Georgia Tech.; NVIDIA.; Univ. of Utah.; Univ. of Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811931/",
        "gs_citation": 104,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2218182828834510985&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Georgia Institute of Technology;NVIDIA;University of Utah;University of Washington",
        "aff_unique_dep": ";NVIDIA Corporation;;",
        "aff_unique_url": "https://www.gatech.edu;https://www.nvidia.com;https://www.utah.edu;https://www.washington.edu",
        "aff_unique_abbr": "Georgia Tech;NVIDIA;Utah;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811904",
        "title": "Superpoint-guided Semi-supervised Semantic Segmentation of 3D Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "3D point cloud semantic segmentation is a challenging topic in the computer vision field. Most of the existing methods in literature require a large amount of fully labeled training data, but it is extremely time-consuming to obtain these training data by manually labeling massive point clouds. Addressing this problem, we propose a superpoint-guided semi-supervised segmentation network for 3D point clouds, which jointly utilizes a small portion of labeled scene point clouds and a large number of unlabeled point clouds for network training. The proposed network is iteratively updated with its predicted pseudo labels, where a superpoint generation module is introduced for extracting superpoints from 3D point clouds, and a pseudo-label optimization module is explored for automatically assigning pseudo labels to the unlabeled points under the constraint of the extracted superpoints. Additionally, there are some 3D points without pseudo-label supervision. We propose an edge prediction module to constrain features of edge points. A superpoint feature aggregation module and a superpoint feature consistency loss function are introduced to smooth superpoint features. Extensive experimental results on two 3D public datasets demonstrate that our method can achieve better performance than several state-of-the-art point cloud segmentation networks and several popular semi-supervised segmentation methods with few labeled scenes.",
        "primary_area": "",
        "author": "Shuang Deng;Qiulei Dong;Bo Liu;Zhanyi Hu;Shuang Deng;Qiulei Dong;Bo Liu;Zhanyi Hu",
        "authorids": "/37088905932;/38032242900;/37090021233;/37281086500;/37088905932;/38032242900;/37090021233;/37281086500",
        "aff": "Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Beijing, China; Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Beijing, China; Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Beijing, China; Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811904/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7396985110374802610&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences",
        "aff_unique_dep": "Center for Excellence in Brain Science and Intelligence Technology",
        "aff_unique_url": "http://www.cas.cn",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811675",
        "title": "Symbolic State Estimation with Predicates for Contact-Rich Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulation tasks often require a robot to adjust its sensorimotor skills based on the state it finds itself in. Taking peg-in-hole as an example: once the peg is aligned with the hole, the robot should push the peg downwards. While high level execution frameworks such as state machines and behavior trees are commonly used to formalize such decision-making problems, these frameworks require a mechanism to detect the high-level symbolic state. Handcrafting heuristics to identify symbolic states can be brittle, and using data-driven methods can produce noisy predictions, particularly when working with limited datasets, as is common in real-world robotic scenarios. This paper proposes a Bayesian state estimation method to predict symbolic states with predicate classifiers. This method requires little training data and allows fusing noisy observations from multiple sensor modalities. We evaluate our framework on a set of real-world peg-in-hole and connector-socket insertion tasks, demonstrating its ability to classify symbolic states and to generalize to unseen tasks, outperforming baseline methods. We also demonstrate the ability of our method to improve the robustness of manipulation policies on a real robot.",
        "primary_area": "",
        "author": "Toki Migimatsu;Wenzhao Lian;Jeannette Bohg;Stefan Schaal;Toki Migimatsu;Wenzhao Lian;Jeannette Bohg;Stefan Schaal",
        "authorids": "/37086141343;/37088998889;/37591153900;/37282144700;/37086141343;/37088998889;/37591153900;/37282144700",
        "aff": "Stanford Artificial Intelligence Laboratory, Stanford University, CA, USA; Intrinsic Innovation LLC, CA, USA; Stanford Artificial Intelligence Laboratory, Stanford University, CA, USA; Intrinsic Innovation LLC, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811675/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1213864313247575494&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Stanford University;Intrinsic Innovation LLC",
        "aff_unique_dep": "Artificial Intelligence Laboratory;",
        "aff_unique_url": "https://www.stanford.edu;",
        "aff_unique_abbr": "Stanford;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811990",
        "title": "Symphony: Learning Realistic and Diverse Agents for Autonomous Driving Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulation is a crucial tool for accelerating the development of autonomous vehicles. Making simulation realistic requires models of the human road users who interact with such cars. Such models can be obtained by applying learning from demonstration (LfD) to trajectories observed by cars already on the road. However, existing LfD methods are typically insufficient, yielding policies that frequently collide or drive off the road. To address this problem, we propose Symphony, which greatly improves realism by combining conventional policies with a parallel beam search. The beam search refines these policies on the fly by pruning branches that are unfavourably evaluated by a discriminator. However, it can also harm diversity, i.e., how well the agents cover the entire distribution of realistic behaviour, as pruning can encourage mode collapse. Symphony addresses this issue with a hierarchical approach, factoring agent behaviour into goal generation and goal conditioning. The use of such goals ensures that agent diversity neither disappears during adversarial training nor is pruned away by the beam search. Experiments on both proprietary and open Waymo datasets confirm that Symphony agents learn more realistic and diverse behaviour than several baselines.",
        "primary_area": "",
        "author": "Maximilian Igl;Daewoo Kim;Alex Kuefler;Paul Mougin;Punit Shah;Kyriacos Shiarlis;Dragomir Anguelov;Mark Palatucci;Brandyn White;Shimon Whiteson;Maximilian Igl;Daewoo Kim;Alex Kuefler;Paul Mougin;Punit Shah;Kyriacos Shiarlis;Dragomir Anguelov;Mark Palatucci;Brandyn White;Shimon Whiteson",
        "authorids": "/37089448320;/37089448418;/37086115893;/37089447101;/37089446849;/37086104617;/37278026400;/37089447248;/37089448312;/37269324800;/37089448320;/37089448418;/37086115893;/37089447101;/37089446849;/37086104617;/37278026400;/37089447248;/37089448312;/37269324800",
        "aff": "Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research; Waymo Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811990/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10115272952477686053&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Waymo",
        "aff_unique_dep": "Waymo Research",
        "aff_unique_url": "https://waymo.com",
        "aff_unique_abbr": "Waymo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812328",
        "title": "Synergistic Scheduling of Learning and Allocation of Tasks in Human-Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of completing a set of nn tasks with a human-robot team using minimum effort. In many domains, teaching a robot to be fully autonomous can be counterproductive if there are finitely many tasks to be done. Rather, the optimal strategy is to weigh the cost of teaching a robot and its benefit- how many new tasks it allows the robot to solve autonomously. We formulate this as a planning problem where the goal is to decide what tasks the robot should do autonomously (act), what tasks should be delegated to a human (delegate) and what tasks the robot should be taught (learn) so as to complete all the given tasks with minimum effort. This planning problem results in a search tree that grows expo-nentially with nn - making standard graph search algorithms intractable. We address this by converting the problem into a mixed integer program that can be solved efficiently using off-the-shelf solvers with bounds on solution quality. To predict the benefit of learning, we use an approximate simulation model of the tasks to train a precondition model that is parameterized by the training task. Finally, we evaluate our approach on peg insertion and Lego stacking tasks- both in simulation and real-world, showing substantial savings in human effort.",
        "primary_area": "",
        "author": "Shivam Vats;Oliver Kroemer;Maxim Likhachev;Shivam Vats;Oliver Kroemer;Maxim Likhachev",
        "authorids": "/37088690871;/37593222300;/37309318800;/37088690871;/37593222300;/37309318800",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812328/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9441920000225586503&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811871",
        "title": "Systematic Development of a Novel, Dynamic, Reduced Complexity Quadruped Robot Platform for Robotic Tail Research",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a systematical approach to develop a novel reduced complexity quadruped (RCQ) robot designed for serpentine robotic tail research purposes. The critical design requirements are determined based on careful dynamic analysis and synthesis results. Guided by formulated design requirements and principles, a robot prototype was designed and built. The robot has an overall weight of 5 Kg and the body size of a domestic cat. The existing electronic system allows a control frequency of up to 1 kHz and accepts both torque and position commands. These features guarantee that the platform could be used to explore the dynamic usages of robotic tails on legged locomotion. The preliminary tests show that the hardware can lift itself off the ground up to 112 mm (46.7% of its body height) and stay in the air for at least 0.3 seconds.",
        "primary_area": "",
        "author": "Yujiong Liu;Pinhas Ben-Tzvi;Yujiong Liu;Pinhas Ben-Tzvi",
        "authorids": "/37089448790;/38277770000;/37089448790;/38277770000",
        "aff": "Robotics and Mechatronics Lab in the Mechanical Engineering Department, Virginia Tech, Blacksburg, VA, USA; Robotics and Mechatronics Lab in the Mechanical Engineering Department, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811871/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1908521227702391936&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812238",
        "title": "TERP: Reliable Planning in Uneven Outdoor Environments using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel method for reliable robot navigation in uneven outdoor terrains. Our approach employs a fully-trained Deep Reinforcement Learning (DRL) network that uses elevation maps of the environment, robot pose, and goal as inputs to compute an attention mask of the environment. The attention mask is used to identify reduced stability regions in the elevation map and is computed using channel and spatial attention modules and a novel reward function. We continuously compute and update a navigation cost-map that encodes the elevation information or the level-of-flatness of the terrain using the attention mask. We then generate locally least-cost waypoints on the cost-map and compute the final dynamically feasible trajectory using another DRL-based method. Our approach guarantees safe, locally least-cost paths and dynamically feasible robot velocities in uneven terrains. We observe an increase of 35.18% in terms of success rate and, a decrease of 26.14% in the cumulative elevation gradient of the robot's trajectory compared to prior navigation methods in high-elevation regions. We evaluate our method on a Husky robot in real-world uneven terrains (\u223c 4m4m of elevation gain) and demonstrate its benefits.",
        "primary_area": "",
        "author": "Kasun Weerakoon;Adarsh Jagan Sathyamoorthy;Utsav Patel;Dinesh Manocha;Kasun Weerakoon;Adarsh Jagan Sathyamoorthy;Utsav Patel;Dinesh Manocha",
        "authorids": "/37089653638;/37086924122;/37088415023;/37267825600;/37089653638;/37086924122;/37088415023;/37267825600",
        "aff": "Dept. of Electrical and Computer Engineering, University of Maryland, College Park, MD, USA; Dept. of Electrical and Computer Engineering, University of Maryland, College Park, MD, USA; Dept. of Computer Science, University of Maryland, College Park, MD, USA; Dept. of Computer Science, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812238/",
        "gs_citation": 82,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8393396417038031311&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "University of Maryland, College Park;University of Maryland",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www/umd.edu;https://www/umd.edu",
        "aff_unique_abbr": "UMD;UMD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812424",
        "title": "TOPP-MPC-Based Dual-Arm Dynamic Collaborative Manipulation for Multi-Object Nonprehensile Transportation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a unified controller for dual-arm robot dynamic multi-object nonprehensile transportation. The controller is composed of time-optimal path parameteri-zation (TOPP) and model predictive control (MPC) and aimed at efficiently and dynamically transporting objects using the dual-arm robot under physical constraints while avoiding the slippage of the objects. A force tracking controller without using the force sensor is also proposed to achieve accurate contact force control between the arms and objects. Experiments on the real robot show the effectiveness of the proposed TOPP-MPC-based controller.",
        "primary_area": "",
        "author": "Cheng Zhou;Maolin Lei;Longfei Zhao;Zunran Wang;Yu Zheng;Cheng Zhou;Maolin Lei;Longfei Zhao;Zunran Wang;Yu Zheng",
        "authorids": "/37088946786;/37089332783;/37088945859;/37089447885;/37086993722;/37088946786;/37089332783;/37088945859;/37089447885;/37086993722",
        "aff": "Tencent Robotics X, Shenzhen, Guangdong, China; Humanoids and Human Centered Mechatronics (HHCM) research line of the Istituto Italiano Di Tecnologia (IIT), Genova, Italy; Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China; Tencent Robotics X, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812424/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3646691179240524507&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Tencent;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Robotics X;Humanoids and Human Centered Mechatronics",
        "aff_unique_url": "https://robotics.tencent.com;https://www.iit.it",
        "aff_unique_abbr": "Tencent Robotics X;IIT",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Shenzhen;Genova",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "China;Italy"
    },
    {
        "id": "9811890",
        "title": "TP-AE: Temporally Primed 6D Object Pose Tracking with Auto-Encoders",
        "track": "main",
        "status": "Poster",
        "abstract": "Fast and accurate tracking of an object's motion is one of the key functionalities of a robotic system for achieving reliable interaction with the environment. This paper focuses on the instance-level six-dimensional (6D) pose tracking problem with a symmetric and textureless object under occlusion. We propose a Temporally Primed 6D pose tracking framework with Auto-Encoders (TP-AE) to tackle the pose tracking problem. The framework consists of a prediction step and a temporally primed pose estimation step. The prediction step aims to quickly and efficiently generate a guess on the object's real-time pose based on historical information about the target object's motion. Once the prior prediction is obtained, the temporally primed pose estimation step embeds the prior pose into the RGB-D input, and leverages auto-encoders to reconstruct the target object with higher quality under occlusion, thus improving the framework's performance. Extensive experiments show that the proposed 6D pose tracking method can accurately estimate the 6D pose of a symmetric and textureless object under occlusion, and significantly outperforms the state-of-the-art on T-LESS dataset while running in real-time at 26 FPS.",
        "primary_area": "",
        "author": "Linfang Zheng;Ale\u0161 Leonardis;Tze Ho Elden Tse;Nora Horanyi;Hua Chen;Wei Zhang;Hyung Jin Chang;Linfang Zheng;Ale\u0161 Leonardis;Tze Ho Elden Tse;Nora Horanyi;Hua Chen;Wei Zhang;Hyung Jin Chang",
        "authorids": "/37088480134;/38560304200;/37089447192;/37086324709;/37086195529;/37089656248;/37293111600;/37088480134;/38560304200;/37089447192;/37086324709;/37086195529;/37089656248;/37293111600",
        "aff": "School of Computer Science, University of Birmingham, UK; School of Computer Science, University of Birmingham, UK; School of Computer Science, University of Birmingham, UK; School of Computer Science, University of Birmingham, UK; Department of Mechanical and Energy Engineering, Southern University of Science and Technology (SUSTech), China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology (SUSTech), China; School of Computer Science, University of Birmingham, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811890/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8935460248207561617&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;0",
        "aff_unique_norm": "University of Birmingham;Southern University of Science and Technology",
        "aff_unique_dep": "School of Computer Science;Department of Mechanical and Energy Engineering",
        "aff_unique_url": "https://www.birmingham.ac.uk;https://www.sustech.edu.cn",
        "aff_unique_abbr": "UoB;SUSTech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Birmingham;",
        "aff_country_unique_index": "0;0;0;0;1;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9811806",
        "title": "TaTa: A Universal Jamming Gripper with High-Quality Tactile Perception and Its Application to Underwater Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Large-area and high-precision tactile sensing information can not only improve the stability of robot grasping but also compensate for the lack of visual information in specific environments such as turbid underwater, dimness, and smoke. In this paper, we devise a universal jamming gripper with high-quality tactile sensing capability. The gripper adopts the particle jamming mechanism for grasping, and simultaneously uses a built-in camera to detect the deformation of its surface to obtain tactile information. To make the inside of the gripper transparent, glass beads and liquid with the same refractive index are applied as the internal filling. Besides, special treatments are taken to improve the tactile perception resolution of the gripper. The design perfectly merges visual-based tactile sensing into the traditional universal jamming gripper without changing its original gripping performance, making it possible for simultaneous grasping and sensing. To verify the tactile perception and grasping ability of the gripper in specific environments, we design two underwater experiments for grasping and pipe leak detection based on tactile information. Both have achieved a success rate not less than 95%, which demonstrates the effectiveness of the proposed gripper for manipulation in low visibility environments.",
        "primary_area": "",
        "author": "Shoujie Li;Xianghui Yin;Chongkun Xia;Linqi Ye;Xueqian Wang;Bin Liang;Shoujie Li;Xianghui Yin;Chongkun Xia;Linqi Ye;Xueqian Wang;Bin Liang",
        "authorids": "/37089229975;/37089449416;/37086260813;/37086311678;/37085383477;/37270783900;/37089229975;/37089449416;/37086260813;/37086311678;/37085383477;/37270783900",
        "aff": "Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; Center for Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; Department of Automation, Navigation and Control Research Center, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811806/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12126168302991032977&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Center for Intelligent Control and Telescience",
        "aff_unique_url": "http://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Shenzhen;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811825",
        "title": "Tactile Classification of Object Materials for Virtual Reality based Robot Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a method for tactile classification of materials for virtual reality (VR) based robot teleoperation. In our system, a human-operator uses a remotely controlled robot-manipulator with an optical fibre-based tactile and proximity sensor to scan surfaces of objects in a remote environment. Tactile and proximity data and the robot's end-effector state feedback are used for the classification of objects' materials which are then visualized in the VR reconstruction of the remote environment for each object. Machine learning techniques such as random forest, convolutional neural and multi-modal convolutional neural networks were used for material classification. The proposed system and methods were tested with five different materials and classification accuracy of 90 % and more was achieved. The results of material classification were successfully exploited for visualising the remote scene in the VR interface to provide more information to the human-operator.",
        "primary_area": "",
        "author": "Bukeikhan Omarali;Francesca Palermo;Kaspar Althoefer;Maurizio Valle;Ildar Farkhatdinov;Bukeikhan Omarali;Francesca Palermo;Kaspar Althoefer;Maurizio Valle;Ildar Farkhatdinov",
        "authorids": "/37085674582;/37086017844;/37265264700;/37352083800;/37396157800;/37085674582;/37086017844;/37265264700;/37352083800;/37396157800",
        "aff": "Department of Electrical, Cosmic Lab, Electronics and Telecommunication Engineering and Naval Architecture, University of Genoa, Italy; Department of Brain Science, Faculty of Medicine, Imperial College of Science, Technology and Medicine, London, UK; School of Electronic Engineering and Computer Science, Queen Mary University of London, UK; Department of Electrical, Cosmic Lab, Electronics and Telecommunication Engineering and Naval Architecture, University of Genoa, Italy; Department of Bioengineering, Imperial College of Science, Technology and Medicine, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811825/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10173308478727376949&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;1",
        "aff_unique_norm": "University of Genoa;Imperial College of Science, Technology and Medicine;Queen Mary University of London",
        "aff_unique_dep": "Department of Electrical, Electronics and Telecommunication Engineering and Naval Architecture;Department of Brain Science;School of Electronic Engineering and Computer Science",
        "aff_unique_url": "https://www.unige.it;https://www.imperial.ac.uk;https://www.qmul.ac.uk",
        "aff_unique_abbr": ";Imperial College;QMUL",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "9811574",
        "title": "Targeted Attack on Deep RL-based Autonomous Driving with Learned Visual Patterns",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent studies demonstrated the vulnerability of control policies learned through deep reinforcement learning against adversarial attacks, raising concerns about the application of such models to risk-sensitive tasks such as autonomous driving. Threat models for these demonstrations are limited to (1) targeted attacks through real-time manipulation of the agent's observation, and (2) untargeted attacks through manipulation of the physical environment. The former assumes full access to the agent's states/observations at all times, while the latter has no control over attack outcomes. This paper investigates the feasibility of targeted attacks through visually learned patterns placed on physical objects in the environment, a threat model that combines the practicality and effectiveness of the existing ones. Through analysis, we demonstrate that a pre-trained policy can be hijacked within a time window, e.g., performing an unintended self-parking, when an adversarial object is present. To enable the attack, we adopt an assumption that the dynamics of both the environment and the agent can be learned by the attacker. Lastly, we empirically show the effectiveness of the proposed attack on different driving scenarios, perform a location robustness test, and study the tradeoff between the attack strength and its effectiveness Code is available at https://github.com/ASU-APG/ Targeted-Physical-Adversarial-Attacks-on-AD",
        "primary_area": "",
        "author": "Prasanth Buddareddygari;Travis Zhang;Yezhou Yang;Yi Ren;Prasanth Buddareddygari;Travis Zhang;Yezhou Yang;Yi Ren",
        "authorids": "/37089447002;/37089447023;/37086004333;/37086861024;/37089447002;/37089447023;/37086004333;/37086861024",
        "aff": "Active Perception Group at the School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ, USA; intern at the Active Perception Group, Arizona State University; Active Perception Group at the School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ, USA; School for Engineering of Matter, Transport, and Energy, Arizona State University, Tempe",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811574/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15994471424680179736&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of Computing and Augmented Intelligence",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tempe;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811648",
        "title": "TartanDrive: A Large-Scale Dataset for Learning Off-Road Dynamics Models",
        "track": "main",
        "status": "Poster",
        "abstract": "We present TartanDrive, a large scale dataset for learning dynamics models for off-road driving. We collected a dataset of roughly 200,000 off-road driving interactions on a modified Yamaha Viking ATV with seven unique sensing modalities in diverse terrains. To the authors' knowledge, this is the largest real-world multi-modal off-road driving dataset, both in terms of number of interactions and sensing modalities. We also benchmark several state-of-the-art methods for model-based reinforcement learning from high-dimensional observations on this dataset. We find that extending these models to multi-modality leads to significant performance on off-road dynamics prediction, especially in more challenging terrains. We also identify some shortcomings with current neural network architectures for the off-road driving task. Our dataset is available at https://github.com/castacks/tartan_drive.",
        "primary_area": "",
        "author": "Samuel Triest;Matthew Sivaprakasam;Sean J. Wang;Wenshan Wang;Aaron M. Johnson;Sebastian Scherer;Samuel Triest;Matthew Sivaprakasam;Sean J. Wang;Wenshan Wang;Aaron M. Johnson;Sebastian Scherer",
        "authorids": "/37088642042;/37088996836;/37088687699;/37087322184;/37589025300;/37584159000;/37088642042;/37088996836;/37088687699;/37087322184;/37589025300;/37584159000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Electrical & Computer Engineering Dept., University of Pittsburgh, Pittsburgh, PA, USA; Mechanical Engineering Dept., Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Mechanical Engineering Dept., Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811648/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7956601540163995773&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Pittsburgh",
        "aff_unique_dep": "Robotics Institute;Electrical & Computer Engineering Dept.",
        "aff_unique_url": "https://www.cmu.edu;https://www.pitt.edu",
        "aff_unique_abbr": "CMU;Pitt",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811374",
        "title": "Task Allocation with Load Management in Multi-Agent Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "In operations of multi-agent teams ranging from homogeneous robot swarms to heterogeneous human-autonomy teams, unexpected events might occur. While efficiency of operation for multi-agent task allocation problems is the primary objective, it is essential that the decision-making framework is intelligent enough to manage unexpected task load with limited resources. Otherwise, operation effectiveness would drastically plummet with overloaded agents facing unforeseen risks. In this work, we present a decision-making framework for multiagent teams to learn task allocation with the consideration of load management through decentralized reinforcement learning, where idling is encouraged and unnecessary resource usage is avoided. We illustrate the effect of load management on team performance and explore agent behaviors in example scenarios. Furthermore, a measure of agent importance in collaboration is developed to infer team resilience when facing handling potential overload situations.",
        "primary_area": "",
        "author": "Haochen Wu;Amin Ghadami;Alparslan Emrah Bayrak;Jonathon M. Smereka;Bogdan I. Epureanu;Haochen Wu;Amin Ghadami;Alparslan Emrah Bayrak;Jonathon M. Smereka;Bogdan I. Epureanu",
        "authorids": "/37088921242;/37088658581;/37085712404;/37401580800;/37085465693;/37088921242;/37088658581;/37085712404;/37401580800;/37085465693",
        "aff": "University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ; US Army CCDC Ground Vehicle Systems Center, Warren, MI, USA; University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811374/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10285156705951350308&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of Michigan;Stevens Institute of Technology;US Army CCDC Ground Vehicle Systems Center",
        "aff_unique_dep": ";School of Systems and Enterprises;",
        "aff_unique_url": "https://www.umich.edu;https://www.stevens.edu;",
        "aff_unique_abbr": "UM;SIT;",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Ann Arbor;Hoboken;Warren",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812208",
        "title": "Task Persistification for Robots with Control-Dependent Energy Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a solution to the problem of executing robotic tasks over time horizons that exceed the robot's total battery capacity. In the presented robotics application, the robot's mission is to satisfy two tasks: environmental exploration and environmental monitoring, both of which need to be executed over long time periods. These tasks need therefore to be persistified. Ensuring the longevity of the system requires to consider a maximum energy consumption at all times. Including a dependency of battery voltage dynamics on the control input introduces a quadratic term in the battery's dynamic equation, making previous persistification approaches no longer directly applicable, as they used control-affine dynamics. In this paper an alternative task persistification approach is formulated. The control strategy used is based on Control Barrier Functions (CBFs). Using which, the generated controller renders the system state variables, position and battery voltage, to remain within the boundaries of their safe sets. This generated safe controller minimally modifies the nominal controller, which commands the robot to satisfy its environmental mission. Once the CBFs are selected, the minimization problem that results is one with a quadratic cost and two nested scalar constraints: one of which is quadratic and the other is linear. This new class of problems is noted as Quadratic Cost Scalar Linear and Quadratically Constrained (QCSLQC) problems. An analytical solution to the general QCSLQC problem is presented.",
        "primary_area": "",
        "author": "Carmen Jimenez Cortes;Magnus Egerstedt;Carmen Jimenez Cortes;Magnus Egerstedt",
        "authorids": "/37089448018;/37269707500;/37089448018;/37269707500",
        "aff": "Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Samueli School of Engineering, University of California Irvine, Irvine, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812208/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Dy8D7ttIHlkJ:scholar.google.com/&scioq=Task+Persistification+for+Robots+with+Control-Dependent+Energy+Dynamics&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Georgia Institute of Technology;University of California, Irvine",
        "aff_unique_dep": "Electrical and Computer Engineering;Samueli School of Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://www.uci.edu",
        "aff_unique_abbr": "Georgia Tech;UCI",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Atlanta;Irvine",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812317",
        "title": "Task-Oriented Generation of Stable Motions for Wheeled Inverted Pendulum Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a whole-body control architecture for the generation of stable task-oriented motions in Wheeled Inverted Pendulum (WIP) robots. Controlling WIP systems is challenging because the successful execution of tasks is subordinate to the ability to maintain balance. Our feedback control approach relies both on partial feedback linearization and Model Predictive Control (MPC). The partial feedback linearization reshapes the system into a convenient form, while the MPC computes inputs to execute the desired task by solving a constrained optimization problem. Input constraints account for actuation limits and a stability constraint is in charge of stabilizing the unstable body pitch angle dynamics. The proposed approach is validated by simulations on an ALTER-EGO robot performing navigation and loco-manipulation tasks.",
        "primary_area": "",
        "author": "Marco Kanneworff;Tommaso Belvedere;Nicola Scianca;Filippo M. Smaldone;Leonardo Lanari;Giuseppe Oriolo;Marco Kanneworff;Tommaso Belvedere;Nicola Scianca;Filippo M. Smaldone;Leonardo Lanari;Giuseppe Oriolo",
        "authorids": "/37089447043;/37087078396;/37086072440;/37088339742;/37354641900;/37283188300;/37089447043;/37087078396;/37086072440;/37088339742;/37354641900;/37283188300",
        "aff": "Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universit\u00e0 di Roma, Roma, Italy; Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universit\u00e0 di Roma, Roma, Italy; Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universit\u00e0 di Roma, Roma, Italy; Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universit\u00e0 di Roma, Roma, Italy; Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universit\u00e0 di Roma, Roma, Italy; Dipartimento di Ingegneria Informatica, Automatica e Gestionale, Sapienza Universit\u00e0 di Roma, Roma, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812317/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9611128795687127027&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Sapienza Universit\u00e0 di Roma",
        "aff_unique_dep": "Dipartimento di Ingegneria Informatica, Automatica e Gestionale",
        "aff_unique_url": "https://www.uniroma1.it",
        "aff_unique_abbr": "Sapienza",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Roma",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9811611",
        "title": "Task-Specific Design Optimization and Fabrication for Inflated-Beam Soft Robots with Growable Discrete Joints",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robot serial chain manipulators with the capability for growth, stiffness control, and discrete joints have the potential to approach the dexterity of traditional robot arms, while improving safety, lowering cost, and providing an increased workspace, with potential application in home environments. This paper presents an approach for design optimization of such robots to reach specified targets while minimizing the number of discrete joints and thus construction and actuation costs. We define a maximum number of allowable joints, as well as hardware constraints imposed by the materials and actuation available for soft growing robots, and we formulate and solve an optimization problem to output a planar robot design, i.e., the total number of potential joints and their locations along the robot body, which reaches all the desired targets, avoids known obstacles, and maximizes the workspace. We demonstrate a process to rapidly construct the resulting soft growing robot design. Finally, we use our algorithm to evaluate the ability of this design to reach new targets and demonstrate the algorithm's utility as a design tool to explore robot capabilities given various constraints and objectives.",
        "primary_area": "",
        "author": "Ioannis Exarchos;Karen Wang;Brian H. Do;Fabio Stroppa;Margaret M. Coad;Allison M. Okamura;C. Karen Liu;Ioannis Exarchos;Karen Wang;Brian H. Do;Fabio Stroppa;Margaret M. Coad;Allison M. Okamura;C. Karen Liu",
        "authorids": "/37089653411;/37089448721;/37086414589;/37085855948;/37086124465;/37276156400;/38240584300;/37089653411;/37089448721;/37086414589;/37085855948;/37086124465;/37276156400;/38240584300",
        "aff": "Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Faculty of Computer Engineering, Kadir Has University, Turkey; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811611/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2423784513822112105&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;2;0;0",
        "aff_unique_norm": "Stanford University;Kadir Has University;University of Notre Dame",
        "aff_unique_dep": "Department of Computer Science;Faculty of Computer Engineering;Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu;https://www.khas.edu.tr;https://www.nd.edu",
        "aff_unique_abbr": "Stanford;;Notre Dame",
        "aff_campus_unique_index": "0;0;0;2;0;0",
        "aff_campus_unique": "Stanford;;Notre Dame",
        "aff_country_unique_index": "0;0;0;1;0;0;0",
        "aff_country_unique": "United States;T\u00fcrkiye"
    },
    {
        "id": "9812168",
        "title": "Telerobotically Controlled Magnetic Soft Continuum Robots for Neurovascular Interventions",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the recent advances in continuum robots for minimally invasive surgery or interventions, their applications to endovascular neurosurgery have remained technically challenging due to the difficulty of miniaturization. Aimed at enabling robotic applications to neurovascular interventions for endovascular treatments of stroke or brain aneurysms, we present a telerobotically controlled magnetic soft continuum robot capable of active steering and navigation under externally applied magnetic fields. For magnetic steering, a seven-degree-of-freedom (7-DOF) serial manipulator is employed to place an actuating magnet that can be manipulated via real-time teleoperation of the robot arm. A motorized linear drive is used to advance or retract the magnetic soft continuum robot, the distal tip of which is steered by the actuating magnet to enable endovascular navigation in the complex cerebral vasculature. We demonstrate the system's ability to guide selective navigation in different branches of cerebral arteries using anatomical models under visual feedback. We also compare the navigational performance of our system with that of a manually controlled passive guidewire and a conventional magnet-tipped guidewire. We found that the telerobotically controlled magnetic soft continuum robot allows for safer and quicker access to hard-to-reach areas in clinically challenging anatomies by enabling smooth navigation in narrow and winding pathways.",
        "primary_area": "",
        "author": "Yoonho Kim;Emily Genevriere;Pablo Harker;Jaehun Choe;Marcin Balicki;Aman B. Patel;Xuanhe Zhao;Yoonho Kim;Emily Genevriere;Pablo Harker;Jaehun Choe;Marcin Balicki;Aman B. Patel;Xuanhe Zhao",
        "authorids": "/37089448722;/37089450052;/37089449405;/37089450219;/38509264600;/37089447617;/37088506010;/37089448722;/37089450052;/37089449405;/37089450219;/38509264600;/37089447617;/37088506010",
        "aff": "Department of Mechanical Engineering, Zhao Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Zhao Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Neurology and Rehabilitation Medicine, University of Cincinnati College of Medicine, Cincinnati, OH, USA; Department of Mechanical Engineering, Zhao Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; Philips Research, Cambridge, MA, USA; Department of Neurosurgery, Massachusetts General Hospital and Harvard Medical School, Boston, MA, USA; Department of Mechanical Engineering, Zhao Lab, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812168/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3622367575459876067&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;2;3;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Cincinnati College of Medicine;Philips Research;Massachusetts General Hospital",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Neurology and Rehabilitation Medicine;;Department of Neurosurgery",
        "aff_unique_url": "https://web.mit.edu;https://med.uc.edu;https://www.philips.com/research;https://www.massgeneral.org",
        "aff_unique_abbr": "MIT;UC College of Medicine;;MGH",
        "aff_campus_unique_index": "0;0;1;0;0;2;0",
        "aff_campus_unique": "Cambridge;Cincinnati;Boston",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811707",
        "title": "Temporal Logic Guided Motion Primitives for Complex Manipulation Tasks with User Preferences",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic movement primitives (DMPs) are a flexible trajectory learning scheme widely used in motion generation of robotic systems. However, existing DMP-based methods mainly focus on simple go-to-goal tasks. Motivated to handle tasks beyond point-to-point motion planning, this work presents temporal logic guided optimization of motion primitives, namely \\mathbf{PI}^{\\mathbf{BB}-\\mathbf{TL}}\\mathbf{PI}^{\\mathbf{BB}-\\mathbf{TL}} algorithm, for complex manipulation tasks with user preferences. In particular, weighted truncated linear temporal logic (wTLTL) is incorporated in the \\mathbf{PI}^{\\mathbf{BB}-\\mathbf{TL}}\\mathbf{PI}^{\\mathbf{BB}-\\mathbf{TL}} algorithm, which not only enables the encoding of complex tasks that involve a sequence of logically organized action plans with user preferences, but also provides a convenient and efficient means to design the cost function. The black-box optimization is then adapted to identify optimal shape parameters of DMPs to enable motion planning of robotic systems. The effectiveness of the \\mathbf{PI}^{\\mathbf{BB}-\\mathbf{TL}}\\mathbf{PI}^{\\mathbf{BB}-\\mathbf{TL}} algorithm is demonstrated via simulation and experiment.",
        "primary_area": "",
        "author": "Hao Wang;Haoyuan He;Weiwei Shang;Zhen Kan;Hao Wang;Haoyuan He;Weiwei Shang;Zhen Kan",
        "authorids": "/37088523179;/37089446948;/37409386300;/37545883400;/37088523179;/37089446948;/37409386300;/37545883400",
        "aff": "Department of Automation, University of Science and Technology of China, Hefei, Anhui, China; Department of Automation, University of Science and Technology of China, Hefei, Anhui, China; Department of Automation, University of Science and Technology of China, Hefei, Anhui, China; Department of Automation, University of Science and Technology of China, Hefei, Anhui, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811707/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2636353517507328073&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hefei",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811544",
        "title": "Temporally-Aggregating Multiple-Discontinuous-Image Saliency Prediction with Transformer-Based Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we aim to apply deep saliency prediction to automatic drone exploration, which should consider not only one single image, but multiple images from different view angles or localizations in order to determine the exploration direction. However, little attention has been paid to such saliency prediction problem over multiple-discontinuous-image and none of existing methods take temporal information into consideration, which may mean that the current predicted saliency map is not consistent with the previous predicted results. For this purpose, we propose a method named Temporally-Aggregating Multiple-Discontinuous-Image Saliency Prediction Network (TA-MSNet). It utilizes a transformer-based attention module to correlate relative saliency information among multiple discontinuous images and, furthermore, applies the ConvLSTM module to capture the temporal information. Experiments show that the proposed TA-MSNet can estimate better and more consistent results than previous works for time series data.",
        "primary_area": "",
        "author": "Pin-Jie Huang;Chi-An Lu;Kuan-Wen Chen;Pin-Jie Huang;Chi-An Lu;Kuan-Wen Chen",
        "authorids": "/37088999229;/37089450754;/37557502900;/37088999229;/37089450754;/37557502900",
        "aff": "Department of Computer Science, National Yang Ming Chiao Tung University, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811544/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16508297209699158310&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National Yang Ming Chiao Tung University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nctu.edu.tw",
        "aff_unique_abbr": "NYCU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812175",
        "title": "Tenodesis Grasp Emulator: Kinematic Assessment of Wrist-Driven Orthotic Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Wrist-driven orthotics have been designed to assist people with C6-7 spinal cord injury, however, the kinematic constraint imposed by such a control strategy can impede mobility and lead to abnormal body motion. This study characterizes body compensation using the novel Tenodesis Grasp Emulator, an adaptor orthotic that allows for the investigation of tenodesis grasping in subjects with unimpaired hand function. Subjects perform a series of grasp-and-release tasks in order to compare normal (test control) and constrained wrist-driven modes, showing significant compensation as a result of the constraint. A motor-augmented mode is also compared against traditional wrist-driven operation, to explore the potential role of hybrid human-robot control. We find that both the passive wrist-driven and motor-augmented modes fulfill different roles throughout various tasks tested. Thus, we conclude that a flexible control scheme that can alter intervention based on the task at hand holds the potential to reduce compensation in future work.",
        "primary_area": "",
        "author": "Erin Y. Chang;Raghid Mardini;Andrew I. W. McPherson;Yuri Gloumakov;Hannah S. Stuart;Erin Y. Chang;Raghid Mardini;Andrew I. W. McPherson;Yuri Gloumakov;Hannah S. Stuart",
        "authorids": "/37089450615;/37089447827;/37085340588;/37085736896;/37085437460;/37089450615;/37089447827;/37085340588;/37085736896;/37085437460",
        "aff": "Dept. of Mechanical Engineering, Embodied Dexterity Group, University of California Berkeley, Berkeley, CA, USA; Dept. of Mechanical Engineering, Embodied Dexterity Group, University of California Berkeley, Berkeley, CA, USA; Dept. of Mechanical Engineering, Embodied Dexterity Group, University of California Berkeley, Berkeley, CA, USA; Dept. of Mechanical Engineering, Embodied Dexterity Group, University of California Berkeley, Berkeley, CA, USA; Dept. of Mechanical Engineering, Embodied Dexterity Group, University of California Berkeley, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812175/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6112810459388952166&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811922",
        "title": "The Design of Stretch: A Compact, Lightweight Mobile Manipulator for Indoor Human Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile manipulators for indoor human environments can serve as versatile devices that perform a variety of tasks, yet adoption of this technology has been limited. Reducing size, weight, and cost could facilitate adoption, but risks restricting capabilities. We present a novel design that reduces size, weight, and cost, while supporting a variety of tasks. The core design consists of a two-wheeled differential-drive mobile base, a lift, and a telescoping arm configured to achieve Cartesian motion at the end of the arm. Design extensions include a 1 degree-of-freedom (DOF) wrist to stow a tool, a 2-DOF dexterous wrist to pitch and roll a tool, and a compliant gripper. We justify our design with anthropometry and mathematical models of static stability. We also provide empirical support from teleoperating and autonomously controlling a commercial robot based on our design (the Stretch RE1 from Hello Robot Inc.) to perform tasks in real homes.",
        "primary_area": "",
        "author": "Charles C. Kemp;Aaron Edsinger;Henry M. Clever;Blaine Matulevich;Charles C. Kemp;Aaron Edsinger;Henry M. Clever;Blaine Matulevich",
        "authorids": "/37266709400;/37295610100;/37086353764;/37086706393;/37266709400;/37295610100;/37086353764;/37086706393",
        "aff": "Hello Robot Inc. (HRI), Martinez, CA, USA; Hello Robot Inc. (HRI), Martinez, CA, USA; Georgia Institute of Technology (GT), Atlanta, GA, USA; Hello Robot Inc. (HRI), Martinez, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811922/",
        "gs_citation": 100,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7776164109157583796&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Hello Robot Inc.;Georgia Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.gatech.edu",
        "aff_unique_abbr": "HRI;GT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811370",
        "title": "The Feedback Trajectory Control of a SMA-Driven Miniature Jumping Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Jumping motion is an effective way to overcome large obstacles, especially for the miniature robots. However, controlling of the jumping trajectory on a centimeter scale robot is not easy due to the limitation of size and payload. None of the jumping robots lighter than 90 g achieved the feedback control of their jumping height and take-off angle independently. In this work, we proposed a miniature 6 g jumping robot that ensured the feedback control of jumping trajectory. Two simple PD controllers were used in take-off angle and jumping height control, respectively. The robot can control its jumping height from 0 to 73cm, take-off angle from \u221220\u00b0 to +20\u00b0 with respect to the vertical direction. The control errors of the jumping height and the take-off angle were less than 5 cm and 2\u00b0, respectively. The robot can hop upon different obstacles exactly, greatly increased the controllability of the micro jumping robot.",
        "primary_area": "",
        "author": "Lingqi Tang;Xuelin Wu;Peng Liu;Yao Li;Bing Li;Lingqi Tang;Xuelin Wu;Peng Liu;Yao Li;Bing Li",
        "authorids": "/37089449874;/37089447864;/37086298431;/37088420142;/37405869400;/37089449874;/37089447864;/37086298431;/37088420142;/37405869400",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen 518055, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen 518055, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen 518055, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811370/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4739499503497227011&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "School of Mechanical Engineering and Automation",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811902",
        "title": "The Second Generation (G2) Fingertip Sensor for Near-Distance Ranging and Material Sensing in Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "To continuously improve robotic grasping, we are interested in developing a contactless fingertip-mounted sensor for near-distance ranging and material sensing. Previously, we demonstrated a dual-modal and dual sensing mechanisms (DMDSM) pretouch sensor prototype based on pulse-echo ultrasound and optoacoustics. However, the complex system, the bulky and expensive pulser-receiver, and the omni-directionally sensitive microphone block the sensor from practical applications in real robotic fingers. To address these issues, we report the second generation (G2) DMDSM sensor without the pulser-receiver and microphone, which is made possible by redesigning the ultrasound transmitter and receiver to gain much wider acoustic bandwidth. To verify our design, a prototype of the G2 DMDSM sensor has been fabricated and tested. The testing results show that the G2 DMDSM sensor can achieve better ranging and similar material/structure sensing performance, but with much-simplified configuration and operation. The primary results indicate that the G2 DMDSM sensor could provide a promising solution for fingertip pretouch sensing in robotic grasping.",
        "primary_area": "",
        "author": "Cheng Fang;Di Wang;Dezhen Song;Jun Zou;Cheng Fang;Di Wang;Dezhen Song;Jun Zou",
        "authorids": "/37085893142;/37086453325;/37275586600;/37576103200;/37085893142;/37086453325;/37275586600;/37576103200",
        "aff": "Electrical and Computer Engineering Department, Texas A&M University, College Station, TX, USA; Computer Science and Engineering Department, Texas A&M University, College Station, TX, USA; Computer Science and Engineering Department, Texas A&M University, College Station, TX, USA; Electrical and Computer Engineering Department, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811902/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18063382599451620446&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812329",
        "title": "The ThreeDWorld Transport Challenge: A Visually Guided Task-and-Motion Planning Benchmark Towards Physically Realistic Embodied AI",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a visually-guided task-and-motion planning benchmark, which we call the ThreeDWorld Trans-port Challenge. In this challenge, an embodied agent is spawned randomly in a simulated physical home environment and required to transport a small set of objects scattered around the house with containers. We build this benchmark challenge using the ThreeDWorld simulation: a virtual 3D environment where all objects respond to physics, and a robot agent can be controlled using a fully physics-driven navigation and interaction API. We evaluate several existing agents on this benchmark. Experimental results suggest that: 1) a pure RL model struggles on this challenge; 2) state-of-the-art hierarchical planning-based agents can transport some objects but are still far from solving this task. We anticipate that this benchmark will empower researchers to develop more intelligent physics-aware robot learning algorithms.",
        "primary_area": "",
        "author": "Chuang Gan;Siyuan Zhou;Jeremy Schwartz;Seth Alter;Abhishek Bhandwaldar;Dan Gutfreund;Daniel L.K. Yamins;James J. DiCarlo;Josh McDermott;Antonio Torralba;Joshua B. Tenenbaum;Chuang Gan;Siyuan Zhou;Jeremy Schwartz;Seth Alter;Abhishek Bhandwaldar;Dan Gutfreund;Daniel L.K. Yamins;James J. DiCarlo;Josh McDermott;Antonio Torralba;Joshua B. Tenenbaum",
        "authorids": "/37085611353;/37089448916;/37089447166;/37089448386;/37089194363;/38312427400;/37088217541;/37846337100;/37683856900;/38183107900;/37622583000;/37085611353;/37089448916;/37089447166;/37089448386;/37089194363;/38312427400;/37088217541;/37846337100;/37683856900;/38183107900;/37622583000",
        "aff": "MIT-IBM Watson AI Lab; MIT; MIT; MIT; MIT-IBM Watson AI Lab; MIT-IBM Watson AI Lab; Stanford University; MIT; MIT; MIT; MIT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812329/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14990844153829331452&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;1;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Stanford University",
        "aff_unique_dep": "IBM Watson AI Lab;",
        "aff_unique_url": "https://www.mitibmwatsonailab.org;https://www.stanford.edu",
        "aff_unique_abbr": "MIT-IBM AI Lab;Stanford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811956",
        "title": "The Visual-Inertial- Dynamical Multirotor Dataset",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, the community has witnessed numerous datasets built for developing and testing state estimators. However, for some applications such as aerial transportation or search-and-rescue, the contact force or other disturbance must be perceived for robust planning and control, which is beyond the capacity of these datasets. This paper introduces a Visual-Inertial-Dynamical (VID) dataset, not only focusing on traditional six degrees of freedom (6-DOF) pose estimation but also providing dynamical characteristics of the flight platform for external force perception or dynamics-aided estimation. The VID dataset contains hardware synchronized imagery and inertial measurements, with accurate ground truth trajectories for evaluating common visual-inertial estimators. Moreover, the proposed dataset highlights rotor speed and motor current measurements, control inputs, and ground truth 6-axis force data to evaluate external force estimation. To the best of our knowledge, the proposed VID dataset is the first public dataset containing visual-inertial and complete dynamical information in the real world for pose and external force evaluation. The dataset1and related files2 are open-sourced.",
        "primary_area": "",
        "author": "Kunyi Zhang;Tiankai Yang;Ziming Ding;Sheng Yang;Teng Ma;Mingyang Li;Chao Xu;Fei Gao;Kunyi Zhang;Tiankai Yang;Ziming Ding;Sheng Yang;Teng Ma;Mingyang Li;Chao Xu;Fei Gao",
        "authorids": "/37089000368;/37089001320;/37088968067;/37086933342;/37089409269;/37086936897;/37404060100;/37086045143;/37089000368;/37089001320;/37088968067;/37086933342;/37089409269;/37086936897;/37404060100;/37086045143",
        "aff": "Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China; Alibaba DAMO Academy Autonomous Driving Lab, Hangzhou, China; Alibaba DAMO Academy Autonomous Driving Lab, Hangzhou, China; Alibaba DAMO Academy Autonomous Driving Lab, Hangzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811956/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16250108090385349763&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;1;1;0;0",
        "aff_unique_norm": "Zhejiang University;Alibaba DAMO Academy",
        "aff_unique_dep": "Huzhou Institute;Autonomous Driving Lab",
        "aff_unique_url": "https://www.zju.edu.cn;https://damo.alibaba.com",
        "aff_unique_abbr": "ZJU;Alibaba DAMO",
        "aff_campus_unique_index": "0;0;0;1;1;1;0;0",
        "aff_campus_unique": "Huzhou;Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811548",
        "title": "The Wavejoints: A Novel Methodology to Design Soft-Rigid Grippers Made by Monolithic 3D Printed Fingers with Adjustable Joint Stiffness",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a methodology to design soft-rigid grippers able to perform different manipulation tasks. The main idea is the introduction of wave-shaped hinges whose geometrical parameters can be designed to achieve different three-dimensional impedance characteristics. This allows one to use the same tendon-driven actuation to perform different tasks including grasping objects with different shapes and in-hand manipulation of small objects. We report all design procedures and an experimental evaluation of two different prototypes exploiting two possible tasks, the first one is designed to grasp objects adapting to different shapes and dimensions, the second one performs an in-hand manipulation task consisting in object rotation with respect to an axis perpendicular to hand palm, resembling a \u201cscrew\u201d movement. Obtained results confirm the feasibility and potentialities of the proposed methodology, that can be applied to obtain 3D printed monolithic fingers able to move in predefined directions when activated through a tendon-driven system, paving the way toward a new task-specific realization of compliant grippers.",
        "primary_area": "",
        "author": "Mihai Dragusanu;Gabriele Maria Achilli;Maria Cristina Valigi;Domenico Prattichizzo;Monica Malvezzi;Gionata Salvietti;Mihai Dragusanu;Gabriele Maria Achilli;Maria Cristina Valigi;Domenico Prattichizzo;Monica Malvezzi;Gionata Salvietti",
        "authorids": "/37086132491;/37089435160;/37089434461;/37276309600;/37550800700;/37393115500;/37086132491;/37089435160;/37089434461;/37276309600;/37550800700;/37393115500",
        "aff": "Department of Information Engineering and Mathematics, University of Siena, Siena, Italy; Department of Engineering, University of Perugia, Terni, Italy; Department of Engineering, University of Perugia, Perugia, Italy; Humanoids & Human Centered Mechatronics Research Line, Istituto Italiano di Tecnologia, Genoa, Italy; Department of Information Engineering and Mathematics, University of Siena, Siena, Italy; Department of Information Engineering and Mathematics, University of Siena, Siena, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811548/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10341433414998006579&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;0;0",
        "aff_unique_norm": "University of Siena;University of Perugia;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Information Engineering and Mathematics;Department of Engineering;Humanoids & Human Centered Mechatronics Research Line",
        "aff_unique_url": "https://www.unisi.it;https://www.unipg.it;https://www.iit.it",
        "aff_unique_abbr": ";;IIT",
        "aff_campus_unique_index": "0;1;2;3;0;0",
        "aff_campus_unique": "Siena;Terni;Perugia;Genoa",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9811362",
        "title": "Tightly-coupled GNSS-aided Visual-Inertial Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "A navigation system which can output drift-free global trajectory estimation with local consistency holds great potential for autonomous vehicles and mobile devices. We propose a tightly-coupled GNSS-aided visual-inertial navigation system (GAINS) which is able to leverage the complementary sensing modality from a visual-inertial sensing pair, which provides high-frequency local information, and a Global Navigation Satellite System (GNSS) receiver with low-frequency global observations. Specifically, the raw GNSS measurements (including pseudorange, carrier phase changes, and Doppler frequency shift) are carefully leveraged and tightly fused within a visual-inertial framework. The proposed GAINS can accurately model the raw measurement uncertainties by canceling the atmospheric effects (e.g., ionospheric and tropospheric delays) which requires no prior model information. A robust state initialization procedure is presented to facilitate the fusion of global GNSS information with local visual-inertial odometry, and the spatiotemporal calibration between IMU-GNSS are also optimized in the estimator. The proposed GAINS is evaluated on extensive Monte-Carlo simulations on a trajectory generated from a large-scale urban driving dataset with specific verification for each component (i.e., online calibration and system initialization). GAINS also demonstrates competitive performance against existing state-of-the-art methods on a publicly available dataset with ground truth.",
        "primary_area": "",
        "author": "Woosik Lee;Patrick Geneva;Yulin Yang;Guoquan Huang;Woosik Lee;Patrick Geneva;Yulin Yang;Guoquan Huang",
        "authorids": "/37087323297;/37086125563;/37085990232;/37077670600;/37087323297;/37086125563;/37085990232;/37077670600",
        "aff": "Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811362/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4650879091951907414&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Robot Perception and Navigation Group",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812311",
        "title": "Topologically-Informed Atlas Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new technique that enables manifold learning to accurately embed data manifolds that contain holes, without discarding any topological information. Manifold learning aims to embed high-dimensional data into a lower dimensional Euclidean space by learning a coordinate chart, but it requires that the entire manifold can be embedded in a single chart. This is impossible for manifolds with holes. In such cases, it is necessary to learn an atlas: a collection of charts that collectively cover the entire manifold. We begin with many small charts, and combine them in a bottom-up approach, where charts are only combined if doing so will not introduce problematic topological features. When it is no longer possible to combine any charts, each chart is individually embedded with standard manifold learning techniques, completing the construction of the atlas. We show the efficacy of our method by constructing atlases for challenging synthetic manifolds; learning human motion embeddings from motion capture data; and learning kinematic models of articulated objects.",
        "primary_area": "",
        "author": "Thomas Cohn;Nikhil Devraj;Odest Chadwicke Jenkins;Thomas Cohn;Nikhil Devraj;Odest Chadwicke Jenkins",
        "authorids": "/37088473399;/37089194381;/37297252400;/37088473399;/37089194381;/37297252400",
        "aff": "Department of Electrical Engineering and Computer Science Engineering, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science Engineering, Robotics Institute, University of Michigan, Ann Arbor, MI, USA; Department of Electrical Engineering and Computer Science Engineering, Robotics Institute, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812311/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3526062893498403345&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science Engineering",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812451",
        "title": "Toward Physical Human-Robot Interaction Control with Aerial Manipulators: Compliance, Redundancy Resolution, and Input Limits",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we introduce a comprehensive framework to control an aerial manipulator, i.e., an aerial vehicle with a robotic arm, in physical interaction with a human operator or co-worker. The framework uses an admittance control paradigm in order to attain human ergonomy and safety; an interaction supervisor to automatically shape the compliance based on the interaction regions defined around the human co-worker; a projected gradient redundancy resolution scheme to exploit the multiple degrees of freedom of the aerial robot to accommodate for possible additional secondary tasks; and a quadratic programming optimization-based inner loop to cope with real world input saturation and increase the safety level of the human co-worker. The control framework is demonstrated and validated through numerical simulations with a human-in-the loop.",
        "primary_area": "",
        "author": "Amr Afifi;Mark van Holland;Antonio Franchi;Amr Afifi;Mark van Holland;Antonio Franchi",
        "authorids": "/37089004302;/37089448532;/37541446900;/37089004302;/37089448532;/37541446900",
        "aff": "Faculty of Electrical Engineering, Mathematics & Computer Science, Robotics and Mechatronics lab, University of Twente, Enschede, The Netherlands; Faculty of Electrical Engineering, Mathematics & Computer Science, Robotics and Mechatronics lab, University of Twente, Enschede, The Netherlands; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812451/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16686351964410683751&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Twente;LAAS-CNRS",
        "aff_unique_dep": "Faculty of Electrical Engineering, Mathematics & Computer Science;",
        "aff_unique_url": "https://www.utwente.nl;https://www.laas.fr/",
        "aff_unique_abbr": "UT;LAAS-CNRS",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Enschede;Toulouse",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Netherlands;France"
    },
    {
        "id": "9812346",
        "title": "Towards 6DoF Bilateral Teleoperation of an Omnidirectional Aerial Vehicle for Aerial Physical Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Bilateral teleoperation offers an intriguing solution towards shared autonomy with aerial vehicles in contact-based inspection and manipulation tasks. Omnidirectional aerial robots allow for full pose operations, making them particularly attractive in such tasks. Naturally, the question arises whether standard bilateral teleoperation methodologies are suitable for use with these vehicles. In this work, a fully decoupled 6DoF bilateral teleoperation framework for aerial physical interaction is designed and tested for the first time. The method is based on the well established rate control, recentering and interaction force feedback policy. However, practical experiments evince the difficulty of performing de-coupled motions in a single axis only. As such, this work shows that the trivial extension of standard methods is insufficient for omnidirectional teleoperation, due to the operator's physical inability to properly decouple all input DoFs. This suggests that further studies on enhanced haptic feedback are necessary.",
        "primary_area": "",
        "author": "Mike Allenspach;Nicholas Lawrance;Marco Tognon;Roland Siegwart;Mike Allenspach;Nicholas Lawrance;Marco Tognon;Roland Siegwart",
        "authorids": "/37088490648;/37571923900;/37085377048;/37281398300;/37088490648;/37571923900;/37085377048;/37281398300",
        "aff": "ETH Z\u00fcrich, Autonomous Systems Lab, Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Autonomous Systems Lab, Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Autonomous Systems Lab, Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Autonomous Systems Lab, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812346/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5902380730714677739&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9811851",
        "title": "Towards Accurate Positioning of Underwater Vehicles Using Low-cost Acoustic Modems",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigating autonomous underwater vehicles (AUVs) in shallow and harbor waters is challenging and typically has higher accuracy requirements than navigation in the open sea. We investigate enhancements to underwater localization techniques based on Two-Way Ranging (TWR) using acoustic modems, which have great potential to meet localization accuracy requirements at lower cost and complexity than current systems. By modifying the Extended Kalman Filter, we account for dynamic positioning errors that occur during the movement of the localization target, i.e., the underwater vehicle, and the fact that distance measurements with acoustic modems are delayed in time. The method is evaluated numerically and experimentally showing an accuracy improvement of about 20 cm compared to the traditional EKF scheme. In real-world tests at ranges below 30 m, the absolute localization accuracy is assessed using an RTK-GPS reference, showing that a positioning error below 35 cm can be achieved in a quasi-static test, while in a dynamic test the tracking error is mostly below 75 cm.",
        "primary_area": "",
        "author": "Christian Busse;Bernd-Christian Renner;Christian Busse;Bernd-Christian Renner",
        "authorids": "/37089299318;/37685162600;/37089299318;/37685162600",
        "aff": "Institute of Telematics, Hamburg University of Technology; Institute of Computer Science and Institute for Software Technology, University of Koblenz-Landau",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811851/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11865108053254050138&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Hamburg University of Technology;University of Koblenz-Landau",
        "aff_unique_dep": "Institute of Telematics;Institute of Computer Science",
        "aff_unique_url": "https://www.tu-harburg.de;https://www.uni-koblenz-landau.de",
        "aff_unique_abbr": "TU Hamburg;UKL",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Hamburg;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811933",
        "title": "Towards Artefact Aware Human Motion Capture using Inertial Sensors Integrated into Loose Clothing",
        "track": "main",
        "status": "Poster",
        "abstract": "Inertial motion capture has become an attractive alternative to optical motion capture for human joint angle estimation outside the laboratory. Usually inertial sensors are assumed to be tightly fixed to the body segments, which can be cumbersome regarding setup-time and ease-of-use. However, integrating the sensors directly into loose clothing, usually, results in additional clothing motion relative to the motion of the underlying bones that should be captured. In this work we propose the Difference Mapping distributions approach that corrects the segment orientations of a given inertial motion capture system that assumes tightly coupled sensors. The approach allows to reduce the joint angle errors due to clothing artefacts by at least 77.2% for people with similar morphology performing a similar task as seen in the training data, including an ergonomic assessments scenario at work places with ten participants. Moreover, we show that the uncertainty of the distribution can be used to measure the reliability of the predicted map if e.g. the motion is further away from the training data to allow for an artefact aware inertial motion tracking approach. The experimental data for this study is available online under [1].",
        "primary_area": "",
        "author": "Michael Lorenz;Gabriele Bleser;Takayuki Akiyama;Takehiro Niikura;Didier Stricker;Bertram Taetz;Michael Lorenz;Gabriele Bleser;Takayuki Akiyama;Takehiro Niikura;Didier Stricker;Bertram Taetz",
        "authorids": "/37088219507;/37669510600;/37085392747;/38529368600;/37326112700;/37085669580;/37088219507;/37669510600;/37085392747;/38529368600;/37326112700;/37085669580",
        "aff": "German Research Institute for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Institute for Artificial Intelligence (DFKI), Kaiserslautern, Germany; Research and Development Group, Hitachi, Ltd., Tokyo, Japan; Research and Development Group, Hitachi, Ltd., Tokyo, Japan; German Research Institute for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Institute for Artificial Intelligence (DFKI), Kaiserslautern, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811933/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15528246731697545604&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "German Research Institute for Artificial Intelligence;Hitachi, Ltd.",
        "aff_unique_dep": ";Research and Development Group",
        "aff_unique_url": "https://www.dFKI.de;https://www.hitachi.com",
        "aff_unique_abbr": "DFKI;Hitachi",
        "aff_campus_unique_index": "0;0;1;1;0;0",
        "aff_campus_unique": "Kaiserslautern;Tokyo",
        "aff_country_unique_index": "0;0;1;1;0;0",
        "aff_country_unique": "Germany;Japan"
    },
    {
        "id": "9812204",
        "title": "Towards Broad Learning Networks on Unmanned Mobile Robot for Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "This article investigates the real-time semantic segmentation in robot engineering applications based on the Broad Learning System (BLS), and a novel Multi-level Enhancement Layers Network (MELNet) based on BLS framework is proposed for real-time vision tasks in a complex street scene on the unmanned mobile robot. This network mainly solves two problems: (1) mitigating the contradiction between accuracy and speed while maintaining low model complexity, and (2) accurately describing objects based on their shape despite their different sizes. Firstly, the BLS architecture is expanded to the deep network with trainable parameters. This trainable network could adjust its weights in a complex environment, and mitigate the adverse impact of the environment on the complex tasks. Secondly, enhancement layers with the extended enhancement layers could extract both detailed information and semantic information. Moreover, an Upsampling Atrous Spatial Pyramid Pooling (UPASPP) is designed to fuse detail and semantic information to describe object features properly. Finally, in the case of the MNIST dataset and Cityscapes dataset, we get high accuracy with 8.01M parameters and quicker inference speed on a single GTX 1070 Ti card. At the same time, the unmanned mobile robot (BIT-NAZA) is employed to evaluate semantic performance in real-world situations. This reveals that MELNet could be run adequately on the embedded device and effectively operate in the real-robot system.",
        "primary_area": "",
        "author": "Jiehao Li;Yingpeng Dai;Junzheng Wang;Xiaohang Su;Ruijun Ma;Jiehao Li;Yingpeng Dai;Junzheng Wang;Xiaohang Su;Ruijun Ma",
        "authorids": "/37087890868;/37086131048;/37406464200;/37089449094;/37086527022;/37087890868;/37086131048;/37406464200;/37089449094;/37086527022",
        "aff": "State Key Laboratory of Intelligent Control and Decision of Complex Systems, School of Automation, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex Systems, School of Automation, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex Systems, School of Automation, Beijing Institute of Technology, Beijing, China; School of Computer Science and Engineering, South China University of Technology, Guangzhou, China; Department of Computer and Information Science, PAMI Research Group, niversity of Macau, Macau, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812204/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17893075657029387315&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Beijing Institute of Technology;South China University of Technology;University of Macau",
        "aff_unique_dep": "School of Automation;School of Computer Science and Engineering;Department of Computer and Information Science",
        "aff_unique_url": "http://www.bit.edu.cn;https://www.scut.edu.cn;https://www.um.edu.mo",
        "aff_unique_abbr": "BIT;SCUT;UM",
        "aff_campus_unique_index": "0;0;0;1;2",
        "aff_campus_unique": "Beijing;Guangzhou;Macau",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812081",
        "title": "Towards Dynamic Visual Servoing for Interaction Control and Moving Targets",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we present our results on dynamic visual servoing for the case of moving targets while also exploring the possibility of using such a controller for interaction with the environment. We illustrate the derivation of a feature space impedance controller for tracking a moving object as well as an Extended Kalman Filter based on the visual servoing kinematics for increasing the rate of the visual information and estimating the target velocity for both the cases of PBVS and IBVS with image point features. Simulations are carried out to validate the estimator performance during a Peg-in-Hole insertion task with a moving part. Experiments are also conducted on a real redundant manipulator with a low-cost wrist-mounted camera. Details on several implementation issues encountered during implementation are also discussed.",
        "primary_area": "",
        "author": "Alexander Antonio Oliva;Erwin Aertbeli\u00ebn;Joris De Schutter;Paolo Robuffo Giordano;Fran\u00e7ois Chaumette;Alexander Antonio Oliva;Erwin Aertbeli\u00ebn;Joris De Schutter;Paolo Robuffo Giordano;Fran\u00e7ois Chaumette",
        "authorids": "/37086595573;/37449455800;/37283056500;/37544316400;/37265186700;/37086595573;/37449455800;/37283056500;/37544316400;/37265186700",
        "aff": "Inria, Univ Rennes, CNRS, IRISA, Rennes, France; Core Lab ROB, Flanders Make, Leuven, Belgium; Core Lab ROB, Flanders Make, Leuven, Belgium; CNRS at IRISA and Inria, Rennes, France; Inria, Univ Rennes, CNRS, IRISA, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812081/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9667456676873681288&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "INRIA;Flanders Make;CNRS",
        "aff_unique_dep": ";Core Lab ROB;IRISA and Inria",
        "aff_unique_url": "https://www.inria.fr;https://www.flandersmake.be;https://www.cnrs.fr",
        "aff_unique_abbr": "Inria;;CNRS",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Rennes;Leuven",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "France;Belgium"
    },
    {
        "id": "9812325",
        "title": "Towards Efficient 3D Human Motion Prediction using Deformable Transformer-based Adversarial Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Human motion prediction is a crucial step for achieving human-robot interactions. While recent transformer-based methods have shown great potentials in 3D human motion prediction, they still suffer from mode collapse to non-plausible poses and quadratically computational complexity with respect to the increasing length of input sequences. In this paper, we propose a novel spatio-temporal deformable transformer-based adversarial network (STDTA) for 3D human motion prediction. First, we design a spatio-temporal deformable transformer module to capture the correlations between human joints while reducing the computational costs. Second, we introduce the adversarial training mechanism and design fidelity and continuity discriminators to maintain smoothness and stability for the long-term prediction. Finally, extensive experiments on Human 3.6M and AMASS benchmarks demonstrate that the proposed STDTA achieves state-of-the-art performance.",
        "primary_area": "",
        "author": "Yu Hua;Fan Xuanzhe;Hou Yaqing;Liu Yi;Kang Cai;Zhou Dongsheng;Zhang Qiang;Yu Hua;Fan Xuanzhe;Hou Yaqing;Liu Yi;Kang Cai;Zhou Dongsheng;Zhang Qiang",
        "authorids": "/37089448055;/37089447791;/37088495269;/37089447917;/37089450411;/37089447668;/37088495540;/37089448055;/37089447791;/37088495269;/37089447917;/37089450411;/37089447668;/37088495540",
        "aff": "College of Computer Science and Technology, Dalian University of Technology, Liaoning, China; College of Computer Science and Technology, Dalian University of Technology, Liaoning, China; College of Computer Science and Technology, Dalian University of Technology, Liaoning, China; Baidu Inc., Beijing, China; College of Computer Science and Technology, Dalian University of Technology, Liaoning, China; School of Software Engineering, Dalian University, Liaoning, China; College of Computer Science and Technology, Dalian University of Technology, Liaoning, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812325/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10288096067552637569&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;2;0",
        "aff_unique_norm": "Dalian University of Technology;Baidu;Dalian University",
        "aff_unique_dep": "College of Computer Science and Technology;Baidu Inc.;School of Software Engineering",
        "aff_unique_url": "http://en.dlut.edu.cn/;https://www.baidu.com;https://www.dlu.edu.cn",
        "aff_unique_abbr": "DUT;Baidu;",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Dalian;Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812450",
        "title": "Towards More Generalizable One-shot Visual Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "A general-purpose robot should be able to master a wide range of tasks and quickly learn a novel one by leveraging past experiences. One-shot imitation learning (OSIL) approaches this goal by training an agent with (pairs of) expert demonstrations, such that at test time, it can directly execute a new task from just one demonstration. However, so far this framework has been limited to training on many variations of one task, and testing on other unseen but similar variations of the same task. In this work, we push for a higher level of generalization ability by investigating a more ambitious multi-task setup. We introduce a diverse suite of vision-based robot manipulation tasks, consisting of 7 tasks, a total of 61 variations, and a continuum of instances within each variation. For consistency and comparison purposes, we first train and evaluate single-task agents (as done in prior few-shot imitation work). We then study the multi-task setting, where multi-task training is followed by (i) one-shot imitation on variations within the training tasks, (ii) one-shot imitation on new tasks, and (iii) fine-tuning on new tasks. Prior state-of-the-art, while performing well within some single tasks, struggles in these harder multi-task settings. To address these limitations, we propose MOSAIC (Multi-task One-Shot Imitation with self-Attention and Contrastive learning), which integrates a self-attention model architecture and a temporal contrastive module to enable better task disambiguation and more robust representation learning. Our experiments show that MOSAIC outperforms prior state of the art in learning efficiency, final performance, and learns a multi-task policy with promising generalization ability via fine-tuning on novel tasks.",
        "primary_area": "",
        "author": "Zhao Mandi;Fangchen Liu;Kimin Lee;Pieter Abbeel;Zhao Mandi;Fangchen Liu;Kimin Lee;Pieter Abbeel",
        "authorids": "/37089448649;/37087232113;/37085866548;/37542877900;/37089448649;/37087232113;/37085866548;/37542877900",
        "aff": "University of California, Berkeley, USA; University of California, Berkeley, USA; University of California, Berkeley, USA; University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812450/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17426456272859768933&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812252",
        "title": "Towards Optimal Correlational Object Search",
        "track": "main",
        "status": "Poster",
        "abstract": "In realistic applications of object search, robots will need to locate target objects in complex environments while coping with unreliable sensors, especially for small or hard-to-detect objects. In such settings, correlational information can be valuable for planning efficiently. Previous approaches that consider correlational information typically resort to ad-hoc, greedy search strategies. We introduce the Correlational Object Search POMDP (COS-POMDP), which models correlations while preserving optimal solutions with a reduced state space. We propose a hierarchical planning algorithm to scale up COS-POMDPs for practical domains. Our evaluation, conducted with the AI2-THOR household simulator and the YOLOv5 object detector, shows that our method finds objects more successfully and efficiently compared to baselines, particularly for hard-to-detect objects such as srub brush and remote control.",
        "primary_area": "",
        "author": "Kaiyu Zheng;Rohan Chitnis;Yoonchang Sung;George Konidaris;Stefanie Tellex;Kaiyu Zheng;Rohan Chitnis;Yoonchang Sung;George Konidaris;Stefanie Tellex",
        "authorids": "/37087321724;/37085544593;/38235977600;/38318614200;/37402794800;/37087321724;/37085544593;/38235977600;/38318614200;/37402794800",
        "aff": "Brown University, Providence, RI; MIT CSAIL, Cambridge, MA; MIT CSAIL, Cambridge, MA; Brown University, Providence, RI; Brown University, Providence, RI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812252/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9318626717379479449&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Brown University;Massachusetts Institute of Technology",
        "aff_unique_dep": ";Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.brown.edu;https://www.csail.mit.edu",
        "aff_unique_abbr": "Brown;MIT CSAIL",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Providence;Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811728",
        "title": "Towards Robust Part-aware Instance Segmentation for Industrial Bin Picking",
        "track": "main",
        "status": "Poster",
        "abstract": "Industrial bin picking is a challenging task that requires accurate and robust segmentation of individual object instances. Particularly, industrial objects can have irregular shapes, that is, thin and concave, whereas in bin-picking scenarios, objects are often closely packed with strong occlusion. To address these challenges, we formulate a novel part-aware instance segmentation pipeline. The key idea is to decompose industrial objects into correlated approximate convex parts and enhance the object-level segmentation with part-level segmentation. We design a part-aware network to predict part masks and part-to-part offsets, followed by a part aggregation module to assemble the recognized parts into instances. To guide the network learning, we also propose an automatic label decoupling scheme to generate ground-truth part-level labels from instance-level labels. Finally, we contribute the first instance segmentation dataset, which contains a variety of industrial objects that are thin and have non-trivial shapes. Extensive experimental results on various industrial objects demonstrate that our method can achieve the best segmentation results compared with the state-of-the-art approaches.",
        "primary_area": "",
        "author": "Yidan Feng;Biqi Yang;Xianzhi Li;Chi-Wing Fu;Rui Cao;Kai Chen;Qi Dou;Mingqiang Wei;Yun-Hui Liu;Pheng-Ann Heng;Yidan Feng;Biqi Yang;Xianzhi Li;Chi-Wing Fu;Rui Cao;Kai Chen;Qi Dou;Mingqiang Wei;Yun-Hui Liu;Pheng-Ann Heng",
        "authorids": "/37088456659;/37089307076;/37086569101;/37336329800;/37089307526;/37404002500;/37085465414;/37395413200;/37279412600;/37283077400;/37088456659;/37089307076;/37086569101;/37336329800;/37089307526;/37404002500;/37085465414;/37395413200;/37279412600;/37283077400",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811728/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8922300233295983239&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811766",
        "title": "Towards Safe, Realistic Testbed for Robotic Systems with Human Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulation has been a necessary, safe testbed for robotics systems (RS). However, testing in simulation alone is not enough for robotic systems operating in close proximity, or interacting directly with, humans, because simulated humans are very limited. Furthermore, testing with real humans can be unsafe and costly. As recent advances in machine learning are being brought to physical robotic systems, how to collect data as well as evaluate them with human interactions safely yet realistically is a critical question. This paper presents a Mixed-Reality (MR) system toward human-centered development of robotic systems emphasizing benefits as a data collection and testbed tool. MR testbeds allow humans to interact with various levels of virtuality to maintain both realism and safety. We detail the advantages and limitations of these different levels of realism or virtualization, and report our MR-based RS testbed implemented using off-the-shelf MR devices with the Unity game engine and ROS. We demonstrate our testbed in a multi-robot, multi-person tracking and monitoring application. We share our vision and insights earned during the development and data collection.",
        "primary_area": "",
        "author": "Bhoram Lee;Jonathan Brookshire;Rhys Yahata;Supun Samarasekera;Bhoram Lee;Jonathan Brookshire;Rhys Yahata;Supun Samarasekera",
        "authorids": "/37089447442;/37087344741;/37086663683;/37326240700;/37089447442;/37087344741;/37086663683;/37326240700",
        "aff": "Center for Vision Technologies, SRI International; LatentAI; University of Southern California, Institute for Creative Technologies; Center for Vision Technologies, SRI International",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811766/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3725846963802131048&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "SRI International;LatentAI;University of Southern California",
        "aff_unique_dep": "Center for Vision Technologies;;Institute for Creative Technologies",
        "aff_unique_url": "https://www.sri.com;https://latentai.org;https://www.usc.edu",
        "aff_unique_abbr": "SRI;LatentAI;USC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812347",
        "title": "Towards Scale Consistent Monocular Visual Odometry by Learning from the Virtual World",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular visual odometry (VO) has attracted extensive research attention by providing real-time vehicle motion from cost-effective camera images. However, state-of-the-art optimization-based monocular VO methods suffer from the scale inconsistency problem for long-term predictions. Deep learning has recently been introduced to address this issue by leveraging stereo sequences or ground-truth motions in the training dataset. However, it comes at an additional cost for data collection, and such training data may not be available in all datasets. In this work, we propose VRVO, a novel framework for retrieving the absolute scale from virtual data that can be easily obtained from modern simulation environments, whereas in the real domain no stereo or ground-truth data are required in either the training or inference phases. Specifically, we first train a scale-aware disparity network using both monocular real images and stereo virtual data. The virtual-to-real domain gap is bridged by using an adversarial training strategy to map images from both domains into a shared feature space. The resulting scale-consistent disparities are then integrated with a direct VO system by constructing a virtual stereo objective that ensures the scale consistency over long trajectories. Additionally, to address the suboptimality issue caused by the separate optimization backend and the learning process, we further propose a mutual reinforcement pipeline that allows bidirectional information flow between learning and optimization, which boosts the robustness and accuracy of each other. We demonstrate the effectiveness of our framework on the KITTI and vKITTI2 datasets.",
        "primary_area": "",
        "author": "Sen Zhang;Jing Zhang;Dacheng Tao;Sen Zhang;Jing Zhang;Dacheng Tao",
        "authorids": "/37089447158;/37087004829;/37269935500;/37089447158;/37087004829;/37269935500",
        "aff": "School of Computer Science The University of Sydney, Australia; School of Computer Science The University of Sydney, Australia; School of Computer Science The University of Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812347/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8483436722899430876&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Sydney",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.sydney.edu.au",
        "aff_unique_abbr": "USYD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9811918",
        "title": "Towards Sensor Autonomy in Sub-Gram Flying Insect Robots: A Lightweight and Power-Efficient Avionics System",
        "track": "main",
        "status": "Poster",
        "abstract": "Flying insect robots weighing less than a gram (FIRs) have advantages over their larger counterparts due to their low materials cost, small size, and low weight, allowing for deployment in large numbers. Control autonomy in such aircraft introduces challenges arising from their small size such as high-speed dynamics, limited power and payload capacity. Previous work has produced and characterized sensors with compatible mass and power specifications, many of which are biologically-inspired. And controlled flight has been demon-strated using feedback from external motion capture cameras. But to date, no avionics system has been reported that is light enough and capable of providing the feedback necessary to perform controlled hovering flight using only components carried on-board. Here we present such a system. It consists a sensor package consisting of an inertial measurement unit, a laser rangefinder and an optical flow sensor, and an associated estimator based on the nonlinear Extended Kalman Filter (EKF). The sensor suite weighs 187 mg and consumes 21 mW. We implemented a low-latency wireless link to transmit this data at 1 kHz without cumbersome wires. The EKF estimates attitude, altitude and lateral velocities. We estimate that computation power usage is <400 \u00b5W using floating-point operations on a standard microcontroller. Our system's RMSE attitude and position error are less than 4\u00b0 and 1 cm relative to motion capture estimates.",
        "primary_area": "",
        "author": "Yash P. Talwekar;Andrew Adie;Vikram Iyer;Sawyer B. Fuller;Yash P. Talwekar;Andrew Adie;Vikram Iyer;Sawyer B. Fuller",
        "authorids": "/37089194315;/37089449258;/37086452962;/37408404900;/37089194315;/37089449258;/37086452962;/37408404900",
        "aff": "Department of Mechanical Engineering, University of Washington, Seattle, WA, USA; Department of Mechanical Engineering, University of Washington, Seattle, WA, USA; School of Computer Science, University of Washington, Seattle, WA, USA; School of Computer Science, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811918/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12278322336837411007&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811764",
        "title": "Towards Time-Optimal Tunnel-Following for Quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "Minimum-time navigation within constrained and dynamic environments is of special relevance in robotics. Seeking time-optimality, while guaranteeing the integrity of time-varying spatial bounds, is an appealing trade-off for agile vehicles, such as quadrotors. State-of-the-art approaches, either assume bounds to be static and generate time-optimal trajectories offline, or compromise time-optimality for constraint satisfaction. Leveraging nonlinear model predictive control and a path parametric reformulation of the quadrotor model, we present a real-time control that approximates time-optimal behavior and remains within dynamic corridors. The efficacy of the approach is evaluated by simulated results, showing itself capable of performing extremely aggressive maneuvers as well as stop-and-go and backward motions. Video: https://youtu.be/Apc8MCu7Yvo",
        "primary_area": "",
        "author": "Jon Arrizabalaga;Markus Ryll;Jon Arrizabalaga;Markus Ryll",
        "authorids": "/37089224871;/38251847500;/37089224871;/38251847500",
        "aff": "Department of Aerospace and Geodesy, Autonomous Aerial Systems Lab, Technical University of Munich, Germany; Department of Aerospace and Geodesy, Autonomous Aerial Systems Lab, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811764/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17966090644380566743&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Aerospace and Geodesy",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812219",
        "title": "Towards a Microfluidic Microcontroller Circuit Library for Soft Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotics has seen an exponential growth in the past decade, in part because the transition to soft materials has made a wider range of applications possible. Tasks involving contact with fragile objects or unstructured environments are particularly amenable to devices based on soft materials. To date, research has primarily focused on the development of soft analogs to traditional sensors and actuators while controllers for soft robots have tended to rely on common rigid electronic components. We aspire to create a library of elastomer-based devices that can evolve soft controllers beyond component-level demonstrations and towards system-level completeness taking inspiration from electronic microcontrollers. Our approach combines microfluidic circuit designs with soft robotic fabrication techniques to create fluidic microcontroller components that are composed of soft materials and are of minimal size. We have identified the shift register, oscillator, and demultiplexer as key circuit elements for both individual functionality and for multi-component systems that can mimic microcontroller behaviors. In this paper, we present a review of fluidic circuits, fabrication processes, and implementation of these circuits into soft robotic platforms. In this work, we demonstrate a shift register, demultiplexer, and oscillator. They contain characteristics such as memory storage, data communication, and timing capabilities.",
        "primary_area": "",
        "author": "Elizabeth Gallardo Hevia;Louis De La Rochefoucauld;Robert J. Wood;Elizabeth Gallardo Hevia;Louis De La Rochefoucauld;Robert J. Wood",
        "authorids": "/37086456016;/37089449399;/37326227400;/37086456016;/37089449399;/37326227400",
        "aff": "John A. Paulson School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; \u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812219/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1585313635094378944&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Harvard University;\u00c9cole polytechnique f\u00e9d\u00e9rale de Lausanne",
        "aff_unique_dep": "John A. Paulson School of Engineering and Applied Sciences;",
        "aff_unique_url": "https://www.harvard.edu;https://www.epfl.ch",
        "aff_unique_abbr": "Harvard;EPFL",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Boston;Lausanne",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "9811873",
        "title": "TraSeTR: Track-to-Segment Transformer with Contrastive Query for Instance-level Instrument Segmentation in Robotic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Surgical instrument segmentation - in general a pixel classification task - is fundamentally crucial for promoting cognitive intelligence in robot-assisted surgery (RAS). However, previous methods are struggling with discriminating instrument types and instances. To address above issues, we explore a mask classification paradigm that produces per-segment predictions. We propose TraSeTR, a novel Track-to-Segment Transformer that wisely exploits tracking cues to assist surgical instrument segmentation. TraSeTR jointly reasons about the instrument type, location, and identity with instance-level predictions i.e., a set of class-bbox-mask pairs, by decoding query embeddings. Specifically, we introduce the prior query that encoded with previous temporal knowledge, to transfer tracking signals to current instances via identity matching. A contrastive query learning strategy is further applied to reshape the query feature space, which greatly alleviates the tracking difficulty caused by large temporal variations. The effectiveness of our method is demonstrated with state-of-the-art instrument type segmentation results on three public datasets, including two RAS benchmarks from EndoVis Challenges and one cataract surgery dataset CaDIs.",
        "primary_area": "",
        "author": "Zixu Zhao;Yueming Jin;Pheng\u2013Ann Heng;Zixu Zhao;Yueming Jin;Pheng\u2013Ann Heng",
        "authorids": "/37088904291;/37086369638;/37283077400;/37088904291;/37086369638;/37283077400",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Comouter Science, University College, London, UK; Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811873/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2875285178864139330&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Chinese University of Hong Kong;University College London;Chinese Academy of Sciences",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Computer Science;Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.ucl.ac.uk;http://www.cas.cn",
        "aff_unique_abbr": "CUHK;UCL;CAS",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Hong Kong SAR;London;Shenzhen",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9812189",
        "title": "Tracking Fast Trajectories with a Deformable Object using a Learned Model",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a method for robotic control of deformable objects using a learned nonlinear dynamics model. After collecting a dataset of trajectories from the real system, we train a recurrent neural network (RNN) to approximate its input-output behavior with a latent state-space model. The RNN internal state is low-dimensional enough to enable realtime nonlinear control methods. We demonstrate a closed-loop control scheme with the RNN model using a standard nonlinear state observer and model-predictive controller. We apply our method to track a highly dynamic trajectory with a point on the deformable object, in real time and on real hardware. Our experiments show that the RNN model captures the true system's frequency response and can be used to track trajectories outside the training distribution. In an ablation study, we find that the full method improves tracking accuracy compared to an open-loop version without the state observer.",
        "primary_area": "",
        "author": "James A. Preiss;David Millard;Tao Yao;Gaurav S. Sukhatme;James A. Preiss;David Millard;Tao Yao;Gaurav S. Sukhatme",
        "authorids": "/37086138258;/37088996818;/37089450838;/37278934100;/37086138258;/37088996818;/37089450838;/37278934100",
        "aff": "University of Southern California; University of Southern California; University of Southern California; University of Southern California",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812189/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3604180350011912342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811724",
        "title": "Traffic Context Aware Data Augmentation for Rare Object Detection in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Detection of rare objects (e.g., traffic cones, traffic barrels and traffic warning triangles) is an important perception task to improve the safety of autonomous driving. Training of such models typically requires a large number of annotated data which is expensive and time consuming to obtain. To address the above problem, an emerging approach is to apply data augmentation to automatically generate cost-free training samples. In this work, we propose a systematic study on simple Copy-Paste data augmentation for rare object detection in autonomous driving. Specifically, local adaptive instance-level image transformation is introduced to generate realistic rare object masks from source domain to the target domain. Moreover, traffic scene context is utilized to guide the placement of masks of rare objects. To this end, our data augmentation generates training data with high quality and realistic characteristics by leveraging both local and global consistency. In addition, we build a new dataset named NM10k consisting 10k training images, 4k validation images and the corresponding labels with a diverse range of scenarios in autonomous driving. Experiments on NM10k show that our method achieves promising results on rare object detection. We also present a thorough study to illustrate the effectiveness of our local-adaptive and global constraints based Copy-Paste data augmentation for rare object detection. The data, development kit and more information of NM10k dataset are available online at: https://nullmax-vision.github.io.",
        "primary_area": "",
        "author": "Naifan Li;Fan Song;Ying Zhang;Pengpeng Liang;Erkang Cheng;Naifan Li;Fan Song;Ying Zhang;Pengpeng Liang;Erkang Cheng",
        "authorids": "/37089450922;/37089449806;/37089299867;/37076966700;/37088874018;/37089450922;/37089449806;/37089299867;/37076966700;/37088874018",
        "aff": "NullMax, Shanghai, China; NullMax, Shanghai, China; NullMax, Shanghai, China; School of Information Engineering, Zhengzhou University, China; NullMax, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811724/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=831833551684917555&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "NullMax;Zhengzhou University",
        "aff_unique_dep": ";School of Information Engineering",
        "aff_unique_url": ";http://www.zzu.edu.cn",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811615",
        "title": "Trajectory Distribution Control for Model Predictive Path Integral Control using Covariance Steering",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel control approach for autonomous systems operating under uncertainty. We combine Model Predictive Path Integral (MPPI) control with Covariance Steering (CS) theory to obtain a robust controller for general nonlinear systems. The proposed Covariance-Controlled Model Predictive Path Integral (CC-MPPI) controller addresses the performance degradation observed in some MPPI implementations owing to unexpected disturbances and uncertainties. Namely, in cases where the environment changes too fast or the simulated dynamics during the MPPI rollouts do not capture the noise and uncertainty in the actual dynamics, the baseline MPPI implementation may lead to divergence. The proposed CC-MPPI controller avoids divergence by controlling the dispersion of the rollout trajectories at the end of the prediction horizon. Furthermore, the CC-MPPI has adjustable trajectory sampling distributions that can be changed according to the environment to achieve efficient sampling. Numerical examples using a ground vehicle navigating in challenging environments demonstrate the proposed approach.",
        "primary_area": "",
        "author": "Ji Yin;Zhiyuan Zhang;Evangelos Theodorou;Panagiotis Tsiotras;Ji Yin;Zhiyuan Zhang;Evangelos Theodorou;Panagiotis Tsiotras",
        "authorids": "/37089449275;/37089448852;/37546007800;/37330609800;/37089449275;/37089448852;/37546007800;/37330609800",
        "aff": "D. Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, GA; D. Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, GA; D. Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, GA; D. Guggenheim School of Aerospace Engineering, Georgia Institute of Technology, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811615/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12281569906316432077&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Aerospace Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Georgia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812199",
        "title": "Trajectory Optimization Formulation with Smooth Analytical Derivatives for Track-leg and Wheel-leg Ground Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Tracks, wheels, and legs are all useful locomotion modes for Unmanned Ground Vehicles (UGVs), and ground robots that combine these mechanisms have the potential to climb over large obstacles. As robot morphologies include more degrees of freedom and obstacles become increasingly large and complex, UGVs will need to rely on automatic motion planning to compute the joint trajectories for traversal. This article presents a trajectory optimization formulation for multibody UGVs with combined wheel-leg and track-leg designs. We derive the dynamics and constraints for rolling wheels and circulating elliptical tracks. Using direct collocation, we formulate a model-based trajectory optimization where all constraints and objectives are written in closed-form with smooth and exact derivatives for tractable computation times with existing large-scale nonlinear optimization solvers (<1 minute). We demonstrate the trajectory optimization on numerous simulated planar wheel-leg and track-leg morphologies completing locomotion tasks, demonstrating full body dynamic coupling for the multibody system. Future work will extend this formulation to 3D and include contact planning.",
        "primary_area": "",
        "author": "Adwait Mane;Dylan Swart;Jason White;Christian Hubicki;Adwait Mane;Dylan Swart;Jason White;Christian Hubicki",
        "authorids": "/37089449115;/37088506500;/37088506782;/37085380316;/37089449115;/37088506500;/37088506782;/37085380316",
        "aff": "Department of Mechanical Engineering, FAMU-FSU College of Engineering, Florida State University, Tallahassee, FL, USA; Department of Computer Science, Florida State University, Tallahassee, FL, USA; Department of Mechanical Engineering, FAMU-FSU College of Engineering, Florida State University, Tallahassee, FL, USA; Department of Mechanical Engineering, FAMU-FSU College of Engineering, Florida State University, Tallahassee, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812199/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17380106197364909861&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Florida State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.fsu.edu",
        "aff_unique_abbr": "FSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tallahassee",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811773",
        "title": "Trajectory Planning for Sensors and Payloads Moving Through Mixed and Uncertain Media",
        "track": "main",
        "status": "Poster",
        "abstract": "Heterogeneous robotic systems in the field often encounter bodies of water with unknown traversability properties. One approach to measuring depth, current, soil composition, etc. is via an in situ underwater sensor being dragged by cable attached to a maneuvering airborne multicopter - which entails a novel motion planning and control problem with mixed resistive media. In this work we propose a framework to plan trajectories for future characterization sensors and payloads moving through mixed (air-water) media while considering uncertainty in the depth of the underwater ground surface. The methodology is applied to example underactuated systems with suspended payloads of increasing levels of complexity, including a cable robot and 4- and 8-DOF multicopter systems. Simulation studies employing trajectory optimization indicate that under certain payload configurations and task constraints, there are maneuvers in which it is more efficient to drag the payloads through water than through air. The paper also includes preliminary experiments with a testbed cable robot platform.",
        "primary_area": "",
        "author": "Camilo Ordonez;David Jay;Christian Hubicki;Camilo Ordonez;David Jay;Christian Hubicki",
        "authorids": "/37571185000;/37089450928;/37085380316;/37571185000;/37089450928;/37085380316",
        "aff": "Department of Mechanical Engineering, FAMU-FSU College of Engineering, Tallahassee, Fl, USA; Department of Mechanical Engineering, FAMU-FSU College of Engineering, Tallahassee, Fl, USA; Department of Mechanical Engineering, FAMU-FSU College of Engineering, Tallahassee, Fl, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811773/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:vCKsHL7AQj0J:scholar.google.com/&scioq=Trajectory+Planning+for+Sensors+and+Payloads+Moving+Through+Mixed+and+Uncertain+Media&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "FAMU-FSU College of Engineering",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.famu-fsu.edu/engineering",
        "aff_unique_abbr": "FAMU-FSU Eng",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tallahassee",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811712",
        "title": "Trajectory Prediction for Autonomous Driving with Topometric Map",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art autonomous driving systems rely on high definition (HD) maps for localization and navigation. However, building and maintaining HD maps is time-consuming and expensive. Furthermore, the HD maps assume structured environment such as the existence of major road and lanes, which are not present in rural areas. In this work, we propose an end-to-end transformer networks based approach for map-less autonomous driving. The proposed model takes raw LiDAR data and noisy topometric map as input and produces precise local trajectory for navigation. We demonstrate the effectiveness of our method in real-world driving data, including both urban and rural areas. The experimental results show that the proposed method outperforms state-of-the-art multimodal methods and is robust to the perturbations of the topometric map. The code of the proposed method is publicly available at https://github.com/Jiaolong/trajectory-prediction.",
        "primary_area": "",
        "author": "Jiaolong Xu;Liang Xiao;Dawei Zhao;Yiming Nie;Bin Dai;Jiaolong Xu;Liang Xiao;Dawei Zhao;Yiming Nie;Bin Dai",
        "authorids": "/37073877600;/37085349060;/37085406223;/37086934086;/37397374200;/37073877600;/37085349060;/37085406223;/37086934086;/37397374200",
        "aff": "Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811712/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=517064782407871573&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "National Innovation Institute of Defense Technology",
        "aff_unique_dep": "Unmanned Systems Research Center",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811928",
        "title": "Trajectory Prediction with Linguistic Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Language allows humans to build mental models that interpret what is happening around them resulting in more accurate long-term predictions. We present a novel trajectory prediction model that uses linguistic intermediate representations to forecast trajectories, and is trained using trajectory samples with partially-annotated captions. The model learns the meaning of each of the words without direct per-word supervision. At inference time, it generates a linguistic description of trajectories which captures maneuvers and interactions over an extended time interval. This generated description is used to refine predictions of the trajectories of multiple agents. We train and validate our model on the Argoverse dataset, and demonstrate improved accuracy results in trajectory prediction. In addition, our model is more interpretable: it presents part of its reasoning in plain language as captions, which can aid model development and can aid in building confidence in the model before deploying it.",
        "primary_area": "",
        "author": "Yen-Ling Kuo;Xin Huang;Andrei Barbu;Stephen G. McGill;Boris Katz;John J. Leonard;Guy Rosman;Yen-Ling Kuo;Xin Huang;Andrei Barbu;Stephen G. McGill;Boris Katz;John J. Leonard;Guy Rosman",
        "authorids": "/37086579906;/37086595235;/37086580332;/37089259672;/37086574046;/37329387400;/37393688300;/37086579906;/37086595235;/37086580332;/37089259672;/37086574046;/37329387400;/37393688300",
        "aff": "CSAIL & CBMM MIT, Cambridge, MA, USA; CSAIL & CBMM MIT, Cambridge, MA, USA; CSAIL & CBMM MIT, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; CSAIL & CBMM MIT, Cambridge, MA, USA; CSAIL & CBMM MIT, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811928/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6822156415660458564&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Toyota Research Institute",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory & Center for Brains, Minds, and Machines;",
        "aff_unique_url": "https://www.mit.edu;https://www.tri.global",
        "aff_unique_abbr": "MIT;TRI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811657",
        "title": "Trajectory Scaling for Reactive Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory scaling has long been used to address velocity and acceleration constraints in robotic motion planning. In later years, reactive motion planning based on dynamical systems has become popular. The traditional scaling techniques are not always suitable to adopt directly when online modifications of the trajectories are made leading to feasibility problems. In this paper, we propose an approach which scales trajectories modelled as dynamical systems for improved feasibility. This is achieved by proactively scaling the trajectory as the acceleration limits are approached. Performance is illustrated by means of simulations and experiments on a UR10 robot.",
        "primary_area": "",
        "author": "Albin Dahlin;Yiannis Karayiannidis;Albin Dahlin;Yiannis Karayiannidis",
        "authorids": "/37087080787;/37300987100;/37087080787;/37300987100",
        "aff": "Department of Electrical Engineering, Chalmers University of Technology, Gothenburg, Sweden; Department of Electrical Engineering, Chalmers University of Technology, Gothenburg, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811657/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5921531997766667655&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chalmers University of Technology",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.chalmers.se",
        "aff_unique_abbr": "Chalmers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Gothenburg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9812001",
        "title": "TransGrasp: A Multi-Scale Hierarchical Point Transformer for 7-DoF Grasp Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic grasping pose detection that predicts the configuration of the robotic gripper for object grasping is fundamental in robot manipulation. Based on point clouds, most of the existing methods predict grasp pose with the hierarchical PointNet++ backbone, while the non-local geometric information is underexplored. In this work, we address the 7-DoF (6- DoF with the grasp width) grasp detection by introducing a one- stage Transformer-based hierarchical multi-scale model dubbed TransGrasp. Empowered by TransGrasp, the point features are enhanced via acquiring multi-scale shape awareness in the whole scene. By directly modeling the long-range relevance, our pipeline is aware of object contour to avoid collisions and able to apply analogy reasoning for long-distance geometric structures. The evaluation results on the large scale GraspNet- 1Billion dataset demonstrate the effectiveness of the proposed TransGrasp. The real robot experiments on an ABB YUMI robot with an Azure Kinect DK camera and an ABB Smart two-finger gripper show high success rates in both single object and cluttered scenes.",
        "primary_area": "",
        "author": "Zhixuan Liu;Zibo Chen;Shangjin Xie;Wei\u2013Shi Zheng;Zhixuan Liu;Zibo Chen;Shangjin Xie;Wei\u2013Shi Zheng",
        "authorids": "/37089449314;/37089448528;/37089447615;/37399449200;/37089449314;/37089448528;/37089447615;/37399449200",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812001/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9891599820024352026&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Sun Yat-sen University",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "http://www.sysu.edu.cn",
        "aff_unique_abbr": "SYSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811901",
        "title": "Translating Images into Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "We approach instantaneous mapping, converting images to a top-down view of the world, as a translation problem. We show how a novel form of transformer network can be used to map from images and video directly to an overhead map or bird's-eye-view (BEV) of the world, in a single end-to-end network. We assume a 1\u20131 correspondence between a vertical scanline in the image, and rays passing through the camera location in an overhead map. This lets us formulate map generation from an image as a set of sequence-to-sequence translations. Posing the problem as translation allows the network to use the context of the image when interpreting the role of each pixel. This constrained formulation, based upon a strong physical grounding of the problem, leads to a restricted transformer network that is convolutional in the horizontal direction only. The structure allows us to make efficient use of data when training, and obtains state-of-the-art results for instantaneous mapping of three large-scale datasets, including a 15% and 30% relative gain against existing best performing methods on the nuScenes and Argoverse datasets, respectively.",
        "primary_area": "",
        "author": "Avishkar Saha;Oscar Mendez;Chris Russell;Richard Bowden;Avishkar Saha;Oscar Mendez;Chris Russell;Richard Bowden",
        "authorids": "/37089002033;/37710939600;/37089653118;/37268872100;/37089002033;/37710939600;/37089653118;/37268872100",
        "aff": "Centre for Vision Speech and Signal Processing, University of Surrey, Guildford, UK; Centre for Vision Speech and Signal Processing, University of Surrey, Guildford, UK; Amazon, Tubingen, Germany; Centre for Vision Speech and Signal Processing, University of Surrey, Guildford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811901/",
        "gs_citation": 174,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16618165251908109074&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Surrey;Amazon",
        "aff_unique_dep": "Centre for Vision Speech and Signal Processing;Amazon",
        "aff_unique_url": "https://www.surrey.ac.uk;https://www.amazon.de",
        "aff_unique_abbr": "Surrey;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Guildford;Tubingen",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "9811750",
        "title": "Translation Invariant Global Estimation of Heading Angle Using Sinogram of LiDAR Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "Global point cloud registration is an essential module for localization, of which the main difficulty exists in estimating the rotation globally without initial value. With the aid of gravity alignment, the degree of freedom in point cloud registration could be reduced to 4DoF, in which only the heading angle is required for rotation estimation. In this paper, we propose a fast and accurate global heading angle estimation method for gravity-aligned point clouds. Our key idea is that we generate a translation invariant representation based on Radon Transform, allowing us to solve the decoupled heading angle globally with circular cross-correlation. Besides, for heading angle estimation between point clouds with different distributions, we implement this heading angle estimator as a differentiable module to train a feature extraction network end-to-end. The experimental results validate the effectiveness of the proposed method in heading angle estimation and show better performance compared with other methods.",
        "primary_area": "",
        "author": "Xiaqing Ding;Xuecheng Xu;Sha Lu;Yanmei Jiao;Mengwen Tan;Rong Xiong;Huanjun Deng;Mingyang Li;Yue Wang;Xiaqing Ding;Xuecheng Xu;Sha Lu;Yanmei Jiao;Mengwen Tan;Rong Xiong;Huanjun Deng;Mingyang Li;Yue Wang",
        "authorids": "/37086331151;/37087245452;/37089449878;/37086475262;/37089447267;/37271511300;/37088996595;/37086936897;/37072299700;/37086331151;/37087245452;/37089449878;/37086475262;/37089447267;/37271511300;/37088996595;/37086936897;/37072299700",
        "aff": "Alibaba Group, Hangzhou, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Alibaba Group, Hangzhou, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811750/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14444169195484351251&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;0;1;0;0;1",
        "aff_unique_norm": "Alibaba Group;Zhejiang University",
        "aff_unique_dep": ";State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control",
        "aff_unique_url": "https://www.alibaba.com;http://www.zju.edu.cn",
        "aff_unique_abbr": "Alibaba;ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811591",
        "title": "TridentNetV2: Lightweight Graphical Global Plan Representations for Dynamic Trajectory Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a framework for dynamic trajectory generation for autonomous navigation, which does not rely on HD maps as the underlying representation. High Definition (HD) maps have become a key component in most autonomous driving frameworks, which include complete road network information annotated at a centimeter-level that include traversable waypoints, lane information, and traffic signals. Instead, the presented approach models the distributions of feasible ego-centric trajectories in real-time given a nominal graph-based global plan and a lightweight scene representation. By embedding contextual information, such as crosswalks, stop signs, and traffic signals, our approach achieves low errors across multiple urban navigation datasets that include diverse intersection maneuvers, while maintaining real-time performance and reducing network complexity. Underlying datasets introduced are available online.",
        "primary_area": "",
        "author": "David Paz;Hao Xiang;Andrew Liang;Henrik I. Christensen;David Paz;Hao Xiang;Andrew Liang;Henrik I. Christensen",
        "authorids": "/37088688508;/37089006777;/37088643537;/37281307400;/37088688508;/37089006777;/37088643537;/37281307400",
        "aff": "Contextual Robotics Institute, University of California San Diego, La Jolla, CA, USA; Contextual Robotics Institute, University of California San Diego, La Jolla, CA, USA; Contextual Robotics Institute, University of California San Diego, La Jolla, CA, USA; Contextual Robotics Institute, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811591/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14781476715217206949&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Contextual Robotics Institute",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812295",
        "title": "TrussBot: Modeling, Design, and Control of a Compliant, Helical Truss of Tetrahedral Modules",
        "track": "main",
        "status": "Poster",
        "abstract": "Modular and truss robots offer the potential of high reconfigurability and great functional flexibility, but common implementations relying on rigid components often lead to highly complex actuation and control requirements. This paper introduces a new type of modular, compliant robot: TrussBot. TrussBot is composed of 3D-printed tetrahedral modules connected at the corners with compliant joints. We propose a truss geometry, analyze its deformation modes, and provide a simulation framework for predicting its behavior under applied loads and actuation. The TrussBot is geometrically constrained, thus requiring compliant joints to move. The TrussBot can be actuated through a network of tendons which pinch vertices together and apply a twisting motion due to the structure's connectivity. The truss was demonstrated in a physical prototype and compared to simulation results.",
        "primary_area": "",
        "author": "Yuhong Qin;Linda Ting;Celestina Saven;Yumika Amemiya;Michael Tanis;Randall D. Kamien;Cynthia Sung;Yuhong Qin;Linda Ting;Celestina Saven;Yumika Amemiya;Michael Tanis;Randall D. Kamien;Cynthia Sung",
        "authorids": "/37089447778;/37089447720;/37089447915;/37089450278;/37089450301;/37089450876;/37086639646;/37089447778;/37089447720;/37089447915;/37089450278;/37089450301;/37089450876;/37086639646",
        "aff": "General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania, Philadelphia, PA, USA; General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania, Philadelphia, PA, USA; General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania, Philadelphia, PA, USA; General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania, Philadelphia, PA, USA; Department of Physics and Astronomy, University of Pennsylvania; Department of Physics and Astronomy, University of Pennsylvania; Department of Physics and Astronomy, University of Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812295/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5915865705333222529&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "General Robotics, Automation, Sensing & Perception (GRASP) Lab",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812374",
        "title": "UFO Depth: Unsupervised learning with flow-based odometry optimization for metric depth estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an efficient method for unsupervised learning of metric depth estimation from a single image in the context of unconstrained videos captured from UAVs. We combine the accuracy of an analytical solution based on odometry with the power of deep learning. First, we show how to correct the noisy odometric measurements by optimizing the alignment between the derotated optical flow and the projected linear speed in the image. Then, we detail an analytical depth estimation method based on optical flow and corrected camera velocities. Subsequently, the improved depth and camera veloc-ities obtained analytically are used, as additional cost terms, for training our novel unsupervised learning architecture for metric depth estimation. We extensively test on a recent UAV dataset, which we significantly extend by adding completely novel scenes. We outperform by significant margins different kinds of state-of-the-art approaches, ranging from analytical and unsupervised solutions to transformer-based architectures that require heavy computation and pre-training. The resulting algorithm could be deployed on embedded devices, being a good candidate for practical robotics use cases, such as obstacle avoidance and safe landing for UAV s.",
        "primary_area": "",
        "author": "Vlad Lic\u0103ret;Victor Robu;Alina Marcu;Drago\u015f Costea;Emil Slu\u015fanschi;Rahul Sukthankar;Marius Leordeanu;Vlad Lic\u0103ret;Victor Robu;Alina Marcu;Drago\u015f Costea;Emil Slu\u015fanschi;Rahul Sukthankar;Marius Leordeanu",
        "authorids": "/37088951392;/37088952415;/37085614342;/37086334024;/37598756500;/37282878500;/37281853500;/37088951392;/37088952415;/37085614342;/37086334024;/37598756500;/37282878500;/37281853500",
        "aff": "University Politehnica of Bucharest, Bucharest; Institute of Mathematics of the Romanian Academy, Bucharest; Institute of Mathematics of the Romanian Academy, Bucharest; Institute of Mathematics of the Romanian Academy, Bucharest; University Politehnica of Bucharest, Bucharest; Google Research, Mountain View, CA, USA; Institute of Mathematics of the Romanian Academy, Bucharest",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812374/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15664272774822496786&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;0;2;1",
        "aff_unique_norm": "University Politehnica of Bucharest;Romanian Academy;Google",
        "aff_unique_dep": ";Institute of Mathematics;Google Research",
        "aff_unique_url": "https://www.upb.ro;https://www.math.ro;https://research.google",
        "aff_unique_abbr": "UPB;IMAR;Google",
        "aff_campus_unique_index": "0;0;0;0;0;1;0",
        "aff_campus_unique": "Bucharest;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;1;0",
        "aff_country_unique": "Romania;United States"
    },
    {
        "id": "9811811",
        "title": "UnDAF: A General Unsupervised Domain Adaptation Framework for Disparity or Optical Flow Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Disparity and optical flow estimation are respectively 1D and 2D dense correspondence matching (DCM) tasks in nature. Unsupervised domain adaptation (UDA) is crucial for their success in new and unseen scenarios, enabling networks to draw inferences across different domains without manually-labeled ground truth. In this paper, we propose a general UDA framework (UnDAF) for disparity or optical flow estimation. Unlike existing approaches based on adversarial learning that suffers from pixel distortion and dense correspondence mismatch after domain alignment, our UnDAF adopts a straightforward but effective coarse-to-fine strategy, where a co-teaching strategy (two networks evolve by complementing each other) refines DCM estimations after Fourier transform initializes domain alignment. The simplicity of our approach makes it extremely easy to guide adaptation across different domains, or more practically, from synthetic to real-world domains. Extensive experiments carried out on the KITTI and MPI Sintel benchmarks demonstrate the accuracy and robustness of our UnDAF, advancing all other state-of-the-art UDA approaches for disparity or optical flow estimation. Our project page is available at https://sites.google.com/view/undaf.",
        "primary_area": "",
        "author": "Hengli Wang;Rui Fan;Peide Cai;Ming Liu;Lujia Wang;Hengli Wang;Rui Fan;Peide Cai;Ming Liu;Lujia Wang",
        "authorids": "/37086939511;/37085892666;/37087104388;/37085398677;/37406752700;/37086939511;/37085892666;/37087104388;/37085398677;/37406752700",
        "aff": "Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong SAR, China; Department of Control Science and Engineering, College of Electronics and Information Engineering, Tongji University, Shanghai, P. R. China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811811/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13251844873478704386&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Tongji University",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;Department of Control Science and Engineering",
        "aff_unique_url": "https://www.ust.hk;https://www.tongji.edu.cn",
        "aff_unique_abbr": "HKUST;Tongji",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Clear Water Bay;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812222",
        "title": "Uncertainty from Motion for DNN Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deployment of deep neural networks (DNNs) for monocular depth estimation in safety-critical scenarios on resource-constrained platforms requires well-calibrated and efficient uncertainty estimates. However, many popular uncertainty estimation techniques, including state-of-the-art ensembles and popular sampling-based methods, require multiple inferences per input, making them difficult to deploy in latency-constrained or energy-constrained scenarios. We propose a new algorithm, called Uncertainty from Motion (UfM), that requires only one inference per input. UfM exploits the temporal redundancy in video inputs by merging incrementally the per-pixel depth prediction and per-pixel aleatoric uncertainty prediction of points that are seen in multiple views in the video sequence. When UfM is applied to ensembles, we show that UfM can retain the uncertainty quality of ensembles at a fraction of the energy by running only a single ensemble member at each frame and fusing the uncertainty over the sequence of frames. In a set of representative experiments using FCDenseNet and eight indistribution and out-of-distribution video sequences, UfM offers comparable uncertainty quality to an ensemble of size 10 while consuming only 11.3% of the ensemble's energy and running 6.4\u00d7 faster on a single Nvidia RTX 2080 Ti GPU, enabling near ensemble uncertainty quality for resource-constrained, real-time scenarios.",
        "primary_area": "",
        "author": "Soumya Sudhakar;Vivienne Sze;Sertac Karaman;Soumya Sudhakar;Vivienne Sze;Sertac Karaman",
        "authorids": "/37088504818;/37394718900;/37304113000;/37088504818;/37394718900;/37304113000",
        "aff": "Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812222/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3827990685732255584&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811599",
        "title": "Uncertainty-based Exploring Strategy in Densely Cluttered Scenes for Vacuum Cup Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping a wide range of novel objects in densely cluttered scenes is difficult due to irregular shapes of objects and the uncertainty in sensing. In this paper, a novel vacuum cup grasping method, based on uncertainty modeling of perception data and grasp geometric heuristics, is proposed to grasp unknown objects in densely cluttered scenes. The probabilistic signed distance function is proposed to both reconstruct the point cloud of a scene and explicitly model the uncertainty from depth images captured from a low-cost stereo camera. The quasi-static spring model is used to approximate seal formation between the suction cup and the reconstructed point cloud. A coarse-to-fine exploration procedure is proposed to refine the estimated point cloud, reduce uncertainties during the movement of the robot and redetermine the target grasp pose iteratively. Extensive experiments show that our proposed method achieves state-of-the-art performance on real-world grasping and outperforms existing methods by a large margin.",
        "primary_area": "",
        "author": "Kimwa Tung;Jingcheng Su;Junhao Cai;Zhaoliang Wan;Hui Cheng;Kimwa Tung;Jingcheng Su;Junhao Cai;Zhaoliang Wan;Hui Cheng",
        "authorids": "/37089447077;/37086936546;/37086455338;/37089449082;/38008557800;/37089447077;/37086936546;/37086455338;/37089449082;/38008557800",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811599/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6762564082149070225&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Sun Yat-sen University",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "http://www.sysu.edu.cn",
        "aff_unique_abbr": "SYSU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812423",
        "title": "Uncertainty-driven Planner for Exploration and Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problems of exploration and pointgoal navigation in previously unseen environments, where the spatial complexity of indoor scenes and partial observability constitute these tasks challenging. We argue that learning occupancy priors over indoor maps provides significant advantages towards addressing these problems. To this end, we present a novel planning framework that first learns to generate occupancy maps beyond the field-of-view of the agent, and second leverages the model uncertainty over the generated areas to formulate path selection policies for each task of interest. For pointgoal navigation the policy chooses paths with an upper confidence bound policy for efficient and traversable paths, while for exploration the policy maximizes model uncertainty over candidate paths. We perform experiments in the visually realistic environments of Matterport3D using the Habitat simulator and demonstrate: 1) Improved results on exploration and map quality metrics over competitive methods, and 2) The effectiveness of our planning module when paired with the state-of-the-art DD-PPO method for the point-goal navigation task.",
        "primary_area": "",
        "author": "Georgios Georgakis;Bernadette Bucher;Anton Arapin;Karl Schmeckpeper;Nikolai Matni;Kostas Daniilidis;Georgios Georgakis;Bernadette Bucher;Anton Arapin;Karl Schmeckpeper;Nikolai Matni;Kostas Daniilidis",
        "authorids": "/37086062117;/37089194773;/37089450991;/37086802970;/37398611500;/37270623200;/37086062117;/37089194773;/37089450991;/37086802970;/37398611500;/37270623200",
        "aff": "Department of Computer and Information Science, GRASP Laboratory, University of Pennsylvania, Philadelphia, PA; Department of Computer and Information Science, GRASP Laboratory, University of Pennsylvania, Philadelphia, PA; Department of Computer Science, The University of Chicago, Chicago, IL, 60637; Department of Computer and Information Science, GRASP Laboratory, University of Pennsylvania, Philadelphia, PA; Department of Computer and Information Science, GRASP Laboratory, University of Pennsylvania, Philadelphia, PA; Department of Computer and Information Science, GRASP Laboratory, University of Pennsylvania, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812423/",
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11320224534736298648&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "University of Pennsylvania;University of Chicago",
        "aff_unique_dep": "Department of Computer and Information Science;Department of Computer Science",
        "aff_unique_url": "https://www.upenn.edu;https://www.uchicago.edu",
        "aff_unique_abbr": "UPenn;UChicago",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Philadelphia;Chicago",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812349",
        "title": "Understanding Xacro Misunderstandings",
        "track": "main",
        "status": "Poster",
        "abstract": "The Xacro XML macro language can be used to augment the Universal Robot Description Format (URDF) and is part of a critical toolchain from geometric representations to simulation, visualization, and system execution. However, mem-bers of the robotics community, especially newcomers, struggle to troubleshoot and understand the interplay between systems and the Xacro preprocessing pipeline. To better understand how system developers struggle with Xacros, we manually examine 712 Xacro-related questions from the question and answer site answers.ros.org and find Xacro misunderstandings fit into eight key categories using a systematic, qualitative approach called Open Coding. By examining the 'tags' applied to questions, we further find that Xacro problems manifest in a befuddlingly broad set of contexts. This hinders onboarding and complicates system developers' understanding of representations and tools in the Robot Operating System. We aim to provide an empirical grounding that identifies and prioritizes impediments to users of open robotics systems, so that tool designers, teachers, and robotics practitioners can devise ways of improving robot software tooling and education.",
        "primary_area": "",
        "author": "Nicholas Albergo;Vivek Rathi;John-Paul Ore;Nicholas Albergo;Vivek Rathi;John-Paul Ore",
        "authorids": "/37089449311;/37089447674;/37085490765;/37089449311;/37089447674;/37085490765",
        "aff": "Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Electrical and Computer Engineering Department, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812349/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17002577021318018063&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "North Carolina State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ncsu.edu",
        "aff_unique_abbr": "NCSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Raleigh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812143",
        "title": "Underwater Dock Detection through Convolutional Neural Networks Trained with Artificial Image Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous Underwater Vehicles (AUVs) are a vital element for ocean exploration in various applications; however, energy sustainability still limits long-term operations. An option to overcome this problem is using underwater docking for power and data transfer. To robustly guide an AUV into a docking station, we propose an underwater vision algorithm for short-distance detection. In this paper, we present a Convolutional Neural Network architecture to accurately estimate the dock position during the terminal homing stage of the docking. Additionally, to alleviate the lack of available underwater datasets, two methods are proposed to generate synthetic datasets, one using a CycleGAN network, and another using Artistic Style transfer network. Both methods are used to train the same CNN architecture to compare the results. Finally, implementation details of the CNN are presented under the backseat architecture and ROS framework, running on an IVER3 AUV.",
        "primary_area": "",
        "author": "Jalil Chavez-Galaviz;Nina Mahmoudian;Jalil Chavez-Galaviz;Nina Mahmoudian",
        "authorids": "/37085612426;/37401735600;/37085612426;/37401735600",
        "aff": "School of Mechanical Engineering, Purdue University, West Lafayette, IN, USA; School of Mechanical Engineering, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812143/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18148490720307064888&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811772",
        "title": "Unfreezing Social Navigation: Dynamical Systems based Compliance for Contact Control in Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Large efforts have focused on ensuring that the controllers for mobile service robots follow proxemics and other social rules to ensure both safe and socially acceptable distance to pedestrians. Nonetheless, involuntary contact may be unavoidable when the robot travels in crowded areas or when encountering adversarial pedestrians. Freezing the robot in response to contact might be detrimental to bystanders' safety and prevents it from achieving its task. Unavoidable contacts must hence be controlled to ensure the safe and smooth travelling of robots in pedestrian alleys. We present a force-limited and obstacle avoidance controller integrated into a time-invariant dynamical system (DS) in a closed-loop force controller that let the robot react instantaneously to contact or to the sudden appearance of pedestrians. Mitigating the risk of collision is done by modulating the velocity commands upon detecting a contact and by absorbing part of the contact force through active compliant control when the robot bumps inad-vertently against a pedestrian. We evaluated our method with a personal mobility robot -Qolo- showing contact mitigation with passive and active compliance. We showed the robot able to overcome an adversarial pedestrian within 9 N of the set limit contact force for speeds under 1 m/s. Moreover, we evaluated integrated obstacle avoidance proving the ability to advance without Incurring any other collision.",
        "primary_area": "",
        "author": "Diego Paez-Granados;Vaibhav Gupta;Aude Billard;Diego Paez-Granados;Vaibhav Gupta;Aude Billard",
        "authorids": "/37085669907;/37089447395;/37273980800;/37085669907;/37089447395;/37273980800",
        "aff": "LASA, EPFL, SCAI Lab at SPZ, ETH Zurich, Switzerland; Learning Algorithms and Systems Laboratory (LASA), Swiss Federal School of Technology in Lausanne - EPFL, Switzerland; Learning Algorithms and Systems Laboratory (LASA), Swiss Federal School of Technology in Lausanne - EPFL, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811772/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2364224435444056473&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Ecole Polytechnique Federale de Lausanne (EPFL);Swiss Federal Institute of Technology in Lausanne (EPFL)",
        "aff_unique_dep": "LASA;Learning Algorithms and Systems Laboratory (LASA)",
        "aff_unique_url": "https://www.epfl.ch;https://www.epfl.ch",
        "aff_unique_abbr": "EPFL;EPFL",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Lausanne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9811629",
        "title": "Unified Data Collection for Visual-Inertial Calibration via Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual-inertial sensors have a wide range of applications in robotics. However, good performance often requires different sophisticated motion routines to accurately calibrate camera intrinsics and inter-sensor extrinsics. This work presents a novel formulation to learn a motion policy to be executed on a robot arm for automatic data collection for calibrating intrinsics and extrinsics jointly. Our approach models the calibration process compactly using model-free deep reinforcement learning to derive a policy that guides the motions of a robotic arm holding the sensor to efficiently collect measurements that can be used for both camera intrinsic calibration and camera-IMU extrinsic calibration. Given the current pose and collected measurements, the learned policy generates the subsequent transformation that optimizes sensor calibration accuracy. The evaluations in simulation and on a real robotic system show that our learned policy generates favorable motion trajectories and collects enough measurements efficiently that yield the desired intrinsics and extrinsics with short path lengths. In simulation, we are able to perform calibrations 10\u00d7 faster than hand-crafted policies, which transfers to a real-world speed up of 3\u00d7 over a human expert. The code of this work is publicly available at: https://github.com/ethz-asl/Learn-to-Calibrate.",
        "primary_area": "",
        "author": "Yunke Ao;Le Chen;Florian Tschopp;Michel Breyer;Roland Siegwart;Andrei Cramariuc;Yunke Ao;Le Chen;Florian Tschopp;Michel Breyer;Roland Siegwart;Andrei Cramariuc",
        "authorids": "/37089450031;/37089447547;/37086688697;/37086692289;/37281398300;/37085840497;/37089450031;/37089447547;/37086688697;/37086692289;/37281398300;/37085840497",
        "aff": "Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland; Arrival Ltd, United Kingdom; Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811629/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2812842670743780154&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "ETH Zurich;Arrival Ltd",
        "aff_unique_dep": "Autonomous Systems Lab;",
        "aff_unique_url": "https://www.ethz.ch;",
        "aff_unique_abbr": "ETHZ;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "Switzerland;United Kingdom"
    },
    {
        "id": "9812162",
        "title": "Unified Representation of Geometric Primitives for Graph-SLAM Optimization Using Decomposed Quadrics",
        "track": "main",
        "status": "Poster",
        "abstract": "In Simultaneous Localization And Mapping (SLAM) problems, high-level landmarks have the potential to build compact and informative maps compared to traditional point-based landmarks. In this work, we focus on the param-eterization of frequently used geometric primitives including points, lines, planes, ellipsoids, cylinders, and cones. We first present a unified representation based on quadrics, an algebraic representation of quadratic surfaces in 3D. Then we propose a decomposed model of quadrics that discloses the symmetry and degeneration properties of a primitive. Based on the decomposition, we develop geometrically meaningful quadrics factors for the graph-SLAM problem. Then in simulation, it is shown that the decomposed formulation has better efficiency and robustness to observation noises than baseline parame-terizations. Finally, in real-world experiments, the proposed back-end framework is demonstrated to be capable of building compact and regularized maps.",
        "primary_area": "",
        "author": "Weikun Zhen;Huai Yu;Yaoyu Hu;Sebastian Scherer;Weikun Zhen;Huai Yu;Yaoyu Hu;Sebastian Scherer",
        "authorids": "/37086162020;/37086223088;/37086920250;/37584159000;/37086162020;/37086223088;/37086920250;/37584159000",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812162/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1006196661728920545&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811646",
        "title": "Unseen Object Amodal Instance Segmentation via Hierarchical Occlusion Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Instance-aware segmentation of unseen objects is essential for a robotic system in an unstructured environment. Although previous works achieved encouraging results, they were limited to segmenting the only visible regions of unseen objects. For robotic manipulation in a cluttered scene, amodal perception is required to handle the occluded objects behind others. This paper addresses Unseen Object Amodal Instance Segmentation (UOAIS) to detect 1) visible masks, 2) amodal masks, and 3) occlusions on unseen object instances. For this, we propose a Hierarchical Occlusion Modeling (HOM) scheme designed to reason about the occlusion by assigning a hierarchy to a feature fusion and prediction order. We evaluated our method on three benchmarks (tabletop, indoors, and bin environments) and achieved state-of-the-art (SOTA) performance. Robot demos for picking up occluded objects, codes, and datasets are available at https://sites.google.com/view/uoais.",
        "primary_area": "",
        "author": "Seunghyeok Back;Joosoon Lee;Taewon Kim;Sangjun Noh;Raeyoung Kang;Seongho Bak;Kyoobin Lee;Seunghyeok Back;Joosoon Lee;Taewon Kim;Sangjun Noh;Raeyoung Kang;Seongho Bak;Kyoobin Lee",
        "authorids": "/37088523664;/37088923935;/37089197297;/37088524145;/37088520412;/37089213716;/37087407149;/37088523664;/37088923935;/37089197297;/37088524145;/37088520412;/37089213716;/37087407149",
        "aff": "School of Integrated Technology (SIT), Gwangju Institute of Science and Technology (GIST), Gwangju, Republic of Korea; School of Integrated Technology (SIT), Gwangju Institute of Science and Technology (GIST), Gwangju, Republic of Korea; School of Integrated Technology (SIT), Gwangju Institute of Science and Technology (GIST), Gwangju, Republic of Korea; School of Integrated Technology (SIT), Gwangju Institute of Science and Technology (GIST), Gwangju, Republic of Korea; School of Integrated Technology (SIT), Gwangju Institute of Science and Technology (GIST), Gwangju, Republic of Korea; School of Integrated Technology (SIT), Gwangju Institute of Science and Technology (GIST), Gwangju, Republic of Korea; School of Integrated Technology (SIT), Gwangju Institute of Science and Technology (GIST), Gwangju, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811646/",
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11065985554584432069&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Gwangju Institute of Science and Technology",
        "aff_unique_dep": "School of Integrated Technology",
        "aff_unique_url": "https://www.gist.ac.kr",
        "aff_unique_abbr": "GIST",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Gwangju",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9812392",
        "title": "Unsupervised Depth Completion and Denoising for RGB-D Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth information is considered valuable as it describes geometric structures, which benefits various robotic tasks. However, the depth acquired by RGB-D sensors still suffers from two deficiencies, i.e., incompletion and noises. Previous methods complete depth by exploring hand-tuned models or raising surface assumptions, while nowadays, deep approaches intend to solve this problem with rendered image pairs. For depth denoising, as a consequence of different sensor mechanisms, most methods can only work under specific devices. With existing methods, three challenges emerge: the onerous training set collecting process, the mismatch between existing models and present RGB-D sensors, and the non-real-time computation. In this paper, we first state depth completion and denoising are inherently different and without the need to collect or render complete and noiseless ground truths. We address all mentioned challenges with two separate un-supervised learning procedures. The completion network takes color and incomplete depth as input and predicts values to the unobserved area, which combines prior knowledge and color-depth correlations. The denoising step exploits image sequences to construct noise models in a self-supervised manner with the ability to cater to different sensors. Experimental comparisons and ablation studies demonstrate that even without human-labeled ground truths, the proposed method could produce better completion results and also reduce noises in real-time.",
        "primary_area": "",
        "author": "Lei Fan;Yunxuan Li;Chen Jiang;Ying Wu;Lei Fan;Yunxuan Li;Chen Jiang;Ying Wu",
        "authorids": "/37089316015;/37089450559;/37089448045;/37281224100;/37089316015;/37089450559;/37089448045;/37281224100",
        "aff": "Department of Electrical and Computer Engineering, Northwestern University, Evanston, IL; Department of Electrical and Computer Engineering, Northwestern University, Evanston, IL; Department of Electrical and Computer Engineering, Northwestern University, Evanston, IL; Department of Electrical and Computer Engineering, Northwestern University, Evanston, IL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812392/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16511825958181605994&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Northwestern University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.northwestern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Evanston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811654",
        "title": "Unsupervised Domain Adaptation in LiDAR Semantic Segmentation with Self-Supervision and Gated Adapters",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we focus on a less explored, but more realistic and complex problem of domain adaptation in LiDAR semantic segmentation. There is a significant drop in performance of an existing segmentation model when training (source domain) and testing (target domain) data originate from different LiDAR sensors. To overcome this shortcoming, we propose an unsupervised domain adaptation framework that leverages unlabeled target domain data for self-supervision, coupled with an unpaired mask transfer strategy to mitigate the impact of domain shifts. Furthermore, we introduce the gated adapter module with a small number of parameters into the network to account for target domain-specific information. Experiments adapting from both real-to-real and synthetic-to-real LiDAR semantic segmentation benchmarks demonstrate the significant improvement over prior arts.",
        "primary_area": "",
        "author": "Mrigank Rochan;Shubhra Aich;Eduardo R. Corral-Soto;Amir Nabatchian;Bingbing Liu;Mrigank Rochan;Shubhra Aich;Eduardo R. Corral-Soto;Amir Nabatchian;Bingbing Liu",
        "authorids": "/37855882200;/37085387003;/38305749200;/38272684200;/38572992400;/37855882200;/37085387003;/38305749200;/38272684200;/38572992400",
        "aff": "Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab; Huawei Noah's Ark Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811654/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12098634549862112629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Noah's Ark Lab",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9812296",
        "title": "Unsupervised Learning of Terrain Representations for Haptic Monte Carlo Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Haptic sensing has recently been used effectively for legged robot localization in extreme scenarios where cam-eras and LiDAR might fail, such as dusty mines and foggy sewers. However, existing haptic sensing mainly relies on supervised classification, with training and evaluation executed over explicit terrain classes. Defining classes is a significant limitation to real-world applications, where prior labelling and handcrafted classes are often impractical. This paper proposes a novel haptic localization system based on a fully unsupervised terrain representation learned solely from the force/torque sensors located in the quadruped robot's feet. Instead of using the detected terrain class for localization, we propose an improved autoencoder architecture to generate a sparse map of encodings on the first run and to localize against this sparse map during subsequent runs. We compare our approach to a haptic localization system based on supervised terrain classification, showing that the unsupervised method has comparable or better performance than the supervised one for the same trajectories while clearly outperforming the proprioceptive odometry estimator available on the robot. Therefore, the proposed approach is well-suited for a routine maintenance application, increasing the platform's robustness.",
        "primary_area": "",
        "author": "Miko\u0142aj \u0141ysakowski;Micha\u0142 R. Nowicki;Russell Buchanan;Marco Camurri;Maurice Fallon;Krzysztof Walas;Miko\u0142aj \u0141ysakowski;Micha\u0142 R. Nowicki;Russell Buchanan;Marco Camurri;Maurice Fallon;Krzysztof Walas",
        "authorids": "/37089232836;/37085439474;/37086700722;/37085638130;/37540365100;/37688621800;/37089232836;/37085439474;/37086700722;/37085638130;/37540365100;/37688621800",
        "aff": "Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland; Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poznan, Poland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812296/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4071387279895075775&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "Poznan University of Technology;University of Oxford",
        "aff_unique_dep": "Institute of Robotics and Machine Intelligence;Oxford Robotics Institute",
        "aff_unique_url": "https://www.put.poznan.pl/;https://www.ox.ac.uk",
        "aff_unique_abbr": "PUT;Oxford",
        "aff_campus_unique_index": "0;0;1;1;1;0",
        "aff_campus_unique": "Poznan;Oxford",
        "aff_country_unique_index": "0;0;1;1;1;0",
        "aff_country_unique": "Poland;United Kingdom"
    },
    {
        "id": "9811824",
        "title": "Using Arm Swing Movements to Maintain the Walking State in a Self-Balanced Lower-Limb Exoskeleton",
        "track": "main",
        "status": "Poster",
        "abstract": "This work investigates how arm swing movements measured by Inertial Motion Unit (IMU) sensors can be used to identify and maintain the walking state in a self-balanced lower-limb exoskeleton for medical use. When an exoskeleton is in a dynamical state during gait, short patterns in IMU signals (e.g. a braking movement) can be hard to extract. Therefore, by relying on a threshold-based classifier constructed upon descriptive features of actively maintained arm swing movements, it is possible to build a gait termination detection method in which the transition between the walking and standstill states occurs whenever arm movements cease, and the corresponding patterns in the IMU signals disappear. Analysis of arm IMU signals were used to identify three amplitude and coordination-based features for the classification architecture. An online implementation of this novel detection interface for maintaining the walking state was validated with 11 unimpaired participants using the Atalante exoskeleton, leading to high accuracy with less than 2% of false negatives when the arms were swinging at a high amplitude, and less than 15% when they were swinging at a medium amplitude.",
        "primary_area": "",
        "author": "Omar Mounir Alaoui;Fabien Expert;Guillaume Morel;Nathana\u00ebl Jarrass\u00e9;Omar Mounir Alaoui;Fabien Expert;Guillaume Morel;Nathana\u00ebl Jarrass\u00e9",
        "authorids": "/37089449282;/37089656114;/37274022000;/38324251300;/37089449282;/37089656114;/37274022000;/38324251300",
        "aff": "Institute of Intelligent Systems and Robotics, Sorbonne Universit\u00e9, Paris, France; Institute of Intelligent Systems and Robotics, Sorbonne Universit\u00e9, Paris, France; Institute of Intelligent Systems and Robotics, Sorbonne Universit\u00e9, Paris, France; Wandercraft, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811824/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3897756247670422128&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Sorbonne Universit\u00e9;Wandercraft",
        "aff_unique_dep": "Institute of Intelligent Systems and Robotics;",
        "aff_unique_url": "https://www.sorbonne-universite.fr;",
        "aff_unique_abbr": "Sorbonne U;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Paris;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9812079",
        "title": "Using Eye Gaze to Forecast Human Pose in Everyday Pick and Place Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robots that operate alongside humans require the ability to understand their intent and forecast their pose. Among the various indicators of intent, the eye gaze is particularly important as it signals action towards the gazed object. By observing a person's gaze, one can effectively predict the object of interest and subsequently, forecast the person's pose. We leverage this and present a method that forecasts the human pose using gaze information for everyday pick and place actions in a home environment. Our method first attends to fixations to locate the coordinates of the object of interest before inputting said coordinates to a pose forecasting network. Experiments on the MoGaze dataset show that our gaze network lowers the errors of existing pose forecasting methods and that incorporating prior in the form of textual instructions further lowers the errors by a significant amount. Furthermore, the use of eye gaze now allows a simple multilayer perceptron network to directly forecast the keypose.aaCode available at www.imperial.ac.uk/personal-robotics/software",
        "primary_area": "",
        "author": "Haziq Razali;Yiannis Demiris;Haziq Razali;Yiannis Demiris",
        "authorids": "/37086341171;/37296338900;/37086341171;/37296338900",
        "aff": "Dept of EEE, Personal Robotics Laboratory, Imperial College London, UK; Dept of EEE, Personal Robotics Laboratory, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812079/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8876413009926099211&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dept of EEE",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9812355",
        "title": "Using Language to Generate State Abstractions for Long-Range Planning in Outdoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots that process navigation instructions in large outdoor environments will need to operate at different levels of abstraction. For example, a land-surveying aerial robot receiving the instruction \u201cgo to Boston and go through the state forest on the way\u201d must reason about a long-range goal like \u201cgo to Boston\u201d while also processing a finer-grained constraint like \u201cgo through the state forest.\u201d Existing approaches struggle to plan such commands because of the immense number of locations and constraints that can be expressed in language. We introduce a hierarchical representation of outdoor environments and a planning approach that dynamically compacts the robot's state space to enable tractable planning in city and state-scale environments. Our approach leverages natural abstractions in real-world map data, coupled with abstractions generated from users' instructions, to generate filtered environment views that accelerate planning while supporting a robot's ability to obey complex temporal goals and constraints at different levels of abstraction. We evaluate our approach on seven templates of LTLJ formulas and in an 80 kilometer-radius environment containing over 250,000 locations downloaded from OpenStreetMap. The results show our approach enables planning in seconds or minutes in a large outdoor environment while still satisfying the task specification.",
        "primary_area": "",
        "author": "Matthew Berg;George Konidaris;Stefanie Tellex;Matthew Berg;George Konidaris;Stefanie Tellex",
        "authorids": "/37088507597;/38318614200;/37402794800;/37088507597;/38318614200;/37402794800",
        "aff": "Brown University, Providence, RI, USA; Brown University, Providence, RI, USA; Brown University, Providence, RI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812355/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5739959708761229052&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Providence",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811905",
        "title": "Using Monocular Vision and Human Body Priors for AUVs to Autonomously Approach Divers",
        "track": "main",
        "status": "Poster",
        "abstract": "Direct communication between humans and autonomous underwater vehicles (AUVs) is a relatively under-explored area in human-robot interaction research, although many tasks (e.g., surveillance, inspection, and search-and-rescue) require close diver-robot collaboration. Suboptimal AUV positioning relative to its human collaborators can lead to poor quality interaction and lead to excessive cognitive and physical load for divers. In this paper, we introduce a novel method for AUVs to autonomously navigate and achieve diver-relative positioning to begin interaction. Our method is based only on monocular vision, requires no global localization, and is computationally efficient. We present our algorithm and its implementation on board a physical AUV, performing extensive evaluations in the form of closed-water tests in a controlled pool. Our results show that the proposed monocular vision-based algorithm performs reliably and efficiently, operating entirely on-board the AUV.",
        "primary_area": "",
        "author": "Michael Fulton;Jungseok Hong;Junaed Sattar;Michael Fulton;Jungseok Hong;Junaed Sattar",
        "authorids": "/37086541498;/37088505608;/37546394500;/37086541498;/37088505608;/37546394500",
        "aff": "Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811905/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4280019508634234735&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota Twin Cities",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812354",
        "title": "VIP-SLAM: An Efficient Tightly-Coupled RGB-D Visual Inertial Planar SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a tightly-coupled SLAM system fused with RGB, Depth, IMU and structured plane information. Traditional sparse points based SLAM systems always maintain a mass of map points to model the environment. Huge number of map points bring us a high computational complexity, making it difficult to be deployed on mobile devices. On the other hand, planes are common structures in man-made environment especially in indoor environments. We usually can use a small number of planes to represent a large scene. So the main purpose of this article is to decrease the high complexity of sparse points based SLAM. We build a lightweight back-end map which consists of a few planes and map points to achieve efficient bundle adjustment (BA) with an equal or better accuracy. We use homography constraints to eliminate the parameters of numerous plane points in the optimization and reduce the complexity of BA. We separate the parameters and measurements in homography and point-to-plane constraints and compress the measurements part to further effectively im-prove the speed of BA. We also integrate the plane information into the whole system to realize robust planar feature extraction, data association, and global consistent planar reconstruction. Finally, we perform an ablation study and compare our method with similar methods in simulation and real environment data. Our system achieves obvious advantages in accuracy and efficiency. Even if the plane parameters are involved in the optimization, we effectively simplify the back-end map by using planar structures. The global bundle adjustment is nearly 2 times faster than the sparse points based SLAM algorithm.",
        "primary_area": "",
        "author": "Danpeng Chen;Shuai Wang;Weijian Xie;Shangjin Zhai;Nan Wang;Hujun Bao;Guofeng Zhang;Danpeng Chen;Shuai Wang;Weijian Xie;Shangjin Zhai;Nan Wang;Hujun Bao;Guofeng Zhang",
        "authorids": "/37089006316;/37089450155;/37086173334;/37089354164;/37089016712;/37271755400;/37405938800;/37089006316;/37089450155;/37086173334;/37089354164;/37089016712;/37271755400;/37405938800",
        "aff": "Tetras. AI; Tetras. AI; SenseTime Research; SenseTime Research; Tetras. AI; State Key Lab of CAD&CG, Zhejiang University; State Key Lab of CAD&CG, Zhejiang University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812354/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3446126438898038985&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;0;2;2",
        "aff_unique_norm": "Tetras AI;SenseTime;Zhejiang University",
        "aff_unique_dep": ";SenseTime Research;State Key Lab of CAD&CG",
        "aff_unique_url": ";https://www.sensetime.com;http://www.zju.edu.cn",
        "aff_unique_abbr": ";SenseTime;ZJU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "1;1;1;1",
        "aff_country_unique": ";China"
    },
    {
        "id": "9812097",
        "title": "VIRDO: Visio-tactile Implicit Representations of Deformable Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Deformable object manipulation requires computationally efficient representations that are compatible with robotic sensing modalities. In this paper, we present VIRDO: an implicit, multi-modal, and continuous representation for deformable-elastic objects. VIRDO operates directly on visual (point cloud) and tactile (reaction forces) modalities and learns rich latent embeddings of contact locations and forces to predict object deformations subject to external contacts. Here, we demonstrate VIRDOs ability to: i) produce high-fidelity cross-modal reconstructions with dense unsupervised correspondences, ii) generalize to unseen contact formations, and iii) state-estimation with partial visio-tactile feedback. https://github.com/MMintLab/VIRDO",
        "primary_area": "",
        "author": "Youngsun Wi;Pete Florence;Andy Zeng;Nima Fazeli;Youngsun Wi;Pete Florence;Andy Zeng;Nima Fazeli",
        "authorids": "/37089447983;/37085786926;/37086217185;/37072790600;/37089447983;/37085786926;/37086217185;/37072790600",
        "aff": "Robotics Department, University of Michigan, MI, USA; Robotics, Google, Mountain View, CA, USA; Robotics, Google, Mountain View, CA, USA; Robotics Department, University of Michigan, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812097/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9085517779022240196&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Michigan;Google",
        "aff_unique_dep": "Robotics Department;Robotics",
        "aff_unique_url": "https://www.umich.edu;https://www.google.com",
        "aff_unique_abbr": "UM;Google",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Ann Arbor;Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812276",
        "title": "VISTA 2.0: An Open, Data-driven Simulator for Multimodal Sensing and Policy Learning for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulation has the potential to transform the development of robust algorithms for mobile agents deployed in safety-critical scenarios. However, the poor photorealism and lack of diverse sensor modalities of existing simulation engines remain key hurdles towards realizing this potential. Here, we present VISTA\u2020\u2020Full code release for the VISTA data-driven simulation engine is available here: vista.csail.mit.edu., an open source, data-driven simulator that integrates multiple types of sensors for autonomous vehicles. Using high fidelity, real-world datasets, VISTA represents and simulates RGB cameras, 3D LiDAR, and event-based cameras, enabling the rapid generation of novel viewpoints in simulation and thereby enriching the data available for policy learning with corner cases that are difficult to capture in the physical world. Using VISTA, we demonstrate the ability to train and test perception-to-control policies across each of the sensor types and showcase the power of this approach via deployment on a full scale autonomous vehicle. The policies learned in VISTA exhibit sim-to-real transfer without modification and greater robustness than those trained exclusively on real-world data.",
        "primary_area": "",
        "author": "Alexander Amini;Tsun-Hsuan Wang;Igor Gilitschenski;Wilko Schwarting;Zhijian Liu;Song Han;Sertac Karaman;Daniela Rus;Alexander Amini;Tsun-Hsuan Wang;Igor Gilitschenski;Wilko Schwarting;Zhijian Liu;Song Han;Sertac Karaman;Daniela Rus",
        "authorids": "/37086454594;/37089287640;/38469566100;/37085590089;/37087231394;/37086460117;/37304113000;/37279652300;/37086454594;/37089287640;/38469566100;/37085590089;/37087231394;/37086460117;/37304113000;/37279652300",
        "aff": "Department of Electrical Engineering and Computer Science (EECS), Massachusetts Institute of Technology (MIT); Department of Electrical Engineering and Computer Science (EECS), Massachusetts Institute of Technology (MIT); Department of Computer Science, University of Toronto and Toyota Research Institute (TRI); Department of Electrical Engineering and Computer Science (EECS), Massachusetts Institute of Technology (MIT); Department of Electrical Engineering and Computer Science (EECS), Massachusetts Institute of Technology (MIT); Department of Electrical Engineering and Computer Science (EECS), Massachusetts Institute of Technology (MIT); Department of Electrical Engineering and Computer Science (EECS), Massachusetts Institute of Technology (MIT); Department of Electrical Engineering and Computer Science (EECS), Massachusetts Institute of Technology (MIT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812276/",
        "gs_citation": 108,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10888523405950777385&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Toronto",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;Department of Computer Science",
        "aff_unique_url": "https://web.mit.edu;https://www.utoronto.ca",
        "aff_unique_abbr": "MIT;U of T",
        "aff_campus_unique_index": "0;0;1;0;0;0;0;0",
        "aff_campus_unique": "Cambridge;Toronto",
        "aff_country_unique_index": "0;0;1;0;0;0;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9812316",
        "title": "VOILA: Visual-Observation-Only Imitation Learning for Autonomous Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "While imitation learning for vision-based au-tonomous mobile robot navigation has recently received a great deal of attention in the research community, existing approaches typically require state-action demonstrations that were gathered using the deployment platform. However, what if one cannot easily outfit their platform to record these demonstration signals or-worse yet-the demonstrator does not have access to the platform at all? Is imitation learning for vision-based autonomous navigation even possible in such scenarios? In this work, we hypothesize that the answer is yes and that recent ideas from the Imitation from Observation (IfO) literature can be brought to bear such that a robot can learn to navigate using only ego-centric video collected by a demonstrator, even in the presence of viewpoint mismatch. To this end, we introduce a new algorithm, Visual-Observation-only Imitation Learning for Autonomous navigation (VOILA), that can successfully learn navigation policies from a single video demonstration collected from a physically different agent. We evaluate VOILA in the AirSim simulator and show that VOILA not only successfully imitates the expert, but that it also learns navigation policies that can generalize to novel environments. Further, we demonstrate the effectiveness of VOILA in a real-world setting by showing that it allows a wheeled Jackal robot to successfully imitate a human walking in an environment while recording video with a handheld mobile phone camera.",
        "primary_area": "",
        "author": "Haresh Karnan;Garrett Warnell;Xuesu Xiao;Peter Stone;Haresh Karnan;Garrett Warnell;Xuesu Xiao;Peter Stone",
        "authorids": "/37086310655;/37079072000;/37086258082;/37269574900;/37086310655;/37079072000;/37086258082;/37269574900",
        "aff": "Department of Mechanical Engineering, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Sony AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812316/",
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=779096308847187822&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Texas at Austin;Sony",
        "aff_unique_dep": "Department of Mechanical Engineering;Sony AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;Sony AI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9811621",
        "title": "Validate on Sim, Detect on Real - Model Selection for Domain Randomization",
        "track": "main",
        "status": "Poster",
        "abstract": "A practical approach to learning robot skills, often termed sim2real, is to train control policies in simulation and then deploy them on a real robot. Popular sim2real techniques build on domain randomization (DR) - training the policy on diverse randomly generated domains for better generalization to the real world. Due to the large number of hyper-parameters in both the policy learning and DR algorithms, one often ends up with a large number of trained policies, where choosing the best policy among them demands costly evaluation on the real robot. In this work we ask - can we rank the policies without running them in the real world? Our main idea is that a predefined set of real world data can be used to evaluate all policies, using out-of-distribution detection (OOD) techniques. In a sense, this approach can be seen as a \u2018unit test\u2019 to evaluate policies before any real world execution. However, we find that by itself, the OOD score can be inaccurate and very sensitive to the particular OOD method. Our main contribution is a simple-yet-effective policy score that combines OOD with an evaluation in simulation. We show that our score - VSDR - can significantly improve the accuracy of policy ranking without requiring additional real world data. We evaluate the effectiveness of VSDR on sim2real transfer in a robotic grasping task with image inputs. We extensively evaluate different DR parameters and OOD methods, and show that VSDR improves policy selection across the board. More importantly, our method achieves significantly better ranking, and uses significantly less data compared to baselines. Project website is at https://sites.google.com/view/vsdr/home",
        "primary_area": "",
        "author": "Gal Leibovich;Guy Jacob;Shadi Endrawis;Gal Novik;Aviv Tamar;Gal Leibovich;Guy Jacob;Shadi Endrawis;Gal Novik;Aviv Tamar",
        "authorids": "/37088998683;/37089000829;/37088996479;/37088997297;/37086002269;/37088998683;/37089000829;/37088996479;/37088997297;/37086002269",
        "aff": "Intel Labs; Intel Labs; Intel Labs; Intel Labs; Technion - Israel Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811621/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4092494981088571392&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Intel;Technion - Israel Institute of Technology",
        "aff_unique_dep": "Intel Labs;",
        "aff_unique_url": "https://www.intel.com;https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Intel;Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "9811993",
        "title": "Value learning from trajectory optimization and Sobolev descent: A step toward reinforcement learning with superlinear convergence properties",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent successes in deep reinforcement learning largely rely on the capabilities of generating masses of data, which in turn implies the use of a simulator. In particular, current progress in multi body dynamic simulators are under-pinning the implementation of reinforcement learning for end-to-end control of robotic systems. Yet simulators are mostly considered as black boxes while we have the knowledge to make them produce a richer information. In this paper, we are proposing to use the derivatives of the simulator to help with the convergence of the learning. For that, we combine model-based trajectory optimization to produce informative trials using 1st- and 2nd-order simulation derivatives. These locally-optimal runs give fair estimates of the value function and its derivatives, that we use to accelerate the convergence of the critics using Sobolev learning. We empirically demonstrate that the algorithm leads to a faster and more accurate estimation of the value function. The resulting value estimate is used in model-predictive controller as a proxy for shortening the preview horizon. We believe that it is also a first step toward superlinear reinforcement learning algorithm using simulation derivatives, that we need for end-to-end legged locomotion.",
        "primary_area": "",
        "author": "Amit Parag;S\u00e9bastien Kleff;L\u00e9o Saci;Nicolas Mansard;Olivier Stasse;Amit Parag;S\u00e9bastien Kleff;L\u00e9o Saci;Nicolas Mansard;Olivier Stasse",
        "authorids": "/37089449515;/37086163635;/37089449777;/37542913400;/37295476000;/37089449515;/37086163635;/37089449777;/37542913400;/37295476000",
        "aff": "LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; New York University, USA; Artificial and Natural Intelligence Toulouse Institute, France; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811993/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14665967081072823963&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "LAAS-CNRS;New York University;Artificial and Natural Intelligence Toulouse Institute",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.laas.fr/;https://www.nyu.edu;",
        "aff_unique_abbr": "LAAS-CNRS;NYU;ANITI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toulouse;",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "France;United States"
    },
    {
        "id": "9812239",
        "title": "Variable Rate Compression for Raw 3D Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel variable rate deep compression architecture that operates on raw 3D point cloud data. The majority of learning-based point cloud compression methods work on a downsampled representation of the data. Moreover, many existing techniques require training multiple networks for different compression rates to generate consolidated point clouds of varying quality. In contrast, our network is capable of explicitly processing point clouds and generating a compressed description at a comprehensive range of bitrates. Furthermore, our approach ensures that there is no loss of information as a result of the voxelization process and the density of the point cloud does not affect the encoder/decoder performance. An extensive experimental evaluation shows that our model obtains state-of-the-art results, it is computationally efficient, and it can work directly with point cloud data thus avoiding an expensive voxelized representation.",
        "primary_area": "",
        "author": "Md Ahmed Al Muzaddid;William J. Beksi;Md Ahmed Al Muzaddid;William J. Beksi",
        "authorids": "/37089449011;/37085463379;/37089449011;/37085463379",
        "aff": "Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, TX, USA; Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812239/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16021760644751059820&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Texas at Arlington",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.uta.edu",
        "aff_unique_abbr": "UTA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Arlington",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811955",
        "title": "Variable Stiffness Control via External Torque Estimation Using LSTM",
        "track": "main",
        "status": "Poster",
        "abstract": "Stable contact and safe responses to the collision have been studied to develop interactive robots such as service and collaborative robots. Stable and safe interactions are usually achieved through the inherent compliance of a motion controller with external torque estimation. However, a fixed control gain would sacrifice either compliance or position tracking performance. Additionally, external torque estimation is susceptible to model errors. In this study, a novel variable stiffness control approach is proposed to achieve a high position tracking performance in free motion and compliant behavior in the contact state. For this purpose, a precise estimation of the external torque and control gains that change based on the external torque are required. To estimate the external torque precisely, a collision detecting learning algorithm that uses long short-term memory (LSTM) is adopted. Although this method uses only proprioceptive sensors, its torque estimation capability is comparable to that of methods that use additional sensors. Then, the stiffness of a motion controller is adjusted based on the external torque in the stable region. Moreover, by adopting the Operational Space Formulation considering joint elasticity for a motion controller, high position tracking performance can be achieved with only proprioceptive sensors. The performance of the proposed method was validated through comparative experiments with two degrees of freedom (DoF) manipulator.",
        "primary_area": "",
        "author": "Jaesug Jung;Seungbin You;Donghyeon Kim;Jaeheung Park;Jaesug Jung;Seungbin You;Donghyeon Kim;Jaeheung Park",
        "authorids": "/37085674476;/37088924527;/37087324205;/37281014000;/37085674476;/37088924527;/37087324205;/37281014000",
        "aff": "Department of Intelligence and Information, Seoul National University, Seoul, South Korea; Department of Intelligence and Information, Seoul National University, Seoul, South Korea; Department of Intelligence and Information, Seoul National University, Seoul, South Korea; Advanced Institutes of Convergence Technology, Suwon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811955/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12622658752560131494&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Seoul National University;Advanced Institutes of Convergence Technology",
        "aff_unique_dep": "Department of Intelligence and Information;",
        "aff_unique_url": "https://www.snu.ac.kr;",
        "aff_unique_abbr": "SNU;",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Seoul;Suwon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9811373",
        "title": "Vision-Aided Dynamic Quadrupedal Locomotion on Discrete Terrain Using Motion Libraries",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a framework rooted in control and planning that enables quadrupedal robots to traverse challenging terrains with discrete footholds using visual feedback. Navigating discrete terrain is challenging for quadrupeds because the motion of the robot can be aperiodic, highly dynamic, and blind for the hind legs of the robot. Additionally, the robot needs to reason over both the feasible footholds as well as the base velocity in order to speed up or slow down at different parts of the discrete terrain. To address these challenges, we build an offline library of periodic gaits which span two trotting steps, and switch between different motion primitives to achieve aperiodic motions of different step lengths on a quadrupedal robot. The motion library is used to provide targets to a geometric model predictive controller which outputs the contact forces at the stance feet. To incorporate visual feedback, we use terrain mapping tools and a forward facing depth camera to build a local height map of the terrain around the robot, and extract feasible foothold locations around both the front and hind legs of the robot. Our experiments show a small scale quadruped robot navigating multiple unknown, challenging and discrete terrains in the real world.",
        "primary_area": "",
        "author": "Ayush Agrawal;Shuxiao Chen;Akshara Rai;Koushil Sreenath;Ayush Agrawal;Shuxiao Chen;Akshara Rai;Koushil Sreenath",
        "authorids": "/37086081045;/37088660463;/37085480350;/37563179200;/37086081045;/37088660463;/37085480350;/37563179200",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley; Department of Mechanical Engineering, University of California, Berkeley; Department of Mechanical Engineering, University of California, Berkeley; Department of Mechanical Engineering, University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811373/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1804795211766611878&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811368",
        "title": "Vision-Based Large-scale 3D Semantic Mapping for Autonomous Driving Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a complete pipeline for 3D semantic mapping solely based on a stereo camera system. The pipeline comprises a direct sparse visual odometry frontend as well as a back-end for global optimization including GNSS integration, and semantic 3D point cloud labeling. We propose a simple but effective temporal voting scheme which improves the quality and consistency of the 3D point labels. Qualitative and quantitative evaluations of our pipeline are performed on the KITTI-360 dataset. The results show the effectiveness of our proposed voting scheme and the capability of our pipeline for efficient large-scale 3D semantic mapping. The large-scale mapping capabilities of our pipeline is furthermore demonstrated by presenting a very large-scale semantic map covering 8000 km of roads generated from data collected by a fleet of vehicles.",
        "primary_area": "",
        "author": "Qing Cheng;Niclas Zeller;Daniel Cremers;Qing Cheng;Niclas Zeller;Daniel Cremers",
        "authorids": "/37089449104;/37085527099;/37282875300;/37089449104;/37085527099;/37282875300",
        "aff": "Artisense GmbH; Karlsruhe University of Applied Sciences; Technical University of Munich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811368/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4650256131212274188&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Artisense;Karlsruhe University of Applied Sciences;Technical University of Munich",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";https://www.hs-karlsruhe.de;https://www.tum.de",
        "aff_unique_abbr": "Artisense;HsKA;TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9812456",
        "title": "Vision-based Ascending Staircase Detection with Interpretable Classification Model for Stair Climbing Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots capable of traversing flights of stairs play an important role in both indoor and outdoor applications. The capability of accurately identifying a staircase is one of the vital technical functions in these robots. This paper presents a vision-based ascending stair detection algorithm using RGB-Depth (RGB-D) data based on an interpretable model. The method follows the four steps: 1) pre-processing of RGB images for line extraction by applying the dilatation and Canny filters followed by the probabilistic Hough line transform, 2) defining the regions of interests (ROIs) via K- mean clustering, 3) training the initial model based on a support vector machine (SVM) using three extracted features (i.e., gradient, continuity factor, and deviation cost), and 4) building an interpretable model for stair classification by determining the decision boundary conditions. The developed method was evaluated for its performance using our dataset, and the results showed 85% sensitivity and 94% specificity. When the same model was tested on a different test set, the sensitivity and specificity slightly decreased to 80% and 90%, respectively. By shifting the boundary conditions using only a small subset of the new dataset without rebuilding the model, performance was improved to 90% sensitivity and 96% specificity. The presented method is also compared with existing SVM- and neural- network- based methods.",
        "primary_area": "",
        "author": "Kangneoung Lee;Vishnu Kalyanram;Chuanqi Zhengl;Siddharth Sane;Kiju Lee;Kangneoung Lee;Vishnu Kalyanram;Chuanqi Zhengl;Siddharth Sane;Kiju Lee",
        "authorids": "/37089447733;/37089450019;/37089448316;/37089447936;/37407649700;/37089447733;/37089450019;/37089448316;/37089447936;/37407649700",
        "aff": "Department of Mechanical Engineering, Texas A&M University, College Station, Texas, USA; Department of Mechanical Engineering, Texas A&M University, College Station, Texas, USA; Department of Mechanical Engineering, Texas A&M University, College Station, Texas, USA; Department of Mechanical Engineering, Texas A&M University, College Station, Texas, USA; Department of Mechanical Engineering, Texas A&M University, College Station, Texas, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812456/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4588462527279112920&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812032",
        "title": "Visual Navigation Using Sparse Optical Flow and Time-to-Transit",
        "track": "main",
        "status": "Poster",
        "abstract": "Drawing inspiration from biology, we describe the way in which visual sensing with a monocular camera can provide a reliable signal for navigation of mobile robots. The work takes inspiration from the classic paper [3] which described a behavioral strategy pursued by diving sea birds based on a visual cue called time-to-contact. A closely related concept of time-to-transit, \\tau\\tau, is defined, and it is shown that steering laws based on monocular camera perceptions of \\tau\\tau can reliably steer a mobile vehicle. The contribution of the paper is two-fold. It provides a simple theory of robust vision-based steering control. It goes on to show how the theory guides the implementation of robust visual navigation using ROS-Gazebo simulations as well as deployment and experiments with a camera-equipped Jackal robot. As will be noted, there is an extensive literature on how animals use optical flow to guide their movements. The novelty of the work below is the introduction of the concepts of Eulerian optical flow and time-to-transit, \\tau\\tau and the demonstration that control laws based on the \\tau\\tau-values associated with an aggregated set of features in the field of view can be used to reliably steer a laboratory robot.",
        "primary_area": "",
        "author": "Chiara Boretti;Philippe Bich;Yanyu Zhang;John Baillieul;Chiara Boretti;Philippe Bich;Yanyu Zhang;John Baillieul",
        "authorids": "/37089447265;/37089446862;/37088921109;/37265825600;/37089447265;/37089446862;/37088921109;/37265825600",
        "aff": "Department of Electronics and Telecommunications (DET), Politecnico di Torino; Department of Electronics and Telecommunications (DET), Politecnico di Torino; College of Engineering at Boston University; College of Engineering at Boston University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812032/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9498916932376900233&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Politecnico di Torino;Boston University",
        "aff_unique_dep": "Department of Electronics and Telecommunications;College of Engineering",
        "aff_unique_url": "https://www.polito.it;https://www.bu.edu",
        "aff_unique_abbr": "Politecnico di Torino;BU",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Boston",
        "aff_country_unique_index": "0;0;1;1",
        "aff_country_unique": "Italy;United States"
    },
    {
        "id": "9811763",
        "title": "Visual Perception of Robot Appearance Attributes in the Peripheral Field of View Depends on Human Observer Eye-Movement Behaviors",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents results from a study on the perception of robot attributes by human observers in their peripheral field of view depending on types of eye-movements of the latter. A between-subjects design is used, where a picture of a robot head is presented on a screen in the peripheral field of view of the participants with two conditions of eye-movements: static and pursuit. The two conditions are realized by a dot to be tracked by the participants, which is placed either in the center of the screen or moving linearly between left and right screen margins. As a subjective measure for appearance attributes, anthropomorphism is used using the multi-component Human-Robot Interaction Evaluation Scale (HRIES). Significant differences are revealed in the sociability and agency sub-scales of HRIES with respect to eye-movement behaviors. The results show, that humans perceive robot appearance attributes differently depending on whether or not pursuit eye-movements are conducted supporting the main hypothesis. Further, for pursuit movements, the scale center is rated for these sub-scales, which may indicate, that the particular robot characteristic is perceived less distinctively. No significant interactions are found for animacy and disturbance, which may be due to less applicability of these sub-scales to static images. The findings may have an impact on close interaction between humans and robots and potential anthropomorphism-related influences on task accomplishment to be considered in interaction design.",
        "primary_area": "",
        "author": "Kolja K\u00fchnlenz;Barbara K\u00fchnlenz;Kolja K\u00fchnlenz;Barbara K\u00fchnlenz",
        "authorids": "/37274067900;/37086268577;/37274067900;/37086268577",
        "aff": "Department of Electrical Engineering and Computer Science, Robotics Research Lab, Coburg University of Applied Sciences and Art, Coburg, Germany; Academic Center of Sciences and Humanities, Coburg University of Applied Sciences and Arts, Coburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811763/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5225644081925722409&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Coburg University of Applied Sciences and Art;Coburg University of Applied Sciences and Arts",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;Academic Center of Sciences and Humanities",
        "aff_unique_url": "https://www.hs-coburg.de;https://www.coburg-uni.de",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Coburg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811828",
        "title": "Visual Representation Learning for Preference-Aware Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous mobile robots deployed in outdoor environments must reason about different types of terrain for both safety (e.g., prefer dirt over mud) and deployer preferences (e.g., prefer dirt path over flower beds). Most existing solutions to this preference-aware path planning problem use semantic segmentation to classify terrain types from camera images, and then ascribe costs to each type. Unfortunately, there are three key limitations of such approaches - they 1) require preenumeration of the discrete terrain types, 2) are unable to handle hybrid terrain types (e.g., grassy dirt), and 3) require expensive labelled data to train visual semantic segmentation. We introduce Visual Representation Learning for Preference-Aware Path Planning (VRL-PAP), an alternative approach that overcomes all three limitations: VRL-PAP leverages un-labelled human demonstrations of navigation to autonomously generate triplets for learning visual representations of terrain that are viewpoint invariant and encode terrain types in a continuous representation space. The learned representations are then used along with the same unlabelled human navigation demonstrations to learn a mapping from the representation space to terrain costs. At run time, VRL-PAP maps from images to representations and then representations to costs to perform preference-aware path planning. We present empirical results from challenging outdoor settings that demonstrate VRL-PAP 1) is successfully able to pick paths that reflect demonstrated preferences, 2) is comparable in execution to geometric navigation with a highly detailed manually annotated map (without requiring such annotations), 3) is able to generalize to novel terrain types with minimal additional unlabeled demonstrations.",
        "primary_area": "",
        "author": "Kavan Singh Sikand;Sadegh Rabiee;Adam Uccello;Xuesu Xiao;Garrett Warnell;Joydeep Biswas;Kavan Singh Sikand;Sadegh Rabiee;Adam Uccello;Xuesu Xiao;Garrett Warnell;Joydeep Biswas",
        "authorids": "/37089193943;/37086933532;/37089447444;/37086258082;/37079072000;/37538259200;/37089193943;/37086933532;/37089447444;/37086258082;/37079072000;/37538259200",
        "aff": "Department of Computer Science, The University of Texas at Austin, Austin, TX; Department of Computer Science, The University of Texas at Austin, Austin, TX; United States Army Research Laboratory (ARL); Department of Computer Science, The University of Texas at Austin, Austin, TX; United States Army Research Laboratory (ARL); Department of Computer Science, The University of Texas at Austin, Austin, TX",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811828/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12573414773702068737&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;1;0",
        "aff_unique_norm": "University of Texas at Austin;United States Army Research Laboratory",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.utexas.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "UT Austin;ARL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9812055",
        "title": "Visually Grounded Task and Motion Planning for Mobile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Task and motion planning (TAMP) algorithms aim to help robots achieve task-level goals, while maintaining motion-level feasibility. This paper focuses on TAMP domains that involve robot behaviors that take extended periods of time (e.g., long-distance navigation). In this paper, we develop a visual grounding approach to help robots probabilistically evaluate action feasibility, and introduce a TAMP algorithm, called GROP, that optimizes both feasibility and efficiency. We have collected a dataset that includes 96, 000 simulated trials of a robot conducting mobile manipulation tasks, and then used the dataset to learn to ground symbolic spatial relationships for action feasibility evaluation. Compared with competitive TAMP baselines, GROP exhibited a higher task-completion rate while maintaining lower or comparable action costs. In addition to these extensive experiments in simulation, GROP is fully implemented and tested on a real robot system.",
        "primary_area": "",
        "author": "Xiaohan Zhang;Yifeng Zhu;Yan Ding;Yuke Zhu;Peter Stone;Shiqi Zhang;Xiaohan Zhang;Yifeng Zhu;Yan Ding;Yuke Zhu;Peter Stone;Shiqi Zhang",
        "authorids": "/37088687363;/37088690974;/37086190662;/37086080772;/37269574900;/37086294744;/37088687363;/37088690974;/37086190662;/37086080772;/37269574900;/37086294744",
        "aff": "Department of Computer Science, The State University of New York, Binghamton; Department of Computer Science, The University of Texas, Austin; Department of Computer Science, The State University of New York, Binghamton; Department of Computer Science, The University of Texas, Austin; Sony AI; Department of Computer Science, The State University of New York, Binghamton",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812055/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11411816521404202024&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;2;0",
        "aff_unique_norm": "State University of New York at Binghamton;University of Texas at Austin;Sony",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science;Sony AI",
        "aff_unique_url": "https://www.binghamton.edu;https://www.utexas.edu;https://www.sony.com",
        "aff_unique_abbr": "SUNY Binghamton;UT Austin;Sony AI",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Binghamton;Austin;",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9812279",
        "title": "Visually Grounding Language Instruction for History-Dependent Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper emphasizes the importance of a robot's ability to refer to its task history, especially when it exe-cutes a series of pick-and-place manipulations by following language instructions given one by one. The advantage of referring to the manipulation history can be categorized into two folds: (1) the language instructions omitting details but using expressions referring to the past can be interpreted, and (2) the visual information of objects occluded by previous manipulations can be inferred. For this, we introduce a history-dependent manipulation task which objective is to visually ground a series of language instructions for proper pick-and-place manipulations by referring to the past. We also suggest a relevant dataset and model which can be a baseline, and show that our model trained with the proposed dataset can also be applied to the real world based on the CycleGAN. Our dataset and code are publicly available on the project website: https://sites.google.com/view/history-dependent-manipulation.",
        "primary_area": "",
        "author": "Hyemin Ahn;Obin Kwon;Kyungdo Kim;Jaeyeon Jeong;Howoong Jun;Hongjung Lee;Dongheui Lee;Songhwai Oh;Hyemin Ahn;Obin Kwon;Kyungdo Kim;Jaeyeon Jeong;Howoong Jun;Hongjung Lee;Dongheui Lee;Songhwai Oh",
        "authorids": "/37085492273;/37089215420;/37088686363;/37089450979;/37089447768;/37089447859;/37068725100;/37068116900;/37085492273;/37089215420;/37088686363;/37089450979;/37089447768;/37089447859;/37068725100;/37068116900",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Department of Electrical and Computer Enginnering and ASRI, Seoul National University, Seoul, Korea; Transdisciplinary Institute of Medicine & Advanced Technology, Seoul National University Hopital, Seoul, Korea; Department of Electrical and Computer Enginnering and ASRI, Seoul National University, Seoul, Korea; Graduate School of Artificial Intelligence (GSAI) and ASRI, Seoul National University, Seoul, Korea; Graduate School of Artificial Intelligence (GSAI) and ASRI, Seoul National University, Seoul, Korea; Human-centered Assistive Robotics, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Enginnering and ASRI, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812279/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=473209128168681985&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;1;1;1;3;1",
        "aff_unique_norm": "German Aerospace Center;Seoul National University;Seoul National University Hospital;Technical University of Munich",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;Department of Electrical and Computer Engineering;Transdisciplinary Institute of Medicine & Advanced Technology;Human-centered Assistive Robotics",
        "aff_unique_url": "https://www.dlr.de;https://www.snu.ac.kr;https://www.snuh.org;https://www.tum.de",
        "aff_unique_abbr": "DLR;SNU;SNUH;TUM",
        "aff_campus_unique_index": "0;1;1;1;1;1;2;1",
        "aff_campus_unique": "Wessling;Seoul;Munich",
        "aff_country_unique_index": "0;1;1;1;1;1;0;1",
        "aff_country_unique": "Germany;South Korea"
    },
    {
        "id": "9812019",
        "title": "Visuotactile-RL: Learning Multimodal Manipulation Policies with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulating objects with dexterity requires timely feedback that simultaneously leverages the senses of vision and touch. In this paper, we focus on the problem setting where both visual and tactile sensors provide pixel-level feedback for Visuotactile reinforcement learning agents. We investigate the challenges associated with multimodal learning and propose several improvements to existing RL methods; including tactile gating, tactile data augmentation, and visual degradation. When compared with visual-only and tactile-only baselines, our Visuotactile-RL agents showcase (1) significant improvements in contact-rich tasks; (2) improved robustness to visual changes (lighting/camera view) in the workspace; and (3) resilience to physical changes in the task environment (weight/friction of objects).",
        "primary_area": "",
        "author": "Johanna Hansen;Francois Hogan;Dmitriy Rivkin;David Meger;Michael Jenkin;Gregory Dudek;Johanna Hansen;Francois Hogan;Dmitriy Rivkin;David Meger;Michael Jenkin;Gregory Dudek",
        "authorids": "/37086296468;/37086455261;/37088997535;/37542891800;/37269066400;/37274057100;/37086296468;/37086455261;/37088997535;/37542891800;/37269066400;/37274057100",
        "aff": "Samsung AI Research Center Montreal, Montreal, QC, Canada; Samsung AI Research Center Montreal, Montreal, QC, Canada; Samsung AI Research Center Montreal, Montreal, QC, Canada; Samsung AI Research Center Montreal, Montreal, QC, Canada; Samsung AI Research Center Montreal, Montreal, QC, Canada; Samsung AI Research Center Montreal, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812019/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11689656578356583531&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Research",
        "aff_unique_url": "https://www.samsung.com/global/research-centers/samsung-ai-research-center-montreal/",
        "aff_unique_abbr": "SARC Montreal",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812054",
        "title": "Watch and Learn: Learning to control feedback linearizable systems from expert demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we revisit the problem of learning a stabilizing controller from a finite number of demonstrations by an expert. By focusing on feedback linearizable systems, we show how to combine expert demonstrations into a stabilizing controller, provided that demonstrations are sufficiently long and there are at least n+1n+1 of them, where nn is the number of states of the system being controlled. The results are experimentally demonstrated on a CrazyFlie 2.0 quadrotor.",
        "primary_area": "",
        "author": "Alimzhan Sultangazin;Luigi Pannocchi;Lucas Fraile;Paulo Tabuada;Alimzhan Sultangazin;Luigi Pannocchi;Lucas Fraile;Paulo Tabuada",
        "authorids": "/37086021419;/37086116670;/37088334942;/37300854400;/37086021419;/37086116670;/37088334942;/37300854400",
        "aff": "Department of Electrical and Computer Engineering, University of California, Los Angeles, USA; Department of Electrical and Computer Engineering, University of California, Los Angeles, USA; Department of Electrical and Computer Engineering, University of California, Los Angeles, USA; Department of Electrical and Computer Engineering, University of California, Los Angeles, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812054/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6321925647065085736&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811959",
        "title": "WeakLabel3D-Net: A Complete Framework for Real-Scene LiDAR Point Clouds Weakly Supervised Multi-Tasks Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing state-of-the-art 3D point clouds understanding methods only perform well in a fully supervised manner. To the best of our knowledge, there exists no unified framework which simultaneously solves the downstream high-level understanding tasks, especially when labels are extremely limited. This work presents a general and simple framework to tackle point clouds understanding when labels are limited. We propose a novel unsupervised region expansion based clustering method for generating clusters. More importantly, we innovatively propose to learn to merge the over-divided clusters based on the local low-level geometric property similarities and the learned high-level feature similarities supervised by weak labels. Hence, the true weak labels guide pseudo labels merging taking both geometric and semantic feature correlations into consideration. Finally, the self-supervised data augmentation optimization module is proposed to guide the propagation of labels among semantically similar points within a scene. Experimental Results demonstrate that our framework has the best performance among the three most important weakly supervised point clouds understanding tasks including semantic segmentation, instance segmentation, and object detection even when limited points are labeled.",
        "primary_area": "",
        "author": "Kangcheng Liu;Yuzhi Zhao;Zhi Gao;Ben M. Chen;Kangcheng Liu;Yuzhi Zhao;Zhi Gao;Ben M. Chen",
        "authorids": "/37087245508;/37087009874;/37085495662;/38520079900;/37087245508;/37087009874;/37085495662;/38520079900",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Shatin, N.T. Hong Kong, China; Department of Electronic Engineering, City University of Hong Kong, Kowloon, Hong Kong, China; School of Remote Sensing and Information Engineering, Wuhan University, Hubei, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Shatin, N.T. Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811959/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14700501193010638923&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Chinese University of Hong Kong;City University of Hong Kong;Wuhan University",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;Department of Electronic Engineering;School of Remote Sensing and Information Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.cityu.edu.hk;http://www.whu.edu.cn/",
        "aff_unique_abbr": "CUHK;CityU;WHU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Shatin;Kowloon;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9811729",
        "title": "Weakly Supervised Correspondence Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Correspondence learning is a fundamental problem in robotics, which aims to learn a mapping between state, action pairs of agents of different dynamics or embodiments. However, current correspondence learning methods either leverage strictly paired data-which are often difficult to collect-or learn in an unsupervised fashion from unpaired data using regularization techniques such as cycle-consistency-which suffer from severe misalignment issues. We propose a weakly supervised correspondence learning approach that trades off between strong supervision over strictly paired data and unsupervised learning with a regularizer over unpaired data. Our idea is to leverage two types of weak supervision: i) temporal ordering of states and actions to reduce the compounding error, and ii) paired abstractions, instead of paired data, to alleviate the misalignment problem and learn a more accurate correspondence. The two types of weak supervision are easy to access in real-world applications, which simultaneously reduces the high cost of annotating strictly paired data and improves the quality of the learned correspondence. We show the videos of the experiments on our website.",
        "primary_area": "",
        "author": "Zihan Wang;Zhangjie Cao;Yilun Hao;Dorsa Sadigh;Zihan Wang;Zhangjie Cao;Yilun Hao;Dorsa Sadigh",
        "authorids": "/37089447875;/37089504094;/37089447479;/38234464200;/37089447875;/37089504094;/37089447479;/38234464200",
        "aff": "Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811729/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6965185050438357032&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9811841",
        "title": "When Being Soft Makes You Tough: A Collision-Resilient Quadcopter Inspired by Arthropods' Exoskeletons",
        "track": "main",
        "status": "Poster",
        "abstract": "Flying robots are usually rather delicate and require protective enclosures when facing the risk of collision, while high complexity and reduced payload are recurrent problems with collision-resilient flying robots. Inspired by arthropods' exoskeletons, we design a simple, open source, easily manufactured, semi-rigid structure with soft joints that can withstand high-velocity impacts. With an exoskeleton, the protective shell becomes part of the main robot structure, thereby minimizing its loss in payload capacity. Our design is simple to build and customize using cheap components (e.g. bamboo skewers) and consumer-grade 3D printers. The result is CogniFly, a sub-250 g autonomous quadcopter that survives multiple collisions at speeds up to 7 m s\u22121. In addition to its collision-resilience, CogniFly carries sensors that allow it to fly for approx. 17 min without the need of GPS or an external motion capture system, and it has enough computing power to run deep neural network models on-board. This structure becomes an ideal platform for high-risk activities, such as flying in a cluttered environment or reinforcement learning training, by dramatically reducing the risks of damaging its own hardware or the environment. Source code, 3D files, instructions and videos are available (open source license) through the project's website: https://thecognifly.github.io.",
        "primary_area": "",
        "author": "Ricardo de Azambuja;Hassan Fouad;Yann Bouteiller;Charles Sol;Giovanni Beltrame;Ricardo de Azambuja;Hassan Fouad;Yann Bouteiller;Charles Sol;Giovanni Beltrame",
        "authorids": "/38581043300;/37089051363;/37088414940;/37089449262;/37295768000;/38581043300;/37089051363;/37088414940;/37089449262;/37295768000",
        "aff": "MISTLab, Ecole Polytechnique de Montr\u00e9al, Montr\u00e9al, Canada; MISTLab, Ecole Polytechnique de Montr\u00e9al, Montr\u00e9al, Canada; MISTLab, Ecole Polytechnique de Montr\u00e9al, Montr\u00e9al, Canada; MISTLab, Ecole Polytechnique de Montr\u00e9al, Montr\u00e9al, Canada; MISTLab, Ecole Polytechnique de Montr\u00e9al, Montr\u00e9al, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811841/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11596605003442458838&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Ecole Polytechnique de Montr\u00e9al",
        "aff_unique_dep": "MISTLab",
        "aff_unique_url": "https://www.polymtl.ca",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Montr\u00e9al",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9812190",
        "title": "Where to Look Next: Learning Viewpoint Recommendations for Informative Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Search missions require motion planning and navigation methods for information gathering that continuously replan based on new observations of the robot's surroundings. Current methods for information gathering, such as Monte Carlo Tree Search, are capable of reasoning over long horizons, but they are computationally expensive. An alternative for fast online execution is to train, offline, an information gathering policy, which indirectly reasons about the information value of new observations. However, these policies lack safety guarantees and do not account for the robot dynamics. To overcome these limitations we train an information-aware policy via deep reinforcement learning, that guides a receding-horizon trajectory optimization planner. In particular, the policy continuously recommends a reference viewpoint to the local planner, such that the resulting dynamically feasible and collision-free trajectories lead to observations that maximize the information gain and reduce the uncertainty about the environment. In simulation tests in previously unseen environments, our method consistently outperforms greedy next-best-view policies and achieves competitive performance compared to Monte Carlo Tree Search, in terms of information gains and coverage time, with a reduction in execution time by three orders of magnitude.",
        "primary_area": "",
        "author": "Max Lodel;Bruno Brito;\u00c1lvaro Serra-G\u00f3mez;Laura Ferranti;Robert Babu\u0161ka;Javier Alonso-Mora;Max Lodel;Bruno Brito;\u00c1lvaro Serra-G\u00f3mez;Laura Ferranti;Robert Babu\u0161ka;Javier Alonso-Mora",
        "authorids": "/37089449195;/37086963867;/37088691504;/37085778570;/37270682600;/38271697300;/37089449195;/37086963867;/37088691504;/37085778570;/37270682600;/38271697300",
        "aff": "Department of Cognitive Robotics (CoR), Delft University of Technology, Delft, The Netherlands; Department of Cognitive Robotics (CoR), Delft University of Technology, Delft, The Netherlands; Department of Cognitive Robotics (CoR), Delft University of Technology, Delft, The Netherlands; Department of Cognitive Robotics (CoR), Delft University of Technology, Delft, The Netherlands; CIIRC, Czech Technical University in Prague, Czech Republic; Department of Cognitive Robotics (CoR), Delft University of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9812190/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15950078466672094&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Delft University of Technology;Czech Technical University in Prague",
        "aff_unique_dep": "Department of Cognitive Robotics (CoR);CIIRC",
        "aff_unique_url": "https://www.tudelft.nl;https://www.ciirc.cvut.cz/",
        "aff_unique_abbr": "TUDelft;CTU",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Delft;Prague",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Netherlands;Czech Republic"
    },
    {
        "id": "9811616",
        "title": "Whole-Body Control of Series-Parallel Hybrid Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Parallel mechanisms are becoming increasingly popular as subsystems in various robots due to their superior stiffness, payload-to-weight ratio, and dynamic properties. The serial connection of parallel subsystems leads to series-parallel hybrid robots, which are more difficult to model and control than serial or tree-type systems. At the same time, Whole-Body Control (WBC) has become the method of choice in the control of robots with redundant degrees of freedom, e.g., legged robots. However, most state-of-the-art WBC frameworks can only deal with serial or tree-type robot topologies. In this paper, we describe a computationally efficient framework for Whole-Body Control of series-parallel hybrid robots subjected to a large number of holonomic constraints. In contrast to existing WBC frameworks, our approach describes the optimization problem in the actuation space of a series-parallel robot, which provides better exploitation of the feasible workspace, higher accuracy, and more transparent behavior near singularities. We evaluate the proposed framework on two different humanoids with series-parallel architecture and compare its performance to a WBC approach for tree-type robots.",
        "primary_area": "",
        "author": "Dennis Mronga;Shivesh Kumar;Frank Kirchner;Dennis Mronga;Shivesh Kumar;Frank Kirchner",
        "authorids": "/37592491000;/37085850436;/37283559600;/37592491000;/37085850436;/37283559600",
        "aff": "Robotics Innovation Center of German Research Center for Artificial Intelligence GmbH (DFKI), Bremen, Germany; Robotics Innovation Center of German Research Center for Artificial Intelligence GmbH (DFKI), Bremen, Germany; Robotics Group, University of Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811616/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8547543592343486605&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "German Research Center for Artificial Intelligence GmbH (DFKI);University of Bremen",
        "aff_unique_dep": "Robotics Innovation Center;Robotics Group",
        "aff_unique_url": "https://www.dFKI.de;https://www.uni-bremen.de",
        "aff_unique_abbr": "DFKI;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9811536",
        "title": "Whole-Body MPC and Dynamic Occlusion Avoidance: A Maximum Likelihood Visibility Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a novel approach for whole-body motion planning and dynamic occlusion avoidance. The proposed approach reformulates the visibility constraint as a likelihood maximization of visibility probability. In this formulation, we augment the primary cost function of a whole-body model predictive control scheme through a relaxed log barrier function yielding a relaxed log-likelihood maximization formulation of visibility probability. The visibility probability is computed through a probabilistic shadow field that quantifies point light source occlusions. We provide the necessary algorithms to obtain such a field for both 2D and 3D cases. We demonstrate 2D implementations of this field in simulation and 3D implementations through real-time hardware experiments. We show that due to the linear complexity of our shadow field algorithm to the map size, we can achieve high update rates, which facilitates onboard execution on mobile platforms with limited computational power. Lastly, we evaluate the performance of the proposed MPC reformulation in simulation for a quadrupedal mobile manipulator.",
        "primary_area": "",
        "author": "Ibrahim Ibrahim;Farbod Farshidian;Jan Preisig;Perry Franklin;Paolo Rocco;Marco Hutter;Ibrahim Ibrahim;Farbod Farshidian;Jan Preisig;Perry Franklin;Paolo Rocco;Marco Hutter",
        "authorids": "/462226664395243;/37085428006;/37088732699;/37089447273;/37274178600;/37545251000;/462226664395243;/37085428006;/37088732699;/37089447273;/37274178600;/37545251000",
        "aff": "Robotic Systems Lab ETH, Z\u00fcrich; Robotic Systems Lab ETH, Z\u00fcrich; Robotic Systems Lab ETH, Z\u00fcrich; Robotic Systems Lab ETH, Z\u00fcrich; MERLIN, Politecnico di Milano.; Robotic Systems Lab ETH, Z\u00fcrich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811536/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6941484260118255775&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "ETH Zurich;Politecnico di Milano",
        "aff_unique_dep": "Robotic Systems Lab;",
        "aff_unique_url": "https://www.ethz.ch;https://www.polimi.it/",
        "aff_unique_abbr": "ETH;Polimi",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich;",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Switzerland;Italy"
    },
    {
        "id": "9811727",
        "title": "dSEDA: a Differential Series Elastic Damped Actuator",
        "track": "main",
        "status": "Poster",
        "abstract": "Compliant actuation bestows robots with the ability to cope with unstructured environments, move with agility, and interact safely with humans at the expense of reduced tracking accuracy. The inclusion of dampening components aims to reduce oscillatory dynamics and partially restore precision without sacrificing the previously obtained characteristics. This paper introduces the concept and design of a novel damped compliant actuator suitable for building multi-degree of freedom systems. The proposed unit has a unique actuator topology that has never been seen before in the literature. The gearbox is used as a differential component, allowing the design of compact units without giving up safety and accuracy enhancements. We present and analyze the actuator's model and experimentally characterize the actuator prototype and the elastic and damping component.",
        "primary_area": "",
        "author": "Simone Monteleone;Francesca Negrello;Giorgio Grioli;Manuel G. Catalano;Simone Monteleone;Francesca Negrello;Giorgio Grioli;Manuel G. Catalano",
        "authorids": "/37088353884;/37085388304;/37590311700;/37544547800;/37088353884;/37085388304;/37590311700;/37544547800",
        "aff": "Research Center \u201cFondazione Istituto Italiano di Tecnologia\u201d; Research Center \u201cFondazione Istituto Italiano di Tecnologia\u201d; Research Center \u201cFondazione Istituto Italiano di Tecnologia\u201d; Research Center \u201cFondazione Istituto Italiano di Tecnologia\u201d",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811727/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12205716042852148311&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Fondazione Istituto Italiano di Tecnologia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9811903",
        "title": "f-Cal: Aleatoric uncertainty quantification for robot perception via calibrated neural regression",
        "track": "main",
        "status": "Poster",
        "abstract": "While modern deep neural networks are performant perception modules, performance (accuracy) alone is insufficient, particularly for safety-critical robotic applications such as self-driving vehicles. Robot autonomy stacks also require these otherwise blackbox models to produce reliable and calibrated measures of confidence on their predictions. Existing approaches estimate uncertainty from these neural network perception stacks by modifying network architectures, inference procedure, or loss functions. However, in general, these methods lack calibration, meaning that the predictive uncertainties do not faithfully represent the true underlying uncertainties (process noise). Our key insight is that calibration is only achieved by imposing constraints across multiple examples, such as those in a mini-batch; as opposed to existing approaches which only impose constraints per-sample, often leading to overconfident (thus miscalibrated) uncertainty estimates. By enforcing the distribution of outputs of a neural network to resemble a target distribution by minimizing an ff -divergence, we obtain significantly better-calibrated models compared to prior approaches. Our approach, f-Cal, outperforms existing uncertainty calibration approaches on robot perception tasks such as object detection and monocular depth estimation over multiple real-world benchmarks.",
        "primary_area": "",
        "author": "Dhaivat Bhatt;Kaustubh Mani;Dishank Bansal;Krishna Murthy;Hanju Lee;Liam Paull;Dhaivat Bhatt;Kaustubh Mani;Dishank Bansal;Krishna Murthy;Hanju Lee;Liam Paull",
        "authorids": "/37086310106;/37086153849;/37089449653;/37086947002;/37087013964;/37935956000;/37086310106;/37086153849;/37089449653;/37086947002;/37087013964;/37935956000",
        "aff": "Montreal Robotics and Embodied AI Lab, Mila, Universite de Montreal; Montreal Robotics and Embodied AI Lab, Mila, Universite de Montreal; Montreal Robotics and Embodied AI Lab, Mila, Universite de Montreal; Montreal Robotics and Embodied AI Lab, Mila, Universite de Montreal; DENSO CORP.; Montreal Robotics and Embodied AI Lab, Mila, Universite de Montreal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811903/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=396443933023365130&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Universite de Montreal;DENSO Corporation",
        "aff_unique_dep": "Montreal Robotics and Embodied AI Lab;",
        "aff_unique_url": "https://www.mila.quebec;https://www.denso.com",
        "aff_unique_abbr": "Mila;DENSO",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Montreal;",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Canada;Japan"
    },
    {
        "id": "9811845",
        "title": "\u201cThe World Is Its Own Best Model\u201d: Robust Real-World Manipulation Through Online Behavior Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic manipulation behavior should be robust to disturbances that violate high-level task-structure. Such robustness can be achieved by constantly monitoring the environment to observe the discrete high-level state of the task. This is possible because different phases of a task are characterized by different sensor patterns and by monitoring these patterns a robot can decide which controllers to execute in the moment. This relaxes assumptions about the temporal sequence of those controllers and makes behavior robust to unforeseen disturbances. We implement this idea as probabilistic filter over discrete states where each state is direcly associated with a controller. Based on this framework we present a robotic system that is able to open a drawer and grasp tennis balls from it in a surprisingly robust way.",
        "primary_area": "",
        "author": "Manuel Baum;Oliver Brock;Manuel Baum;Oliver Brock",
        "authorids": "/37085674996;/37279727100;/37085674996;/37279727100",
        "aff": "Science of Intelligence (SCIoI), Cluster of Excellence, Berlin, Germany; Science of Intelligence (SCIoI), Cluster of Excellence, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9811845/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15881020765340593042&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Science of Intelligence",
        "aff_unique_dep": "Cluster of Excellence",
        "aff_unique_url": "",
        "aff_unique_abbr": "SCIoI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    }
]